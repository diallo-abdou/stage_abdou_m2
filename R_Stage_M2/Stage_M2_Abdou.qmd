---
title: "Internship progress"
author: "Abdourahmane Diallo"
date: '`r Sys.Date()`'
format: 
  revealjs
#smaller: true
scrollable: true
#theme: sky
editor: visual
number-sections: true
toc: FALSE
#toc-expand: false
#toc_float: 'yes'
code_download: 'yes'
slide-number: true
margin: 0.1
#center: true
code-fold: true
width: 1300
height: 700
toc_depth: 1
execute: 
  cache: true
---

# Setting

```{r setup, include=FALSE,fig.align='center',message=FALSE,warning=FALSE,message=FALSE,echo=TRUE}
# rm(list=ls()) # Properly clear workspace
# source("function_abdou.R")

```

## Packages

```{r packages,echo=TRUE}
  library(tidyverse)
  library(glme)
  library(lsmeans)
  library(agricolae)
  library(RVAideMemoire)
  library(corrplot)
  library(emmeans)
  library(lme4)
  library(multcomp)
  library(MASS)
  library(R2WinBUGS)
  library(arm)
  library(performance)
  library(AER)
  library(AICcmodavg)
  library(MuMIn)
  library(ade4)
  library(Hmisc)
  library(labdsv)
  library(vegan)
  library(cowplot)
  library(ggpubr)
  library(rstatix)
  library(patchwork)
  library(multcompView)
  library(ggsignif)
  library(grid)
  library(FactoMineR)
  library(factoextra)
  library(explore)
  library(ggrepel)
  library(naniar)
  library(outliers)
  library(leaps)
  library(fastDummies)
  library(caret) # pour l'entrainement des models
  library(mgcv)
  library(ggeffects)
  library(gratia)
  library(GGally)
  library(caTools)
  library(rpart)
  library(rpart.plot)
  library(openxlsx)
  library(readxl)
  library(leaflet)
  library(quarto)
  library(raster)
  library(knitr)
  library(kableExtra)
  library(stringr)
  library(plotly)
  library(PerformanceAnalytics)
  library(usdm)
  library(vcd) # pour la distribution des var reponse
  library(prospectr)# pour split data avec kenSton()
  library(glmnet)
  library(randomForest)
  library(doParallel)
  library(gbm)
  library(kernlab)
  library(e1071)
  library(ggforce)
  library(keras)
  library(tensorflow)
  library(neuralnet)
  library(parallel)
  library(iml) # pour l'interpretabilité des models https://cran.r-project.org/web/packages/iml/vignettes/intro.html
  library(e1071)
  library(stats)



```

## Functions

```{r fonction, echo=TRUE}

## Identification des NA dans un df -----------------------------------------------
taux_completion<-
  function(df, afficher_zero_percent = FALSE, seuil, trie=FALSE) {
    # Calcule du pourcentage de NA dans le dataframe
    pourcentage_total <-
      round(sum(is.na(df)) / (nrow(df) * ncol(df)) * 100, 1)
    
    # Calcule du pourcentage de NA par colonne
    pourcentage_colonnes <- round(colMeans(is.na(df)) * 100, 1)
    
    # Creation d'un dataframe résultat avec deux colonnes
    result <-
      data.frame(
        Variables = names(df),
        CR = pourcentage_colonnes,
        row.names = NULL
      )
    
    if (afficher_zero_percent) {
      result <- result[result$CR == 0, ]
      result$CR = 100 -result$CR
    } else {
      result <- result[result$CR > 0, ]
      result$CR = 100 -result$CR
      
    }
    
    result <- rbind(result, c("Total", pourcentage_total))
    #result <- rbind(result, c("Total", paste0(pourcentage_total, "")))
    
    result <- result[, c("Variables", "CR")]
    result$CR = as.numeric(result$CR)
    result$CR = round(result$CR,1)
    if (trie){
      result = result %>% arrange(desc(CR))
    }
    result$CR = paste0(result$CR,"%")
    
    return(result)
  }
# Converssion des colonne en num ou factor-----------------------------------------------
conv_col <- function (data, columns_to_convert, to_types) {
  if (to_types == "numeric") {
    # Conversion des colonnes en numeric
    for (col in columns_to_convert) {
      data[, col] <- as.numeric(data[, col])
    }
  } else {
    # Conversion des colonnes en facteurs
    for (col in columns_to_convert) {
      data[, col] <- as.factor(data[, col])
    }
  }
  return(data)
}
#data_converted <- conv_col(data, names(data [, c(1, 3)]), "factor")

# exploration graphiques des variables numeriques -----------------------------------------------
explo_num <- function(nom_col, titre, df = bdd, ligne_col = c(2, 2),mini = min(df[[nom_col]]), maxi=max(df[[nom_col]]) ) {
  par(mfrow = ligne_col)
  
  df[complete.cases(df[[nom_col]]), ]
  df <- df %>%filter(!is.na(df[[nom_col]]))
  df[[nom_col]] = as.numeric(df[[nom_col]])
  # Boxplot
  boxplot(df[[nom_col]], col = 'blue', ylab = titre, ylim = c(mini, maxi))
  # Cleveland plot
  dotchart(df[[nom_col]], pch = 16, col = 'blue', xlab = titre)
  # Histogram
  hist(df[[nom_col]], col = 'blue', xlab = titre, main = "")
  # Quantile-Quantile plot
  qqnorm(df[[nom_col]], pch = 16, col = 'blue', xlab = '')
  qqline(df[[nom_col]], col = 'red') 
}

# Extraction des predictors + moyennes -----------------------------------------------

extraction <- function(nom_col, tif_file_path, df = bdd, conv = 1) {
  #df <- df %>%filter(!is.na(gps_x) & !is.na(gps_y))
  raster_data <- raster(tif_file_path)
  
  # Création d'un dataframe pour stocker les valeurs extraites
  df_interne <- data.frame(gps_x = df$gps_x, gps_y = df$gps_y)
  proj4Str <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
  # Transformer les coordonnées GPS en système de coordonnées du raster
  gps_coords_sp <- SpatialPoints(df_interne, proj4string = CRS(proj4Str))
  gps_coords_proj <- spTransform(gps_coords_sp, crs(raster_data))
  
  # Extraction des valeurs du raster 
  values <- raster::extract(raster_data, gps_coords_proj)
  
  # Ajout des valeurs extraites comme nouvelles colonnes a df
  #df_save = data.frame()
  #df_save[[nom_col]] <- values / conv
  
  df[[nom_col]] <- values / conv
  
  return(df)
}

# la moyenne des predictores -----------------------------------------------
moyenne_val_extrct <- function(nom_col, vec_col, df=bdd) {
  df[[nom_col]] <- rowMeans(as.matrix(df[, vec_col, drop = FALSE]), na.rm = TRUE)
  df[[nom_col]] = round(df[[nom_col]],1)
  return(as.data.frame(df))
}


# tests de corrélation avec un seuil -----------------------------------------------
cor_function_seuil <- function(data, seuil,affiche=FALSE) {
  # Création d'un vecteur pour stocker les paires de variables corrélées
  variables_corr <- c()
  
  # Boucle pour tester la corrélation entre chaque paire de variables
  for (i in 1:(ncol(data) - 1)) {
    for (j in (i + 1):ncol(data)) {
      # Calcul de la corrélation entre les variables i et j
      cor_value <- stats::cor(data[, i], data[, j], use = "na.or.complete")
      
      # Stockage du résultat dans le vecteur si supérieur au seuil
      if (cor_value >= seuil | cor_value <= -seuil) {
        if(affiche){
        cat(
          "***",
          colnames(data)[i],
          "  __est correlee a__  ",
          colnames(data)[j],
          "avec un R =",
          cor_value,
          "\n \n \n"
        )
      }
        
        variables_corr <-
          c(variables_corr, colnames(data)[i], colnames(data)[j])
      }
    }
  }
  
  return(variables_corr)
}


# tests de valeurs aberant -----------------------------------------------
test_grub <- function(data, variable, direction = "maxi") {
  
  if (direction == "maxi") { 
    repeat {
      # Effectuer le test de Grubbs
      test_aberrant <- grubbs.test(data[[variable]], opposite = FALSE)
      
      # Obtenir la p-valeur du test
      p.value <- test_aberrant$p.value
      # Si la p-valeur est inférieure au seuil de 0.05, on supprime la valeur aberrante
      if (p.value < 0.05) {
        max_value <- max(data[[variable]],na.rm=TRUE)
        data <- subset(data, data[[variable]] != max_value | is.na(data[[variable]]))
      } else {
        # S'il n'y a plus de valeurs aberrantes, sortir de la boucle
        break
      }
    }
  }
  
  
  if (direction == "mini") { 
    repeat {
      test_aberrant <- grubbs.test(data[[variable]], opposite = TRUE)
      # Obtenir la p-valeur du test
      p.value <- test_aberrant$p.value
      # Si la p-valeur est inférieure au seuil de 0.05, on supprime la valeur aberrante
      if (p.value < 0.05) {
        min_value <- min(data[[variable]],na.rm=TRUE)
        data <- subset(data, data[[variable]] != min_value | is.na(data[[variable]]))
      } else {
        # S'il n'y a plus de valeurs aberrantes, sortir de la boucle
        break
      }
    }
  }
  
  
  return(data)
}




# boxplote -----------------------------------------------
plot_boxplot <-function(donnee,
           x_col,y_col,x_label,y_label,title,legend_title,
           couleurs,
           affiche_point = TRUE,
           ymin = min(donnee[[y_col]]),
           ymax = 1.2 * max(donnee[[y_col]])) {
    
  graphe <-ggplot(donnee,
             aes_string(
               x = x_col,
               y = y_col,
               colour = x_col
             )) +
  geom_boxplot(
        outlier.shape = NA,
        outlier.colour = "black",
        alpha = 0.20,
        size = 1.5 
      ) +
  labs(title = title,x = x_label,y = y_label) +
  scale_color_manual(values = couleurs, name = legend_title) +
  theme_classic(base_size = 12, base_family = "Arial") +
  theme(axis.text = element_text(size = 10),
        axis.title.y = element_text(
          vjust = 5, size = 12, face = "bold"),
        axis.title.x = element_text(face = "bold"),
        axis.ticks.length = unit(0.2, "cm"),
        legend.position = "none",  # Cette ligne supprime la lÃ©gende
        #legend.position = "right",
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12, face = "bold"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title = element_text(size = 14, face = "bold"),
        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm")
      )
    if (affiche_point) {
      graphe <-
        graphe + geom_jitter(position = position_jitter(seed = 0.5), size = 0.8)
    }
    
    if (y_col %in% names(donnee)) {
      graphe <- graphe +
        coord_cartesian(ylim = c(ymin, ymax))
    }
  
    graphe = graphe + stat_summary(
      fun.y = mean,
      geom = "point",
      shape = 15,
      size = 1.5,
      col = "black",
      fill = "black"
    )
    
    return(graphe)
}



#pour le  pairwise.t.test() -----------------------------------------------------
tri.to.squ <- function(x) {
  rn <- row.names(x)
  cn <- colnames(x)
  an <- unique(c(cn, rn))
  myval <- x[!is.na(x)]
  mymat <-
    matrix(
      1,
      nrow = length(an),
      ncol = length(an),
      dimnames = list(an, an)
    )
  for (ext in 1:length(cn))
  {
    for (int in 1:length(rn))
    {
      if (is.na(x[row.names(x) == rn[int], colnames(x) == cn[ext]]))
        next
      mymat[row.names(mymat) == rn[int], colnames(mymat) == cn[ext]] <-
        x[row.names(x) == rn[int], colnames(x) == cn[ext]]
      mymat[row.names(mymat) == cn[ext], colnames(mymat) == rn[int]] <-
        x[row.names(x) == rn[int], colnames(x) == cn[ext]]
    }
  }
  return(mymat)
}



# Selection interaction -------------------------------
select_inter <- function(response_var, df, explanatory_vars) {
  results <- data.frame()
  combinations <- combn(explanatory_vars, 2, simplify = FALSE)

  for(i in seq_along(combinations)) {

    formula <- as.formula(paste(response_var, "~", paste(combinations[[i]], collapse = "*")))
    model <- gam(formula, data = df)
    r_squared <- summary(model)$r.sq
    aic <- AIC(model)
    results <- rbind(results, data.frame("variables" = paste0(combinations[[i]], collapse = ".inter."), 
                                         "r_squared" = r_squared, 
                                 "aic" = aic))
  }
  return(results)
}

# Comparaion betwen predtited and observed -----------------------------------
plot_comp = function (df,ylabel, title_class, legende = TRUE,plotly = FALSE,xlabel = "observations",title=""){ 

  
  p = ggplot(df, aes(x = observation)) + 
  #graph representant observed
  geom_point(aes(y = Observed, color = "Real values")) +
  geom_line(aes(y = Observed, color = "Real values")) + 
  
  #graph representant  preticted
  geom_point(aes(y = Predicted, color="Predicted values")) +
  geom_line(aes(y = Predicted, color="Predicted values")) + 
  # ggtitle(title)
  theme(plot.title = element_text(hjust = 0.5)) + 
  labs(title = title,x=xlabel, y=ylabel, color = "Legend :") + 
  ylim(min(c(min(df$Predicted), min(df$Observed))),
            max(c(max(df$Predicted), max(df$Observed)))+1  ) +
    
  scale_color_manual(values = c("Real values"='red', "Predicted values"='green')) +
  annotate("text", x = 8, y =  max(c(max(df$Predicted), max(df$Observed)))+1, 
           label = title_class, col = "black", size = 3)

  
  if (!legende) {
    p <- p + theme(legend.position = "none")
  }
  
  if(plotly){
    p = ggplotly(p)
  }

return (p)

}


# Calcul R²
calcule_R2 = function(x, y) {cor(x, y)^2}

```

## Plan

-   Database exploration

-   Earthworms data

-   Soil data extraction

-   Climate data extraction

-   Exploratory analysis

-   Importance of variables

-   Predictive modeling

-   Results 

-   Conclusion


# Database import

-   Import of database **LandWorm_dataset_site_V1.9.xlsx** (february 22, 2024)

```{r import,echo=FALSE}
chemin_fichier_excel = "C:/Users/diall/Downloads/datas/LandWorm_dataset_site_V1.9.xlsx"
bdd <- read.xlsx(chemin_fichier_excel, sheet = "Sheet1")
```

-   The database contains **`r nrow(bdd)`** rows and **`r ncol(bdd)`** columns

```{r conversion,echo=FALSE}
col_en_factor = c("Programme","Annee","ID_Site","Code_Parcelle","postal_code","clcm_lvl1",
                  "clcm_lvl2","clcm_lvl3","Modalite","Bloc","Protocole","land_cover_detail","type_tillage","fertilisation","ferti_min_product","ferti_orga_product")
bdd = conv_col(bdd, col_en_factor, "factor")
```

## Data selection: EcoBioSoil

```{r selection dc1,echo=FALSE}
n_line=nrow(bdd)
bdd$owner=as.factor(bdd$owner)
summary_df <- as.data.frame(summary(bdd$owner))
colnames(summary_df) <- c("Numbers")
kable(summary_df)
```

```{r selection dc2,echo=FALSE}
bdd <- subset(bdd, owner == "dc")
bdd$owner=droplevels(bdd$owner)

```

-   The database therefore changes from **`r n_line`** to **`r nrow(bdd)`** observations.

# Database exploration

-   CR = Completion rate

## Complete columns

```{r Complete columns, echo=TRUE}
df_col=taux_completion(bdd,TRUE,trie=FALSE)
df_col = df_col[df_col$Variables != "Total",]
#print("table")
kable(df_col, caption = "", col.width = c("75%", "25%"))
# cat(                                                    )
# head(bdd[, "ID"])
```

## Non-complete columns

```{r Non-complete columns, scrollable = TRUE}
df_col= taux_completion(bdd,FALSE,trie = TRUE)
df_col = df_col[df_col$Variables != "Total",]
kable(df_col, caption = " ", col.width = c("75%", "25%"))
```

## Focus on GPS coordinates

-   There is **`r sum(is.na(bdd$gps_x))`** NA (CR = `r df_col[df_col$Variable=="gps_x", "CR"]`) in **GPS_X**
-   There is **`r sum(is.na(bdd$gps_y))`** NA (CR = `r df_col[df_col$Variable=="gps_y", "CR"]`) in **GPS_Y**

```{r GPS,echo=TRUE}
n_line= nrow(bdd)
bdd$gps_x <- as.numeric(gsub("[^0-9.-]", "", bdd$gps_x))
bdd$gps_y <- as.numeric(gsub("[^0-9.-]", "", bdd$gps_y))
bdd <- bdd[complete.cases(bdd$gps_x, bdd$gps_y), ]
bdd <- bdd %>%filter(!is.na(gps_x) & !is.na(gps_y))
#sum(is.na(bdd$gps_x))
#sum(is.na(bdd$gps_y))
```

-   We delete the *NA* lines in the GPS coordinates
-   The database therefore changes from **`r n_line`** to **`r nrow(bdd)`** observations.
-   Merging database and climat database

```{r mergins & climat, echo=TRUE}
# Ajout variables climatiques (voir chunk extraction données climatiques)
chemin_fichier <- "C:/Users/diall/OneDrive/Bureau/M2_MODE/stage_abdou_m2/datas/bdd_climat_ok.rds"
# saveRDS(bdd_climat_ok, chemin_fichier)
bdd_climat_ok <- readRDS(chemin_fichier)
df_fusion <- subset(bdd_climat_ok, select = -c(gps_x, gps_y))

rows_not_in_df_fusion <- anti_join(bdd, df_fusion, by = "ID")
merged_df <- merge(bdd, df_fusion, by = "ID")

ids_not_matching <- anti_join( merged_df,bdd, by = "ID")

bdd = merged_df

#bdd <- cbind(bdd, df_fusion) # all = TRUE pour garder toutes les lignes
```

## Cartography

```{r Cartography,echo=TRUE}
n_ligne= nrow(bdd)
df_coord <- bdd[, c("gps_x", "gps_y")] %>% mutate(gps_x = as.numeric(gps_x),gps_y = as.numeric(gps_y))

df_coord$num_ligne <- seq(nrow(df_coord))
carte <- leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~gps_x, lat = ~gps_y, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")
carte
```

```{r outside France}
hors_france= read.csv(file = "C:/Users/diall/Downloads/datas/hors_france.csv", header = TRUE)

bdd <- bdd[!(bdd$gps_x %in% hors_france$gps_x & bdd$gps_y %in% hors_france$gps_y), ]
bdd <- droplevels(bdd)
```

-   We delete points outside France (**`r nrow(hors_france)`**)
-   The database therefore changes from **`r n_ligne`** to **`r nrow(bdd)`** observations.

## Focus on years

-   Cleaning the Annee column 
<br/> 
<!--
```{r years1, echo=TRUE}
# levels(bdd$Annee) # parfois années et jours et ou mois
# bdd$Annee= as.factor(bdd$Annee)
# bdd$Annee <- gsub("^(\\d{4}).*$", "\\1", bdd$Annee) # on prend uniquement les 04 premier chiffre
# bdd$Annee= as.factor(bdd$Annee)

```
-->

-   CR of Annee = **`r df_col[df_col$Variable=="Annee", "CR"]`** (`r length(levels(bdd$Annee))` levels)

```{r years2, echo=TRUE, scrollable = TRUE}
bdd$Annee= as.factor(bdd$Annee)
summary_df <- as.data.frame(summary(bdd$Annee))
colnames(summary_df) <- c("Numbers")
kable(summary_df)
```


<!-- 
-   We remove all the years before **1990** and the NA 

```{r years3, echo=TRUE, scrollable = TRUE}
n_ligne =nrow(bdd)
bdd <- bdd %>%filter(!is.na(Annee))# on enleve les NA
annes_omit= c("1821", "1960", "1978", "1982", "1983", "1984", "1986", "1988", "1989") # annee sup
bdd <- bdd[!bdd$Annee %in% annes_omit, ]
bdd=droplevels(bdd)
#levels (bdd$Annee)
#summary (bdd$Annee)
summary_df <- as.data.frame(summary(bdd$Annee))
colnames(summary_df) <- c("Numbers")
kable(summary_df,padding = 5)
```

-   The database therefore changes from **`r n_ligne`** to **`r nrow(bdd)`** observations. 
-->



<!--
## Table land use & protocol ( start )

-   clcm_lvl1 & protocol

```{r clcm_lvl1 & protocol, echo=TRUE}
kable(table(bdd$clcm_lvl1, bdd$Protocole,exclude = NULL),padding = 10,align = "c")

```

\n\n\n

-   clcm_lvl2 & protocol

```{r clcm_lvl2 & protocol, echo=TRUE}
kable(table(bdd$clcm_lvl2, bdd$Protocole,exclude = NULL),padding = 10,align = "c")
```

\n\n\n

-   clcm_lvl3 & protocol

```{r clcm_lvl3 & protocol, echo=TRUE}
kable(table(bdd$clcm_lvl3, bdd$Protocole,exclude = NULL),padding = 0,align = "c")
```
-->


## Focus on protocols

-   List of protocols available on the database ( `r length(levels(bdd$Protocole))` levels)

```{r protocols,echo=TRUE}
bdd$Protocole = as.factor(bdd$Protocole)
summary_df <- as.data.frame(summary(bdd$Protocole))
colnames(summary_df) <- c("Numbers")
kable(summary_df,padding = 5)
```


<!--
-   Selection of protocols: **F_HS, FHS, hand sorting, HS**
-->

-   Selection of protocols: **F_HS, HS**

```{r select protocols,echo=TRUE}
n_ligne = nrow(bdd)
#select_protocole =c("F_HS", "FHS", "hand sorting" ,"HS")
select_protocole =c("F_HS", "HS")
bdd <- bdd[bdd$Protocole %in% select_protocole, ]
bdd=droplevels(bdd)
bdd$Protocole = as.factor(bdd$Protocole)
summary_df <- as.data.frame(summary(bdd$Protocole))
colnames(summary_df) <- c("Numbers")
kable(summary_df,padding = 5)
```

-   The database therefore changes from **`r n_ligne`** to **`r nrow(bdd)`** observations.


<!--
-   Merging levels :

    -   F_HS $=$ F_HS $+$ FHS
    -   HS $=$ HS $+$ hand sorting

    ```{r merging protocols,echo=TRUE}
    levels(bdd$Protocole)[levels(bdd$Protocole) == "FHS"] <- "F_HS"
    levels(bdd$Protocole)[levels(bdd$Protocole) == "hand sorting"] <- "HS"
    bdd$Protocole = as.factor(bdd$Protocole)
    summary_df <- as.data.frame(summary(bdd$Protocole))
    colnames(summary_df) <- c("Numbers")
    kable(summary_df,padding = 5)
    ```
-->

## Focus on clcm_lvl1

-   CR of clcm_lvl1 = **`r df_col[df_col$Variable=="clcm_lvl1","CR"]`** (`r length(levels(bdd$clcm_lvl1))` levels)

```{r clcm_lvl1, echo=TRUE}
bdd$clcm_lvl1= as.factor(bdd$clcm_lvl1)
summary_df <- as.data.frame(summary(bdd$clcm_lvl1))
colnames(summary_df) <- c("Numbers")
# kable(summary_df,padding = 5)
```

-   Merging levels

```{r merging clcm_lvl1, echo=TRUE}
levels(bdd$clcm_lvl1)[levels(bdd$clcm_lvl1) == "1_Naturel"] <- "Forest and semi natural areas"
levels(bdd$clcm_lvl1)[levels(bdd$clcm_lvl1) == "2_Agricole"] <- "Agricultural areas"

bdd$clcm_lvl1= as.factor(bdd$clcm_lvl1)
summary_df <- as.data.frame(summary(bdd$clcm_lvl1))
colnames(summary_df) <- c("Numbers")
kable(summary_df,padding = 5)
```

-   Update **code_clcm_lvl1**

```{r code_clcm_lvl1, echo=TRUE}
#bdd$code_clcm_lvl1 = as.factor(bdd$code_clcm_lvl1)

bdd$code_clcm_lvl1 <- ifelse(bdd$clcm_lvl1 == "Forest and semi natural areas", 3, bdd$code_clcm_lvl1)

bdd$code_clcm_lvl1 <- ifelse(bdd$clcm_lvl1 == "Agricultural areas", 2, bdd$code_clcm_lvl1)
```

-   For the moment, we will keep the NA of **clcm_lvl1**

## Focus on clcm_lvl2

-   CR of clcm_lvl2 = **`r df_col[df_col$Variable=="clcm_lvl2","CR"]`** (`r length(levels(bdd$clcm_lvl2))` levels)

```{r clcm_lvl2 , echo=TRUE}
bdd$clcm_lvl2= as.factor(bdd$clcm_lvl2)
summary_df <- as.data.frame(summary(bdd$clcm_lvl2))
colnames(summary_df) <- c("Numbers")
# kable(summary_df,padding = 8)
```

-   Merging levels

```{r merging clcm_lvl2, echo=TRUE}
levels(bdd$clcm_lvl2)[levels(bdd$clcm_lvl2) == "21_Agricole ouvert"] <- "Arable land"

bdd$clcm_lvl2= as.factor(bdd$clcm_lvl2)
summary_df <- as.data.frame(summary(bdd$clcm_lvl2))
colnames(summary_df) <- c("Numbers")
kable(summary_df,padding = 5)
```

-   Update **code_clcm_lvl2**

```{r code_clcm_lvl2, echo=TRUE}

bdd$code_clcm_lvl2 <- ifelse(bdd$clcm_lvl2 == "Arable land", 21, bdd$code_clcm_lvl2)

```

## Focus on clcm_lvl3

-   CR of clcm_lvl3 = **`r df_col[df_col$Variable=="clcm_lvl3","CR"]`** (`r length(levels(bdd$clcm_lvl3))` levels)

```{r clcm_lvl3, echo=TRUE, scrollable = TRUE}
bdd$clcm_lvl3= as.factor(bdd$clcm_lvl3)
summary_df <- as.data.frame(summary(bdd$clcm_lvl3))
colnames(summary_df) <- c("Numbers")
kable(summary_df,padding = 5)

```

## Land use selection (clcm_lvl3)


<!--
-   **Broad-leaved forest** 
-   **Coniferous forest** 
-   **Mixed forest** 

-   **Pastures, meadows and other permanent grasslands under agricultural use** 

-   **Non-irrigated arable land** 

-   **Vineyards**

-   **Green urban areas**

-   **Natural grasslands**
-->

```{r select clcm_lvl3, echo=TRUE}
select_os= c("Broad-leaved forest", "Coniferous forest", "Mixed forest", 
"Pastures, meadows and other permanent grasslands under agricultural use", "Non-irrigated arable land", 
"Vineyards","Green urban areas","Natural grasslands")

bdd <- bdd[bdd$clcm_lvl3 %in% select_os, ]
bdd=droplevels(bdd)
bdd$clcm_lvl3 = as.factor(bdd$clcm_lvl3)
summary_df <- as.data.frame(summary(bdd$clcm_lvl3))
colnames(summary_df) <- c("Numbers")
kable(summary_df)

```

-   **Maybe, we can merge the three types of forest ?**

## Land use & protocol overview

```{r LU & protocol overview, echo=TRUE}
# kable (table(bdd$clcm_lvl1, bdd$Protocole,exclude = NULL), align = "c", format = "pipe", padding = 10)
# kable (table(bdd$clcm_lvl2, bdd$Protocole,exclude = NULL), align = "c", format = "pipe", padding = 10)
kable (table(bdd$clcm_lvl3, bdd$Protocole,exclude = NULL), align = "c", format = "pipe", padding = 10)
```



# Earthworms data

## Total richness calculation method

-   Removal of columns with only NA (**`r length(colnames(bdd)[colSums(is.na(bdd)) == nrow(bdd)])`**) and/or only 0
-   Identify columns beginning with **AB\_**
-   Deletion of **AB\_** columns that are not species
-   Calculate richness by assigning **1** to each column if the value is different from 0 and NA
-   Total richness = **1** if the plot has a value in AB and/or BM


```{r calcul richness, echo=FALSE}
# on supprime tout les colonnes ayant que des NA
colonnes_na <- colnames(bdd)[colSums(is.na(bdd)) == nrow(bdd)]
# summary(bdd[, colonnes_na])
bdd <- bdd[, !colnames(bdd) %in% colonnes_na]



# On supprimme toutes les colonnes ayant que des NA et des 0
colonnes_numeriques <- sapply(bdd, is.numeric)
somme_colonnes_numeriques <- colSums(bdd[, colonnes_numeriques],na.rm=TRUE)
colonnes_zeros <- names(somme_colonnes_numeriques[somme_colonnes_numeriques == 0])
#summary(bdd[, colonnes_zeros])
bdd <- bdd[, !colnames(bdd) %in% colonnes_zeros]



# On récupère toutes les colonnes qui commencent par **AB_**
colonnes_AB <- grep("^AB_", names(bdd), value = TRUE)



# On supprimme les colonnes AB_ qui ne sont pas des espèces dans le calcule
ab_supprimee =  c("AB_AD","AB_JV","AB_SA","AB_STAD_X","AB_indéterminable","AB_Indéterminable","AB_indéterminable_endogeic","AB_tot","AB_Indéterminable_epigeic","AB_indéterminable_endogeic","AB_Ep.X","AB_vide", "AB_Ep.X1","AB_Ep.X2","AB_A.X","AB_Adult","AB_cocon","AB_indéterminé","AB_Juvenile","AB_Sub.adult","AB_Indéterminé","AB_Lumbricidae")
colonnes_AB <- colonnes_AB[!colonnes_AB %in% ab_supprimee]



# On calcule la richesse en attribiant 1 à chaque colonne si la valeur est différent de 0 et de NA
bdd$Richesse_tot <- 0
bdd$Richesse_tot <- rowSums(!is.na(bdd[colonnes_AB]) & bdd[colonnes_AB] != 0)
#sum (is.na(bdd$Richesse_tot) )
#summary(bdd$Richesse_tot)



# Check des lignes ayant des 0 richesse et X AB ou BM : 0 lignes
# vdt_a_checker = bdd[bdd$Richesse_tot == 0 & (bdd$Total_AB !=0 | bdd$BM_to !=0), c("ID_Site","AB_tot","BM_tot","Richesse_tot")]
# vdt_a_checker = subset(vdt_a_checker, Richesse_tot==0)
# View(vdt_a_checker)
# vdt_a_checker$Richesse_tot <- 1
# Mettre à jour les ligne correspondant dans la bdd 
# bdd[rownames(bdd) %in% rownames(vdt_a_checker), "Richesse_tot"] <- 1



# Check si y a des ligne ayant que des NA dans AB, BM et Richesse : nop
resultat <- subset(bdd, is.na(AB_tot) & is.na(BM_tot) & is.na(Richesse_tot))
# View(resultat[, c("AB_tot","BM_tot", "Richesse_tot")])



# Check si y a des ligne ayant que des zéros ou des NA dans AB, BM et Richesse_tot: 66 ligne
vdt <- c("AB_tot", "BM_tot", "Richesse_tot")
lignes_zero <- which(rowSums(bdd[vdt] != 0, na.rm = TRUE) == 0)
# View(bdd[lignes_zero,c("ID_Site","AB_tot", "BM_tot", "Richesse_tot")])



# Check des lignes ayant de BM mais pas de AB
bm_sans_ab <- subset(bdd, AB_tot == 0 & BM_tot != 0)
# bm_sans_ab[, c("ID","ID_Site", "Programme", "Protocole", "AB_tot", "BM_tot")]

ab_sans_bm <- subset(bdd, BM_tot == 0 & AB_tot != 0) # 1 parcelles
# ab_sans_bm[, c("ID","ID_Site", "Programme", "Protocole", "AB_tot", "BM_tot")]


# Check des doublons

#duplicated_rows <- subset(bdd, duplicated(bdd[, c("ID", "AB_tot", "BM_tot")]) | #duplicated(bdd[, c("ID", "AB_tot", "BM_tot")], fromLast = TRUE))

```



## Total abundance (CR = 100 % )

```{r fig AB_tot,fig.align='center',fig.height=10}
AB_tot_aberant = bdd[,c("ID","Programme", "Annee", "ID_Site","clcm_lvl1","clcm_lvl2","clcm_lvl3","Protocole","AB_tot", "Richesse_tot")]
# summary(bdd$AB_tot) 
df_cleaned = bdd

df_cleaned$AB_tot = as.numeric(df_cleaned$AB_tot)
explo_num(nom_col = 'AB_tot', titre = 'AB_tot (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'AB_tot', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'AB_tot', direction = 'mini')
explo_num(nom_col = 'AB_tot', titre = 'AB_tot (après', df = df_cleaned)
# summary(df_cleaned$AB_tot) 
bdd = df_cleaned

```


## Total biomass (CR = `r df_col[df_col$Variable=="BM_tot","CR"]`)

```{r fig BM_tot,fig.align='center',fig.height=10}
# summary(bdd$BM_tot) 
df_cleaned = bdd

df_cleaned$BM_tot = as.numeric(df_cleaned$BM_tot)
explo_num(nom_col = 'BM_tot', titre = 'BM_tot (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'BM_tot', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'BM_tot', direction = 'mini')
explo_num(nom_col = 'BM_tot', titre = 'BM_tot (après', df = df_cleaned)
# summary(df_cleaned$BM_tot) 
bdd = df_cleaned
```




## Total taxonomic richness
 (CR = 100 % )

```{r fig richness, fig.align='center',fig.height=10}
df_cleaned = bdd

df_cleaned$Richesse_tot = as.numeric(df_cleaned$Richesse_tot)
explo_num(nom_col = 'Richesse_tot', titre = 'Richesse_tot (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'Richesse_tot', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'Richesse_tot', direction = 'mini')
explo_num(nom_col = 'Richesse_tot', titre = 'Richesse_tot (après', df = df_cleaned)
# summary(df_cleaned$Richesse_tot) 
bdd = df_cleaned

```


## Graphe valeurs aberant AB_tot

```{r}
# summary(AB_tot_aberant)
AB_tot_aberant_2 = AB_tot_aberant[AB_tot_aberant$AB_tot > max(bdd$AB_tot),]
AB_tot_aberant_2$clcm_lvl1 =as.factor(AB_tot_aberant_2$clcm_lvl1)
AB_tot_aberant_2$clcm_lvl2 =as.factor(AB_tot_aberant_2$clcm_lvl2)
AB_tot_aberant_2$clcm_lvl3 =as.factor(AB_tot_aberant_2$clcm_lvl3)
AB_tot_aberant_2 = droplevels(AB_tot_aberant_2)
summary(AB_tot_aberant_2)
nrow(AB_tot_aberant_2)
kable(unique(AB_tot_aberant_2[,c("Programme","Annee","clcm_lvl3")]))

df = AB_tot_aberant_2

df$observation = 1:nrow(df)
 g = ggplot(df, aes(x = observation)) + 
  #graph representant observed
  geom_point(aes(y = AB_tot, color = "Abundance")) +
  geom_line(aes(y = AB_tot, color = "Abundance")) + 
  
  #graph representant  preticted
  geom_point(aes(y = Richesse_tot, color="Richness")) +
  geom_line(aes(y = Richesse_tot, color="Richness")) + 
  # ggtitle(title)
  theme(plot.title = element_text(hjust = 0.5)) + 
  labs(title = "  ",x="Observation", y="Values", color = "Legend :") +
    
  scale_color_manual(values = c("Abundance"='red', "Richness"='green'))
    g = ggplotly(g)

    g
 
```

<!--
# Synthèse du taux de remplissage

## Complete columns

```{r synt CR, echo=TRUE}
df_col=taux_completion(bdd,TRUE,trie=FALSE)
df_col = df_col[df_col$Variables != "Total",]
kable(df_col, caption = " ", col.width = c("75%", "25%"))
```

## Non-complete columns

```{r, scrollable = TRUE}
df_col= taux_completion(bdd,FALSE,trie = TRUE)
df_col = df_col[df_col$Variables != "Total",]
kable(df_col, caption = " ", col.width = c("75%", "25%"))
```

-->



<!--
# Climate data extraction
## The source database ([CHELSA V2](https://chelsa-climate.org/bioclim/){target="_blank"})

```{r Climate df extraction,echo=TRUE}

# Lire le fichier Excel
chemin_fichier_excel <- "C:/Users/diall/Downloads/datas/ODMAP.xlsx"
climat <- read.xlsx(chemin_fichier_excel, sheet = "climat")

# Fusions des cellules des colonnes avec des éléments dupliqués
for (col in names(climat)) {
  climat[[col]] <- ifelse(duplicated(climat[[col]]), "", climat[[col]])
}

# Affichage du tableau avec kableExtra et centrage du contenu des cellules
kableExtra::kable(climat) %>%
  kableExtra::kable_styling() %>%
  kableExtra::column_spec(1:ncol(climat)) 

```

## Extraction method

-   Link recovery ( see file [link .tif](https://1drv.ms/t/s!Avfm81EzNGBHjIZWw8YePljXaGSpCQ?e=qIPeWR){target="_blank"} )

-   Extracting variable names

-   Uses of the **extraction()** function

-   Convert columns to correct format and unit

-   Adding variables to the LANDWORM database

```{r Extraction method,echo=TRUE}
liens_tif = read.table(file = "C:/Users/diall/Downloads/datas/envidatS3paths.txt")
liens_tif$shortname <- str_extract(liens_tif$V1, "(?<=CHELSA_).*?(?=_1981)")
liens_tif[liens_tif$shortname=="rsds","shortname"]=c("rsds_max","rsds_mean","rsds_min","rsds_range")

#all(is.na(bdd$gps_x))
#all(is.na(bdd$gps_y))

bdd_climat= bdd[, c("ID","gps_x","gps_y")]

temp_1=Sys.time()
#for( i in 1:nrow(liens_tif)){
  #nom=liens_tif[i,c("shortname")]
  #df_ext <- extraction(nom_col = nom,df = bdd_climat,conv = 1, 
                  #tif_file_path = liens_tif[i,c("V1")] ) 
  #bdd_climat[[nom]] <- df_ext [,nom]
  #rm("df_ext","nom")
  #cat("Extraction: ",i,"/",nrow(liens_tif), "\n")
#}
temp_2=Sys.time()
duree= difftime(temp_2,temp_1)

chemin_fichier <- "C:/Users/diall/OneDrive/Bureau/M2_MODE/stage_abdou_m2/datas/bdd_climat.rds"
# saveRDS(bdd_climat, chemin_fichier)
#bdd_climat <- readRDS(chemin_fichier)

# debut cnversion ------------------------------------------------------------
conv_df_climat= data.frame(shortname =liens_tif$shortname )

# unit = 1
conv_df_climat$unit = rep(1)
# unit = 100
unit_100=c("bio4")
conv_df_climat$unit <- ifelse(conv_df_climat$shortname %in% unit_100, 100, 1)


# scale = 0.1
conv_df_climat$scale = rep(0.1)
# scale = 1
scale_1=c("fcf","fgd","gddlgd0","gddlgd5","gddlgd10","gdgfgd0","gdgfgd5","gdgfgd10","gsl","kg0","kg1" ,"kg2" ,"kg3" ,"kg4" ,"kg5","lgd","ngd0","ngd5","ngd10","scd")

# scale = 0.01
scale_01=c("hurs_max","hurs_mean","hurs_min","hurs_range","pet_penman_max",
       "pet_penman_mean","pet_penman_min","pet_penman_range")

# scale = 0.001
scale_001=c("rsds","sfcWind_max","sfcWind_mean","sfcWind_min","sfcWind_range","pet_penman_max","pet_penman_mean","pet_penman_min","pet_penman_range","rsds_max","rsds_mean","rsds_min","rsds_range")

# Remplacement des valeurs de l'échelle en fonction des conditions
conv_df_climat$scale <- ifelse(conv_df_climat$shortname %in% scale_1, 1,
              ifelse(conv_df_climat$shortname %in% scale_01, 0.01,
                    ifelse(conv_df_climat$shortname %in% scale_001,0.001, 0.1)))

# offset = 0
conv_df_climat$offset = rep(0)
# offset = - 273.15
offset_273=c("bio1","bio5","bio6","bio8","bio9","bio10","bio11","gdgfgd10","gsl","gst")
conv_df_climat$offset = ifelse(conv_df_climat$shortname %in% offset_273, -273.15, 0)

# Pas present dans dans le pdf explicative donc pas de conversion
pas_pdf=c( "ai","swb", "clt_max","clt_mean","clt_min","clt_range")
verif=c(unit_100,scale_1,scale_01,scale_001,offset_273)
pas_pdf_2=setdiff(conv_df_climat$shortname, verif)
conv_df_climat[conv_df_climat$shortname %in% pas_pdf,"scale"] = 1

#bdd_climat_ok=bdd_climat[,c("ID","gps_x","gps_y")]

#for ( i in conv_df_climat$shortname){
  #if (i %in% names(bdd_climat)){
  #unitee= conv_df_climat[conv_df_climat$shortname ==i,"unit"]
  #echelle = conv_df_climat[conv_df_climat$shortname ==i,"scale"]
  #decalage = conv_df_climat[conv_df_climat$shortname ==i,"offset"]
  #bdd_climat_ok[[i]] = ((bdd_climat[[i]] / unitee)* echelle) + decalage
  #}else {
    #cat("Attention ",i, "n'exite pas dans la bdd_climat","\n")
  #}
#}


# chemin_fichier <- "C:/Users/diall/OneDrive/Bureau/M2_MODE/stage_abdou_m2/datas/bdd_climat_ok.rds"
# saveRDS(bdd_climat_ok, chemin_fichier)
# bdd_climat_ok <- readRDS(chemin_fichier)
# fin conversion

#df_fusion <- subset(bdd_climat_ok, select = -c(ID,gps_x, gps_y))
#bdd <- cbind(bdd, df_fusion) # all = TRUE pour garder toutes les lignes
```

## List of variables

[Variable description](https://chelsa-climate.org/wp-admin/download-page/CHELSA_tech_specification_V2.pdf){target="_blank"}

```{r}
summary(bdd_climat_ok)
```
-->


<!--
## Temperature

-   Average annual air temperature (°C) = bio1

```{r Temperature,fig.align='center',fig.height=8}
summary(bdd$bio1)
explo_num(nom_col = "bio1", titre = "temp°.")
```

## Precipitation

-   Annual precipitation (kg/m²) = bio12

```{r Precipitation,fig.align='center',fig.height=8}
summary(bdd$bio12)
explo_num(nom_col = "bio12", titre = "Précipitat°.")
```

-->



<!--
# Questions

```{r Questions}
ID_Site_dupliques <- bdd$ID_Site[duplicated(bdd$ID_Site)]
#length(ID_Site_dupliques)

lignes_dupliquees <- subset(bdd, duplicated(ID_Site))

lignes_unique <- unique(lignes_dupliquees$ID_Site)
#length(lignes_unique)

# nrow(bdd) - length(ID_Site_dupliques) + length(lignes_unique)
```

-   Comment gérer la répétition temporelle des parcelles ?
    -   Avec répétition : **`r nrow(bdd)`** observations
    -   Sans répétition : **`r nrow(bdd) - length(ID_Site_dupliques) + length(lignes_unique)`** observations
-   Liens des données du sol (sable, argile et limon) de data.gouv.fr ?

-->

# Soil data extraction

```{r Soil data extraction}
# Calcul des distances euclidiennes entre les sites
distances <- dist(cbind(bdd$gps_x, bdd$gps_y))
distance_moyenne <- mean(distances)
# distance_moyenne

df_col= taux_completion(bdd,FALSE,trie = TRUE)
df_col = df_col[df_col$Variables != "Total",]
```


## The source database ([openlandmap](https://openlandmap.org/?center=25,39&zoom=4&opacity=72&base=OpenStreetMap&layer=lc_glc.fcs30d&time=2022){target="_blank"})

```{r soil source database,echo=TRUE}
chemin_fichier_excel <- "C:/Users/diall/Downloads/datas/ODMAP.xlsx"
pedo <- read.xlsx(chemin_fichier_excel, sheet = "pedo")

# Fusion des cellules des colonnes avec des éléments dupliqués
for (col in names(pedo)) {
  pedo[[col]] <- ifelse(duplicated(pedo[[col]]), "", pedo[[col]])
}

#tableau avec kableExtra et centrage du contenu des cellules
kableExtra::kable(pedo) %>%
  kableExtra::kable_styling() %>%
  kableExtra::column_spec(1:ncol(pedo))  # Centrer le contenu de toutes les colonnes
```

\n
-   Average values between surface (0 cm) and 30 cm depth


## Changing the resolution ![](https://logowik.com/content/uploads/images/python.jpg){width="200"}

-   Long compilation time in R

-   GDAL module with the resampleAlg = bilinear method

-   Resolution = 0.0083 = 30 arc-second \~ 1km

```{r changing resolution}
    test_resolution = bdd
    tif_file_path_origine = "C:/Users/diall/Downloads/datas/raster_origine/sol_ph.h2o_usda.4c1a2a_m_250m_b10..10cm_1950..2017_v0.2.tif"
    raster_ph_origine <- raster(tif_file_path_origine)
    test_resolution <- extraction(nom_col = "ph_10_origine",df = test_resolution,conv = 10, 
                      tif_file_path = tif_file_path_origine)


    tif_file_path_rech = "C:/Users/diall/Downloads/datas/raster_modif/sol_ph.h2o_usda.4c1a2a_m_250m_b10..10cm_1950..2017_v0.2.tif"
    raster_ph_rech <- raster(tif_file_path_rech)
    test_resolution <- extraction(nom_col = "ph_10_rech",df = test_resolution,conv = 10, 
                      tif_file_path = tif_file_path_rech)

    par(mforw=c(1,2))
    image(raster_ph_origine,main="pH at 10cm: original raster (0.002)")
    image(raster_ph_rech, main = "pH at 10cm: raster modify (0.008)")


    bdd_echan = test_resolution
    bdd_echan <- bdd_echan %>%filter(!is.na(ph_10_origine) & !is.na(ph_10_rech))

    # graphique avec ggplot
        # coefficient de corrélation
    correlation <- cor(as.numeric(bdd_echan$ph_10_origine), bdd_echan$ph_10_rech)
    p <- ggplot(bdd_echan, aes(x = ph_10_origine, y = ph_10_rech)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle = paste("r = ", round(correlation, 2)),
           x = "Original pH", y = "Resampled pH") + 
      theme_classic() 

    p

    ```





## Soil organic carbone (g/kg)

```{r extract C,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = "c_orga_0",df = bdd,conv = 5, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_organic.carbon_usda.6a1c_m_250m_b0..0cm_1950..2017_v0.2.tif")
bdd <- extraction(nom_col = "c_orga_10",df = bdd,conv = 5, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_organic.carbon_usda.6a1c_m_250m_b10..10cm_1950..2017_v0.2.tif")
bdd <- extraction(nom_col = "c_orga_30",df = bdd,conv = 5, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_organic.carbon_usda.6a1c_m_250m_b30..30cm_1950..2017_v0.2.tif")
bdd = moyenne_val_extrct(nom_col = "c_orga_0_a_30", vec_col = c("c_orga_0","c_orga_10","c_orga_30"),df=bdd)



df_cleaned = bdd

df_cleaned$c_orga_0_a_30 = as.numeric(df_cleaned$c_orga_0_a_30)
explo_num(nom_col = 'c_orga_0_a_30', titre = 'c_orga_0_a_30 (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'c_orga_0_a_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'c_orga_0_a_30', direction = 'mini')
explo_num(nom_col = 'c_orga_0_a_30', titre = 'c_orga_0_a_30 (après', df = df_cleaned)
# summary(df_cleaned$c_orga_0_a_30) 
bdd = df_cleaned


```

## pH

**Extracted values**

```{r extract pH,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = "ph_0",df = bdd,conv = 10, 
                  tif_file_path ="C:/Users/diall/Downloads/datas/raster_modif/sol_ph.h2o_usda.4c1a2a_m_250m_b10..10cm_1950..2017_v0.2.tif")

bdd <- extraction(nom_col = "ph_10" ,df = bdd,conv = 10, 
                  tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_ph.h2o_usda.4c1a2a_m_250m_b10..10cm_1950..2017_v0.2.tif")
bdd <- extraction(nom_col = "ph_30" ,df = bdd,conv = 10, 
                  tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_ph.h2o_usda.4c1a2a_m_250m_b30..30cm_1950..2017_v0.2.tif")
bdd = moyenne_val_extrct(nom_col = "ph_0_a_30", vec_col = c("ph_0","ph_10","ph_30"),df=bdd)
# summary(bdd$ph_0_a_30)

df_cleaned = bdd

df_cleaned$ph_0_a_30 = as.numeric(df_cleaned$ph_0_a_30)
explo_num(nom_col = 'ph_0_a_30', titre = 'ph_0_a_30 (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'ph_0_a_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'ph_0_a_30', direction = 'mini')
explo_num(nom_col = 'ph_0_a_30', titre = 'ph_0_a_30 (après', df = df_cleaned)
# summary(df_cleaned$ph_0_a_30) 
bdd = df_cleaned

```

**Measured values & extracted values**

-   Clean pH column

```{r clean pH,echo=TRUE}
# On recupere les deux colonnes du pH
df_comp=bdd[, c("ID", "ID_Site","ph_eau","ph_0_a_30" )]
df_comp =df_comp[complete.cases(df_comp$ph_eau),] 
df_comp =df_comp[complete.cases(df_comp$ph_0_a_30),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$ph_eau), ]
df_comp$ph_eau <- as.numeric(df_comp$ph_eau)
df_comp$ph_0_a_30 <- as.numeric(df_comp$ph_0_a_30)


df_comp = df_comp[!df_comp$ph_eau== 44140.00,]
df_comp = df_comp[!df_comp$ph_eau== "NA",]
df_comp = df_comp[!df_comp$ph_0_a_30== "NA",]
df_comp = droplevels(df_comp)
```

```{r,echo=TRUE}
ID_Site_dupliques <- df_comp$ID_Site[duplicated(df_comp$ID_Site)]
#length(ID_Site_dupliques)

lignes_dupliquees <- subset(df_comp, duplicated(ID_Site) & duplicated(ph_eau))

lignes_unique <- unique(lignes_dupliquees$ID_Site )
#length(lignes_unique)

# nrow(df_comp) - length(ID_Site_dupliques) + length(lignes_unique)


dupliquees <- duplicated(df_comp$ID_Site)
df_comp <- df_comp[!dupliquees, ]
df_comp=droplevels(df_comp)

# correlation <- cor.test(df_comp$ph_eau, df_comp$ph_0_a_30,method = "pearson")
#resultat_test <- t.test(df_comp$ph_eau, df_comp$ph_0_a_30)

df_comp$ph_eau <- as.numeric(df_comp$ph_eau)
df_comp$ph_0_a_30 <- as.numeric(df_comp$ph_0_a_30)

```

<!-- <br/>  -->

::: columns
::: {.column width="60%"}
-   Method ?

-   Depth ?

-   Measured values (CR = `r df_col[df_col$Variable=="ph_eau","CR"]`)

```{r}
  summary(df_comp$ph_eau)
```

-   Extracted values

```{r}
  summary(df_comp$ph_0_a_30)
```
:::

::: {.column width="40%"}
```{r fig cor pH,fig.align='center',fig.height=5,fig.width=4}
    correlation <- cor(as.numeric(df_comp$ph_eau), df_comp$ph_0_a_30)
# graphique avec ggplot
    p <- ggplot(df_comp, aes(x = ph_eau, y = ph_0_a_30)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle =paste("r = ", round(correlation, 2)),x = "pH measured values", y = "pH extracted values") + 
      theme_classic() 
p
# plot(as.numeric(df_comp$ph_eau))
```
:::
:::

<!--
## Bulk density (kg / m-cube)

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = "d_ap_0",df = bdd,conv = 10, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_bulkdens.fineearth_usda.4a1h_m_250m_b0..0cm_1950..2017_v0.2.tif")
bdd <- extraction(nom_col = "d_ap_10",df = bdd,conv = 10, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_bulkdens.fineearth_usda.4a1h_m_250m_b10..10cm_1950..2017_v0.2.tif")
bdd <- extraction(nom_col = "d_ap_30",df = bdd,conv = 10, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_bulkdens.fineearth_usda.4a1h_m_250m_b30..30cm_1950..2017_v0.2.tif")
bdd = moyenne_val_extrct(nom_col = "d_ap_0_a_30", vec_col = c("d_ap_0","d_ap_10","d_ap_30"),bdd)
summary(bdd$d_ap_0_a_30)
explo_num(nom_col = "d_ap_0_a_30", titre = "Bulk density (0 - 30 cm)")
```


## Sand content (% kg/kg)

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = "sable_0",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_sand.wfraction_usda.3a1a1a_m_250m_b0..0cm_1950..2017_v0.2.tif")
bdd <- extraction(nom_col = "sable_10",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_sand.wfraction_usda.3a1a1a_m_250m_b10..10cm_1950..2017_v0.2.tif")
bdd <- extraction(nom_col = "sable_30",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_sand.wfraction_usda.3a1a1a_m_250m_b30..30cm_1950..2017_v0.2.tif")
bdd = moyenne_val_extrct(nom_col = "sable_0_a_30", vec_col = c("sable_0","sable_10","sable_30"),df=bdd)
summary(bdd$sable_0_a_30)
explo_num(nom_col = "sable_0_a_30", titre = "Sand (0 - 30 cm)")
```



-->

## Sand

**Extracted values (g/kg, 0 - 30 cm)**

```{r extract sand,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = "sable.0_5",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sable.0_5.tif")

bdd <- extraction(nom_col = "sable.5_15",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sable.5_15.tif")

bdd <- extraction(nom_col = "sable.15_30",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sable.15_30.tif")

bdd = moyenne_val_extrct(nom_col = "sable.0_30", vec_col = c("sable.0_5","sable.5_15","sable.15_30"),df=bdd)

# summary(bdd$sable.0_30)


df_cleaned = bdd

df_cleaned$sable.0_30 = as.numeric(df_cleaned$sable.0_30)
explo_num(nom_col = 'sable.0_30', titre = 'sable.0_30 (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'sable.0_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'sable.0_30', direction = 'mini')
explo_num(nom_col = 'sable.0_30', titre = 'sable.0_30 (après', df = df_cleaned)
# summary(df_cleaned$sable.0_30) 
bdd = df_cleaned

```

**Measured values & extracted values**

-   Clean sand column

```{r,echo=TRUE}
# On recupere les deux colonnes du pH
df_comp=bdd[, c("ID", "ID_Site","sand","sable.0_30" )]
df_comp =df_comp[complete.cases(df_comp$sand),] 
df_comp =df_comp[complete.cases(df_comp$sable.0_30),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$sand), ]
df_comp$sand <- as.numeric(df_comp$sand)
df_comp$sable.0_30 <- as.numeric(df_comp$sable.0_30)
# colSums(is.na(df_comp))

df_comp = df_comp[!df_comp$sand== "NA",]
df_comp = df_comp[!df_comp$sable.0_30== "NaN",]
df_comp = droplevels(df_comp)
```

```{r,echo=TRUE}
# -   Deleting duplicate measured values

ID_Site_dupliques <- df_comp$ID_Site[duplicated(df_comp$ID_Site)]
#length(ID_Site_dupliques)

lignes_dupliquees <- subset(df_comp, duplicated(ID_Site) & duplicated(sand))

lignes_unique <- unique(lignes_dupliquees$ID_Site )
#length(lignes_unique)
# nrow(df_comp) - length(ID_Site_dupliques) + length(lignes_unique)

dupliquees <- duplicated(df_comp$ID_Site)
df_comp <- df_comp[!dupliquees, ]
df_comp=droplevels(df_comp)
df_comp$sand <- as.numeric(df_comp$sand)
df_comp$sable.0_30 <- as.numeric(df_comp$sable.0_30)

# summary(df_comp$sand)
# explo_num(nom_col = "sand", titre = "Sand extracted values",df = df_comp)
id_ligne <- df_comp[which(df_comp$sand >=83), "ID"] 
df_comp <- df_comp[!df_comp$ID %in% id_ligne, ]
df_comp=droplevels(df_comp)


# 
# summary(df_comp$sable.0_30)
# explo_num(nom_col = "sable.0_30", titre = "Sand extracted values",df = df_comp)
id_ligne <- df_comp[which(df_comp$sable.0_30 >=60), "ID"] 
df_comp <- df_comp[!df_comp$ID %in% id_ligne, ]
df_comp=droplevels(df_comp)

```

::: columns
::: {.column width="60%"}
-   Method ?

-   Depth ?

-   Measured values (CR = `r df_col[df_col$Variable=="sand","CR"]`)

```{r}
  summary(df_comp$sand)
```

-   Extracted values

```{r}
  summary(df_comp$sable.0_30)
```
:::

::: {.column width="40%"}
\n\n\n

```{r,fig.align='center',fig.height=5,fig.width=4}
# graphique avec ggplot
correlation <- cor(as.numeric(df_comp$sand), df_comp$sable.0_30)
    p <- ggplot(df_comp, aes(x = sand, y = sable.0_30)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle =paste("r = ", round(correlation, 2)) ,x = "Sand measured values", y = "Sand extracted values") + 
      theme_classic() 
p
# plot(as.numeric(df_comp$sand))
# plot(df_comp$sable.0_30)
```

:::
:::

## Silt

**Extracted values (g/kg, 0 - 30 cm)**

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = "limon.0_5",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.0_5.tif")

bdd <- extraction(nom_col = "limon.5_15",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.5_15.tif")

bdd <- extraction(nom_col = "limon.15_30",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.15_30.tif")

bdd = moyenne_val_extrct(nom_col = "limon.0_30", vec_col = c("limon.0_5","limon.5_15","limon.15_30"),df=bdd)

df_cleaned = bdd

df_cleaned$limon.0_30 = as.numeric(df_cleaned$limon.0_30)
explo_num(nom_col = 'limon.0_30', titre = 'limon.0_30 (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'limon.0_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'limon.0_30', direction = 'mini')
explo_num(nom_col = 'limon.0_30', titre = 'limon.0_30 (après', df = df_cleaned)
# summary(df_cleaned$limon.0_30) 
bdd = df_cleaned

```

**Measured values & extracted values**

-   Clean silt column

```{r,echo=TRUE}
# On recupere les deux colonnes du pH
df_comp=bdd[, c("ID", "ID_Site","silt","limon.0_30" )]
df_comp =df_comp[complete.cases(df_comp$silt),] 
df_comp =df_comp[complete.cases(df_comp$limon.0_30),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$silt), ]
df_comp$silt <- as.numeric(df_comp$silt)
df_comp$limon.0_30 <- as.numeric(df_comp$limon.0_30)
# colSums(is.na(df_comp))


df_comp = df_comp[!df_comp$silt== "NA",]
df_comp = df_comp[!df_comp$limon.0_30== "NaN",]
df_comp = droplevels(df_comp)
```

```{r,echo=TRUE}
# -   Deleting duplicate measured values

ID_Site_dupliques <- df_comp$ID_Site[duplicated(df_comp$ID_Site)]
#length(ID_Site_dupliques)

lignes_dupliquees <- subset(df_comp, duplicated(ID_Site) & duplicated(silt))

lignes_unique <- unique(lignes_dupliquees$ID_Site )
#length(lignes_unique)
# nrow(df_comp) - length(ID_Site_dupliques) + length(lignes_unique)


dupliquees <- duplicated(df_comp$ID_Site)
df_comp <- df_comp[!dupliquees, ]
df_comp=droplevels(df_comp)
df_comp$silt <- as.numeric(df_comp$silt)
df_comp$limon.0_30 <- as.numeric(df_comp$limon.0_30)




# summary(df_comp$silt)
# explo_num(nom_col = "silt", titre = "Silt",df = df_comp)
id_ligne <- df_comp[which(df_comp$silt <=7.3), "ID"] 
df_comp <- df_comp[!df_comp$ID %in% id_ligne, ]
df_comp=droplevels(df_comp)



# summary(df_comp$limon.0_30)
# explo_num(nom_col = "limon.0_30", titre = "limon.0_30",df = df_comp)
id_ligne <- df_comp[which(df_comp$limon.0_30 >=80), "ID"] 
df_comp <- df_comp[!df_comp$ID %in% id_ligne, ]
df_comp=droplevels(df_comp)


```

::: columns
::: {.column width="60%"}
-   Method ?

-   Depth ?

-   Measured values (CR = `r df_col[df_col$Variable=="silt","CR"]`)

```{r}
  summary(df_comp$silt)
```

-   Extracted values

```{r}
  summary(df_comp$limon.0_30)
```
:::

::: {.column width="40%"}
\n\n\n

```{r,fig.align='center',fig.height=5,fig.width=4}
# graphique avec ggplot
correlation <- cor(as.numeric(df_comp$silt), df_comp$limon.0_30)
    p <- ggplot(df_comp, aes(x = silt, y = limon.0_30)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle =paste("r = ", round(correlation, 2)) ,x = "Silt measured values", y = "Silt extracted values") + 
      theme_classic() 
p

# plot(as.numeric(df_comp$limon.0_30))
```


:::
:::

## Clay

**Extracted values (g/kg, 0 - 30 cm)**

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = "argile.0_5",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/argile.0_5.tif")

bdd <- extraction(nom_col = "argile.5_15",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/argile.5_15.tif")

bdd <- extraction(nom_col = "argile.15_30",df = bdd,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/argile.15_30.tif")

bdd = moyenne_val_extrct(nom_col = "argile.0_30", vec_col = c("argile.0_5","argile.5_15","argile.15_30"),df=bdd)


df_cleaned = bdd

df_cleaned$argile.0_30 = as.numeric(df_cleaned$argile.0_30)
explo_num(nom_col = 'argile.0_30', titre = 'argile.0_30 (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'argile.0_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'argile.0_30', direction = 'mini')
explo_num(nom_col = 'argile.0_30', titre = 'argile.0_30 (après', df = df_cleaned)
# summary(df_cleaned$argile.0_30) 
bdd = df_cleaned

```

**Measured values & extracted values** - Clean clay column

```{r,echo=TRUE}
# On recupere les deux colonnes du pH
df_comp=bdd[, c("ID", "ID_Site","clay","argile.0_30" )]
df_comp =df_comp[complete.cases(df_comp$clay),] 
df_comp =df_comp[complete.cases(df_comp$argile.0_30),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$clay), ]
df_comp$clay <- as.numeric(df_comp$clay)
df_comp$argile.0_30 <- as.numeric(df_comp$argile.0_30)
# colSums(is.na(df_comp))

df_comp = df_comp[!df_comp$clay== "NA",]
df_comp = df_comp[!df_comp$argile.0_30== "NaN",]
df_comp = droplevels(df_comp)
```

```{r,echo=TRUE}
# -   Deleting duplicate measured values

ID_Site_dupliques <- df_comp$ID_Site[duplicated(df_comp$ID_Site)]
#length(ID_Site_dupliques)

lignes_dupliquees <- subset(df_comp, duplicated(ID_Site) & duplicated(clay))

lignes_unique <- unique(lignes_dupliquees$ID_Site )
#length(lignes_unique)
# nrow(df_comp) - length(ID_Site_dupliques) + length(lignes_unique)

dupliquees <- duplicated(df_comp$ID_Site)
df_comp <- df_comp[!dupliquees, ]
df_comp=droplevels(df_comp)
df_comp$clay <- as.numeric(df_comp$clay)
df_comp$argile.0_30 <- as.numeric(df_comp$argile.0_30)


df_comp$clay = as.numeric(df_comp$clay)/10 # pour conv en %

```

::: columns
::: {.column width="60%"}
-   Method ?

-   Depth ?

-   Measured values (CR = `r df_col[df_col$Variable=="clay","CR"]`)

```{r}
  summary(df_comp$clay)
```

-   Extracted values

```{r}
  summary(df_comp$argile.0_30)
```
:::

::: {.column width="40%"}
\n\n\n

```{r,fig.align='center',fig.height=5,fig.width=4}
# graphique avec ggplot
correlation <- cor(as.numeric(df_comp$clay), df_comp$argile.0_30)
    p <- ggplot(df_comp, aes(x = clay, y = argile.0_30)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle =paste("r = ", round(correlation, 2)) ,x = "Clay measured values", y = "Clay extracted values") + 
      theme_classic() 
p
```
:::
:::

## Elevation

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = "elevation",df = bdd,conv = 1, 
                  tif_file_path ="C:/Users/diall/Downloads/datas/raster_modif/GMTED2010_Spatial.tif")


df_cleaned = bdd

df_cleaned$elevation = as.numeric(df_cleaned$elevation)
explo_num(nom_col = 'elevation', titre = 'elevation (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'elevation', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'elevation', direction = 'mini')
explo_num(nom_col = 'elevation', titre = 'elevation (après', df = df_cleaned)
# summary(df_cleaned$elevation) 
bdd = df_cleaned

```


<!--
## pH_H2O_CaCl 

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = 'jrc_pH_H2O_CaCl', df = bdd, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/pH_H2O_CaCl.tif')

summary(bdd$jrc_pH_H2O_CaCl)

explo_num(nom_col = 'jrc_pH_H2O_CaCl', titre = 'jrc_pH_H2O_CaCl')
```

## pH_H2O 

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = 'jrc_pH_H2O', df = bdd, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/pH_H2O.tif')

summary(bdd$jrc_pH_H2O)

explo_num(nom_col = 'jrc_pH_H2O', titre = 'jrc_pH_H2O')

df_comp=bdd[, c("ID", "ID_Site","ph_eau","jrc_pH_H2O" )]
df_comp =df_comp[complete.cases(df_comp$ph_eau),] 
df_comp =df_comp[complete.cases(df_comp$jrc_pH_H2O),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$ph_eau), ]
df_comp$ph_eau <- as.numeric(df_comp$ph_eau)
df_comp$jrc_pH_H2O <- as.numeric(df_comp$jrc_pH_H2O)


df_comp = df_comp[!df_comp$ph_eau== 44140.00,]
df_comp = df_comp[!df_comp$ph_eau== "NA",]
df_comp = df_comp[!df_comp$jrc_pH_H2O== "NA",]
df_comp = droplevels(df_comp)

correlation <- cor(as.numeric(df_comp$ph_eau), df_comp$jrc_pH_H2O)
```

## pH_CaCl 

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = 'jrc_pH_CaCl', df = bdd, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/pH_CaCl.tif')

summary(bdd$jrc_pH_CaCl)

explo_num(nom_col = 'jrc_pH_CaCl', titre = 'jrc_pH_CaCl')
```

-->


## Phosphore (P, mg/kg)

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = 'P', df = bdd, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/P.tif')

df_cleaned = bdd

df_cleaned$P = as.numeric(df_cleaned$P)
explo_num(nom_col = 'P', titre = 'P (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'P', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'P', direction = 'mini')
explo_num(nom_col = 'P', titre = 'P (après', df = df_cleaned)
# summary(df_cleaned$P) 
bdd = df_cleaned
```

## Azote (N, g/kg)

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = 'N', df = bdd, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/N.tif')


df_cleaned = bdd

df_cleaned$N = as.numeric(df_cleaned$N)
explo_num(nom_col = 'N', titre = 'N (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'N', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'N', direction = 'mini')
explo_num(nom_col = 'N', titre = 'N (après', df = df_cleaned)
# summary(df_cleaned$N) 
bdd = df_cleaned
```

## Potassium (K, mg/kg)

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = 'K', df = bdd, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/K.tif')


df_cleaned = bdd

df_cleaned$K = as.numeric(df_cleaned$K)
explo_num(nom_col = 'K', titre = 'K (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'K', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'K', direction = 'mini')
explo_num(nom_col = 'K', titre = 'K (après', df = df_cleaned)
# summary(df_cleaned$N) 
bdd = df_cleaned
```

## C/N

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = 'CN', df = bdd, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/CN.tif')


df_cleaned = bdd

df_cleaned$CN = as.numeric(df_cleaned$CN)
explo_num(nom_col = 'CN', titre = 'CN (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'CN', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'CN', direction = 'mini')
explo_num(nom_col = 'CN', titre = 'CN (après', df = df_cleaned)
# summary(df_cleaned$N) 
bdd = df_cleaned
```

## Capacité d'échange de cations (CEC, cmol/kg)

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = 'CEC', df = bdd, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/CEC.tif')

df_cleaned = bdd

df_cleaned$CEC = as.numeric(df_cleaned$CEC)
explo_num(nom_col = 'CEC', titre = 'CEC (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'CEC', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'CEC', direction = 'mini')
explo_num(nom_col = 'CEC', titre = 'CEC (après', df = df_cleaned)
# summary(df_cleaned$N) 
bdd = df_cleaned
```

## Carbonates de calcium (CaCO3, g/kg)

```{r,fig.align='center',fig.height=8}
bdd <- extraction(nom_col = 'CaCO3', df = bdd, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/CaCO3.tif')


df_cleaned = bdd

df_cleaned$CaCO3 = as.numeric(df_cleaned$CaCO3)
explo_num(nom_col = 'CaCO3', titre = 'CaCO3 (avant)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'CaCO3', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'CaCO3', direction = 'mini')
explo_num(nom_col = 'CaCO3', titre = 'CaCO3 (après', df = df_cleaned)
# summary(df_cleaned$N) 
bdd = df_cleaned
```

# Exploratory analysis

**Data set reduction**

```{r ana explo,echo=TRUE,fig.height=8,fig.show='animate',fig.align='center'}
id_col=c("ID","Programme","Annee","ID_Site","Protocole")

vdt_col=c("AB_tot", "BM_tot", "Richesse_tot")

land_cover_col=c("clcm_lvl3")

topo_col=c("elevation","gps_x","gps_y")


soil_col=c("ph_0_a_30","sable.0_30","limon.0_30","argile.0_30","c_orga_0_a_30","P","N","K","CN","CEC","CaCO3")


climate_col=c()
for (i in 1:19){
  climate_col=c(climate_col, paste0("bio",i) )
}
climate_col=c(climate_col,"cmi_mean","gdd0","gdd10","hurs_mean","pet_penman_mean")

bdd_explo= bdd[,c(id_col,vdt_col,land_cover_col,topo_col,soil_col,climate_col)]
# str(bdd_explo)
bdd_explo$ID = as.factor(bdd_explo$ID)


# Renome
new_soil_col=c("pH","sand","silt","clay","C","P","N","K","CN","CEC","CaCO3")
bdd_explo <- rename(bdd_explo, !!setNames(soil_col, new_soil_col))

bdd_explo <- bdd_explo %>% 
  rename(PET = pet_penman_mean)
climate_col=c()
for (i in 1:19){
  climate_col=c(climate_col, paste0("bio",i) )
}
climate_col=c(climate_col,"cmi_mean","gdd0","gdd10","hurs_mean","PET")


col_graph=c(vdt_col,land_cover_col,topo_col,new_soil_col,climate_col)
# for (i in names(bdd_explo[,col_graph])){
#   par(mfrow=c(2,2))
#   plot(bdd_explo[[i]], main=i)
# }





levels(bdd_explo$clcm_lvl3)[levels(bdd_explo$clcm_lvl3) == "Broad-leaved forest"] <- "Mixed forest"
levels(bdd_explo$clcm_lvl3)[levels(bdd_explo$clcm_lvl3) == "Coniferous forest"] <- "Mixed forest"
bdd_explo$clcm_lvl3= as.factor(bdd_explo$clcm_lvl3)

cl_original <- levels(bdd_explo$clcm_lvl3)
new_cl <- c("mf","gua", "ng", "nial", "p", "v")
bdd_explo$clcm_lvl3 <- factor(bdd_explo$clcm_lvl3, levels = cl_original, labels = new_cl)


data_mod = bdd_explo


# STANDARIZATION
# names(data_mod)
var_quanti = c(topo_col,new_soil_col,climate_col)
for (col in var_quanti) {
  data_mod[[col]] <- scale(data_mod[[col]])
}
# summary(data_mod[, var_quanti])
# str(data_mod[, var_quanti])

```


## Test de correlation : intra catégories

-   **Topographie**

Colonnes supprimée : *gps_x*

```{r,echo=FALSE,fig.align='center'}
# ggpairs(bdd_explo[,topo_col])
correlation_matrix <- cor(bdd_explo[,topo_col],use = "na.or.complete")
# 
corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 1,number.cex = 1)
topo_sup=c("gps_x")
bdd_explo <- bdd_explo[, setdiff(names(bdd_explo), topo_sup)]

```


<br/>
-   **Soil data**

```{r,echo=FALSE}
# ggpairs(bdd_explo[,new_soil_col])
soil_sup=c("sand")
```

::: columns
::: {.column width="25%"}
<br/>
Colonnes supprimée : *`r soil_sup`*
:::

::: {.column width="75%"}

```{r,echo=FALSE,fig.height=6,fig.width=9,fig.align='right'}
correlation_matrix <- cor(bdd_explo[,new_soil_col],use = "na.or.complete")
corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 1,number.cex = 0.7)

bdd_explo <- bdd_explo[, setdiff(names(bdd_explo), soil_sup)]
```
:::
:::



<br/>
-   **Climat data**

```{r,echo=FALSE,out.height="100%",out.width="100%"}
# correlation_matrix <- cor(bdd_explo[,climate_col],use = "na.or.complete")
# 
# chemin="C:/Users/diall/OneDrive/Bureau/M2_MODE/stage_abdou_m2/R_Stage_M2/Results/climat_corrplot.png"
# png(chemin, width = 2000, height = 1000,res = 110)
# 
# 
# corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 1,number.cex = 0.7,mar = c(0,0,0,0))
# 
# dev.off()
# ![](Results/climat_corrplot.png)


# cor_function_seuil(data = bdd_explo[,climate_col], seuil = 0.7)
climat_sup=c("bio2","bio4","bio5","bio6","bio7", "bio9", "bio10","bio11","bio13","bio16","bio17","bio18","bio19","gdd0","gdd10", "cmi_mean","PET")
```

::: columns
::: {.column width="25%"}
<br/>
Colonnes supprimmées :*`r climat_sup`*
:::

::: {.column width="75%"}
```{r,echo=FALSE,fig.height=7,fig.width=9,fig.align='right'}
climat_selec = climate_col[!climate_col %in% climat_sup]
# ggpairs(bdd_explo[,climat_selec])
correlation_matrix <- cor(bdd_explo[,climat_selec],use = "na.or.complete")
corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 1,number.cex = 0.9,mar = c(0,0,0,0))

bdd_explo <- bdd_explo[, setdiff(names(bdd_explo), climat_sup)]
```
:::
:::



## Test de correlation : inter catégories

Colonnes supprimée : *gps_y*
```{r,echo=FALSE}
# correlation_matrix <- cor(bdd_explo[,10:31],use = "na.or.complete")
# corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 0.5,number.cex = 0.5,mar = c(0,0,0,0))

# var=c("elevation","pH","silt","clay","C","P","N","K","CN","CEC","CaCO3","bio1","bio3","bio8","bio12","bio14","bio15","hurs_mean","gps_y")
# 
# correlation_matrix <- cor(bdd_explo[,var],use = "na.or.complete")
# 
# chemin="C:/Users/diall/OneDrive/Bureau/M2_MODE/stage_abdou_m2/R_Stage_M2/Results/interC_corrplot.png"
# png(chemin, width = 1200, height = 1000,res = 110)
# 
# 
# corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 1,number.cex = 0.7,mar = c(0,0,0,0))
# 
# dev.off()


bdd_explo <- bdd_explo[, setdiff(names(bdd_explo), c("gps_y"))]
```

![](Results/interC_corrplot.png) {width="1200",aligne="center"}



## VIF

**Suppression de la variable bio14**

```{r VIF var}
var_avant=c("elevation","pH","silt","clay","C","P","N","K","CN","CEC","CaCO3","bio1","bio3",
      "bio8","bio12","bio14","bio15","hurs_mean")
#usdm::vif(bdd_explo[,var_avant])
#usdm::vifcor(bdd_explo[,var_avant], th = 0.9, keep = NULL, method = 'pearson')
usdm::vifstep(bdd_explo[,var_avant], th = 10, keep = NULL, method = 'pearson')
# -   On enleve "bio14" car la plus forte VIF
bdd_explo <- bdd_explo[, setdiff(names(bdd_explo), c("bio14"))]

var=c("elevation","pH","silt","clay","C","P","N","K","CN","CEC","CaCO3","bio1","bio3","bio8","bio12","bio15","hurs_mean")
```


<!--
## Création des variables factices

```{r factices var ,echo=TRUE}
bdd_explo$clcm_lvl3= as.factor(bdd_explo$clcm_lvl3)
summary_df <- as.data.frame(summary(bdd_explo$clcm_lvl3))
colnames(summary_df) <- c("Numbers")
kable(summary_df,padding = 5)
```

-   Merging:
    *Mixed forest = Broad\_leaved forest +* 
                    *Coniferous forest +* 
                    *Mixed forest*

```{r clc3 levels, echo=FALSE}
levels(bdd_explo$clcm_lvl3)[levels(bdd_explo$clcm_lvl3) == "Broad-leaved forest"] <- "Mixed forest"
levels(bdd_explo$clcm_lvl3)[levels(bdd_explo$clcm_lvl3) == "Coniferous forest"] <- "Mixed forest"
bdd_explo$clcm_lvl3= as.factor(bdd_explo$clcm_lvl3)
# summary_df <- as.data.frame(summary(bdd_explo$clcm_lvl3))
# colnames(summary_df) <- c("Numbers")
# kable(summary_df,padding = 5)
```

-   Abréviation des levels

```{r clc3 names, echo=FALSE}
cl_original <- levels(bdd_explo$clcm_lvl3)
new_cl <- c("mf","gua", "ng", "nial", "p", "v")
bdd_explo$clcm_lvl3 <- factor(bdd_explo$clcm_lvl3, levels = cl_original, labels = new_cl)

bdd_explo <- bdd_explo %>% 
  rename(clc3 = clcm_lvl3)
```


-   Variables

```{r head clc var ,echo=FALSE}
bdd_explo <- dummy_cols(bdd_explo, select_columns = c("clc3"))
clc3_col= c("clc3_mf","clc3_gua", "clc3_ng", "clc3_nial", "clc3_p", "clc3_v")
head(bdd_explo[,clc3_col])
# str(bdd_explo[,clc3_col])
```


```{r VIF and clc3}
# usdm::vif(bdd_explo[,c(var,clc3_col)])
# usdm::vifcor(bdd_explo[,c(var,clc3_col)], th = 0.9, keep = NULL, method = 'pearson')
# usdm::vifstep(bdd_explo[,c(var,clc3_col)], th = 10, keep = NULL, method = 'pearson')
# summary(bdd_explo$clc3)
```



## ACP
```{r ACP, echo=TRUE, fig.align='center'}
# On supprime les lignes avec des NA dans toutes les colonnes sauf BM_tot
# colSums(is.na(bdd_explo))
bdd_explo <- bdd_explo[apply(bdd_explo[, !colnames(bdd_explo) %in% "BM_tot"], 1, function(x) all(!is.na(x))), ]
# colSums(is.na(bdd_explo))


var=c("elevation","pH","silt","clay","C","P","N","K","CN","CEC","CaCO3","bio1","bio3",
      "bio8","bio12","bio15","hurs_mean")

data_acp = bdd_explo[, var]
acp0 <- PCA(data_acp, graph = FALSE)


## Choix du nombre d'axes
# acp0$eig
fviz_eig(acp0, addlabels = TRUE) # on prend les trois premiers axes
contrib_axes <- acp0$var$contrib[, 1:3]  # 3 premiers axes
contrib_axes <- round(contrib_axes, 3)   # Plus facile a lire
fviz_contrib(acp0, choice = "var", axes = 1)
fviz_contrib(acp0, choice = "var", axes = 2)
fviz_contrib(acp0, choice = "var", axes = 3)

seuil <- 1 / ncol(data_acp) * 100
lignes_superieures <- rownames(contrib_axes)[apply(contrib_axes, 1,
                                                   function(x)
                                                     any(x >= seuil))]
var [! var %in% lignes_superieures]

#  **** En consderant les Trois premiers axes:
# seul K n'est pas trés influant





# coloree les variables selon leurs contributions aux axes
fviz_pca_var(
  axes = c(1, 2),
  acp0,
  col.var = "contrib",
  gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
  repel = TRUE
) # evite le chevauchement de texte




# coul = c("yellow", "green", "violet", "blue", "black", "red")
# fviz_pca_ind(
#   axes = c(1, 2),
#   acp0,
#   geom.ind = "text",
#   pointshape = 21,
#   pointsize = 2,
#   #palette = coul,
#   palette = "viridis",
#   addEllipses = TRUE,
#   legend.title = "CLC",
#   fill.ind = bdd_explo$clc3
# )


fviz_pca_ind(
  axes = c(1, 2),
  acp0,
  geom.ind = "point",
  pointshape = 21,
  pointsize = 2,
  palette = "viridis",
  addEllipses = TRUE,
  legend.title = "CLC",
  fill.ind = bdd_explo$clc3
)
```


```{r}
# Classification
# class1 = HCPC(acp0)
# plot(class1$call$t$inert.gain, type = "s")
# #Je choisis finalement 4 groupes
# class1 = HCPC(acp0, nb.clust = 4)
# fviz_dend(class1)
# fviz_cluster(class1)
# fviz_cluster(class1, ellipse.type = "norm", ellipse.level = 0.8)    #Groupes
```

-->

# Selecting variables with regsubsets()
```{r select var, echo=TRUE}
# colSums(is.na(bdd_explo))
bdd_explo <- bdd_explo[apply(bdd_explo[, !colnames(bdd_explo) %in% "BM_tot"], 1, function(x) all(!is.na(x))), ]
# colSums(is.na(bdd_explo))
# dim(bdd_explo)
```

## Selection for total abundance
```{r abundance selection, echo=TRUE, fig.align='center'}
# names(bdd_explo)
supp = c("ID","Programme","Annee","ID_Site", "Protocole","BM_tot", "Richesse_tot","clc3")
df_AB_tot= bdd_explo[, setdiff(names(bdd_explo), supp)]
df_AB_tot= df_AB_tot[, setdiff(names(df_AB_tot), clc3_col)]
# str(df_AB_tot)
# colSums(is.na(df_AB_tot))
results_AB_tot <- regsubsets(AB_tot ~ ., data = df_AB_tot,method = "exhaustive",nvmax =17 )
# plot(results_AB_tot, scale = "r2", main='R² criteria')
# summary(results_AB_tot)
rsq_AB_tot= round (summary(results_AB_tot)$rsq,2)
adjr2_AB_tot= round(summary(results_AB_tot)$adjr2,2)
cp_AB_tot=round (summary(results_AB_tot)$cp,2)
bic_AB_tot=round(summary(results_AB_tot)$bic,2)
```


-   Selection by R² adj : stable from `r which.max(adjr2_AB_tot)` variables
```{r, echo=FALSE, fig.align='center'}
plot(results_AB_tot, scale = "adjr2",main='R² adj criteria')
```

-   Selection by Cp : stable from `r which.min(cp_AB_tot)` variables
```{r, echo=FALSE, fig.align='center'}
plot(results_AB_tot, scale = "Cp",main='Mallows Cp criteria')
```

-   Selection by BIC : stable from `r which.min(bic_AB_tot)` variables
```{r, echo=FALSE, fig.align='center'}
plot(results_AB_tot, scale = "bic",main="BIC criteria")
```

```{r}
nbr_AB_tot= max(which.max(rsq_AB_tot),which.max(adjr2_AB_tot),which.min(cp_AB_tot),which.min(bic_AB_tot))
best_var_AB_tot=coefficients(results_AB_tot, id = nbr_AB_tot)
best_var_AB_tot=names(best_var_AB_tot)[-1]
```
-   Les `r length(best_var_AB_tot)` meilleurs variables sont: **`r best_var_AB_tot`**



## Selection for total biomass

```{r biomass selection, echo=TRUE, fig.align='center'}
# names(bdd_explo)
supp = c("ID","Programme","Annee","ID_Site", "Protocole","AB_tot", "Richesse_tot","clc3")
df_BM_tot= bdd_explo[, setdiff(names(bdd_explo), supp)]
df_BM_tot= df_BM_tot[, setdiff(names(df_BM_tot), clc3_col)]
df_BM_tot=drop_na(df_BM_tot)
# str(df_BM_tot)
# colSums(is.na(df_BM_tot))
results_BM_tot <- regsubsets(BM_tot ~ ., data = df_BM_tot,method = "exhaustive",nvmax =17 )
# summary(results_BM_tot)
rsq_BM_tot= round (summary(results_BM_tot)$rsq,2)
adjr2_BM_tot= round(summary(results_BM_tot)$adjr2,2)
cp_BM_tot=round (summary(results_BM_tot)$cp,2)
bic_BM_tot=round(summary(results_BM_tot)$bic,2)
```

-   Suppression de `r sum(is.na(bdd_explo$BM_tot))` lignes de NA de BM_tot (nrow = `r nrow(df_BM_tot)`)

-   Selection by R² adj : stable from `r which.max(adjr2_BM_tot)` variables
```{r, echo=FALSE, fig.align='center'}
plot(results_BM_tot, scale = "adjr2",main='R² adj criteria')
```

-   Selection by Cp : stable from `r which.min(cp_BM_tot)` variables
```{r, echo=FALSE, fig.align='center'}
plot(results_BM_tot, scale = "Cp",main='Mallows Cp criteria')
```

-   Selection by BIC : stable from `r which.min(bic_BM_tot)` variables
```{r, echo=FALSE, fig.align='center'}
plot(results_BM_tot, scale = "bic",main="BIC criteria")
```

```{r}
nbr_BM_tot= max(which.max(rsq_BM_tot),which.max(adjr2_BM_tot),which.min(cp_BM_tot),which.min(bic_BM_tot))
best_var_BM_tot=coefficients(results_BM_tot, id = nbr_BM_tot)
best_var_BM_tot=names(best_var_BM_tot)[-1]
```
-   Les `r length(best_var_BM_tot)` meilleurs variables sont: **`r best_var_BM_tot`**



## Selection for total taxonomic richness

```{r richness selection, echo=TRUE, fig.align='center'}
# names(bdd_explo)
supp = c("ID","Programme","Annee","ID_Site", "Protocole","BM_tot", "AB_tot","clc3")
df_Richesse_tot= bdd_explo[, setdiff(names(bdd_explo), supp)]
df_Richesse_tot= df_Richesse_tot[, setdiff(names(df_Richesse_tot), clc3_col)]
# str(df_Richesse_tot)
# colSums(is.na(df_Richesse_tot))
results_Richesse_tot <- regsubsets(Richesse_tot ~ ., data = df_Richesse_tot,method = "exhaustive",nvmax =17 )
# summary(results_Richesse_tot)
rsq_Richesse_tot= round (summary(results_Richesse_tot)$rsq,2)
adjr2_Richesse_tot= round(summary(results_Richesse_tot)$adjr2,2)
cp_Richesse_tot=round (summary(results_Richesse_tot)$cp,2)
bic_Richesse_tot=round(summary(results_Richesse_tot)$bic,2)
```


-   Selection by R² adj : stable from `r which.max(adjr2_Richesse_tot)` variables
```{r, echo=FALSE, fig.align='center'}
plot(results_Richesse_tot, scale = "adjr2",main='R² adj criteria')
```

-   Selection by Cp : stable from `r which.min(cp_Richesse_tot)` variables
```{r, echo=FALSE, fig.align='center'}
plot(results_Richesse_tot, scale = "Cp",main='Mallows Cp criteria')
```

-   Selection by BIC : stable from `r which.min(bic_Richesse_tot)` variables
```{r, echo=FALSE, fig.align='center'}
plot(results_Richesse_tot, scale = "bic",main="BIC criteria")
```

```{r}
nbr_Richesse_tot= max(which.max(rsq_Richesse_tot),which.max(adjr2_Richesse_tot),which.min(cp_Richesse_tot),which.min(bic_Richesse_tot))
best_var_Richesse_tot=coefficients(results_Richesse_tot, id = nbr_Richesse_tot)
best_var_Richesse_tot=names(best_var_Richesse_tot)[-1]
```
-   Les `r length(best_var_Richesse_tot)` meilleurs variables sont: **`r best_var_Richesse_tot`**


<!--
## Summary
```{r synth selection}
all_var=unique(c(best_var_AB_tot,best_var_BM_tot,best_var_Richesse_tot))

col_max=max(c(length(best_var_AB_tot),length(best_var_BM_tot),length(best_var_Richesse_tot)))


# Colonnes communes
colonnes_communes <- intersect(intersect(best_var_AB_tot, best_var_BM_tot), best_var_Richesse_tot)

resultat_tableau <- data.frame(
  
  Var_AB_tot =c(best_var_AB_tot, rep(" ", col_max - length(best_var_AB_tot))),
  
  Var_BM_tot =  c(best_var_BM_tot, rep(" ", col_max - length(best_var_BM_tot))),
  
  Var_Richesse_tot =  c(best_var_Richesse_tot, rep(" ", col_max -    length(best_var_Richesse_tot))),
  
  Communes =c(colonnes_communes, rep(" ", col_max - length(colonnes_communes)))
)
kable(resultat_tableau,padding=10)

# write.csv2(resultat_tableau,"Results/selct_var_reg.csv")

```
**bio1** = mean annual air temperature

**bio3** = isothermality

**bio8** = mean air temperatures of the wettest quarter

**bio8** = mean air temperatures of the wettest quarter

**bio12** = annual precipitation amount

**bio15** = precipitation seasonality

**hurs_mean** = Mean monthly near-surface relative humidity










-->

# Distributions of response variables
## Total abundance distributions

```{r abundance dist,fig.align='center',fig.height=4,fig.width=4}
# par(mfrow=c(1,2))
# # Noraml
# set.seed(123)
# par(mfrow = c(2,2))
# donnees_normales <- rnorm(nrow(data_mod), mean = mean(data_mod$AB_tot), sd = 2)
# hist(donnees_normales, freq = FALSE, main = "Distribution Normale", xlab = "Valeurs", ylab = "Densité")
# curve(dnorm(x, mean = mean(donnees_normales), sd = sd(donnees_normales)), add = TRUE, col = "blue", lwd = 2)
# 
# 
# # Poisson
# set.seed(123)
# donnees_poisson <- rpois(nrow(data_mod), lambda = mean(data_mod$AB_tot))
# hist(donnees_poisson, freq = FALSE, main = "Distribution de Poisson", xlab = "Valeurs", ylab = "Densité")
# x <- 0:max(donnees_poisson)
# lines(x, dpois(x, lambda = mean(data_mod$AB_tot)), col = "blue", lwd = 2)

# donnees <- data_mod$AB_tot
# frequences_obs <- table(donnees)
# 
# #fréquences attendues pour une distribution de Poisson
# lambda <- mean(donnees)
# frequences_att <- dpois(x = as.numeric(names(frequences_obs)), lambda = lambda) * length(donnees)
# test <- chisq.test(frequences_obs, p = frequences_att)
# print(test)


df <- data.frame(y =data_mod$AB_tot)
# Test de Shapiro-Wilk
AB_tot_test_nor = shapiro.test(df$y)
AB_tot_p.value =round(AB_tot_test_nor$p.value,3)
 if(AB_tot_p.value ==0){
   AB_tot_p.value = "; p.value > 0.001"
 } else {
   AB_tot_p.value = paste0("; p.value = ",AB_tot_p.value)   
 }
AB_tot_sub = paste0("Shapiro-Wilk; W = ",round(AB_tot_test_nor$statistic,2),AB_tot_p.value)

```



::: columns
::: {.column width="50%"}

<p>
  <img src="lamda_boxcox.png">
</p>

<br/>
```{r}
# Histogramme
ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Abundance", subtitle =AB_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
```

-   Transformation sqrt
```{r ,fig.dpi=300,fig.align='center',fig.height=4,fig.width=4}
# par(mfrow=c(1,2))
# # Noraml
# set.seed(123)
# test = sqrt(data_mod$AB_tot)
# par(mfrow = c(2,2))
# donnees_normales <- rnorm(nrow(data_mod), mean = mean(test), sd = 2)
# hist(donnees_normales, freq = FALSE, main = "Distribution Normale", xlab = "Valeurs", ylab = "Densité")
# curve(dnorm(x, mean = mean(donnees_normales), sd = sd(donnees_normales)), add = TRUE, col = "blue", lwd = 2)
# 
# 
# # Poisson
# set.seed(123)
# donnees_poisson <- rpois(nrow(data_mod), lambda = mean(test))
# hist(donnees_poisson, freq = FALSE, main = "Distribution de Poisson", xlab = "Valeurs", ylab = "Densité")
# x <- 0:max(donnees_poisson)
# lines(x, dpois(x, lambda = mean(test)), col = "blue", lwd = 2)



df_2 <- data.frame(y =sqrt(data_mod$AB_tot))
# Test de Shapiro-Wilk
AB_tot_test_nor = shapiro.test(df_2$y)
AB_tot_p.value =round(AB_tot_test_nor$p.value,3)
 if(AB_tot_p.value ==0){
   AB_tot_p.value = "; p.value > 0.001"
 } else {
   AB_tot_p.value = paste0("; p.value = ",AB_tot_p.value)   
 }
AB_tot_sub = paste0("Shapiro-Wilk; W = ",round(AB_tot_test_nor$statistic,2),AB_tot_p.value)

```

```{r}
# Histogramme
ggplot(df_2, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Abundance", subtitle =AB_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))

```
:::

::: {.column width="50%"}
```{r}
# https://r-coder.com/box-cox-transformation-r/?utm_content=cmp-true
# data_mod$AB_tot[data_mod$AB_tot < 0]
x = as.numeric ( data_mod$AB_tot )+1


b <- boxcox(lm(x ~ 1),plotit = FALSE)

# Exact lambda
lambda1 <- b$x[which.max(b$y)]

boxcox(lm(x ~ 1),plotit = TRUE)


```
    lamda = `r lambda1`

<br/> 

```{r}
# QQ-plot
qqnorm(df$y)
qqline(df$y)
```

<br/> 
<br/> 
```{r}

# QQ-plot
qqnorm(df_2$y)
qqline(df_2$y)
```

:::
:::

## Total biomass distributions

```{r biomass dist,fig.align='center',fig.height=4,fig.width=4}
# par(mfrow=c(1,2))
# # Noraml
# set.seed(123)
# par(mfrow = c(2,2))
# donnees_normales <- rnorm(nrow(data_mod), mean = mean(data_mod$BM_tot), sd = 2)
# hist(donnees_normales, freq = FALSE, main = "Distribution Normale", xlab = "Valeurs", ylab = "Densité")
# curve(dnorm(x, mean = mean(donnees_normales), sd = sd(donnees_normales)), add = TRUE, col = "blue", lwd = 2)
# 
# 
# # Poisson
# set.seed(123)
# donnees_poisson <- rpois(nrow(data_mod), lambda = mean(data_mod$BM_tot))
# hist(donnees_poisson, freq = FALSE, main = "Distribution de Poisson", xlab = "Valeurs", ylab = "Densité")
# x <- 0:max(donnees_poisson)
# lines(x, dpois(x, lambda = mean(data_mod$BM_tot)), col = "blue", lwd = 2)

# donnees <- data_mod$BM_tot
# frequences_obs <- table(donnees)
# 
# #fréquences attendues pour une distribution de Poisson
# lambda <- mean(donnees)
# frequences_att <- dpois(x = as.numeric(names(frequences_obs)), lambda = lambda) * length(donnees)
# test <- chisq.test(frequences_obs, p = frequences_att)
# print(test)


df <- data.frame(y =data_mod$BM_tot)
# Test de Shapiro-Wilk
BM_tot_test_nor = shapiro.test(df$y)
BM_tot_p.value =round(BM_tot_test_nor$p.value,3)
 if(BM_tot_p.value ==0){
   BM_tot_p.value = "; p.value > 0.001"
 } else {
   BM_tot_p.value = paste0("; p.value = ",BM_tot_p.value)   
 }
BM_tot_sub = paste0("Shapiro-Wilk; W = ",round(BM_tot_test_nor$statistic,2),BM_tot_p.value)

```


::: columns
::: {.column width="50%"}

<p>
  <img src="lamda_boxcox.png">
</p>

<br/>
```{r}
# Histogramme
ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="biomass", subtitle =BM_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
```

-   Transformation sqrt
```{r ,fig.dpi=300,fig.align='center',fig.height=4,fig.width=4}
# par(mfrow=c(1,2))
# # Noraml
# set.seed(123)
# test = sqrt(data_mod$BM_tot)
# par(mfrow = c(2,2))
# donnees_normales <- rnorm(nrow(data_mod), mean = mean(test), sd = 2)
# hist(donnees_normales, freq = FALSE, main = "Distribution Normale", xlab = "Valeurs", ylab = "Densité")
# curve(dnorm(x, mean = mean(donnees_normales), sd = sd(donnees_normales)), add = TRUE, col = "blue", lwd = 2)
# 
# 
# # Poisson
# set.seed(123)
# donnees_poisson <- rpois(nrow(data_mod), lambda = mean(test))
# hist(donnees_poisson, freq = FALSE, main = "Distribution de Poisson", xlab = "Valeurs", ylab = "Densité")
# x <- 0:max(donnees_poisson)
# lines(x, dpois(x, lambda = mean(test)), col = "blue", lwd = 2)



df_2 <- data.frame(y =sqrt(data_mod$BM_tot))
# Test de Shapiro-Wilk
BM_tot_test_nor = shapiro.test(df_2$y)
BM_tot_p.value =round(BM_tot_test_nor$p.value,3)
 if(BM_tot_p.value ==0){
   BM_tot_p.value = "; p.value > 0.001"
 } else {
   BM_tot_p.value = paste0("; p.value = ",BM_tot_p.value)   
 }
BM_tot_sub = paste0("Shapiro-Wilk; W = ",round(BM_tot_test_nor$statistic,2),BM_tot_p.value)

```

```{r}
# Histogramme
ggplot(df_2, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="biomass", subtitle =BM_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))

```
:::

::: {.column width="50%"}
```{r}
# https://r-coder.com/box-cox-transformation-r/?utm_content=cmp-true
# data_mod$BM_tot[data_mod$BM_tot < 0]
x = as.numeric ( data_mod$BM_tot )+1


b <- boxcox(lm(x ~ 1),plotit = FALSE)

# Exact lambda
lambda <- b$x[which.max(b$y)]

lambda = round(lambda,3)
boxcox(lm(x ~ 1),plotit = TRUE)


```
    lamda = `r lambda`

<br/> 

```{r}
# QQ-plot
qqnorm(df$y)
qqline(df$y)
```

<br/> 
<br/> 
```{r}

# QQ-plot
qqnorm(df_2$y)
qqline(df_2$y)
```

:::
:::



## Total taxonomic richness distributions

```{r richness dist,fig.align='center',fig.height=4,fig.width=4}
# par(mfrow=c(1,2))
# # Noraml
# set.seed(123)
# par(mfrow = c(2,2))
# donnees_normales <- rnorm(nrow(data_mod), mean = mean(data_mod$Richesse_tot), sd = 2)
# hist(donnees_normales, freq = FALSE, main = "Distribution Normale", xlab = "Valeurs", ylab = "Densité")
# curve(dnorm(x, mean = mean(donnees_normales), sd = sd(donnees_normales)), add = TRUE, col = "blue", lwd = 2)
# 
# 
# # Poisson
# set.seed(123)
# donnees_poisson <- rpois(nrow(data_mod), lambda = mean(data_mod$Richesse_tot))
# hist(donnees_poisson, freq = FALSE, main = "Distribution de Poisson", xlab = "Valeurs", ylab = "Densité")
# x <- 0:max(donnees_poisson)
# lines(x, dpois(x, lambda = mean(data_mod$Richesse_tot)), col = "blue", lwd = 2)

# donnees <- data_mod$Richesse_tot
# frequences_obs <- table(donnees)
# 
# #fréquences attendues pour une distribution de Poisson
# lambda <- mean(donnees)
# frequences_att <- dpois(x = as.numeric(names(frequences_obs)), lambda = lambda) * length(donnees)
# test <- chisq.test(frequences_obs, p = frequences_att)
# print(test)


df <- data.frame(y =data_mod$Richesse_tot)
# Test de Shapiro-Wilk
Richesse_tot_test_nor = shapiro.test(df$y)
Richesse_tot_p.value =round(Richesse_tot_test_nor$p.value,3)
 if(Richesse_tot_p.value ==0){
   Richesse_tot_p.value = "; p.value > 0.001"
 } else {
   Richesse_tot_p.value = paste0("; p.value = ",Richesse_tot_p.value)   
 }
Richesse_tot_sub = paste0("Shapiro-Wilk; W = ",round(Richesse_tot_test_nor$statistic,2),Richesse_tot_p.value)

```



::: columns
::: {.column width="50%"}

<p>
  <img src="lamda_boxcox.png">
</p>

<br/>
```{r}
# Histogramme
ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="richness", subtitle =Richesse_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
```

-   Transformation sqrt
```{r ,fig.dpi=300,fig.align='center',fig.height=4,fig.width=4}
# par(mfrow=c(1,2))
# # Noraml
# set.seed(123)
# test = sqrt(data_mod$Richesse_tot)
# par(mfrow = c(2,2))
# donnees_normales <- rnorm(nrow(data_mod), mean = mean(test), sd = 2)
# hist(donnees_normales, freq = FALSE, main = "Distribution Normale", xlab = "Valeurs", ylab = "Densité")
# curve(dnorm(x, mean = mean(donnees_normales), sd = sd(donnees_normales)), add = TRUE, col = "blue", lwd = 2)
# 
# 
# # Poisson
# set.seed(123)
# donnees_poisson <- rpois(nrow(data_mod), lambda = mean(test))
# hist(donnees_poisson, freq = FALSE, main = "Distribution de Poisson", xlab = "Valeurs", ylab = "Densité")
# x <- 0:max(donnees_poisson)
# lines(x, dpois(x, lambda = mean(test)), col = "blue", lwd = 2)



df_2 <- data.frame(y =sqrt(data_mod$Richesse_tot))
# Test de Shapiro-Wilk
Richesse_tot_test_nor = shapiro.test(df_2$y)
Richesse_tot_p.value =round(Richesse_tot_test_nor$p.value,3)
 if(Richesse_tot_p.value ==0){
   Richesse_tot_p.value = "; p.value > 0.001"
 } else {
   Richesse_tot_p.value = paste0("; p.value = ",Richesse_tot_p.value)   
 }
Richesse_tot_sub = paste0("Shapiro-Wilk; W = ",round(Richesse_tot_test_nor$statistic,2),Richesse_tot_p.value)

```

```{r}
# Histogramme
ggplot(df_2, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="richness", subtitle =Richesse_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))

```
-> transformation sqrt (richesse_tot), asuivre !
:::

::: {.column width="50%"}
```{r}
# https://r-coder.com/box-cox-transformation-r/?utm_content=cmp-true
# data_mod$Richesse_tot[data_mod$Richesse_tot < 0]
x = as.numeric ( data_mod$Richesse_tot )+1


b <- boxcox(lm(x ~ 1),plotit = FALSE)

# Exact lambda
lambda1 <- b$x[which.max(b$y)]

boxcox(lm(x ~ 1),plotit = TRUE)


```
    lamda = `r lambda1`

<br/> 

```{r}
# QQ-plot
qqnorm(df$y)
qqline(df$y)
```

<br/> 
<br/> 
```{r}

# QQ-plot
qqnorm(df_2$y)
qqline(df_2$y)
```

:::
:::





# Modeling
## Data preparation
```{r modeling, echo=TRUE}
supp = c("ID","Programme","Annee","ID_Site", "Protocole","AB_tot","BM_tot","Richesse_tot", "AB_tot","clc3")

# names(bdd_explo[,10:26])
# df_mod=bdd_explo
# predicteurs=c(names(df_mod)[! names(df_mod) %in% supp])

set.seed(1234)  # Pour rendre les résultats reproductibles
index <- createDataPartition(data_mod$clcm_lvl3, p = 0.8, list = FALSE)

# Séparer les données en ensembles d'entraînement et de test
df_train <- data_mod[index, ]  # Données d'entraînement
df_test <- data_mod[-index, ]  # Données de test
df_train = droplevels(df_train)
df_test = droplevels(df_test)
# summary(df_train$clcm_lvl3)
# summary(df_test$clcm_lvl3)
# summary(data_mod$clcm_lvl3)
# 80*summary(data_mod$clcm_lvl3)/100

n_sim=30 # Nombre de similation






# AB_tot --------------------------------------------------------------------------
# df_mod_AB_tot = bdd_explo[,c("AB_tot",best_20_AB_tot)]
# # # # colnames(df_mod_AB_tot)[colnames(df_mod_AB_tot) == "clcm_lvl3"] <- "clc3"
# dummy_vars <- model.matrix(~ clcm_lvl3 - 1, data = df_mod_AB_tot)
# df_mod_AB_tot <- cbind(df_mod_AB_tot, dummy_vars)
# df_mod_AB_tot <- df_mod_AB_tot[, -which(names(df_mod_AB_tot) == "clcm_lvl3")]
# 
# df_mod_AB_tot = drop_na(df_mod_AB_tot)
# df_mod_AB_tot = droplevels(df_mod_AB_tot)
# 
# 
# # Partition
# set.seed(1234)
# ind <- sample(2, nrow(df_mod_AB_tot), replace = T, prob = c(.8, .2))
# AB_tot_train <- df_mod_AB_tot[ind==1,]
# AB_tot_test <- df_mod_AB_tot[ind==2,]
# 
# write.csv2(x =AB_tot_train,file = "datas/AB_tot_train.csv", row.names = FALSE)
# write.csv2(x =AB_tot_test,file = "datas/AB_tot_test.csv", row.names = FALSE)

AB_tot_train = read.csv2("datas/AB_tot_train.csv")
AB_tot_test = read.csv2("datas/AB_tot_test.csv")
df_mod_AB_tot = rbind(AB_tot_train,AB_tot_test)

AB_tot_train[,1] = sqrt(AB_tot_train[,1])
AB_tot_train[,2:20] = scale(AB_tot_train[,2:20])
AB_tot_train = as.data.frame(AB_tot_train)

AB_tot_test[,1] = sqrt(AB_tot_test[,1])
AB_tot_test[,2:20] = scale(AB_tot_test[,2:20])
AB_tot_test = as.data.frame(AB_tot_test)


# BM_tot --------------------------------------------------------------------------
# df_mod_BM_tot = bdd_explo[,c("BM_tot",best_20_BM_tot)]
# # # # colnames(df_mod_BM_tot)[colnames(df_mod_BM_tot) == "clcm_lvl3"] <- "clc3"
# dummy_vars <- model.matrix(~ clcm_lvl3 - 1, data = df_mod_BM_tot)
# df_mod_BM_tot <- cbind(df_mod_BM_tot, dummy_vars)
# df_mod_BM_tot <- df_mod_BM_tot[, -which(names(df_mod_BM_tot) == "clcm_lvl3")]
# 
# df_mod_BM_tot = drop_na(df_mod_BM_tot)
# df_mod_BM_tot = droplevels(df_mod_BM_tot)
# 
# # Partition
# set.seed(1234)
# ind <- sample(2, nrow(df_mod_BM_tot), replace = T, prob = c(.8, .2))
# BM_tot_train <- df_mod_BM_tot[ind==1,]
# BM_tot_test <- df_mod_BM_tot[ind==2,]
# 
# 
# write.csv2(x =BM_tot_train,file = "datas/BM_tot_train.csv", row.names = FALSE)
# write.csv2(x =BM_tot_test,file = "datas/BM_tot_test.csv", row.names = FALSE)


BM_tot_train = read.csv2("datas/BM_tot_train.csv")
BM_tot_test = read.csv2("datas/BM_tot_test.csv")
df_mod_BM_tot = rbind(BM_tot_train,BM_tot_test)

BM_tot_train[,1] = sqrt(BM_tot_train[,1])
BM_tot_train[,2:20] = scale(BM_tot_train[,2:20])
BM_tot_train = as.data.frame(BM_tot_train)

BM_tot_test[,1] = sqrt(BM_tot_test[,1])
BM_tot_test[,2:20] = scale(BM_tot_test[,2:20])
BM_tot_test = as.data.frame(BM_tot_test)


# Richesse_tot --------------------------------------------------------------------------
# df_mod_Richesse_tot = bdd_explo[,c("Richesse_tot",best_20_Richesse_tot)]
# # # # colnames(df_mod_Richesse_tot)[colnames(df_mod_Richesse_tot) == "clcm_lvl3"] <- "clc3"
# dummy_vars <- model.matrix(~ clcm_lvl3 - 1, data = df_mod_Richesse_tot)
# df_mod_Richesse_tot <- cbind(df_mod_Richesse_tot, dummy_vars)
# df_mod_Richesse_tot <- df_mod_Richesse_tot[, -which(names(df_mod_Richesse_tot) == "clcm_lvl3")]
# 
# df_mod_Richesse_tot = drop_na(df_mod_Richesse_tot)
# df_mod_Richesse_tot = droplevels(df_mod_Richesse_tot)
# 
# 
# # Partition
# set.seed(1234)
# ind <- sample(2, nrow(df_mod_Richesse_tot), replace = T, prob = c(.8, .2))
# Richesse_tot_train <- df_mod_Richesse_tot[ind==1,]
# Richesse_tot_test <- df_mod_Richesse_tot[ind==2,]
# 
# write.csv2(x =Richesse_tot_train,file = "datas/Richesse_tot_train.csv", row.names = FALSE)
# write.csv2(x =Richesse_tot_test,file = "datas/Richesse_tot_test.csv", row.names = FALSE)

Richesse_tot_train = read.csv2("datas/Richesse_tot_train.csv")
Richesse_tot_test = read.csv2("datas/Richesse_tot_test.csv")
df_mod_Richesse_tot = rbind(Richesse_tot_train,Richesse_tot_test)

#Richesse_tot_train[,1] = sqrt(Richesse_tot_train[,1])
Richesse_tot_train[,2:20] = scale(Richesse_tot_train[,2:20])
Richesse_tot_train = as.data.frame(Richesse_tot_train)

#Richesse_tot_test[,1] = sqrt(Richesse_tot_test[,1])
Richesse_tot_test[,2:20] = scale(Richesse_tot_test[,2:20])
Richesse_tot_test = as.data.frame(Richesse_tot_test)



```


    
::: columns
::: {.column width="50%"}

**Abundance **

-   Data partition (`r dim(df_mod_AB_tot)`):

    -   train data (80 %) = `r dim(AB_tot_train)`
    
    -   test data (20 %) = `r dim(AB_tot_test)`
    


**Biomasse **

-   Data partition (`r dim(df_mod_BM_tot)`):

    -   train data (80 %) = `r dim(BM_tot_train)`
    
    -   test data (20 %) = `r dim(BM_tot_test)`
    


**Richness **

-   Data partition (`r dim(df_mod_Richesse_tot)`):

    -   train data (80 %) = `r dim(Richesse_tot_train)`
    
    -   test data (20 %) = `r dim(Richesse_tot_test)` 

:::

::: {.column width="50%"}
<p>
  <img src="Results/abundance_dist_train_and_test.png">
</p>

<p>
  <img src="Results/biomass_dist_train_and_test.png">
</p>

<p>
  <img src="Results/richness_dist_train_and_test.png">
</p>
:::
:::



    

```{r interaction, eval=FALSE}
# AB_tot ------------------------------------------------------------------

inter_AB_tot <- select_inter("AB_tot", df_mod_AB_tot, best_20_AB_tot[-1])
inter_AB_tot <- arrange(inter_AB_tot, desc(r_squared))
best_inte_AB_tot = inter_AB_tot[1:20, "variables"] 


AB_tot_inter_train = AB_tot_train
for (interaction in best_inte_AB_tot) {
  vars <- strsplit(interaction, ".inter.")[[1]]
  # cat(vars[1], ":", vars[2], "\n")
  # la colonne d'interaction
  AB_tot_inter_train[[interaction]] <- AB_tot_inter_train[[vars[1]]] * AB_tot_inter_train[[vars[2]]]
}
# names(AB_tot_inter_train)


AB_tot_inter_test = AB_tot_test
for (interaction in best_inte_AB_tot) {
  vars <- strsplit(interaction, ".inter.")[[1]]
  # cat(vars[1], ":", vars[2], "\n")
  # la colonne d'interaction
  AB_tot_inter_test[[interaction]] <- AB_tot_inter_test[[vars[1]]] * AB_tot_inter_test[[vars[2]]]
}
# names(AB_tot_inter_test)




# BM_tot ------------------------------------------------------------------

# inter_BM_tot <- select_inter("BM_tot", df_mod_BM_tot, best_20_BM_tot[-1])
# write.csv2(x =inter_BM_tot,file = "Results/inter_BM_tot.csv", row.names = FALSE)
inter_BM_tot = read.csv2("Results/inter_BM_tot.csv")

inter_BM_tot <- arrange(inter_BM_tot, desc(r_squared))
best_inte_BM_tot = inter_BM_tot[1:20, "variables"] 


BM_tot_inter_train = BM_tot_train
for (interaction in best_inte_BM_tot) {
  vars <- strsplit(interaction, ".inter.")[[1]]
  # cat(vars[1], ":", vars[2], "\n")
  # la colonne d'interaction
  BM_tot_inter_train[[interaction]] <- BM_tot_inter_train[[vars[1]]] * BM_tot_inter_train[[vars[2]]]
}
# names(BM_tot_inter_train)


BM_tot_inter_test = BM_tot_test
for (interaction in best_inte_BM_tot) {
  vars <- strsplit(interaction, ".inter.")[[1]]
  # cat(vars[1], ":", vars[2], "\n")
  # la colonne d'interaction
  BM_tot_inter_test[[interaction]] <- BM_tot_inter_test[[vars[1]]] * BM_tot_inter_test[[vars[2]]]
}
# names(BM_tot_inter_test)



# Richesse_tot ------------------------------------------------------------------
# inter_Richesse_tot <- select_inter("Richesse_tot", df_mod_Richesse_tot, best_20_Richesse_tot[-1])
# write.csv2(x =inter_Richesse_tot,file = "Results/inter_Richesse_tot.csv", row.names = FALSE)
inter_Richesse_tot = read.csv2("Results/inter_Richesse_tot.csv")


inter_Richesse_tot <- arrange(inter_Richesse_tot, desc(r_squared))
best_inte_Richesse_tot = inter_Richesse_tot[1:20, "variables"] 


Richesse_tot_inter_train = Richesse_tot_train
for (interaction in best_inte_Richesse_tot) {
  vars <- strsplit(interaction, ".inter.")[[1]]
  # cat(vars[1], ":", vars[2], "\n")
  # la colonne d'interaction
  Richesse_tot_inter_train[[interaction]] <- Richesse_tot_inter_train[[vars[1]]] * Richesse_tot_inter_train[[vars[2]]]
}
# names(Richesse_tot_inter_train)


Richesse_tot_inter_test = Richesse_tot_test
for (interaction in best_inte_Richesse_tot) {
  vars <- strsplit(interaction, ".inter.")[[1]]
  # cat(vars[1], ":", vars[2], "\n")
  # la colonne d'interaction
  Richesse_tot_inter_test[[interaction]] <- Richesse_tot_inter_test[[vars[1]]] * Richesse_tot_inter_test[[vars[2]]]
}
# names(Richesse_tot_inter_test)
```



```{r}
# correlation_matrix <- cor(df_mod_AB_tot[,c(2,5:8,11:16,20)],use = "na.or.complete")
# corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 1,number.cex = 1)
# for(i in names(df_mod_AB_tot[,c(2,5:8,11:16,20:26)])){cat(i,",")}
# for(i in names(df_mod_AB_tot[,c(2,5:8,11:16,20:26)])){cat( paste0("s(",i,") + "))}
# for(i in names(AB_tot_inter_train)) {cat( paste0("s(",i,") + "))}

# 
# names(df_mod_BM_tot)
# correlation_matrix <- cor(df_mod_BM_tot[,c(4:5,7,8,10, 12:17,20)],use = "na.or.complete")
# corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 1,number.cex = 1)
# for(i in names(df_mod_BM_tot[,c(4:5,7,8,10, 12:17,20)])){cat(i,",")}
# for(i in names(df_mod_BM_tot[,c(4:5,7,8,10, 12:17,20:26)])){cat( paste0("s(",i,") + "))}
# for(i in names(BM_tot_inter_train)) {cat( paste0("s(",i,") + "))}
# 
# 
# 
# names(df_mod_Richesse_tot)
# correlation_matrix <- cor(df_mod_Richesse_tot[,c(4:6,8:13,16,18:20)],use = "na.or.complete")
# corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 1,number.cex = 1)
# for(i in names(df_mod_Richesse_tot[,c(4:6,8:13,16,18:20)])){cat(i,",")}
# for(i in names(df_mod_Richesse_tot[,c(4:6,8:13,16,18:26)])){cat( paste0("s(",i,") + "))}
# for(i in names(Richesse_tot_inter_train)) {cat( paste0("s(",i,") + "))}
```
 

## GLM
```{r function GLM, echo=TRUE}
GLM <- function(var_rep, df_app, df_valid,family = 'gaussian'){
  
  
  var_predicteurs = names(df_app[,-1])
 
  df_app = df_app[,c(var_rep,var_predicteurs)]
  df_valid = df_valid[,c(var_rep,var_predicteurs)]
  
  formula <- substitute(var_rep ~ ., list(var_rep = as.name(var_rep)))
  
  
  # entrainement du modele sur le jeu d'entrainement
  modelglm<-glm(formula,family = family ,data = df_app)
  
  # Prediction sur le jeu de validation
  pred.GLM<-predict(modelglm,newdata=as.data.frame(df_valid[,var_predicteurs]))
  
  # Calcul du RMSE pour évaluer la qualite du modele
  rmse <- round (sqrt(mean((df_valid[,var_rep] - pred.GLM)^2,na.rm=TRUE)),2)
  
  
 # Calcul du R² ajusté pour train
  r_squared_train <- calcule_R2(df_app[,var_rep],  predict(modelglm, data=df_app))
  n_train <- nrow(df_app)
  p_train <- ncol(df_app) - 1
  r_adj_train <- 1 - ((1 - r_squared_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  r_squared_test <-calcule_R2(df_valid[,var_rep],pred.GLM)
  n_test <- nrow(df_valid)
  p_test <- ncol(df_valid) - 1
  r_adj_test <- 1 - ((1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1))

  
  MAE <- mean(abs(pred.GLM - df_valid[,var_rep]),na.rm=TRUE)
  
  # Round results
  rmse <- round(rmse, 2)
  r_adj_train <- round(r_adj_train, 2)
  r_adj_test <- round(r_adj_test, 2)
  MAE <- round(MAE, 2)
  
  
  results <- list(RMSE = rmse, R_squared_train = r_adj_train, R_squared_test = r_adj_test, MAE = MAE, model = modelglm,predit = pred.GLM)
  return(results)
}

```

-   Gaussian distribution

## GAM
```{r function GAM, echo=TRUE}
GAM <- function(var_rep, df_app, df_valid, family = 'gaussian',method = "REML", interaction = FALSE){
  
  var_predicteurs = names(df_app[,-1])
  
  
  
  if (var_rep == "AB_tot"){ 
  if (interaction == FALSE){ 
  modelgam<-gam(AB_tot ~ s(CaCO3) + s(bio4) + s(N) + s(bio3) + s(elevation) + s(bio18) + s(CN) + s(P) + s(gdd0) + s(bio6) + s(sand) + s(bio8) + clcm_lvl3mf + clcm_lvl3gua + clcm_lvl3ng + clcm_lvl3nial + clcm_lvl3p + clcm_lvl3v,
        family=family,method = method,data = df_app)
  } else {
    
   modelgam<-gam(AB_tot ~ s(CaCO3) + s(bio4) + s(N) + s(bio3) + s(elevation) + s(bio18) + s(CN) + s(P) + s(gdd0) + s(bio6) + s(sand) + s(bio8) + clcm_lvl3mf + clcm_lvl3gua + clcm_lvl3ng + clcm_lvl3nial + clcm_lvl3p + clcm_lvl3v + s(CaCO3.inter.gps_x) + s(CaCO3.inter.bio4) + s(CaCO3.inter.bio18) + s(CaCO3.inter.bio3) + s(CaCO3.inter.bio7) + s(CaCO3.inter.elevation) + s(CaCO3.inter.bio6) + s(CaCO3.inter.N) + s(gps_x.inter.N) + s(CaCO3.inter.CEC) + s(gps_x.inter.bio6) + s(gps_x.inter.silt) + s(CaCO3.inter.silt) + s(CaCO3.inter.bio15) + s(CaCO3.inter.clay) + s(CaCO3.inter.CN) + s(gps_x.inter.bio15) + s(gps_x.inter.sand) + s(gps_x.inter.gdd0) + s(gps_x.inter.bio8),
        family=family,method = method,data = df_app) 
  }
  
  }
  
  
  
  
  
  if (var_rep == "BM_tot"){ 
     if (interaction == FALSE){ 
  modelgam<-gam(BM_tot ~ s(P) + s(CEC) + s(gps_y) + s(CN) + s(pH) + s(gdd10) + s(silt) + s(bio4) + s(clay) + s(bio3) + s(K) + s(gdd0) + clcm_lvl3mf + clcm_lvl3gua + clcm_lvl3ng + clcm_lvl3nial + clcm_lvl3p + clcm_lvl3v,
        family=family,method = method,data = df_app)
  
     } else {
    modelgam<-gam(BM_tot ~ s(P) + s(CEC) + s(gps_y) + s(CN) + s(pH) + s(gdd10) + s(silt) + s(bio4) + s(clay) + s(bio3) + s(K) + s(gdd0) + clcm_lvl3mf + clcm_lvl3gua + clcm_lvl3ng + clcm_lvl3nial + clcm_lvl3p + clcm_lvl3v + s(CaCO3.inter.CEC) + s(pH.inter.bio3) + s(gps_x.inter.pH) + s(CN.inter.pH) + s(pH.inter.bio4) + s(pH.inter.bio7) + s(CaCO3.inter.pH) + s(gps_x.inter.N) + s(CaCO3.inter.bio3) + s(gps_x.inter.bio4) + s(gps_x.inter.CN) + s(CaCO3.inter.clay) + s(P.inter.pH) + s(gps_x.inter.bio7) + s(hurs_mean.inter.pH) + s(gps_y.inter.hurs_mean) + s(pH.inter.bio12) + s(pH.inter.N) + s(CEC.inter.pH) + s(gps_x.inter.hurs_mean),
        family=family,method = method,data = df_app)
     }
    
  }
  
  
  
  if(var_rep == "Richesse_tot"){ 
    if (interaction == FALSE){
  modelgam<-gam(Richesse_tot ~ s(bio7) + s(CaCO3) + s(pH) + s(elevation) + s(bio18) + s(CEC) + s(P) + s(N) + s(bio15) + s(bio10) + s(gdd10) + s(bio5) + s(PET) + clcm_lvl3mf + clcm_lvl3gua + clcm_lvl3ng + clcm_lvl3nial + clcm_lvl3p + clcm_lvl3v ,
        family=family,method = method,data = df_app)
    } else { 
          modelgam<-gam(Richesse_tot ~ s(bio7) + s(CaCO3) + s(pH) + s(elevation) + s(bio18) + s(CEC) + s(P) + s(N) + s(bio15) + s(bio10) + s(gdd10) + s(bio5) + s(PET) + clcm_lvl3mf + clcm_lvl3gua + clcm_lvl3ng + clcm_lvl3nial + clcm_lvl3p + clcm_lvl3v + s(bio4.inter.pH) + s(gps_x.inter.PET) + s(gps_x.inter.hurs_mean) + s(gps_x.inter.gdd10) + s(gps_x.inter.pH) + s(pH.inter.elevation) + s(CEC.inter.hurs_mean) + s(gps_x.inter.bio10) + s(bio7.inter.pH) + s(gps_x.inter.gps_y) + s(bio4.inter.P) + s(CEC.inter.bio10) + s(bio4.inter.CaCO3) + s(pH.inter.bio18) + s(gps_x.inter.bio5) + s(gps_x.inter.CaCO3) + s(bio18.inter.hurs_mean) + s(bio4.inter.PET) + s(bio18.inter.bio10) + s(bio4.inter.CEC),
        family=family,method = method,data = df_app)
    }
  }
  
  
  # Prediction sur le jeu de validation
  pred.GAM <- predict(modelgam,newdata=as.data.frame(df_valid[,var_predicteurs]))
  
  # Calcul du RMSE pour évaluer la qualite du modele
  rmse <- sqrt(mean((df_valid[,var_rep] - pred.GAM)^2,na.rm=TRUE))

  
# Calcul du R² ajusté pour train
  r_squared_train <- calcule_R2(df_app[,var_rep],  predict(modelgam, data=df_app))
  n_train <- nrow(df_app)
  p_train <- ncol(df_app) - 1
  r_adj_train <- 1 - ((1 - r_squared_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  r_squared_test <-calcule_R2(df_valid[,col_posi],pred.GAM)
  n_test <- nrow(df_valid)
  p_test <- ncol(df_valid) - 1
  r_adj_test <- 1 - ((1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1))

  # Calcule le MAE
  MAE <- mean(abs(pred.GAM - df_valid[,var_rep]))
  
  # Round results
  rmse <- round(rmse, 2)
  r_adj_train <- round(r_adj_train, 2)
  r_adj_test <- round(r_adj_test, 2)
  MAE <- round(MAE, 2)
  
  
  results <- list(RMSE = rmse, R_squared_train = r_adj_train, R_squared_test = r_adj_test, MAE = MAE, model = modelgam, predit = pred.GAM)
  
  return(results)
}

```

-   Family = gaussian 

-   Link function = identity 

-   Method = REML

-   Tuning



## RF

-   Default model

```{r}
# Grille de hyperparametisation
RF_df_grid <- expand.grid(ntree = c(100,300,500,700,900,1000,1300,1500,1700,2000),
                       mtry = c(2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24),
                       nodesize = c(10 , 20,  30,  40,  50,  60,  70,  80))
```

-   RF model tuning by grid

  -   ntree = $100,300,500,700,900,1000,1300,1500,1700,2000$
  
  -   mtry = $2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24$
  
  -   maxnodes = $10 , 20,  30,  40,  50,  60,  70,  80,  90, 100$
  
 **Total number of models = $ntree * mtry * maxnode = `r nrow(RF_df_grid)`$ **
  
 -    Validation of models on test data
  

```{r function RF, echo=TRUE,fig.align='center'}

ForetAlea <- function(var_rep, df_app, df_valid, mtry, ntree, maxnodes) {
  col_posi <- which(names(df_app) == var_rep)
  ForeVDT <- randomForest::randomForest(df_app[-col_posi], df_app[[col_posi]], mtry = 3, ntree = ntree, maxnodes = maxnodes)
  
  # Prediction on the validation dataset
  col_posi <- which(names(df_valid) == var_rep)
  pred.RF <- predict(ForeVDT, newdata = df_valid[, -col_posi])
  
  # Calculate RMSE to evaluate model quality
  rmse <- sqrt(mean((df_valid[, col_posi] - pred.RF)^2))
  
  
  # Calcul du R² ajusté pour train
  r_squared_train <- calcule_R2(df_app[,var_rep],  predict(ForeVDT, data=df_app))
  n_train <- nrow(df_app)
  p_train <- ncol(df_app) - 1
  r_adj_train <- 1 - ((1 - r_squared_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  r_squared_test <-calcule_R2(df_valid[,col_posi],pred.RF)
  n_test <- nrow(df_valid)
  p_test <- ncol(df_valid) - 1
  r_adj_test <- 1 - ((1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1))
  
  
  # Calculate MAE
  MAE <- mean(abs(pred.RF - df_valid[, col_posi]))
  
  # Round results
  rmse <- round(rmse, 2)
  r_adj_train <- round(r_adj_train, 2)
  r_adj_test <- round(r_adj_test, 2)
  MAE <- round(MAE, 2)
  
  results <- list(RMSE = rmse, R_squared_train = r_adj_train, R_squared_test = r_adj_test, MAE = MAE, model = ForeVDT, predit = pred.RF)
  
  return(results)
}



# # Pour AB_tot  -----------------------------------------------------------------

AB_tot_RF_tuning = read.csv2("results_tuning/AB_tot_RF_tuning.csv")


AB_tot_RF_tuning = as.data.frame(AB_tot_RF_tuning)
AB_tot_RF_tuning = AB_tot_RF_tuning %>% arrange(mae)
# head(AB_tot_RF_tuning)

AB_tot_best_param = AB_tot_RF_tuning[1,]

# plot(seq(1:nrow(AB_tot_RF_tuning)), AB_tot_RF_tuning$r_squared)



df <- data.frame(x = seq(1:nrow(AB_tot_RF_tuning)), y = AB_tot_RF_tuning$r_squared)
RF_tuning = ggplot(df, aes(x = x, y = y)) +
  geom_point() +
  labs(x = "Index", y = "R Squared", title = "Abundance: R Squared over Index") +
  theme_minimal()


# ggsave("results_tuning/RF_tuning.png", plot = RF_tuning, dpi = 300)

```

<p>
  <img src="results_tuning/RF_tuning.png">
</p>



## GBM

```{r}
# Grille de hyperparametisation
GBM_df_grid <- expand.grid(n.trees = c(1000,1500,1700,2000,3000),
                       interaction.depth = c(3,  5,  6,  8, 10),
                       shrinkage = c(0.01, 0.02, 0.05, 0.001, 0.002, 0.005),
                       n.minobsinnode = c(2 , 5,  10,  30,  50,  70))
```

-   Default model

-   GBM model tuning by grid

  -   n.trees = $1000, 1500, 1700, 2000, 3000$
  
  -   shrinkage = $0.01, 0.02, 0.05, 0.001, 0.002, 0.005$
  
  -   interaction.depth = $3,  5,  6,  8, 10$
  
  -   n.minobsinnode = $2, 5,  10,  30,  50,  70$
  
  **Total number of models = $n.trees * shrinkage * interaction.depth * n.minobsinnode = `r nrow(GBM_df_grid)`$ **
  
-   Validation of models on test data
  

```{r function GBM, echo=TRUE}

GBM <- function(var_rep, df_app, df_valid,distribution = 'gaussian',n.trees ,shrinkage,interaction.depth,n.minobsinnode){

  formula <- substitute(var_rep ~ ., list(var_rep = as.name(var_rep)))

  Gradboost<-gbm(formula, data = df_app,
    distribution = distribution, 
    n.trees = n.trees,
    shrinkage = shrinkage,
    interaction.depth = interaction.depth,
    n.minobsinnode = n.minobsinnode) 
  
  # Prediction sur le jeu de validation :
   col_posi <- which(names(df_valid) == var_rep)
  prev.GBM<-predict(Gradboost,newdata=as.data.frame(df_valid[,-col_posi]))
 
  # Calcul du RMSE pour évaluer la qualité du modele
  rmse <- sqrt(mean((df_valid[,var_rep] - prev.GBM)^2))


# Calcul du R² ajusté pour train
  r_squared_train <- calcule_R2(df_app[,var_rep],  predict(Gradboost, data=df_app))
  n_train <- nrow(df_app)
  p_train <- ncol(df_app) - 1
  r_adj_train <- 1 - ((1 - r_squared_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  r_squared_test <-calcule_R2(df_valid[,col_posi],prev.GBM)
  n_test <- nrow(df_valid)
  p_test <- ncol(df_valid) - 1
  r_adj_test <- 1 - ((1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1))

  # calcule MAE
  MAE <- mean(abs(prev.GBM - df_valid[,col_posi])) 
  
    
    # Round results
  rmse <- round(rmse, 2)
  r_adj_train <- round(r_adj_train, 2)
  r_adj_test <- round(r_adj_test, 2)
  MAE <- round(MAE, 2)
  
  
  
  results <- list(RMSE = rmse, R_squared_train = r_adj_train, R_squared_test = r_adj_test, MAE = MAE, model = Gradboost, predit = prev.GBM)
  
  
  return(results)
}


# Pour AB_tot  ------------------------------------------------------------------
AB_tot_GBM_tuning = read.csv2("results_tuning/AB_tot_GBM_tuning.csv")


AB_tot_GBM_tuning = as.data.frame(AB_tot_GBM_tuning)
AB_tot_GBM_tuning = AB_tot_GBM_tuning %>% arrange(mae)
# head(AB_tot_GBM_tuning)
AB_tot_best_param = AB_tot_GBM_tuning[1,]


df <- data.frame(x = seq(1:nrow(AB_tot_GBM_tuning)), y = AB_tot_GBM_tuning$r_squared)
GBM_tuning = ggplot(df, aes(x = x, y = y)) +
  geom_point() +
  labs(x = "Index", y = "R Squared", title = "Abundance: R Squared over Index") +
  theme_minimal()


# ggsave("results_tuning/GBM_tuning.png", plot = GBM_tuning, dpi = 300)

```

<p>
  <img src="results_tuning/GBM_tuning.png">
</p>


## ANN
-   Default model

```{r,include=TRUE}
n <- neuralnet(AB_tot~ clcm_lvl3mf +clcm_lvl3gua +clcm_lvl3ng +clcm_lvl3nial +clcm_lvl3p +clcm_lvl3v + CaCO3 +gps_x +bio7 +bio4 +N +bio3 +elevation +gps_y +bio15 +bio18 +CN +P +gdd0 +bio6 +sand +clay +silt +CEC +bio8,
               data = AB_tot_train,
               # hidden = c(1),
               linear.output = F,
               lifesign = 'full',
               rep=1)

plot(n,
     col.hidden = 'black',
     col.hidden.synapse = 'black',
     show.weights = F,
     information = F,
     fill = 'lightblue')




ANN_1 <- keras_model_sequential()
ANN_1 %>% 
  layer_dense(units = 1, activation = 'relu', input_shape = c(25)) %>%
  layer_dense(units = 1)

# Compile
ANN_1 %>% compile(loss = 'mse',
                  optimizer = 'rmsprop',
                  metrics = 'mae')
summary(ANN_1)

# Fit ANN_1
# myANN_1 <- ANN_1 %>%
#   fit(training,
#       trainingtarget,
#       epochs = 100,
#       #batch_size = 1,
#       validation_split = 0.2)
# plot_ANN1 = plot(myANN_1)

# ggsave("models/plot_ANN_default_model.png", plot = plot_ANN1, dpi = 300)

```


<p>
  <img src="models/ANN_default_model.png">
</p>



<p>
  <img src="models/plot_ANN_default_model.png">
</p>



-   Tunning

runs <- tuning_run("Experiment.R",
                    flags = list(dense_units1 = c(32, 64),
                                 dense_units2 = c(16, 32),
                                 dense_units3 = c(8, 16),
                                 dense_units4 = c(4, 8),
                                 dropout1 = c(0.4, 0.5),
                                 dropout1 = c(0.3, 0.4),
                                 dropout1 = c(0.2, 0.3),
                                 dropout1 = c(0.1, 0.2),
                                 batch_size = c(32, 64)))

-   hidden = c(32,32,16,8) 

```{r,include=TRUE}
n <- neuralnet(AB_tot~ clcm_lvl3mf +clcm_lvl3gua +clcm_lvl3ng +clcm_lvl3nial +clcm_lvl3p +clcm_lvl3v + CaCO3 +gps_x +bio7 +bio4 +N +bio3 +elevation +gps_y +bio15 +bio18 +CN +P +gdd0 +bio6 +sand +clay +silt +CEC +bio8,
               data = AB_tot_train,
               hidden = c(32,32,16,8),
               linear.output = F,
               lifesign = 'full',
               rep=1)

plot(n,
     col.hidden = 'black',
     col.hidden.synapse = 'black',
     show.weights = F,
     information = F,
     fill = 'lightblue')

# Pour AB_tot  ------------------------------------------------------------------
var_rep="AB_tot"
AB_tot_ANN_tuning = read.csv2("results_tuning/AB_tot_ANN_tuning.csv")

# Best hyperparameter values
AB_tot_ANN_tuning = as.data.frame(AB_tot_ANN_tuning)
AB_tot_ANN_tuning = AB_tot_ANN_tuning %>% arrange(metric_val_mae)
# head(AB_tot_ANN_tuning[,2:16])

best_param = AB_tot_ANN_tuning[1,]


dense_units1 = as.numeric(best_param$flag_dense_units1)
dense_units2 = as.numeric(best_param$flag_dense_units2)
dense_units3 = as.numeric(best_param$flag_dense_units3)
dense_units4 = as.numeric(best_param$flag_dense_units4)

dropout1 =as.numeric(best_param$flag_dropout1)
dropout2 =as.numeric(best_param$flag_dropout2)
dropout3 =as.numeric(best_param$flag_dropout3)
dropout4 =as.numeric(best_param$flag_dropout4)

batch_size =as.numeric(best_param$flag_batch_size)


# AB_tot TUNE MODEL
ANN_tune_AB_tot <- keras_model_sequential()
ANN_tune_AB_tot %>% 
  layer_dense(units = dense_units1, activation = 'relu', input_shape = c(25)) %>%
  layer_dropout(rate = dropout1)  %>%
  layer_dense(units = dense_units2, activation = 'relu') %>%
  layer_dropout(rate = dropout2)  %>%
  layer_dense(units = dense_units3, activation = 'relu') %>%
  layer_dropout(rate = dropout3)  %>%
  layer_dense(units = dense_units4, activation = 'relu') %>%
  layer_dropout(rate = dropout4)  %>%
  layer_dense(units = 1)


# Compile
ANN_tune_AB_tot %>% compile(loss = 'mse',
                  optimizer = 'rmsprop',
                  metrics = 'mae')

summary(ANN_tune_AB_tot)
# #  callback EarlyStopping
# mon_callback <- callback_early_stopping(
#   monitor = "val_mae",  # Surveille la perte sur l'ensemble de validation
#   patience = 10,         # Nombre d'époques sans amélioration avant l'arrêt
#   restore_best_weights = TRUE  # Restaure les poids du meilleur modèle
# )
# 
# 
# # Fit ANN_tune_AB_tot
# myANN_tune_AB_tot <- ANN_tune_AB_tot %>%
#   fit(training,
#       trainingtarget,
#       epochs = 100,
#       batch_size = batch_size,
#       validation_split = 0.2,
#       #callbacks = list(mon_callback)
#       )


```

<p>
  <img src="models/ANN_tuning_model.png">
</p>


<p>
  <img src="Results/fig_ANN_tune_BM_tot.png">
</p>


<!--
## Tableau des output
```{r output,echo=FALSE}
# # Pour AB_tot
# AB_tot_RMSE_Results<-matrix(0,ncol=6,nrow=n_sim,dimnames=list(1:n_sim,c("RMSE_GLM", "RMSE_GAM", "RMSE_RF","RMSE_GBM","RMSE_ANN","RMS_BestMod")))
# AB_tot_RMSE_Results<-as.data.frame(AB_tot_RMSE_Results)
# 
# AB_tot_R_Results<-matrix(0,ncol=6,nrow=n_sim,dimnames=list(1:n_sim,c("R_GLM", "R_GAM", "R_RF","R_GBM","R_ANN","R_BestMod")))
# AB_tot_R_Results<-as.data.frame(AB_tot_R_Results)
# 
# 
# 
# # Pour BM_tot
# BM_tot_RMSE_Results<- AB_tot_RMSE_Results
# 
# BM_tot_R_Results<-AB_tot_R_Results
# 
# 
# 
# # Pour Richesse_tot
# Richesse_tot_RMSE_Results<-AB_tot_RMSE_Results
# 
# Richesse_tot_R_Results<-AB_tot_R_Results
# 
# 
# head(AB_tot_RMSE_Results)
# head(AB_tot_R_Results)

```

-->

## Compilation pour chaque algoritme


-   GLM
```{r Compile.GLM}
# # Pour AB_tot ------------------------------------------------------------------

GLM_result_AB_tot = GLM(var_rep ="AB_tot", 
                             df_app=AB_tot_train, 
                             df_valid = AB_tot_test,
                             family = 'gaussian')
# GLM_result_AB_tot$RMSE
# GLM_result_AB_tot$MAE
# GLM_result_AB_tot$R_squared_train
# GLM_result_AB_tot$R_squared_test
# GLM_result_AB_tot$predit
# GLM_result_AB_tot$model



 ### interaction ###
# GLM_result_AB_tot_inter = GLM(var_rep ="AB_tot", 
#                              df_app=AB_tot_inter_train, 
#                              df_valid = AB_tot_inter_test ,
#                              family = 'gaussian')
# GLM_result_AB_tot_inter$RMSE
# GLM_result_AB_tot_inter$MAE
# GLM_result_AB_tot_inter$R_squared
# GLM_result_AB_tot_inter$predit
# GLM_result_AB_tot_inter$model




# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(data_mod$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- data_mod[lignes, ]  # Données d'entraînement
# b_df_test <- data_mod[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # GLM
# GLM_reslt_AB_tot = GLM(var_rep ="AB_tot",df_app = b_df_train, df_valid = b_df_test,family = 'gaussian')
# 
# AB_tot_RMSE_Results[i,"RMSE_GLM"] <- GLM_reslt_AB_tot$RMSE
# 
# AB_tot_R_Results[i,"R_GLM"] <- GLM_reslt_AB_tot$R_squared
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(AB_tot_RMSE_Results)
# # head(AB_tot_R_Results)
# write.csv2(x=AB_tot_RMSE_Results$RMSE_GLM, file = "Results/GLM_AB_tot_RMSE.csv")
# write.csv2(x=AB_tot_R_Results$R_GLM, file = "Results/GLM_AB_tot_R.csv")





# # Pour BM_tot ------------------------------------------------------------------

GLM_result_BM_tot = GLM(var_rep ="BM_tot", 
                             df_app=BM_tot_train, 
                             df_valid = BM_tot_test,
                             family = 'gaussian')
# GLM_result_BM_tot$RMSE
# GLM_result_BM_tot$MAE
# GLM_result_BM_tot$R_squared
# GLM_result_BM_tot$predit
# GLM_result_BM_tot$model




 ### interaction ###
# GLM_result_BM_tot_inter = GLM(var_rep ="BM_tot", 
#                              df_app=BM_tot_inter_train, 
#                              df_valid = BM_tot_inter_test ,
#                              family = 'gaussian')
# GLM_result_BM_tot_inter$RMSE
# GLM_result_BM_tot_inter$MAE
# GLM_result_BM_tot_inter$R_squared
# GLM_result_BM_tot_inter$predit
# GLM_result_BM_tot_inter$model




# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(data_mod$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- data_mod[lignes, ]  # Données d'entraînement
# b_df_test <- data_mod[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # GLM
# GLM_reslt_BM_tot = GLM(var_rep ="BM_tot",df_app = drop_na(b_df_train), df_valid = drop_na(b_df_test),family = 'gaussian')
# 
# BM_tot_RMSE_Results[i,"RMSE_GLM"] <- GLM_reslt_BM_tot$RMSE
# 
# BM_tot_R_Results[i,"R_GLM"] <- GLM_reslt_BM_tot$R_squared
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(BM_tot_RMSE_Results)
# # head(BM_tot_R_Results)
# write.csv2(x=BM_tot_RMSE_Results$RMSE_GLM, file = "Results/GLM_BM_tot_RMSE.csv")
# write.csv2(x=BM_tot_R_Results$R_GLM, file = "Results/GLM_BM_tot_R.csv")





# # Pour Richesse_tot ------------------------------------------------------------------

GLM_result_Richesse_tot = GLM(var_rep ="Richesse_tot", 
                             df_app=Richesse_tot_train, 
                             df_valid = Richesse_tot_test,
                             family = 'gaussian')
# GLM_result_Richesse_tot$RMSE
# GLM_result_Richesse_tot$MAE
# GLM_result_Richesse_tot$R_squared
# GLM_result_Richesse_tot$predit
# GLM_result_Richesse_tot$model



 ### interaction ###
# GLM_result_Richesse_tot_inter = GLM(var_rep ="Richesse_tot", 
#                              df_app=Richesse_tot_inter_train, 
#                              df_valid = Richesse_tot_inter_test ,
#                              family = 'gaussian')
# GLM_result_Richesse_tot_inter$RMSE
# GLM_result_Richesse_tot_inter$MAE
# GLM_result_Richesse_tot_inter$R_squared
# GLM_result_Richesse_tot_inter$predit
# GLM_result_Richesse_tot_inter$model



# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(data_mod$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- data_mod[lignes, ]  # Données d'entraînement
# b_df_test <- data_mod[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # GLM
# GLM_reslt_Richesse_tot = GLM(var_rep ="Richesse_tot",df_app = b_df_train, df_valid = b_df_test,family = 'gaussian')
# 
# Richesse_tot_RMSE_Results[i,"RMSE_GLM"] <- GLM_reslt_Richesse_tot$RMSE
# 
# Richesse_tot_R_Results[i,"R_GLM"] <- GLM_reslt_Richesse_tot$R_squared
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(Richesse_tot_RMSE_Results)
# # head(Richesse_tot_R_Results)
# write.csv2(x=Richesse_tot_RMSE_Results$RMSE_GLM, file = "Results/GLM_Richesse_tot_RMSE.csv")
# write.csv2(x=Richesse_tot_R_Results$R_GLM, file = "Results/GLM_Richesse_tot_R.csv")

```


-   GAM
```{r Compile.GAM}
# # Pour AB_tot ------------------------------------------------------------------

GAM_result_AB_tot = GAM(var_rep ="AB_tot", 
                             df_app=AB_tot_train, 
                             df_valid = AB_tot_test,
                             family = 'gaussian',
                             method = "REML")
# GAM_result_AB_tot$RMSE
# GAM_result_AB_tot$MAE
# GAM_result_AB_tot$R_squared
# GAM_result_AB_tot$predit
# GAM_result_AB_tot$model

# mod_gam1_ab = GAM_result_AB_tot$model
# cv <- gam.check(GAM_result_AB_tot$model)
# print(cv)
# 
# plot(mod_gam1_ab, pages = 1, seWithMean = TRUE)
# plot(mod_gam1_ab, residuals = TRUE, pch = 1)
# plot(ggeffects::ggpredict(mod_gam1_ab), facets = TRUE)
# gratia::draw(mod_gam1_ab, residuals = TRUE)
# 
# 
# # Verification
# par(mfrow = c(2, 2))
# gam.check(mod_gam1_ab)
# shapiro.test(mod_gam1_ab$res)
# concurvity(mod_gam1_ab,full = TRUE)
# concurvity(mod_gam1_ab,full = FALSE)


### interaction ###
# GAM_result_AB_tot_inter = GAM(var_rep ="AB_tot", 
#                              df_app=AB_tot_inter_train, 
#                              df_valid = AB_tot_inter_test ,
#                              family = 'gaussian',
#                              method = "REML",
#                               interaction = TRUE)

# GAM_result_AB_tot_inter$RMSE
# GAM_result_AB_tot_inter$MAE
# GAM_result_AB_tot_inter$R_squared
# GAM_result_AB_tot_inter$predit
# GAM_result_AB_tot_inter$model

# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(data_mod$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- data_mod[lignes, ]  # Données d'entraînement
# b_df_test <- data_mod[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # GAM
# GAM_reslt_AB_tot <- GAM(var_rep ="AB_tot",df_app = b_df_train, df_valid = b_df_test,family = 'gaussian',method = "REML")
# 
# AB_tot_RMSE_Results[i,"RMSE_GAM"] = GAM_reslt_AB_tot$RMSE
# 
# AB_tot_R_Results[i,"R_GAM"] = GAM_reslt_AB_tot$R_squared
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(AB_tot_RMSE_Results)
# # head(AB_tot_R_Results)
# write.csv2(x=AB_tot_RMSE_Results$RMSE_GAM, file = "Results/GAM_AB_tot_RMSE.csv")
# write.csv2(x=AB_tot_R_Results$R_GAM, file = "Results/GAM_AB_tot_R.csv")




# # Pour BM_tot ------------------------------------------------------------------
GAM_result_BM_tot = GAM(var_rep ="BM_tot", 
                             df_app=BM_tot_train, 
                             df_valid = BM_tot_test,
                             family = 'gaussian',
                             method = "REML")
# GAM_result_BM_tot$RMSE
# GAM_result_BM_tot$MAE
# GAM_result_BM_tot$R_squared
# GAM_result_BM_tot$predit
# GAM_result_BM_tot$model



### intarcation ###
# GAM_result_BM_tot_inter = GAM(var_rep ="BM_tot", 
#                              df_app=BM_tot_inter_train, 
#                              df_valid = BM_tot_inter_test ,
#                              family = 'gaussian',
#                              method = "REML",
#                               interaction = TRUE)
# GAM_result_BM_tot_inter$RMSE
# GAM_result_BM_tot_inter$MAE
# GAM_result_BM_tot_inter$R_squared
# GAM_result_BM_tot_inter$predit
# GAM_result_BM_tot_inter$model





# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(data_mod$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- data_mod[lignes, ]  # Données d'entraînement
# b_df_test <- data_mod[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # GAM
# GAM_reslt_BM_tot <- GAM(var_rep ="BM_tot",df_app = drop_na(b_df_train), df_valid = drop_na(b_df_test),family = 'gaussian',method = "REML")
# 
# BM_tot_RMSE_Results[i,"RMSE_GAM"] = GAM_reslt_BM_tot$RMSE
# 
# BM_tot_R_Results[i,"R_GAM"] = GAM_reslt_BM_tot$R_squared
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(BM_tot_RMSE_Results)
# # head(BM_tot_R_Results)
# write.csv2(x=BM_tot_RMSE_Results$RMSE_GAM, file = "Results/GAM_BM_tot_RMSE.csv")
# write.csv2(x=BM_tot_R_Results$R_GAM, file = "Results/GAM_BM_tot_R.csv")




# # Pour Richesse_tot ------------------------------------------------------------------
GAM_result_Richesse_tot = GAM(var_rep ="Richesse_tot", 
                             df_app=Richesse_tot_train, 
                             df_valid = Richesse_tot_test,
                             family = 'gaussian',
                             method = "REML")
# GAM_result_Richesse_tot$RMSE
# GAM_result_Richesse_tot$MAE
# GAM_result_Richesse_tot$R_squared
# GAM_result_Richesse_tot$predit
# GAM_result_Richesse_tot$model



### intarcation ###
# GAM_result_Richesse_tot_inter = GAM(var_rep ="Richesse_tot", 
#                              df_app=Richesse_tot_inter_train, 
#                              df_valid = Richesse_tot_inter_test ,
#                              family = 'gaussian',
#                              method = "REML",
#                               interaction = TRUE)
# GAM_result_Richesse_tot_inter$RMSE
# GAM_result_Richesse_tot_inter$MAE
# GAM_result_Richesse_tot_inter$R_squared
# GAM_result_Richesse_tot_inter$predit
# GAM_result_Richesse_tot_inter$model




# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(data_mod$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- data_mod[lignes, ]  # Données d'entraînement
# b_df_test <- data_mod[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # GAM
# GAM_reslt_Richesse_tot <- GAM(var_rep ="Richesse_tot",df_app = b_df_train, df_valid = b_df_test,family = 'gaussian',method = "REML")
# 
# Richesse_tot_RMSE_Results[i,"RMSE_GAM"] = GAM_reslt_Richesse_tot$RMSE
# 
# Richesse_tot_R_Results[i,"R_GAM"] = GAM_reslt_Richesse_tot$R_squared
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(Richesse_tot_RMSE_Results)
# # head(Richesse_tot_R_Results)
# write.csv2(x=Richesse_tot_RMSE_Results$RMSE_GAM, file = "Results/GAM_Richesse_tot_RMSE.csv")
# write.csv2(x=Richesse_tot_R_Results$R_GAM, file = "Results/GAM_Richesse_tot_R.csv")
```


-   RF
```{r Compile.RF}
# # Pour AB_tot  -----------------------------------------------------------------

AB_tot_RF_tuning = read.csv2("results_tuning/AB_tot_RF_tuning.csv")


AB_tot_RF_tuning = as.data.frame(AB_tot_RF_tuning)
AB_tot_RF_tuning = AB_tot_RF_tuning %>% arrange(mae)
# head(AB_tot_RF_tuning)

AB_tot_best_param = AB_tot_RF_tuning[1,]

# plot(seq(1:nrow(AB_tot_RF_tuning)), AB_tot_RF_tuning$r_squared)
# Best hyperparameter values
AB_tot_best_mtry = AB_tot_best_param$mtry
AB_tot_best_ntree = AB_tot_best_param$ntree
AB_tot_best_maxnodes = AB_tot_best_param$maxnode


RF_result_AB_tot = ForetAlea(var_rep ="AB_tot", 
                             df_app=AB_tot_train, 
                             df_valid = AB_tot_test,
                             mtry = AB_tot_best_mtry,
                             ntree= AB_tot_best_ntree,
                             maxnodes = AB_tot_best_maxnodes)
# RF_result_AB_tot$RMSE
# RF_result_AB_tot$MAE
# RF_result_AB_tot$R_squared
# RF_result_AB_tot$predit
# RF_result_AB_tot$model



### interaction ###
# RF_result_AB_tot_inter = ForetAlea(var_rep ="AB_tot", 
#                              df_app=AB_tot_inter_train, 
#                              df_valid = AB_tot_inter_test ,
#                              mtry = AB_tot_best_mtry,
#                              ntree= AB_tot_best_ntree,
#                              maxnodes = AB_tot_best_maxnodes)
# RF_result_AB_tot_inter$RMSE
# RF_result_AB_tot_inter$MAE
# RF_result_AB_tot_inter$R_squared
# RF_result_AB_tot_inter$predit
# RF_result_AB_tot_inter$model




  

# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(df_mod_AB_tot$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- df_mod_AB_tot[lignes, ]  # Données d'entraînement
# b_df_test <- df_mod_AB_tot[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # RF
# RF_result = ForetAlea(var_rep ="AB_tot", df_app=b_df_train[,c("AB_tot",best_20_AB_tot)], df_valid = b_df_test[,c("AB_tot",best_20_AB_tot)],mtry =9,ntree= 2000)
# 
# AB_tot_RMSE_Results[i,"RMSE_RF"] <- RF_result$RMSE
# 
# AB_tot_R_Results[i,"R_RF"] <- RF_result$R_squared
# 
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(AB_tot_RMSE_Results)
# # head(AB_tot_R_Results)
# # mean(AB_tot_RMSE_Results$RMSE_RF)
# # mean(AB_tot_R_Results$R_RF)
# 
# write.csv2(x=AB_tot_RMSE_Results$RMSE_RF, file = "Results/RF_AB_tot_RMSE.csv")
# write.csv2(x=AB_tot_R_Results$R_RF, file = "Results/RF_AB_tot_R.csv")


# # Pour BM_tot  -----------------------------------------------------------------

BM_tot_RF_tuning = read.csv2("results_tuning/BM_tot_RF_tuning.csv")


BM_tot_RF_tuning = as.data.frame(BM_tot_RF_tuning)
BM_tot_RF_tuning = BM_tot_RF_tuning %>% arrange(mae)
# head(BM_tot_RF_tuning)

BM_tot_best_param = BM_tot_RF_tuning[1,]

# plot(seq(1:nrow(BM_tot_RF_tuning)), BM_tot_RF_tuning$r_squared)
# Best hyperparameter values
BM_tot_best_mtry = BM_tot_best_param$mtry
BM_tot_best_ntree = BM_tot_best_param$ntree
BM_tot_best_maxnodes = BM_tot_best_param$maxnode
  
RF_result_BM_tot = ForetAlea(var_rep ="BM_tot", 
                             df_app=BM_tot_train, 
                             df_valid = BM_tot_test,
                             mtry = BM_tot_best_mtry,
                             ntree= BM_tot_best_ntree,
                             maxnodes = BM_tot_best_maxnodes)
# RF_result_BM_tot$RMSE
# RF_result_BM_tot$MAE
# RF_result_BM_tot$R_squared
# RF_result_BM_tot$predit
# RF_result_BM_tot$model



### interaction ###
# RF_result_BM_tot_inter = ForetAlea(var_rep ="BM_tot", 
#                              df_app=BM_tot_inter_train, 
#                              df_valid = BM_tot_inter_test ,
#                              mtry = BM_tot_best_mtry,
#                              ntree= BM_tot_best_ntree,
#                              maxnodes = BM_tot_best_maxnodes)
# RF_result_BM_tot_inter$RMSE
# RF_result_BM_tot_inter$MAE
# RF_result_BM_tot_inter$R_squared
# RF_result_BM_tot_inter$predit
# RF_result_BM_tot_inter$model




# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(df_mod_BM_tot$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- df_mod_BM_tot[lignes, ]  # Données d'entraînement
# b_df_test <- df_mod_BM_tot[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # RF
# RF_result = ForetAlea(var_rep ="BM_tot", df_app=b_df_train[,c("BM_tot",best_20_BM_tot)], df_valid = b_df_test[,c("BM_tot",best_20_BM_tot)],mtry =9,ntree= 2000)
# 
# BM_tot_RMSE_Results[i,"RMSE_RF"] <- RF_result$RMSE
# 
# BM_tot_R_Results[i,"R_RF"] <- RF_result$R_squared
# 
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(BM_tot_RMSE_Results)
# # head(BM_tot_R_Results)
# # mean(BM_tot_RMSE_Results$RMSE_RF)
# # mean(BM_tot_R_Results$R_RF)
# 
# write.csv2(x=BM_tot_RMSE_Results$RMSE_RF, file = "Results/RF_BM_tot_RMSE.csv")
# write.csv2(x=BM_tot_RMSE_Results$R_RF, file = "Results/RF_BM_tot_R.csv")




# # Pour Richesse_tot  -----------------------------------------------------------

Richesse_tot_RF_tuning = read.csv2("results_tuning/Richesse_tot_RF_tuning.csv")


Richesse_tot_RF_tuning = as.data.frame(Richesse_tot_RF_tuning)
Richesse_tot_RF_tuning = Richesse_tot_RF_tuning %>% arrange(mae)
# head(Richesse_tot_RF_tuning)

Richesse_tot_best_param = Richesse_tot_RF_tuning[1,]


# Best hyperparameter values
Richesse_tot_best_mtry = Richesse_tot_best_param$mtry
Richesse_tot_best_ntree = Richesse_tot_best_param$ntree
Richesse_tot_best_maxnodes = Richesse_tot_best_param$maxnode
  
RF_result_Richesse_tot = ForetAlea(var_rep ="Richesse_tot", 
                             df_app=Richesse_tot_train, 
                             df_valid = Richesse_tot_test,
                             mtry = Richesse_tot_best_mtry,
                             ntree= Richesse_tot_best_ntree,
                             maxnodes = Richesse_tot_best_maxnodes)
# RF_result_Richesse_tot$RMSE
# RF_result_Richesse_tot$MAE
# RF_result_Richesse_tot$R_squared
# RF_result_Richesse_tot$predit
# RF_result_Richesse_tot$model



### interaction ###
# RF_result_Richesse_tot_inter = ForetAlea(var_rep ="Richesse_tot", 
#                              df_app=Richesse_tot_inter_train, 
#                              df_valid = Richesse_tot_inter_test ,
#                              mtry = Richesse_tot_best_mtry,
#                              ntree= Richesse_tot_best_ntree,
#                              maxnodes = Richesse_tot_best_maxnodes)
# RF_result_Richesse_tot_inter$RMSE
# RF_result_Richesse_tot_inter$MAE
# RF_result_Richesse_tot_inter$R_squared
# RF_result_Richesse_tot_inter$predit
# RF_result_Richesse_tot_inter$model




# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(df_mod_Richesse_tot$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- df_mod_Richesse_tot[lignes, ]  # Données d'entraînement
# b_df_test <- df_mod_Richesse_tot[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # RF
# RF_result = ForetAlea(var_rep ="Richesse_tot", df_app=b_df_train[,c("Richesse_tot",best_20_Richesse_tot)], df_valid = b_df_test[,c("Richesse_tot",best_20_Richesse_tot)],mtry =9,ntree= 2000)
# 
# Richesse_tot_RMSE_Results[i,"RMSE_RF"] <- RF_result$RMSE
# 
# Richesse_tot_R_Results[i,"R_RF"] <- RF_result$R_squared
# 
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(Richesse_tot_RMSE_Results)
# # head(Richesse_tot_R_Results)
# # mean(Richesse_tot_RMSE_Results$RMSE_RF)
# # mean(Richesse_tot_R_Results$R_RF)
# 
# write.csv2(x=Richesse_tot_RMSE_Results$RMSE_RF, file = "Results/RF_Richesse_tot_RMSE.csv")
# write.csv2(x=Richesse_tot_R_Results$R_RF, file = "Results/RF_Richesse_tot_R.csv")
```


-   GBM
```{r Compile.GBM}
# Pour AB_tot  ------------------------------------------------------------------
AB_tot_GBM_tuning = read.csv2("results_tuning/AB_tot_GBM_tuning.csv")


AB_tot_GBM_tuning = as.data.frame(AB_tot_GBM_tuning)
AB_tot_GBM_tuning = AB_tot_GBM_tuning %>% arrange(mae)
# head(AB_tot_GBM_tuning)
AB_tot_best_param = AB_tot_GBM_tuning[1,]


# Best hyperparameter values
AB_tot_best_n.trees = AB_tot_best_param$n.trees
AB_tot_best_shrinkage = AB_tot_best_param$shrinkage
AB_tot_best_interaction.depth = AB_tot_best_param$interaction.depth
AB_tot_best_n.minobsinnode = AB_tot_best_param$n.minobsinnode


GBM_result_AB_tot =  GBM(var_rep ="AB_tot", 
                         df_app=AB_tot_train, 
                         df_valid = AB_tot_test,
                         distribution = 'gaussian',
                         n.trees = AB_tot_best_n.trees,
                         shrinkage = AB_tot_best_shrinkage,
                         interaction.depth = AB_tot_best_interaction.depth,
                         n.minobsinnode = AB_tot_best_n.minobsinnode)

# GBM_result_AB_tot$RMSE
# GBM_result_AB_tot$MAE
# GBM_result_AB_tot$R_squared
# GBM_result_AB_tot$predit
# GBM_result_AB_tot$model


# summary(GBM_result_AB_tot$model)
# best.iter <- gbm.perf(GBM_result_AB_tot$model, method = "cv")
# summary(GBM_result_AB_tot$model, n.trees = best.iter)



### interaction ###
# GBM_result_AB_tot_inter =  GBM(var_rep ="AB_tot", 
#                          df_app=AB_tot_inter_train, 
#                          df_valid = AB_tot_inter_test,
#                          distribution = 'gaussian',
#                          n.trees = AB_tot_best_n.trees,
#                          shrinkage = AB_tot_best_shrinkage,
#                          interaction.depth = AB_tot_best_interaction.depth,
#                          n.minobsinnode = AB_tot_best_n.minobsinnode)

# GBM_result_AB_tot_inter$RMSE
# GBM_result_AB_tot_inter$MAE
# GBM_result_AB_tot_inter$R_squared
# GBM_result_AB_tot_inter$predit
# GBM_result_AB_tot_inter$model






# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(df_mod_AB_tot$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- df_mod_AB_tot [lignes, ]  # Données d'entraînement
# b_df_test <- df_mod_AB_tot [-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # GBM
# GBM_result = GBM(var_rep ="AB_tot", df_app=b_df_train[,c("AB_tot",best_20_AB_tot)], df_valid = b_df_test[,c("AB_tot",best_20_AB_tot)],distribution = 'gaussian',n.trees = 6000,shrinkage = 0.01,interaction.depth = 7,n.minobsinnode = 15)
# 
# AB_tot_RMSE_Results[i,"RMSE_GBM"] <- GBM_result$RMSE
# 
# AB_tot_R_Results[i,"R_GBM"] <- GBM_result$R_squared
# 
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(AB_tot_RMSE_Results)
# # head(AB_tot_R_Results)
# write.csv2(x=AB_tot_RMSE_Results$RMSE_GBM, file = "Results/GBM_AB_tot_RMSE.csv")
# write.csv2(x=AB_tot_R_Results$R_GBM, file = "Results/GBM_AB_tot_R.csv")




# Pour BM_tot ------------------------------------------------------------------

BM_tot_GBM_tuning = read.csv2("results_tuning/BM_tot_GBM_tuning.csv")


BM_tot_GBM_tuning = as.data.frame(BM_tot_GBM_tuning)
BM_tot_GBM_tuning = BM_tot_GBM_tuning %>% arrange(mae)
# head(BM_tot_GBM_tuning)
BM_tot_best_param = BM_tot_GBM_tuning[1,]


# Best hyperparameter values
BM_tot_best_n.trees = BM_tot_best_param$n.trees
BM_tot_best_shrinkage = BM_tot_best_param$shrinkage
BM_tot_best_interaction.depth = BM_tot_best_param$interaction.depth
BM_tot_best_n.minobsinnode = BM_tot_best_param$n.minobsinnode


GBM_result_BM_tot =  GBM(var_rep ="BM_tot", 
                         df_app=BM_tot_train, 
                         df_valid = BM_tot_test,
                         distribution = 'gaussian',
                         n.trees = BM_tot_best_n.trees,
                         shrinkage = BM_tot_best_shrinkage,
                         interaction.depth = BM_tot_best_interaction.depth,
                         n.minobsinnode = BM_tot_best_n.minobsinnode)

# GBM_result_BM_tot$RMSE
# GBM_result_BM_tot$MAE
# GBM_result_BM_tot$R_squared
# GBM_result_BM_tot$predit
# GBM_result_BM_tot$model




### interaction ###
# GBM_result_BM_tot_inter =  GBM(var_rep ="BM_tot", 
#                          df_app=BM_tot_inter_train, 
#                          df_valid = BM_tot_inter_test,
#                          distribution = 'gaussian',
#                          n.trees = BM_tot_best_n.trees,
#                          shrinkage = BM_tot_best_shrinkage,
#                          interaction.depth = BM_tot_best_interaction.depth,
#                          n.minobsinnode = BM_tot_best_n.minobsinnode)

# GBM_result_BM_tot_inter$RMSE
# GBM_result_BM_tot_inter$MAE
# GBM_result_BM_tot_inter$R_squared
# GBM_result_BM_tot_inter$predit
# GBM_result_BM_tot_inter$model




# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(df_mod_BM_tot$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- df_mod_BM_tot [lignes, ]  # Données d'entraînement
# b_df_test <- df_mod_BM_tot [-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # GBM
# GBM_result = GBM(var_rep ="BM_tot", df_app=b_df_train[,c("BM_tot",best_20_BM_tot)], df_valid = b_df_test[,c("BM_tot",best_20_BM_tot)],distribution = 'gaussian',n.trees = 6000,shrinkage = 0.01,interaction.depth = 7,n.minobsinnode = 15)
# 
# BM_tot_RMSE_Results[i,"RMSE_GBM"] <- GBM_result$RMSE
# 
# BM_tot_R_Results[i,"R_GBM"] <- GBM_result$R_squared
# 
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# stopCluster(cl)
# head(BM_tot_RMSE_Results)
# head(BM_tot_R_Results)
# write.csv2(x=BM_tot_RMSE_Results$RMSE_GBM, file = "Results/GBM_BM_tot_RMSE.csv")
# write.csv2(x=BM_tot_R_Results$R_GBM, file = "Results/GBM_BM_tot_R.csv")





# # Pour Richesse_tot ------------------------------------------------------------------

Richesse_tot_GBM_tuning = read.csv2("results_tuning/Richesse_tot_GBM_tuning.csv")


Richesse_tot_GBM_tuning = as.data.frame(Richesse_tot_GBM_tuning)
Richesse_tot_GBM_tuning = Richesse_tot_GBM_tuning %>% arrange(mae)
# head(Richesse_tot_GBM_tuning)
Richesse_tot_best_param = Richesse_tot_GBM_tuning[1,]


# Best hyperparameter values
Richesse_tot_best_n.trees = Richesse_tot_best_param$n.trees
Richesse_tot_best_shrinkage = Richesse_tot_best_param$shrinkage
Richesse_tot_best_interaction.depth = Richesse_tot_best_param$interaction.depth
Richesse_tot_best_n.minobsinnode = Richesse_tot_best_param$n.minobsinnode


GBM_result_Richesse_tot =  GBM(var_rep ="Richesse_tot", 
                         df_app=Richesse_tot_train, 
                         df_valid = Richesse_tot_test,
                         distribution = 'gaussian',
                         n.trees = Richesse_tot_best_n.trees,
                         shrinkage = Richesse_tot_best_shrinkage,
                         interaction.depth = Richesse_tot_best_interaction.depth,
                         n.minobsinnode = Richesse_tot_best_n.minobsinnode)

# GBM_result_Richesse_tot$RMSE
# GBM_result_Richesse_tot$MAE
# GBM_result_Richesse_tot$R_squared
# GBM_result_Richesse_tot$predit
# GBM_result_Richesse_tot$model


### interaction ###
# GBM_result_Richesse_tot_inter =  GBM(var_rep ="Richesse_tot", 
#                          df_app=Richesse_tot_inter_train, 
#                          df_valid = Richesse_tot_inter_test,
#                          distribution = 'gaussian',
#                          n.trees = Richesse_tot_best_n.trees,
#                          shrinkage = Richesse_tot_best_shrinkage,
#                          interaction.depth = Richesse_tot_best_interaction.depth,
#                          n.minobsinnode = Richesse_tot_best_n.minobsinnode)

# GBM_result_Richesse_tot_inter$RMSE
# GBM_result_Richesse_tot_inter$MAE
# GBM_result_Richesse_tot_inter$R_squared
# GBM_result_Richesse_tot_inter$predit
# GBM_result_Richesse_tot_inter$model




# temps1=Sys.time()
# set.seed(1234)
# 
# # cl <- detectCores() %>% -1 %>% makeCluster
# # registerDoParallel(cl)
# 
# for (i in 1:n_sim){
# lignes <- createDataPartition(df_mod_Richesse_tot$clcm_lvl3, p = 0.8, list = FALSE)
# 
# # Séparer les données en ensembles d'entraînement et de test
# b_df_train <- df_mod_Richesse_tot[lignes, ]  # Données d'entraînement
# b_df_test <- df_mod_Richesse_tot[-lignes, ]  # Données de test
# b_df_train = droplevels(b_df_train)
# b_df_test = droplevels(b_df_test)
# 
# # GBM
# GBM_result = GBM(var_rep ="Richesse_tot", df_app=b_df_train[,c("Richesse_tot",best_20_Richesse_tot)], df_valid = b_df_test[,c("Richesse_tot",best_20_Richesse_tot)],distribution = 'gaussian',n.trees = 6000,shrinkage = 0.01,interaction.depth = 7,n.minobsinnode = 15)
# 
# Richesse_tot_RMSE_Results[i,"RMSE_GBM"] <- GBM_result$RMSE
# 
# Richesse_tot_R_Results[i,"R_GBM"] <- GBM_result$R_squared
# 
# 
# cat("Itération : ",i, "/",n_sim,"\n")
# }
# temps2=Sys.time()
# duree=difftime(temps2,temps1)
# # stopCluster(cl)
# # head(Richesse_tot_RMSE_Results)
# # head(Richesse_tot_R_Results)
# write.csv2(x=Richesse_tot_RMSE_Results$RMSE_GBM, file = "Results/GBM_Richesse_tot_RMSE.csv")
# write.csv2(x=Richesse_tot_R_Results$R_GBM, file = "Results/GBM_Richesse_tot_R.csv")

```


-   ANN AB_tot
```{r ANN AB_tot}
# Pour AB_tot  ------------------------------------------------------------------
var_rep="AB_tot"
AB_tot_ANN_tuning = read.csv2("results_tuning/AB_tot_ANN_tuning.csv")

# Best hyperparameter values
AB_tot_ANN_tuning = as.data.frame(AB_tot_ANN_tuning)
AB_tot_ANN_tuning = AB_tot_ANN_tuning %>% arrange(metric_val_mae)
# head(AB_tot_ANN_tuning[,2:16])

best_param = AB_tot_ANN_tuning[1,]


dense_units1 = as.numeric(best_param$flag_dense_units1)
dense_units2 = as.numeric(best_param$flag_dense_units2)
dense_units3 = as.numeric(best_param$flag_dense_units3)
dense_units4 = as.numeric(best_param$flag_dense_units4)

dropout1 =as.numeric(best_param$flag_dropout1)
dropout2 =as.numeric(best_param$flag_dropout2)
dropout3 =as.numeric(best_param$flag_dropout3)
dropout4 =as.numeric(best_param$flag_dropout4)

batch_size =as.numeric(best_param$flag_batch_size)


# data
training = AB_tot_train
test = AB_tot_test

training %<>% mutate_if(is.factor, as.numeric)
ind_var_rep <- which(names(training) == var_rep)
trainingtarget <- training[, ind_var_rep]
training <- training[, -ind_var_rep]
training <- as.matrix(training)
dimnames(training) <- NULL

ind_var_rep <- which(names(test) == var_rep)
testtarget <- test[, ind_var_rep]
test <- test[, -ind_var_rep]
test %<>% mutate_if(is.factor, as.numeric)
test <- as.matrix(test)
dimnames(test) <- NULL


# AB_tot TUNE MODEL
ANN_tune_AB_tot <- keras_model_sequential()
ANN_tune_AB_tot %>% 
  layer_dense(units = dense_units1, activation = 'relu', input_shape = c(25)) %>%
  layer_dropout(rate = dropout1)  %>%
  layer_dense(units = dense_units2, activation = 'relu') %>%
  layer_dropout(rate = dropout2)  %>%
  layer_dense(units = dense_units3, activation = 'relu') %>%
  layer_dropout(rate = dropout3)  %>%
  layer_dense(units = dense_units4, activation = 'relu') %>%
  layer_dropout(rate = dropout4)  %>%
  layer_dense(units = 1)


# Compile
ANN_tune_AB_tot %>% compile(loss = 'mse',
                  optimizer = 'rmsprop',
                  metrics = 'mae')

#  callback EarlyStopping
mon_callback <- callback_early_stopping(
  monitor = "val_mae",  # Surveille la perte sur l'ensemble de validation
  patience = 10,         # Nombre d'époques sans amélioration avant l'arrêt
  restore_best_weights = TRUE  # Restaure les poids du meilleur modèle
)


# Fit ANN_tune_AB_tot
myANN_tune_AB_tot <- ANN_tune_AB_tot %>%
  fit(training,
      trainingtarget,
      epochs = 100,
      batch_size = batch_size,
      validation_split = 0.2,
      #callbacks = list(mon_callback)
      )


# fig_ANN_tune_AB_tot = plot(myANN_tune_AB_tot)
# ggsave("Results/fig_ANN_tune_AB_tot.png", plot = fig_ANN_tune_AB_tot, dpi = 300)

# Evaluate
# ANN_tune_AB_tot %>% evaluate(test, testtarget)
ANN_tune_AB_tot_pred = ANN_tune_AB_tot %>% predict(test)
ANN_tune_AB_tot_mse = mean((testtarget-ANN_tune_AB_tot_pred)^2) # loss -> mse
ANN_tune_AB_tot_mae = mean(abs(ANN_tune_AB_tot_pred - testtarget),na.rm=TRUE) # MAE 
ANN_tune_AB_tot_rmse = sqrt(mean((testtarget - ANN_tune_AB_tot_pred)^2,na.rm=TRUE)) # rmse
ANN_tune_AB_tot_cor = cor(testtarget,ANN_tune_AB_tot_pred)^2 # R²



# Calcul du R² ajusté pour train
  r_squared_train <- calcule_R2(trainingtarget,  ANN_tune_AB_tot %>% predict(training))
  n_train <- nrow(training)
  p_train <- ncol(training)
  r_adj_train <- 1 - ((1 - r_squared_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  r_squared_test <-calcule_R2(testtarget,ANN_tune_AB_tot_pred)
  n_test <- nrow(test)
  p_test <- ncol(test)
  r_adj_test <- 1 - ((1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1))
  
  
  
  

ANN_tune_AB_tot_results = data.frame(model = "ANN_tune_AB_tot",
                                     mse = round(ANN_tune_AB_tot_mse,2),                                                        mae = round(ANN_tune_AB_tot_mae,2),
                                     rmse = round(ANN_tune_AB_tot_rmse,2), 
                                     r_adj_train= round(r_adj_train,2),
                                     r_adj_test= round(r_adj_test,2))


# ANN_tune_AB_tot_results

```


-   ANN BM_tot
```{r ANN BM_tot}
# Pour BM_tot  ------------------------------------------------------------------
var_rep="BM_tot"
BM_tot_ANN_tuning = read.csv2("results_tuning/BM_tot_ANN_tuning.csv")

# Best hyperparameter values
BM_tot_ANN_tuning = as.data.frame(BM_tot_ANN_tuning)
BM_tot_ANN_tuning = BM_tot_ANN_tuning %>% arrange(metric_val_mae)
# head(BM_tot_ANN_tuning[,2:16])

best_param = BM_tot_ANN_tuning[1,]

dense_units1 = as.numeric(best_param$flag_dense_units1)
dense_units2 = as.numeric(best_param$flag_dense_units2)
dense_units3 = as.numeric(best_param$flag_dense_units3)
dense_units4 = as.numeric(best_param$flag_dense_units4)

dropout1 =as.numeric(best_param$flag_dropout1)
dropout2 =as.numeric(best_param$flag_dropout2)
dropout3 =as.numeric(best_param$flag_dropout3)
dropout4 =as.numeric(best_param$flag_dropout4)

batch_size =as.numeric(best_param$flag_batch_size)


# data
training = BM_tot_train
test = BM_tot_test

training %<>% mutate_if(is.factor, as.numeric)
ind_var_rep <- which(names(training) == var_rep)
trainingtarget <- training[, ind_var_rep]
training <- training[, -ind_var_rep]
training <- as.matrix(training)
dimnames(training) <- NULL

ind_var_rep <- which(names(test) == var_rep)
testtarget <- test[, ind_var_rep]
test <- test[, -ind_var_rep]
test %<>% mutate_if(is.factor, as.numeric)
test <- as.matrix(test)
dimnames(test) <- NULL


# BM_tot TUNE MODEL
ANN_tune_BM_tot <- keras_model_sequential()
ANN_tune_BM_tot %>% 
  layer_dense(units = dense_units1, activation = 'relu', input_shape = c(25)) %>%
  layer_dropout(rate = dropout1)  %>%
  layer_dense(units = dense_units2, activation = 'relu') %>%
  layer_dropout(rate = dropout2)  %>%
  layer_dense(units = dense_units3, activation = 'relu') %>%
  layer_dropout(rate = dropout3)  %>%
  layer_dense(units = dense_units4, activation = 'relu') %>%
  layer_dropout(rate = dropout4)  %>%
  layer_dense(units = 1)


# Compile
ANN_tune_BM_tot %>% compile(loss = 'mse',
                  optimizer = 'rmsprop',
                  metrics = 'mae')

#  callback EarlyStopping
mon_callback <- callback_early_stopping(
  monitor = "val_mae",  # Surveille la perte sur l'ensemble de validation
  patience = 10,         # Nombre d'époques sans amélioration avant l'arrêt
  restore_best_weights = TRUE  # Restaure les poids du meilleur modèle
)


# Fit ANN_tune_BM_tot
myANN_tune_BM_tot <- ANN_tune_BM_tot %>%
  fit(training,
      trainingtarget,
      epochs = 100,
      batch_size = batch_size,
      validation_split = 0.2,
      #callbacks = list(mon_callback)
      )

# fig_ANN_tune_BM_tot = plot(myANN_tune_BM_tot)
# ggsave("Results/fig_ANN_tune_BM_tot.png", plot = fig_ANN_tune_BM_tot, dpi = 300)


# Evaluate
# ANN_tune_BM_tot %>% evaluate(test, testtarget)
ANN_tune_BM_tot_pred = ANN_tune_BM_tot %>% predict(test)
ANN_tune_BM_tot_mse = mean((testtarget-ANN_tune_BM_tot_pred)^2) # loss -> mse
ANN_tune_BM_tot_mae = mean(abs(ANN_tune_BM_tot_pred - testtarget),na.rm=TRUE) # MAE 
ANN_tune_BM_tot_rmse = sqrt(mean((testtarget - ANN_tune_BM_tot_pred)^2,na.rm=TRUE)) # rmse
ANN_tune_BM_tot_cor = cor(testtarget,ANN_tune_BM_tot_pred)^2 # R²



# Calcul du R² ajusté pour train
  r_squared_train <- calcule_R2(trainingtarget,  ANN_tune_BM_tot %>% predict(training))
  n_train <- nrow(training)
  p_train <- ncol(training)
  r_adj_train <- 1 - ((1 - r_squared_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  r_squared_test <-calcule_R2(testtarget,ANN_tune_BM_tot_pred)
  n_test <- nrow(test)
  p_test <- ncol(test)
  r_adj_test <- 1 - ((1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1))
  
  
  
  

ANN_tune_BM_tot_results = data.frame(model = "ANN_tune_BM_tot",
                                     mse = round(ANN_tune_BM_tot_mse,2),                                                        mae = round(ANN_tune_BM_tot_mae,2),
                                     rmse = round(ANN_tune_BM_tot_rmse,2), 
                                     r_adj_train= round(r_adj_train,2),
                                     r_adj_test= round(r_adj_test,2))
# ANN_tune_BM_tot_results

```

-   ANN Richesse_tot
```{r ANN Richesse_tot}
# Pour Richesse_tot  ------------------------------------------------------------------
var_rep="Richesse_tot"
Richesse_tot_ANN_tuning = read.csv2("results_tuning/Richesse_tot_ANN_tuning.csv")

# Best hyperparameter values
Richesse_tot_ANN_tuning = as.data.frame(Richesse_tot_ANN_tuning)
Richesse_tot_ANN_tuning = Richesse_tot_ANN_tuning %>% arrange(metric_val_mae)
# head(Richesse_tot_ANN_tuning[,2:16])

best_param = Richesse_tot_ANN_tuning[1,]

dense_units1 = as.numeric(best_param$flag_dense_units1)
dense_units2 = as.numeric(best_param$flag_dense_units2)
dense_units3 = as.numeric(best_param$flag_dense_units3)
dense_units4 = as.numeric(best_param$flag_dense_units4)

dropout1 =as.numeric(best_param$flag_dropout1)
dropout2 =as.numeric(best_param$flag_dropout2)
dropout3 =as.numeric(best_param$flag_dropout3)
dropout4 =as.numeric(best_param$flag_dropout4)

batch_size =as.numeric(best_param$flag_batch_size)


# data
training = Richesse_tot_train
test = Richesse_tot_test

training %<>% mutate_if(is.factor, as.numeric)
ind_var_rep <- which(names(training) == var_rep)
trainingtarget <- training[, ind_var_rep]
training <- training[, -ind_var_rep]
training <- as.matrix(training)
dimnames(training) <- NULL

ind_var_rep <- which(names(test) == var_rep)
testtarget <- test[, ind_var_rep]
test <- test[, -ind_var_rep]
test %<>% mutate_if(is.factor, as.numeric)
test <- as.matrix(test)
dimnames(test) <- NULL


# Richesse_tot TUNE MODEL
ANN_tune_Richesse_tot <- keras_model_sequential()
ANN_tune_Richesse_tot %>% 
  layer_dense(units = dense_units1, activation = 'relu', input_shape = c(25)) %>%
  layer_dropout(rate = dropout1+0.2)  %>%
  layer_dense(units = dense_units2, activation = 'relu') %>%
  layer_dropout(rate = dropout2+0.2)  %>%
  layer_dense(units = dense_units3, activation = 'relu') %>%
  layer_dropout(rate = dropout3+0.2)  %>%
  layer_dense(units = dense_units4, activation = 'relu') %>%
  layer_dropout(rate = dropout4+0.2)  %>%
  layer_dense(units = 1)


# Compile
ANN_tune_Richesse_tot %>% compile(loss = 'mse',
                  optimizer = 'rmsprop',
                  metrics = 'mae')

#  callback EarlyStopping
mon_callback <- callback_early_stopping(
  monitor = "val_mae",  # Surveille la perte sur l'ensemble de validation
  patience = 10,         # Nombre d'époques sans amélioration avant l'arrêt
  restore_best_weights = TRUE  # Restaure les poids du meilleur modèle
)


# Fit ANN_tune_Richesse_tot
myANN_tune_Richesse_tot <- ANN_tune_Richesse_tot %>%
  fit(training,
      trainingtarget,
      epochs = 100,
      batch_size = batch_size,
      validation_split = 0.2,
      #callbacks = list(mon_callback)
      )


# fig_ANN_tune_Richesse_tot = plot(myANN_tune_Richesse_tot)
# ggsave("Results/fig_ANN_tune_Richesse_tot.png", plot = fig_ANN_tune_Richesse_tot, dpi = 300)

# Evaluate
# ANN_tune_Richesse_tot %>% evaluate(test, testtarget)
ANN_tune_Richesse_tot_pred = ANN_tune_Richesse_tot %>% predict(test)
ANN_tune_Richesse_tot_mse = mean((testtarget-ANN_tune_Richesse_tot_pred)^2) # loss -> mse
ANN_tune_Richesse_tot_mae = mean(abs(ANN_tune_Richesse_tot_pred - testtarget),na.rm=TRUE) # MAE 
ANN_tune_Richesse_tot_rmse = sqrt(mean((testtarget - ANN_tune_Richesse_tot_pred)^2,na.rm=TRUE)) # rmse
ANN_tune_Richesse_tot_cor = cor(testtarget,ANN_tune_Richesse_tot_pred)^2 # R²



# Calcul du R² ajusté pour train
  r_squared_train <- calcule_R2(trainingtarget,  ANN_tune_Richesse_tot %>% predict(training))
  n_train <- nrow(training)
  p_train <- ncol(training)
  r_adj_train <- 1 - ((1 - r_squared_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  r_squared_test <-calcule_R2(testtarget,ANN_tune_Richesse_tot_pred)
  n_test <- nrow(test)
  p_test <- ncol(test)
  r_adj_test <- 1 - ((1 - r_squared_test) * (n_test - 1) / (n_test - p_test - 1))
  
  
  
  

ANN_tune_Richesse_tot_results = data.frame(model = "ANN_tune_Richesse_tot",
                                     mse = round(ANN_tune_Richesse_tot_mse,2),                                                        mae = round(ANN_tune_Richesse_tot_mae,2),
                                     rmse = round(ANN_tune_Richesse_tot_rmse,2), 
                                     r_adj_train= round(r_adj_train,2),
                                     r_adj_test= round(r_adj_test,2))
# ANN_tune_Richesse_tot_results

```


# Results: Case 1 -> repeated data
```{r}
# coul = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2")
# coul2 = c("#E69F00", "#1F77B4", "#009E73", "#F0E442", "#9467BD")
# coul3=c("#1F77B4", "#7F7F7F", "#2CA02C", "#D62728", "#9467BD")
couleurs = c("#2CA02C","#E69F00", "#1F77B4","#7F7F7F", "#D62728","#9467BD")
```


```{r}
# Transformation
data_mod$AB_tot = sqrt(data_mod$AB_tot)
data_mod$BM_tot = sqrt(data_mod$BM_tot)
```



## Sensitivity to number of observations

```{r sensbilite au nbr}
# df_reslt=data.frame(obs=numeric(),RMSE=numeric(),R=numeric())
# n_linges=seq(0.4,1,0.1)
# set.seed(1234)  # Pour rendre les résultats reproductibles
# 
# for (i in n_linges){
# 
# res = data.frame(obs=numeric(),RMSE=numeric(),R=numeric())
# for (j in 1:3){ 
# 
# index <- createDataPartition(df_explo_AB_tot$clcm_lvl3, p = i, list = FALSE)
# 
# df = df_explo_AB_tot[index, ]
# index <- createDataPartition(df$clcm_lvl3, p = 0.8, list = FALSE)
# # Séparer les données en ensembles d'entraînement et de test
# df_train <- df[index, ]  # Données d'entraînement
# df_test <- df[-index, ]  # Données de test
# df_train = droplevels(df_train)
# df_test = droplevels(df_test)
# 
# 
# 
# res=ForetAlea(var_rep ="AB_tot" , df_app=df_train [,c("AB_tot",best_20_AB_tot)], df_valid = df_test [,c("AB_tot",best_20_AB_tot)],mtry =9,ntree= 2000)
# 
# 
# df_reslt=rbind(df_reslt,data.frame(obs=i,RMSE=res$RMSE,R=res$R_squared))
# }
# 
# }
# 
# 
# df_reslt$obs_ligne = round(df_reslt$obs*nrow(df_explo_AB_tot))
# #df_reslt[nrow(df_reslt)+1,] = c("1",res$RMSE,res$R_squared,nrow(df_explo_AB_tot))
# 
# 
# 
# df_reslt$obs=as.factor(df_reslt$obs)
# df_reslt$RMSE = as.numeric(df_reslt$RMSE)
# df_reslt$R = as.numeric(df_reslt$R)
# df_reslt$obs_ligne = as.numeric(df_reslt$obs_ligne)
# 
# 
# res_f = df_reslt %>% group_by(obs) %>% summarise_at(vars(RMSE,R,obs_ligne),funs(mean(.,na.rm=TRUE)))
# 
# plot(res_f$R ~ res_f$obs_ligne, xlab="Numbers of observations", ylab="R squared (%)", main="Evolution of RF R² (%)",type='p')

```

![](Results/r_square_sensibility_nrow.png)



## Importance of variables for total abundance
```{r}
ForetAlea <- function(var_rep, df_app, df_valid,mtry =9,ntree= 2000,maxnodes=60){
  
  # Nombre de variables tirées aléatoirement pour la construction des arbre : mtry =    1/nombre de variable explicatives totales # nombre d'arbres : ntree = 250
  
  # var_mod=c(var_rep,predicteurs)
  # df_app = df_app[,var_mod]
  # df_valid = df_valid[,var_mod]
  
  
  col_posi <- which(names(df_app) == var_rep)
  ForeVDT <- randomForest(df_app[-col_posi], df_app[[col_posi]], mtry=mtry, ntree=ntree,maxnodes=maxnodes)
  
  # Prediction sur le jeu de validation
  col_posi <- which(names(df_valid) == var_rep)
  pred.RF<-predict(ForeVDT,newdata=as.data.frame(df_valid[,-col_posi]))
  
  # Calcul du RMSE pour évaluer la qualité du modele
  rmse <- round (sqrt(mean((df_valid[,col_posi] - pred.RF)^2)),2)
  
  r_adj = round (mean(ForeVDT$rsq),2)
  
    results <- list(RMSE = rmse, R_squared= r_adj, model=ForeVDT)
  return(results)
}
```

```{r imp abundance}
# names(data_mod)

df_explo_AB_tot = data_mod[,c(6,9:47)]
df_explo_AB_tot = drop_na(df_explo_AB_tot)


set.seed(1234)  # Pour rendre les résultats reproductibles
index <- createDataPartition(df_explo_AB_tot$clcm_lvl3, p = 0.8, list = FALSE)

# Séparer les données en ensembles d'entraînement et de test
df_train_AB_tot <- df_explo_AB_tot[index, ]  # Données d'entraînement
df_test_AB_tot <- df_explo_AB_tot[-index, ]  # Données de test
df_train_AB_tot = droplevels(df_train_AB_tot)
df_test_AB_tot = droplevels(df_test_AB_tot)


all_var_AB_tot=ForetAlea(var_rep ="AB_tot", df_app=df_train_AB_tot, df_valid = df_test_AB_tot,mtry =9,ntree= 2000)
AB_tot_fit_rf = all_var_AB_tot$model

# # Etape 5 importance des variables
# AB_tot_fit_rf #display fitted model
# which.min(AB_tot_fit_rf$mse) #find number of trees that produce lowest test MSE
# sqrt(AB_tot_fit_rf$mse[which.min(AB_tot_fit_rf$mse)]) #find RMSE of best model
# varImpPlot(AB_tot_fit_rf) #produce variable importance plot

# Obtention de l'importance des variables
importance_rf <- as.data.frame(importance(AB_tot_fit_rf))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]

best_20_AB_tot = c(importance_rf$nom[1:20])
var_a_sup_AB_tot= setdiff(y = best_20_AB_tot,x = importance_rf$nom)

best20_var_AB_tot=ForetAlea(var_rep ="AB_tot", df_app=df_train_AB_tot[,c("AB_tot",best_20_AB_tot)], df_valid = df_test_AB_tot [,c("AB_tot",best_20_AB_tot)],mtry =9,ntree= 2000)

varImpPlot(best20_var_AB_tot$model, main = "Abundance") #produce variable importance plot


importance_rf <- as.data.frame(importance(best20_var_AB_tot$model))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
row.names(importance_rf)=NULL
importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
barplot(importance_rf$percent, main = "Importance of variables for total abundance", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)


### sans OS


best20_var_AB_tot=ForetAlea(var_rep ="AB_tot", df_app=df_train_AB_tot[,c("AB_tot",best_20_AB_tot[-1])], df_valid = df_test_AB_tot [,c("AB_tot",best_20_AB_tot[-1])],mtry =9,ntree= 2000)

# varImpPlot(best20_var_AB_tot$model, main = "Abundance") #produce variable importance plot

importance_rf <- as.data.frame(importance(best20_var_AB_tot$model))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
row.names(importance_rf)=NULL
importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
barplot(importance_rf$percent, main = "Importance of variables for total abundance \n Without land cover", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)

```



## Importance of variables for total biomass
```{r imp biomass}
# names(data_mod)
df_explo_BM_tot = data_mod[,c(7,9:47)]
df_explo_BM_tot = drop_na(df_explo_BM_tot)


set.seed(1234)  # Pour rendre les résultats reproductibles
index <- createDataPartition(df_explo_BM_tot$clcm_lvl3, p = 0.8, list = FALSE)

# Séparer les données en ensembles d'entraînement et de test
df_train_BM_tot <- df_explo_BM_tot[index, ]  # Données d'entraînement
df_test_BM_tot <- df_explo_BM_tot[-index, ]  # Données de test
df_train_BM_tot = droplevels(df_train_BM_tot)
df_test_BM_tot = droplevels(df_test_BM_tot)


all_var_BM_tot= ForetAlea(var_rep ="BM_tot", df_app=df_train_BM_tot, df_valid = df_test_BM_tot,mtry =9,ntree= 2000)
BM_tot_fit_rf = all_var_BM_tot$model


# # Etape 5 importance des variables
# BM_tot_fit_rf #display fitted model
# which.min(BM_tot_fit_rf$mse) #find number of trees that produce lowest test MSE
# sqrt(BM_tot_fit_rf$mse[which.min(BM_tot_fit_rf$mse)]) #find RMSE of best model
# sqrt(mean(BM_tot_fit_rf$mse))
# mean(100*BM_tot_fit_rf$rsq)
# varImpPlot(BM_tot_fit_rf) #produce variable importance plot

# Obtention de l'importance des variables
importance_rf <- as.data.frame(importance(BM_tot_fit_rf))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]

best_20_BM_tot = c(importance_rf$nom[1:20])
var_a_sup_BM_tot= setdiff(y = best_20_BM_tot,x = importance_rf$nom)

best20_var_BM_tot= ForetAlea(var_rep ="BM_tot", df_app=df_train_BM_tot[, c("BM_tot",best_20_BM_tot)], df_valid = df_test_BM_tot [, c("BM_tot",best_20_BM_tot)],mtry =9,ntree= 2000)
# varImpPlot(best20_var_BM_tot$model, main = "Biomass") #produce variable importance plot


importance_rf <- as.data.frame(importance(best20_var_BM_tot$model))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
row.names(importance_rf)=NULL
importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
barplot(importance_rf$percent, main = "Importance of variables for total biomass", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)




### sans OS
best20_var_BM_tot= ForetAlea(var_rep ="BM_tot", df_app=df_train_BM_tot[, c("BM_tot",best_20_BM_tot[-1])], df_valid = df_test_BM_tot [, c("BM_tot",best_20_BM_tot[-1])],mtry =9,ntree= 2000)
# varImpPlot(best20_var_BM_tot$model, main = "Biomass") #produce variable importance plot


importance_rf <- as.data.frame(importance(best20_var_BM_tot$model))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
row.names(importance_rf)=NULL
importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
barplot(importance_rf$percent, main = "Importance of variables for total biomass \n Without land cover", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)


```


## Importance of variables for total taxonomic richness

```{r imp richness}
# names(data_mod)
df_explo_Richesse_tot = data_mod[,c(8,9:47)]
df_explo_Richesse_tot = drop_na(df_explo_Richesse_tot)


set.seed(1234)  # Pour rendre les résultats reproductibles
index <- createDataPartition(df_explo_Richesse_tot$clcm_lvl3, p = 0.8, list = FALSE)

# Séparer les données en ensembles d'entraînement et de test
df_train_Richesse_tot <- df_explo_Richesse_tot[index, ]  # Données d'entraînement
df_test_Richesse_tot <- df_explo_Richesse_tot[-index, ]  # Données de test
df_train_Richesse_tot = droplevels(df_train_Richesse_tot)
df_test_Richesse_tot = droplevels(df_test_Richesse_tot)



all_var_Richesse_tot= ForetAlea(var_rep ="Richesse_tot", df_app=df_train_Richesse_tot, df_valid = df_test_Richesse_tot,mtry =9,ntree= 2000)
Richesse_tot_fit_rf = all_var_Richesse_tot$model


# Etape 5 importance des variables
# Richesse_tot_fit_rf #display fitted model
# which.min(Richesse_tot_fit_rf$mse) #find number of trees that produce lowest test MSE
# sqrt(Richesse_tot_fit_rf$mse[which.min(Richesse_tot_fit_rf$mse)]) #find RMSE of best model
# sqrt(mean(Richesse_tot_fit_rf$mse))
# mean(100*Richesse_tot_fit_rf$rsq)
# varImpPlot(Richesse_tot_fit_rf) #produce variable importance plot

# Obtention de l'importance des variables
importance_rf <- as.data.frame(importance(Richesse_tot_fit_rf))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]

best_20_Richesse_tot = c(importance_rf$nom[1:20])
var_a_sup_Richesse_tot= setdiff(y = best_20_Richesse_tot,x = importance_rf$nom)

best20_var_Richesse_tot= ForetAlea(var_rep ="Richesse_tot", df_app=df_train_Richesse_tot[, c("Richesse_tot",best_20_Richesse_tot)], df_valid = df_test_Richesse_tot [, c("Richesse_tot",best_20_Richesse_tot)],mtry =9,ntree= 2000)


# varImpPlot(best20_var_Richesse_tot$model,main = "Richness") #produce variable importance plot

importance_rf <- as.data.frame(importance(best20_var_Richesse_tot$model))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
row.names(importance_rf)=NULL
importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
barplot(importance_rf$percent, main = "Importance of variables for richness", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)


### sans OS

best20_var_Richesse_tot= ForetAlea(var_rep ="Richesse_tot", df_app=df_train_Richesse_tot[, c("Richesse_tot",best_20_Richesse_tot[-1])], df_valid = df_test_Richesse_tot [, c("Richesse_tot",best_20_Richesse_tot[-1])],mtry =9,ntree= 2000)


# varImpPlot(best20_var_Richesse_tot$model,main = "Richness") #produce variable importance plot

importance_rf <- as.data.frame(importance(best20_var_Richesse_tot$model))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
row.names(importance_rf)=NULL
importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
barplot(importance_rf$percent, main = "Importance of variables for richness \n Without land cover", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)

```







<!--

## RMSE sur le JDD test
```{r save result}
# AB_tot
AB_tot_RMSE_Results = read.csv2(file = "Results/AB_tot_RMSE_Results.csv")
AB_tot_RMSE_Results = AB_tot_RMSE_Results [,-1]
AB_tot_R_Results = read.csv2(file = "Results/AB_tot_R_Results.csv")
AB_tot_R_Results = AB_tot_R_Results[,-1]
# write.csv2(x=AB_tot_RMSE_Results, file = "Results/AB_tot_RMSE_Results.csv")
# write.csv2(x=AB_tot_R_Results, file = "Results/AB_tot_R_Results.csv")

# BM_tot
BM_tot_RMSE_Results = read.csv2(file = "Results/BM_tot_RMSE_Results.csv")
BM_tot_RMSE_Results = BM_tot_RMSE_Results[,-1]
BM_tot_R_Results = read.csv2(file = "Results/BM_tot_R_Results.csv")
BM_tot_R_Results=BM_tot_R_Results[,-1]
# write.csv2(x=BM_tot_RMSE_Results, file = "Results/BM_tot_RMSE_Results.csv")
# write.csv2(x=BM_tot_R_Results, file = "Results/BM_tot_R_Results.csv")

# Richesse_tot
Richesse_tot_RMSE_Results = read.csv2(file = "Results/Richesse_tot_RMSE_Results.csv")
Richesse_tot_RMSE_Results= Richesse_tot_RMSE_Results[,-1]
Richesse_tot_R_Results = read.csv2(file = "Results/Richesse_tot_R_Results.csv")
Richesse_tot_R_Results = Richesse_tot_R_Results[,-1]
# write.csv2(x=Richesse_tot_RMSE_Results, file = "Results/Richesse_tot_RMSE_Results.csv")
# write.csv2(x=Richesse_tot_R_Results, file = "Results/Richesse_tot_R_Results.csv")
```

-   AB_tot
```{r RMSE.plot AB_tot, fig.align='center', fig.height=5, fig.dpi=300}
Results_long = AB_tot_RMSE_Results%>%
  select(starts_with("RMSE"))%>%
  pivot_longer(everything())

Results_long$name = as.factor(Results_long$name)
levels(Results_long$name) = c("ANN","GAM", "GBM", "GLM", "RF")
ordonee = c("GLM","GAM","RF","GBM","ANN")
Results_long$name <- factor(Results_long$name, levels = ordonee)
Results_long = as.data.frame(Results_long)
Results_long = Results_long[!Results_long$name=="ANN",]
Results_long$value = Results_long$value^2 # Pour retrouver les données de base

recap = Results_long%>%
  group_by(name)%>%
  summarise(mean.rmse = mean(value),
            sd.rmse = sd(value))


means <- colMeans(AB_tot_R_Results[,-c(5:6)], na.rm = TRUE)
means = round(means,2)
recap$R_squared = means

subtitle <- sprintf("Abundance : %.2f ± %.2f ind/m²", mean(bdd_explo$AB_tot, na.rm = TRUE), sd(bdd_explo$AB_tot, na.rm = TRUE))
result_AB_tot = ggplot()+
  geom_sina(data=Results_long, aes(name, value), alpha = 0.2,shape=19, cex = 2,
            method = "density")+
  geom_point(data = recap, aes(name, mean.rmse), cex =2, col = "orange")+
  geom_errorbar(data = recap, 
                aes(x= name, ymin=mean.rmse-sd.rmse, ymax=mean.rmse+sd.rmse),
                cex =1.2, width=.1, position = position_dodge(0.5), col = "orange")+
  geom_text(data = recap, aes(x = name, y = mean.rmse, label = paste0 ("R² = ",round(R_squared, 2))),
            vjust = -7, size = 6)+   # Ajoute le texte avec les valeurs R²
  labs(y= "RMSE",x ="Models",title = subtitle)+ 
  scale_y_continuous(limits = c(25, 50), breaks = seq(25, 50, by = 5))+
  theme_bw()+
  theme(line = element_blank(), 
        axis.line = element_line(colour = "black"),
        panel.border = element_blank(),
        axis.ticks =  element_line(colour = "black"),
        axis.text.x = element_text(colour = "black", size=20,
                                   angle = 45, hjust = 1),
        axis.text.y = element_text(colour = "black", size=20),
        legend.title = element_text(colour = "black", size=20),
        legend.title.align=0.5,
        legend.text = element_text(colour = "black", size=18),
        axis.title=element_text(size=28),
        strip.background = element_rect(fill="white"))

ggsave("Results/Result_abundance.png", plot = result_AB_tot, dpi = 300)
result_AB_tot

#combined_plot <- grid.arrange(result_AB_tot, R_result_AB_tot, ncol = 2)
```

-   BM_tot
```{r RMSE.plot BM_tot, fig.align='center', fig.height=5, fig.dpi=300}
Results_long = BM_tot_RMSE_Results%>%
  select(starts_with("RMSE"))%>%
  pivot_longer(everything())

Results_long$name = as.factor(Results_long$name)
levels(Results_long$name) = c("ANN","GAM", "GBM", "GLM", "RF")
ordonee = c("GLM","GAM","RF","GBM","ANN")
Results_long$name <- factor(Results_long$name, levels = ordonee)
Results_long = as.data.frame(Results_long)
Results_long = Results_long[!Results_long$name=="ANN",]
Results_long$value = Results_long$value^2 # Pour retrouver les données de base

recap = Results_long%>%
  group_by(name)%>%
  summarise(mean.rmse = mean(value),
            sd.rmse = sd(value),
            max.rmse = max(value))

means <- colMeans(BM_tot_R_Results[,-c(5:6)], na.rm = TRUE)
means = round(means,2)
recap$R_squared = means

subtitle <- sprintf("Biomass : %.2f ± %.2f g/m²", mean(bdd_explo$BM_tot, na.rm = TRUE), sd(bdd_explo$BM_tot, na.rm = TRUE))
result_BM_tot = ggplot()+
  geom_sina(data=Results_long, aes(name, value), alpha = 0.2,shape=19, cex = 2,
            method = "density")+
  geom_point(data = recap, aes(name, mean.rmse), cex =2, col = "orange")+
  geom_errorbar(data = recap, 
                aes(x= name, ymin=mean.rmse-sd.rmse, ymax=mean.rmse+sd.rmse),
                cex =1.2, width=.1, position = position_dodge(0.5), col = "orange")+
    geom_text(data = recap, aes(x = name, y = max.rmse, label = paste0 ("R² = ",round(R_squared, 2))),
            vjust = -1, size = 6)+   # Ajoute le texte avec les valeurs R²
  labs(y= "RMSE",x ="Models",title = subtitle)+ 
  scale_y_continuous(limits = c(6, 18), breaks = seq(6, 18, by = 4))+
  theme_bw()+
  theme(line = element_blank(), 
        axis.line = element_line(colour = "black"),
        panel.border = element_blank(),
        axis.ticks =  element_line(colour = "black"),
        axis.text.x = element_text(colour = "black", size=20,
                                   angle = 45, hjust = 1),
        axis.text.y = element_text(colour = "black", size=20),
        legend.title = element_text(colour = "black", size=20),
        legend.title.align=0.5,
        legend.text = element_text(colour = "black", size=18),
        axis.title=element_text(size=28),
        strip.background = element_rect(fill="white"))

ggsave("Results/Result_biomass.png", plot = result_BM_tot, dpi = 300)
result_BM_tot
```

-   Richesse_tot
```{r RMSE.plot Richesse_tot, fig.align='center', fig.height=5, fig.dpi=300}
Results_long = Richesse_tot_RMSE_Results%>%
  select(starts_with("RMSE"))%>%
  pivot_longer(everything())

Results_long$name = as.factor(Results_long$name)
levels(Results_long$name) = c("ANN","GAM", "GBM", "GLM", "RF")
ordonee = c("GLM","GAM","RF","GBM","ANN")
Results_long$name <- factor(Results_long$name, levels = ordonee)
Results_long = as.data.frame(Results_long)
Results_long = Results_long[!Results_long$name=="ANN",]
#Results_long$value = Results_long$value^2 # Pour retrouver les données de base

recap = Results_long%>%
  group_by(name)%>%
  summarise(mean.rmse = mean(value),
            sd.rmse = sd(value),
            max.rmse = max(value))

means <- colMeans(Richesse_tot_R_Results[,-c(5:6)], na.rm = TRUE)
means = round(means,2)
recap$R_squared = means

subtitle <- sprintf("Richness : %.2f ± %.2f", mean(bdd_explo$Richesse_tot, na.rm = TRUE), sd(bdd_explo$Richesse_tot, na.rm = TRUE))

result_Richesse_tot = ggplot()+
  geom_sina(data=Results_long, aes(name, value), alpha = 0.2,shape=19, cex = 2,
            method = "density")+
  geom_point(data = recap, aes(name, mean.rmse), cex =2, col = "orange")+
  geom_errorbar(data = recap, 
                aes(x= name, ymin=mean.rmse-sd.rmse, ymax=mean.rmse+sd.rmse),
                cex =1.2, width=.1, position = position_dodge(0.5), col = "orange")+
  geom_text(data = recap, aes(x = name, y = max.rmse, label = paste0 ("R² = ",round(R_squared, 2))),
            vjust = -1, size = 6)+   # Ajoute le texte avec les valeurs R²
  labs(y= "RMSE",x ="Models",title = subtitle)+ 
  scale_y_continuous(limits = c(1.6, 2.4), breaks = seq(1.6, 2.4, by = 0.2))+
  theme_bw()+
  theme(line = element_blank(), 
        axis.line = element_line(colour = "black"),
        panel.border = element_blank(),
        axis.ticks =  element_line(colour = "black"),
        axis.text.x = element_text(colour = "black", size=20,
                                   angle = 45, hjust = 1),
        axis.text.y = element_text(colour = "black", size=20),
        legend.title = element_text(colour = "black", size=20),
        legend.title.align=0.5,
        legend.text = element_text(colour = "black", size=18),
        axis.title=element_text(size=28),
        strip.background = element_rect(fill="white"))

ggsave("Results/Result_richness.png", plot = result_Richesse_tot, dpi = 300)
result_Richesse_tot
```



## R² sur le JDD test

-   AB_tot
```{r R.plot AB_tot}
Results_long = AB_tot_R_Results [,-c(5:6)]%>%
  select(starts_with("R"))%>%
  pivot_longer(everything())

Results_long$name = as.factor(Results_long$name)
levels(Results_long$name) = c("GAM", "GBM", "GLM", "RF")
ordonee = c("GLM","GAM","RF","GBM")
Results_long$name <- factor(Results_long$name, levels = ordonee)
Results_long = as.data.frame(Results_long)
#Results_long = Results_long[!Results_long$name=="ANN",]
#Results_long$value = Results_long$value^2 # Pour retrouver les données de base

recap = Results_long%>%
  group_by(name)%>%
  summarise(mean.R = mean(value),
            sd.R = sd(value))
subtitle <- sprintf("Abundance : %.2f ± %.2f ind/m²", mean(bdd_explo$AB_tot, na.rm = TRUE), sd(bdd_explo$AB_tot, na.rm = TRUE))
R_result_AB_tot = ggplot()+
  geom_sina(data=Results_long, aes(name, value), alpha = 0.2,shape=19, cex = 2,
            method = "density")+
  geom_point(data = recap, aes(name, mean.R), cex =2, col = "orange")+
  geom_errorbar(data = recap, 
                aes(x= name, ymin=mean.R-sd.R, ymax=mean.R+sd.R),
                cex =1.2, width=.1, position = position_dodge(0.5), col = "orange")+
  labs(y= "R²",x ="Models",title = subtitle)+ 
  scale_y_continuous(limits = c(0.2, 0.5), breaks = seq(0.2, 0.5, by = 0.1))+
  theme_bw()+
  theme(line = element_blank(), 
        axis.line = element_line(colour = "black"),
        panel.border = element_blank(),
        axis.ticks =  element_line(colour = "black"),
        axis.text.x = element_text(colour = "black", size=20,
                                   angle = 45, hjust = 1),
        axis.text.y = element_text(colour = "black", size=20),
        legend.title = element_text(colour = "black", size=20),
        legend.title.align=0.5,
        legend.text = element_text(colour = "black", size=18),
        axis.title=element_text(size=28),
        strip.background = element_rect(fill="white"))

ggsave("Results/R_abundance.png", plot = R_result_AB_tot, dpi = 300)
R_result_AB_tot
```

-   BM_tot
```{r R.plot BM_tot}
Results_long = BM_tot_R_Results [,-c(5:6)]%>%
  select(starts_with("R"))%>%
  pivot_longer(everything())

Results_long$name = as.factor(Results_long$name)
levels(Results_long$name) = c("GAM", "GBM", "GLM", "RF")
ordonee = c("GLM","GAM","RF","GBM")
Results_long$name <- factor(Results_long$name, levels = ordonee)
Results_long = as.data.frame(Results_long)
#Results_long = Results_long[!Results_long$name=="ANN",]
#Results_long$value = Results_long$value^2 # Pour retrouver les données de base

recap = Results_long%>%
  group_by(name)%>%
  summarise(mean.R = mean(value),
            sd.R = sd(value))
subtitle <- sprintf("Biomass : %.2f ± %.2f g/m²", mean(bdd_explo$BM_tot, na.rm = TRUE), sd(bdd_explo$BM_tot, na.rm = TRUE))
R_result_BM_tot = ggplot()+
  geom_sina(data=Results_long, aes(name, value), alpha = 0.2,shape=19, cex = 2,
            method = "density")+
  geom_point(data = recap, aes(name, mean.R), cex =2, col = "orange")+
  geom_errorbar(data = recap, 
                aes(x= name, ymin=mean.R-sd.R, ymax=mean.R+sd.R),
                cex =1.2, width=.1, position = position_dodge(0.5), col = "orange")+
  labs(y= "R²",x ="Models",title = subtitle)+ 
  scale_y_continuous(limits = c(0, 0.5), breaks = seq(0, 0.5, by = 0.1))+
  theme_bw()+
  theme(line = element_blank(), 
        axis.line = element_line(colour = "black"),
        panel.border = element_blank(),
        axis.ticks =  element_line(colour = "black"),
        axis.text.x = element_text(colour = "black", size=20,
                                   angle = 45, hjust = 1),
        axis.text.y = element_text(colour = "black", size=20),
        legend.title = element_text(colour = "black", size=20),
        legend.title.align=0.5,
        legend.text = element_text(colour = "black", size=18),
        axis.title=element_text(size=28),
        strip.background = element_rect(fill="white"))

ggsave("Results/R_biomass.png", plot = R_result_BM_tot, dpi = 300)
R_result_BM_tot
```

-   Richesse_tot
```{r R.plot Richesse_tot}
Results_long = Richesse_tot_R_Results [,-c(5:6)] %>%
  select(starts_with("R"))%>%
  pivot_longer(everything())

Results_long$name = as.factor(Results_long$name)
levels(Results_long$name) = c("GAM", "GBM", "GLM", "RF")
ordonee = c("GLM","GAM","RF","GBM")
Results_long$name <- factor(Results_long$name, levels = ordonee)
Results_long = as.data.frame(Results_long)
#Results_long = Results_long[!Results_long$name=="ANN",]
#Results_long$value = Results_long$value^2 # Pour retrouver les données de base

recap = Results_long%>%
  group_by(name)%>%
  summarise(mean.R = mean(value),
            sd.R = sd(value))
subtitle <- sprintf("Richness : %.2f ± %.2f", mean(bdd_explo$Richesse_tot, na.rm = TRUE), sd(bdd_explo$Richesse_tot, na.rm = TRUE))

R_result_Richesse_tot = ggplot()+
  geom_sina(data=Results_long, aes(name, value), alpha = 0.2,shape=19, cex = 2,
            method = "density")+
  geom_point(data = recap, aes(name, mean.R), cex =2, col = "orange")+
  geom_errorbar(data = recap, 
                aes(x= name, ymin=mean.R-sd.R, ymax=mean.R+sd.R),
                cex =1.2, width=.1, position = position_dodge(0.5), col = "orange")+
  labs(y= "R²",x ="Models",title = subtitle)+ 
  scale_y_continuous(limits = c(0.2, 0.6), breaks = seq(0.2, 0.6, by = 0.1))+
  theme_bw()+
  theme(line = element_blank(), 
        axis.line = element_line(colour = "black"),
        panel.border = element_blank(),
        axis.ticks =  element_line(colour = "black"),
        axis.text.x = element_text(colour = "black", size=20,
                                   angle = 45, hjust = 1),
        axis.text.y = element_text(colour = "black", size=20),
        legend.title = element_text(colour = "black", size=20),
        legend.title.align=0.5,
        legend.text = element_text(colour = "black", size=18),
        axis.title=element_text(size=28),
        strip.background = element_rect(fill="white"))

ggsave("Results/R_richness.png", plot = R_result_Richesse_tot, dpi = 300)
R_result_Richesse_tot
```






-->

## Prediction of total abundance

```{r}
subtitle <- sprintf("Abundance : %.2f ± %.2f ind/m²", mean(bdd_explo$AB_tot, na.rm = TRUE), sd(bdd_explo$AB_tot, na.rm = TRUE))
```

**Sans interaction ** (`r subtitle`)

```{r predit AB_tot, fig.align='center' ,eval=FALSE}
# Prediction avec GLM -----------------------------------------
# GLM_result_AB_tot$RMSE
# GLM_result_AB_tot$MAE
# GLM_result_AB_tot$R_squared
# GLM_result_AB_tot$predit
# GLM_result_AB_tot$model


GLM_AB_tot_pred <- GLM_result_AB_tot$predit^2

GLM_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = GLM_AB_tot_pred)

cor_GLM_AB_tot <- cor(GLM_df_AB_tot$Observed, GLM_df_AB_tot$Predicted)

  # graphique avec ggplot
GLM_AB_tot <- ggplot(GLM_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GLM: R² = ", round(GLM_result_AB_tot$R_squared,2), 
                           "; RMSE = ",  round(GLM_result_AB_tot$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 

# Prediction avec GAM -----------------------------------------
# GAM_result_AB_tot$RMSE
# GAM_result_AB_tot$MAE
# GAM_result_AB_tot$R_squared
# GAM_result_AB_tot$predit
# GAM_result_AB_tot$model


GAM_AB_tot_pred <- GAM_result_AB_tot$predit^2

GAM_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = GAM_AB_tot_pred)

cor_GAM_AB_tot <- cor(GAM_df_AB_tot$Observed, GAM_df_AB_tot$Predicted)

  # graphique avec ggplot
GAM_AB_tot <- ggplot(GAM_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GAM: R² = ", round(GAM_result_AB_tot$R_squared,2), 
                           "; RMSE = ",  round(GAM_result_AB_tot$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 

# Prediction avec RF -----------------------------------------
# RF_result_AB_tot$RMSE
# RF_result_AB_tot$MAE
# RF_result_AB_tot$R_squared
RF_result_AB_tot$R_squared_train
RF_result_AB_tot$R_squared_test
# RF_result_AB_tot$predit
# RF_result_AB_tot$model


RF_AB_tot_pred <- RF_result_AB_tot$predit^2

RF_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = RF_AB_tot_pred)

cor_RF_AB_tot <- cor(RF_df_AB_tot$Observed, RF_df_AB_tot$Predicted)

  # graphique avec ggplot
RF_AB_tot <- ggplot(RF_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("RF: R² adj (train) = ", round(RF_result_AB_tot$R_squared_train,2), 
                           "; R² adj (test) = ", round(RF_result_AB_tot$R_squared_test,2),
                           "; RMSE = ",  round(RF_result_AB_tot$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 

df_tot = RF_df_AB_tot
df_tot$observation = seq(1,nrow(df_tot))

# Calcul des quartiles
q1 <- quantile(df_tot$Observed, 0.25)
median <- quantile(df_tot$Observed, 0.50)
q3 <- quantile(df_tot$Observed, 0.75)
max_value <- max(df_tot$Observed)

# Création des DataFrames en fonction des quartiles
df1 <- df_tot[df_tot$Observed <= q1,]
df2 <- df_tot[df_tot$Observed > q1 & df_tot$Observed <= median,]
df3 <- df_tot[df_tot$Observed > median & df_tot$Observed <= q3,]
df4 <- df_tot[df_tot$Observed > q3,]




AB_tot_p1 = plot_comp(df = df1,ylabel = "",title_class = "  min to Q1",legende = TRUE,xlabel = "",title = "RF: Abundance predicted and observed values \n for different quartiles")

AB_tot_p2 = plot_comp(df = df2,ylabel = "" ,title_class = "Q1 to median",legende = FALSE,xlabel = "")
AB_tot_p3 = plot_comp(df = df3,ylabel = "" ,title_class = "median to Q3" ,legende = FALSE,xlabel = "")
AB_tot_p4 = plot_comp(df = df4,ylabel = "" ,title_class = " Q3 to max" ,legende = FALSE)


RF_AB_tot_fig = ggarrange(AB_tot_p1, AB_tot_p2, AB_tot_p3, AB_tot_p4,
  # labels = c('(a)', '(b)','(c)', '(d)'),
  ncol = 1,vjust = 0.5,
  common.legend = TRUE,
  legend = 'right'
)


RF_AB_tot_fig
# ggsave("Results/RF_AB_tot_fig.png", plot = RF_AB_tot_fig, dpi = 300)



# Prediction avec GBM -----------------------------------------
# GBM_result_AB_tot$RMSE
# GBM_result_AB_tot$MAE
# GBM_result_AB_tot$R_squared
# GBM_result_AB_tot$predit
# GBM_result_AB_tot$model



GBM_AB_tot_pred = GBM_result_AB_tot$predit^2

GBM_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = GBM_AB_tot_pred)

cor_GBM_AB_tot<- cor(GBM_df_AB_tot$Observed, GBM_df_AB_tot$Predicted)

# graphique avec ggplot
GBM_AB_tot <- ggplot(GBM_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GBM: R² adj (train) = ", round(GBM_result_AB_tot$R_squared_train,2), 
                           "; R² adj (test) = ", round(GBM_result_AB_tot$R_squared_test,2),
                           "; RMSE = ",  round(GBM_result_AB_tot$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") +  
      theme_classic() 





# Prediction avec ANN -----------------------------------------
# ANN_tune_AB_tot_results$mse
# ANN_tune_AB_tot_results$mae
# ANN_tune_AB_tot_results$rmse
# ANN_tune_AB_tot_results$R_squared

ANN_AB_tot_pred = ANN_tune_AB_tot_pred^2

ANN_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = ANN_AB_tot_pred)

cor_ANN_AB_tot <- cor(ANN_df_AB_tot$Observed, ANN_df_AB_tot$Predicted)

  # graphique avec ggplot
ANN_AB_tot <- ggplot(ANN_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") +
      labs(subtitle =paste("ANN: R² = ", round(ANN_tune_AB_tot_results$R_squared,2), 
                           "; RMSE = ", round(ANN_tune_AB_tot_results$rmse^2,2)),
           x = "Real values", y = "Predicted values") +
      theme_classic()
```

```{r predit AB_tot 2, fig.align='center' ,eval=FALSE}
AB_tot_reel =  AB_tot_test[,1]^2

AB_tot_algo <-data.frame(algo = rep(c("Real_value","GLM","GAM","RF","GBM","ANN"),
      each = length(AB_tot_reel)), pred_values = c(
                  AB_tot_reel, 
                  GLM_AB_tot_pred, 
                  GAM_AB_tot_pred, 
                  RF_AB_tot_pred, 
                  GBM_AB_tot_pred, 
                  ANN_AB_tot_pred))

AB_tot_algo$algo <- fct_relevel(AB_tot_algo$algo,c("Real_value","GLM","GAM","RF","GBM","ANN"))


AB_tot_boxplot = plot_boxplot(
  donnee = AB_tot_algo,
  x_col = "algo",
  y_col = "pred_values",
  x_label = "Models",
  y_label = "Abundance",
  title = "Abundance",
  legend_title = "Models",
  couleurs = couleurs,
  affiche_point = T
)


AB_tot_Kteste = kruskal.test(AB_tot_algo$pred_values~AB_tot_algo$algo)
AB_tot_p_value = round(AB_tot_Kteste$p.value,2)
if (AB_tot_p_value==0){
  AB_tot_p_value = 0.001
}

AB_tot_pp <-pairwise.wilcox.test(
        AB_tot_algo$pred_values,
        AB_tot_algo$algo,
        p.adjust.method = "bonferroni",
        paired = FALSE,
        pool.sd = FALSE
      )
AB_tot_mymat <- tri.to.squ(AB_tot_pp$p.value)
nom_stat = paste0("Kruskal-Wallis, chi-squared = ",
                      round(AB_tot_Kteste$statistic, 2),
                      "; p-value = ",
                      AB_tot_p_value)

AB_tot_myletters <-multcompLetters(AB_tot_mymat,
                      compare = "<=",
                      threshold = 0.05,
                      Letters = letters)

AB_tot_myletters <-data.frame(group = names(AB_tot_myletters$Letters),
                 letter = AB_tot_myletters$Letters)



AB_tot_myletters$algo = AB_tot_myletters$group  

# AB_tot_boxplot = AB_tot_boxplot + labs(subtitle = paste0(nom_stat)) +
#       geom_text(data = AB_tot_myletters,
#                 aes(label = letter, y = max(AB_tot_algo$pred_values + 300)))

AB_tot_boxplot


graphe_AB_tot = ggarrange(GLM_AB_tot, GAM_AB_tot, RF_AB_tot, GBM_AB_tot, ANN_AB_tot,
  labels = c('(a)', '(b)','(c)', '(d)','(e)'),
  common.legend = TRUE,
  legend = 'right'
)


# ggsave("Results/AB_tot_boxplot.png", plot = AB_tot_boxplot, dpi = 300, width = 5,height = 3)
# ggsave("Results/graphe_AB_tot.png", plot = graphe_AB_tot, dpi = 300, width = 9,height = 4.9)

```

<p align="center" >
  <img src="Results/AB_tot_boxplot.png">
</p>


<p align="center">
  <img src="Results/graphe_AB_tot.png">
</p>



**Avec interaction** (`r subtitle`)
```{r predit AB_tot inter, fig.align='center',eval=FALSE}
# Prediction avec GLM -----------------------------------------
# GLM_result_AB_tot_inter$RMSE
# GLM_result_AB_tot_inter$MAE
# GLM_result_AB_tot_inter$R_squared
# GLM_result_AB_tot_inter$predit
# GLM_result_AB_tot_inter$model


GLM_AB_tot_inter_pred <- GLM_result_AB_tot_inter$predit^2

GLM_df_AB_tot_inter = data.frame(Observed=AB_tot_inter_test[,1]^2,Predicted = GLM_AB_tot_inter_pred)

cor_GLM_AB_tot_inter <- cor(GLM_df_AB_tot_inter$Observed, GLM_df_AB_tot_inter$Predicted)

  # graphique avec ggplot
GLM_AB_tot_inter <- ggplot(GLM_df_AB_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GLM: R² = ", round(GLM_result_AB_tot_inter$R_squared,2), 
                           "; RMSE = ",  round(GLM_result_AB_tot_inter$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 

# Prediction avec GAM -----------------------------------------
# GAM_result_AB_tot_inter$RMSE
# GAM_result_AB_tot_inter$MAE
# GAM_result_AB_tot_inter$R_squared
# GAM_result_AB_tot_inter$predit
# GAM_result_AB_tot_inter$model


GAM_AB_tot_inter_pred <- GAM_result_AB_tot_inter$predit^2

GAM_df_AB_tot_inter = data.frame(Observed=AB_tot_inter_test[,1]^2,Predicted = GAM_AB_tot_inter_pred)

cor_GAM_AB_tot_inter <- cor(GAM_df_AB_tot_inter$Observed, GAM_df_AB_tot_inter$Predicted)

  # graphique avec ggplot
GAM_AB_tot_inter <- ggplot(GAM_df_AB_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GAM: R² = ", round(GAM_result_AB_tot_inter$R_squared,2), 
                           "; RMSE = ",  round(GAM_result_AB_tot_inter$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 

# Prediction avec RF -----------------------------------------
# RF_result_AB_tot_inter$RMSE
# RF_result_AB_tot_inter$MAE
# RF_result_AB_tot_inter$R_squared
# RF_result_AB_tot_inter$predit
# RF_result_AB_tot_inter$model


RF_AB_tot_inter_pred <- RF_result_AB_tot_inter$predit^2

RF_df_AB_tot_inter = data.frame(Observed=AB_tot_inter_test[,1]^2,Predicted = RF_AB_tot_inter_pred)

cor_RF_AB_tot_inter <- cor(RF_df_AB_tot_inter$Observed, RF_df_AB_tot_inter$Predicted)

  # graphique avec ggplot
RF_AB_tot_inter <- ggplot(RF_df_AB_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("RF: R² = ", round(RF_result_AB_tot_inter$R_squared,2), 
                           "; RMSE = ",  round(RF_result_AB_tot_inter$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 





# Prediction avec GBM -----------------------------------------
# GBM_result_AB_tot_inter$RMSE
# GBM_result_AB_tot_inter$MAE
# GBM_result_AB_tot_inter$R_squared
# GBM_result_AB_tot_inter$predit
# GBM_result_AB_tot_inter$model



GBM_AB_tot_inter_pred = GBM_result_AB_tot_inter$predit^2

GBM_df_AB_tot_inter = data.frame(Observed=AB_tot_inter_test[,1]^2,Predicted = GBM_AB_tot_inter_pred)

cor_GBM_AB_tot_inter<- cor(GBM_df_AB_tot_inter$Observed, GBM_df_AB_tot_inter$Predicted)

# graphique avec ggplot
GBM_AB_tot_inter <- ggplot(GBM_df_AB_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GBM: R² = ", round(GBM_result_AB_tot_inter$R_squared,2) ,
                           "; RMSE = ", round (GBM_result_AB_tot_inter$RMSE^2,2)),
           x = "Real values", y = "Predicted values") + 
      theme_classic() 





# Prediction avec ANN -----------------------------------------
# ANN_tune_AB_tot_inter_results$mse
# ANN_tune_AB_tot_inter_results$mae
# ANN_tune_AB_tot_inter_results$rmse
# ANN_tune_AB_tot_inter_results$R_squared

# ANN_AB_tot_inter_pred = ANN_tune_AB_tot_inter_pred^2
# 
# ANN_df_AB_tot_inter = data.frame(Observed=AB_tot_inter_test[,1]^2,Predicted = ANN_AB_tot_inter_pred)
# 
# cor_ANN_AB_tot_inter <- cor(ANN_df_AB_tot_inter$Observed, ANN_df_AB_tot_inter$Predicted)
# 
#   # graphique avec ggplot
# ANN_AB_tot_inter <- ggplot(ANN_df_AB_tot_inter, aes(x = Observed, y = Predicted)) +
#       geom_point() + # Ajout des points
#       geom_smooth(method = "lm", se = TRUE, color = "red") +
#       labs(subtitle =paste("ANN: R² = ", round(ANN_tune_AB_tot_inter_results$R_squared,2), 
#                            "; RMSE = ", round(ANN_tune_AB_tot_inter_results$rmse^2,2)),
#            x = "Real values", y = "Predicted values") +
#       theme_classic()
```

```{r predit AB_tot 2 inter, fig.align='center' ,eval=FALSE}
AB_tot_inter_reel =  AB_tot_inter_test[,1]^2

AB_tot_inter_algo <-data.frame(algo = rep(c("Real_value","GLM","GAM","RF","GBM"),
      each = length(AB_tot_inter_reel)), pred_values = c(
                  AB_tot_inter_reel, 
                  GLM_AB_tot_inter_pred, 
                  GAM_AB_tot_inter_pred, 
                  RF_AB_tot_inter_pred, 
                  GBM_AB_tot_inter_pred))

AB_tot_inter_algo$algo <- fct_relevel(AB_tot_inter_algo$algo,c("Real_value","GLM","GAM","RF","GBM"))


AB_tot_inter_boxplot = plot_boxplot(
  donnee = AB_tot_inter_algo,
  x_col = "algo",
  y_col = "pred_values",
  x_label = "Models",
  y_label = "Abundance",
  title = "Abundance",
  legend_title = "Models",
  couleurs = couleurs,
  affiche_point = T
)


AB_tot_inter_Kteste = kruskal.test(AB_tot_inter_algo$pred_values~AB_tot_inter_algo$algo)
AB_tot_inter_p_value = round(AB_tot_inter_Kteste$p.value,2)
if (AB_tot_inter_p_value==0){
  AB_tot_inter_p_value = 0.001
}

AB_tot_inter_pp <-pairwise.wilcox.test(
        AB_tot_inter_algo$pred_values,
        AB_tot_inter_algo$algo,
        p.adjust.method = "bonferroni",
        paired = FALSE,
        pool.sd = FALSE
      )
AB_tot_inter_mymat <- tri.to.squ(AB_tot_inter_pp$p.value)
nom_stat = paste0("Kruskal-Wallis, chi-squared = ",
                      round(AB_tot_inter_Kteste$statistic, 2),
                      "; p-value = ",
                      AB_tot_inter_p_value)

AB_tot_inter_myletters <-multcompLetters(AB_tot_inter_mymat,
                      compare = "<=",
                      threshold = 0.05,
                      Letters = letters)

AB_tot_inter_myletters <-data.frame(group = names(AB_tot_inter_myletters$Letters),
                 letter = AB_tot_inter_myletters$Letters)



AB_tot_inter_myletters$algo = AB_tot_inter_myletters$group  
# AB_tot_inter_boxplot = AB_tot_inter_boxplot + labs(subtitle = paste0(nom_stat)) +
#       geom_text(data = AB_tot_inter_myletters,
#                 aes(label = letter, y = max(AB_tot_inter_algo$pred_values + 300)))

AB_tot_inter_boxplot



graphe_AB_tot_inter = ggarrange(GLM_AB_tot_inter, GAM_AB_tot_inter, RF_AB_tot_inter, GBM_AB_tot_inter,
  labels = c('(a)', '(b)','(c)', '(d)'),
  common.legend = TRUE,
  legend = 'right'
)


# ggsave("Results/AB_tot_inter_boxplot.png", plot = AB_tot_inter_boxplot, dpi = 300, width = 5,height = 3)
# ggsave("Results/graphe_AB_tot_inter.png", plot = graphe_AB_tot_inter, dpi = 300, width = 6,height = 4)
# 
# ![](Results/AB_tot_inter_boxplot.png)
# 
# ![](Results/graphe_AB_tot_inter.png)
# ![](Results/AB_tot_inter_boxplot.png){width="500",aligne="center"}
# 
# ![](Results/graphe_AB_tot_inter.png){width="500",aligne="center"}
```



<p align="center" >
  <img src="Results/AB_tot_inter_boxplot.png">
</p>


<p align="center">
  <img src="Results/graphe_AB_tot_inter.png">
</p>


<p align="center">
  <img src="Results/RF_AB_tot_fig.png">
</p>



## Prediction of total biomass
```{r}
subtitle <- sprintf("Biomass : %.2f ± %.2f g/m²", mean(bdd_explo$BM_tot, na.rm = TRUE), sd(bdd_explo$BM_tot, na.rm = TRUE))
```

**Sans interaction ** (`r subtitle`)
```{r predit BM_tot , fig.align='center' ,eval=FALSE}
# Prediction avec GLM -----------------------------------------
# GLM_result_BM_tot$RMSE
# GLM_result_BM_tot$MAE
# GLM_result_BM_tot$R_squared
# GLM_result_BM_tot$predit
# GLM_result_BM_tot$model


GLM_BM_tot_pred <- GLM_result_BM_tot$predit^2

GLM_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = GLM_BM_tot_pred)

cor_GLM_BM_tot <- cor(GLM_df_BM_tot$Observed, GLM_df_BM_tot$Predicted)

  # graphique avec ggplot
GLM_BM_tot <- ggplot(GLM_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GLM: R² = ", round(GLM_result_BM_tot$R_squared,2), 
                           "; RMSE = ",  round(GLM_result_BM_tot$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 


# Prediction avec GAM -----------------------------------------
# GAM_result_BM_tot$RMSE
# GAM_result_BM_tot$MAE
# GAM_result_BM_tot$R_squared
# GAM_result_BM_tot$predit
# GAM_result_BM_tot$model


GAM_BM_tot_pred <- GAM_result_BM_tot$predit^2

GAM_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = GAM_BM_tot_pred)

cor_GAM_BM_tot <- cor(GAM_df_BM_tot$Observed, GAM_df_BM_tot$Predicted)

  # graphique avec ggplot
GAM_BM_tot <- ggplot(GAM_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GAM: R² = ", round(GAM_result_BM_tot$R_squared,2), 
                           "; RMSE = ",  round(GAM_result_BM_tot$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 

# Prediction avec RF -----------------------------------------
# RF_result_BM_tot$RMSE
# RF_result_BM_tot$MAE
RF_result_BM_tot$R_squared_train
RF_result_BM_tot$R_squared_test
# RF_result_BM_tot$R_squared
# RF_result_BM_tot$predit
# RF_result_BM_tot$model


RF_BM_tot_pred = RF_result_BM_tot$predit^2

RF_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = RF_BM_tot_pred)


cor_RF_BM_tot <- cor(RF_df_BM_tot$Observed, RF_df_BM_tot$Predicted)

# graphique avec ggplot
RF_BM_tot <- ggplot(RF_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("RF: R² = ", round(RF_result_BM_tot$R_squared,2), 
                           "; RMSE = ", round(RF_result_BM_tot$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 




# Prediction avec GBM -----------------------------------------
# GBM_result_BM_tot$RMSE
# GBM_result_BM_tot$MAE
# GBM_result_BM_tot$R_squared
# GBM_result_BM_tot$predit
# GBM_result_BM_tot$model



GBM_BM_tot_pred = GBM_result_BM_tot$predit^2

GBM_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = GBM_BM_tot_pred)

cor_GBM_BM_tot <- cor(GBM_df_BM_tot$Observed, GBM_df_BM_tot$Predicted)
# graphique avec ggplot
GBM_BM_tot <- ggplot(GBM_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GBM: R² = ", round(GBM_result_BM_tot$R_squared,2), 
                           "; RMSE = ", round(GBM_result_BM_tot$RMSE^2,2)),
           x = "Real values", y = "Predicted values") + 
      theme_classic()
    



# Prediction avec ANN -----------------------------------------
# ANN_tune_BM_tot_results$mse
# ANN_tune_BM_tot_results$mae
# ANN_tune_BM_tot_results$rmse
# ANN_tune_BM_tot_results$R_squared

ANN_BM_tot_pred = ANN_tune_BM_tot_pred^2

ANN_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = ANN_BM_tot_pred)

cor_ANN_BM_tot <- cor(ANN_df_BM_tot$Observed, ANN_df_BM_tot$Predicted)

  # graphique avec ggplot
ANN_BM_tot <- ggplot(ANN_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") +
      labs(subtitle =paste("ANN: R² = ", round(ANN_tune_BM_tot_results$R_squared,2), 
                           "; RMSE = ", round(ANN_tune_BM_tot_results$rmse^2,2)),
           x = "Real values", y = "Predicted values") +
      theme_classic()
```

```{r predit BM_tot 2 , fig.align='center' ,eval=FALSE}
BM_tot_reel =  BM_tot_test[,1]^2

BM_tot_algo <-data.frame(algo = rep(c("Real_value","GLM","GAM","RF","GBM","ANN"),
      each = length(BM_tot_reel)), pred_values = c(
                  BM_tot_reel, 
                  GLM_BM_tot_pred, 
                  GAM_BM_tot_pred, 
                  RF_BM_tot_pred, 
                  GBM_BM_tot_pred, 
                  ANN_BM_tot_pred))

BM_tot_algo$algo <- fct_relevel(BM_tot_algo$algo,c("Real_value","GLM","GAM","RF","GBM","ANN"))


BM_tot_boxplot = plot_boxplot(
  donnee = BM_tot_algo,
  x_col = "algo",
  y_col = "pred_values",
  x_label = "Models",
  y_label = "Biomass",
  title = "Biomass",
  legend_title = "Models",
  couleurs = couleurs,
  affiche_point = T
)


BM_tot_Kteste = kruskal.test(BM_tot_algo$pred_values~BM_tot_algo$algo)
BM_tot_p_value = round(BM_tot_Kteste$p.value,2)
if (BM_tot_p_value==0){
  BM_tot_p_value = 0.001
}

BM_tot_pp <-pairwise.wilcox.test(
        BM_tot_algo$pred_values,
        BM_tot_algo$algo,
        p.adjust.method = "bonferroni",
        paired = FALSE,
        pool.sd = FALSE
      )
BM_tot_mymat <- tri.to.squ(BM_tot_pp$p.value)
nom_stat = paste0("Kruskal-Wallis, chi-squared = ",
                      round(BM_tot_Kteste$statistic, 2),
                      "; p-value = ",
                      BM_tot_p_value)

BM_tot_myletters <-multcompLetters(BM_tot_mymat,
                      compare = "<=",
                      threshold = 0.05,
                      Letters = letters)

BM_tot_myletters <-data.frame(group = names(BM_tot_myletters$Letters),
                 letter = BM_tot_myletters$Letters)



BM_tot_myletters$algo = BM_tot_myletters$group  
# BM_tot_boxplot = BM_tot_boxplot + labs(subtitle = paste0(nom_stat)) +
#       geom_text(data = BM_tot_myletters,
#                 aes(label = letter, y = max(BM_tot_algo$pred_values + 3)))

BM_tot_boxplot

graphe_BM_tot = ggarrange(GLM_BM_tot, GAM_BM_tot, RF_BM_tot, GBM_BM_tot, ANN_BM_tot,
  labels = c('(a)', '(b)','(c)', '(d)','(e)'),
  common.legend = TRUE,
  legend = 'right'
)

# ggsave("Results/BM_tot_boxplot.png", plot = BM_tot_boxplot, dpi = 300,width = 5,height = 3)
# ggsave("Results/graphe_BM_tot.png", plot = graphe_BM_tot, dpi = 300, width = 9,height = 4.6)
```

<p align="center" >
  <img src="Results/BM_tot_boxplot.png">
</p>


<p align="center">
  <img src="Results/graphe_BM_tot.png">
</p>


**Avec interaction** (`r subtitle`)
```{r predit BM_tot_inter , fig.align='center' ,eval=FALSE}
# Prediction avec GLM -----------------------------------------
# GLM_result_BM_tot_inter$RMSE
# GLM_result_BM_tot_inter$MAE
# GLM_result_BM_tot_inter$R_squared
# GLM_result_BM_tot_inter$predit
# GLM_result_BM_tot_inter$model


GLM_BM_tot_inter_pred <- GLM_result_BM_tot_inter$predit^2

GLM_df_BM_tot_inter = data.frame(Observed=BM_tot_inter_test[,1]^2,Predicted = GLM_BM_tot_inter_pred)

cor_GLM_BM_tot_inter <- cor(GLM_df_BM_tot_inter$Observed, GLM_df_BM_tot_inter$Predicted)

  # graphique avec ggplot
GLM_BM_tot_inter <- ggplot(GLM_df_BM_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GLM: R² = ", round(GLM_result_BM_tot_inter$R_squared,2), 
                           "; RMSE = ",  round(GLM_result_BM_tot_inter$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 


# Prediction avec GAM -----------------------------------------
# GAM_result_BM_tot_inter$RMSE
# GAM_result_BM_tot_inter$MAE
# GAM_result_BM_tot_inter$R_squared
# GAM_result_BM_tot_inter$predit
# GAM_result_BM_tot_inter$model


GAM_BM_tot_inter_pred <- GAM_result_BM_tot_inter$predit^2

GAM_df_BM_tot_inter = data.frame(Observed=BM_tot_inter_test[,1]^2,Predicted = GAM_BM_tot_inter_pred)

cor_GAM_BM_tot_inter <- cor(GAM_df_BM_tot_inter$Observed, GAM_df_BM_tot_inter$Predicted)

  # graphique avec ggplot
GAM_BM_tot_inter <- ggplot(GAM_df_BM_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GAM: R² = ", round(GAM_result_BM_tot_inter$R_squared,2), 
                           "; RMSE = ",  round(GAM_result_BM_tot_inter$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 

# Prediction avec RF -----------------------------------------
# RF_result_BM_tot_inter$RMSE
# RF_result_BM_tot_inter$MAE
# RF_result_BM_tot_inter$R_squared
# RF_result_BM_tot_inter$predit
# RF_result_BM_tot_inter$model


RF_BM_tot_inter_pred = RF_result_BM_tot_inter$predit^2

RF_df_BM_tot_inter = data.frame(Observed=BM_tot_inter_test[,1]^2,Predicted = RF_BM_tot_inter_pred)


cor_RF_BM_tot_inter <- cor(RF_df_BM_tot_inter$Observed, RF_df_BM_tot_inter$Predicted)

# graphique avec ggplot
RF_BM_tot_inter <- ggplot(RF_df_BM_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("RF: R² = ", round(RF_result_BM_tot_inter$R_squared,2), 
                           "; RMSE = ", round(RF_result_BM_tot_inter$RMSE^2,2)),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 




# Prediction avec GBM -----------------------------------------
# GBM_result_BM_tot_inter$RMSE
# GBM_result_BM_tot_inter$MAE
# GBM_result_BM_tot_inter$R_squared
# GBM_result_BM_tot_inter$predit
# GBM_result_BM_tot_inter$model



GBM_BM_tot_inter_pred = GBM_result_BM_tot_inter$predit^2

GBM_df_BM_tot_inter = data.frame(Observed=BM_tot_inter_test[,1]^2,Predicted = GBM_BM_tot_inter_pred)

cor_GBM_BM_tot_inter <- cor(GBM_df_BM_tot_inter$Observed, GBM_df_BM_tot_inter$Predicted)
# graphique avec ggplot
GBM_BM_tot_inter <- ggplot(GBM_df_BM_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GBM: R² = ", round(GBM_result_BM_tot_inter$R_squared,2), 
                           "; RMSE = ", round(GBM_result_BM_tot_inter$RMSE^2,2)),
           x = "Real values", y = "Predicted values") + 
      theme_classic()
    



# Prediction avec ANN -----------------------------------------
# ANN_tune_BM_tot_inter_results$mse
# ANN_tune_BM_tot_inter_results$mae
# ANN_tune_BM_tot_inter_results$rmse
# ANN_tune_BM_tot_inter_results$R_squared

# ANN_BM_tot_inter_pred = ANN_tune_BM_tot_inter_pred^2
# 
# ANN_df_BM_tot_inter = data.frame(Observed=BM_tot_inter_test[,1]^2,Predicted = ANN_BM_tot_inter_pred)
# 
# cor_ANN_BM_tot_inter <- cor(ANN_df_BM_tot_inter$Observed, ANN_df_BM_tot_inter$Predicted)
# 
#   # graphique avec ggplot
# ANN_BM_tot_inter <- ggplot(ANN_df_BM_tot_inter, aes(x = Observed, y = Predicted)) +
#       geom_point() + # Ajout des points
#       geom_smooth(method = "lm", se = TRUE, color = "red") +
#       labs(subtitle =paste("ANN: R² = ", round(ANN_tune_BM_tot_inter_results$R_squared,2), 
#                            "; RMSE = ", round(ANN_tune_BM_tot_inter_results$rmse^2,2)),
#            x = "Real values", y = "Predicted values") +
#       theme_classic()
```

```{r predit BM_tot_inter 2 , fig.align='center' ,eval=FALSE}
BM_tot_inter_reel =  BM_tot_inter_test[,1]^2

BM_tot_inter_algo <-data.frame(algo = rep(c("Real_value","GLM","GAM","RF","GBM"),
      each = length(BM_tot_inter_reel)), pred_values = c(
                  BM_tot_inter_reel, 
                  GLM_BM_tot_inter_pred, 
                  GAM_BM_tot_inter_pred, 
                  RF_BM_tot_inter_pred, 
                  GBM_BM_tot_inter_pred 
                  ))

BM_tot_inter_algo$algo <- fct_relevel(BM_tot_inter_algo$algo,c("Real_value","GLM","GAM","RF","GBM"))


BM_tot_inter_boxplot = plot_boxplot(
  donnee = BM_tot_inter_algo,
  x_col = "algo",
  y_col = "pred_values",
  x_label = "Models",
  y_label = "Biomass",
  title = "Biomass",
  legend_title = "Models",
  couleurs = couleurs,
  affiche_point = T
)


BM_tot_inter_Kteste = kruskal.test(BM_tot_inter_algo$pred_values~BM_tot_inter_algo$algo)
BM_tot_inter_p_value = round(BM_tot_inter_Kteste$p.value,2)
if (BM_tot_inter_p_value==0){
  BM_tot_inter_p_value = 0.001
}

BM_tot_inter_pp <-pairwise.wilcox.test(
        BM_tot_inter_algo$pred_values,
        BM_tot_inter_algo$algo,
        p.adjust.method = "bonferroni",
        paired = FALSE,
        pool.sd = FALSE
      )
BM_tot_inter_mymat <- tri.to.squ(BM_tot_inter_pp$p.value)
nom_stat = paste0("Kruskal-Wallis, chi-squared = ",
                      round(BM_tot_inter_Kteste$statistic, 2),
                      "; p-value = ",
                      BM_tot_inter_p_value)

BM_tot_inter_myletters <-multcompLetters(BM_tot_inter_mymat,
                      compare = "<=",
                      threshold = 0.05,
                      Letters = letters)

BM_tot_inter_myletters <-data.frame(group = names(BM_tot_inter_myletters$Letters),
                 letter = BM_tot_inter_myletters$Letters)



BM_tot_inter_myletters$algo = BM_tot_inter_myletters$group  
# BM_tot_inter_boxplot = BM_tot_inter_boxplot + labs(subtitle = paste0(nom_stat)) +
#       geom_text(data = BM_tot_inter_myletters,
#                 aes(label = letter, y = max(BM_tot_inter_algo$pred_values + 100)))

BM_tot_inter_boxplot

graphe_BM_tot_inter = ggarrange(GLM_BM_tot_inter, GAM_BM_tot_inter, RF_BM_tot_inter, GBM_BM_tot_inter,
  labels = c('(a)', '(b)','(c)', '(d)'),
  common.legend = TRUE,
  legend = 'right'
)



# ggsave("Results/BM_tot_inter_boxplot.png", plot = BM_tot_inter_boxplot, dpi = 300,width = 5,height = 3)
# ggsave("Results/graphe_BM_tot_inter.png", plot = graphe_BM_tot_inter, dpi = 300, width = 7,height = 4)

# ![](Results/BM_tot_inter_boxplot.png){width="1000",aligne="center"}
# ![](Results/graphe_BM_tot_inter.png){width="1000",aligne="center"}
```


<p align="center" >
  <img src="Results/BM_tot_inter_boxplot.png">
</p>


<p align="center">
  <img src="Results/graphe_BM_tot_inter.png">
</p>



## Prediction of total taxonomic richness

```{r}
subtitle <- sprintf("Richness : %.2f ± %.2f", round(mean(bdd_explo$Richesse_tot, na.rm = TRUE)), round(sd(bdd_explo$Richesse_tot, na.rm = TRUE)))
```

**Sans interaction ** (`r subtitle`)
```{r predit Richesse_tot , fig.align='center', eval=FALSE}
# Prediction avec GLM -----------------------------------------
# GLM_result_Richesse_tot$RMSE
# GLM_result_Richesse_tot$MAE
# GLM_result_Richesse_tot$R_squared
# GLM_result_Richesse_tot$predit
# GLM_result_Richesse_tot$model


GLM_Richesse_tot_pred <- GLM_result_Richesse_tot$predit

GLM_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = GLM_Richesse_tot_pred)

cor_GLM_Richesse_tot <- cor(GLM_df_Richesse_tot$Observed, GLM_df_Richesse_tot$Predicted)

  # graphique avec ggplot
GLM_Richesse_tot <- ggplot(GLM_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GLM: R² = ", round(cor_GLM_Richesse_tot^2,2), 
                           "; RMSE = ",  GLM_result_Richesse_tot$RMSE),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 


# Prediction avec GAM -----------------------------------------
# GAM_result_Richesse_tot$RMSE
# GAM_result_Richesse_tot$MAE
# GAM_result_Richesse_tot$R_squared
# GAM_result_Richesse_tot$predit
# GAM_result_Richesse_tot$model


GAM_Richesse_tot_pred <- GAM_result_Richesse_tot$predit

GAM_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = GAM_Richesse_tot_pred)

cor_GAM_Richesse_tot <- cor(GAM_df_Richesse_tot$Observed, GAM_df_Richesse_tot$Predicted)

  # graphique avec ggplot
GAM_Richesse_tot <- ggplot(GAM_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GAM: R² = ", round(cor_GAM_Richesse_tot^2,2), 
                           "; RMSE = ",  GAM_result_Richesse_tot$RMSE),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 


# Prediction avec RF -----------------------------------------
# RF_result_Richesse_tot$RMSE
# RF_result_Richesse_tot$MAE
# RF_result_Richesse_tot$R_squared
RF_result_Richesse_tot$R_squared_train
RF_result_Richesse_tot$R_squared_test
# RF_result_Richesse_tot$predit
# RF_result_Richesse_tot$model


RF_Richesse_tot_pred = RF_result_Richesse_tot$predit

RF_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = RF_Richesse_tot_pred)


cor_RF_Richesse_tot <- cor(RF_df_Richesse_tot$Observed, RF_df_Richesse_tot$Predicted)

# graphique avec ggplot
RF_Richesse_tot <- ggplot(RF_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("RF: R² = ", round(cor_RF_Richesse_tot^2,2),
                           "; RMSE = ", RF_result_Richesse_tot$RMSE),
           x = "Real values", y = "Predicted values") + 
      theme_classic() 

 



# Prediction avec GBM -----------------------------------------
Richesse_tot_GBM_tuning = read.csv2("results_tuning/Richesse_tot_GBM_tuning.csv")


Richesse_tot_GBM_tuning = as.data.frame(Richesse_tot_GBM_tuning)
Richesse_tot_GBM_tuning = Richesse_tot_GBM_tuning %>% arrange(mae)
# head(Richesse_tot_GBM_tuning)
Richesse_tot_best_param = Richesse_tot_GBM_tuning[1,]


# Best hyperparameter values
Richesse_tot_best_n.trees = Richesse_tot_best_param$n.trees
Richesse_tot_best_shrinkage = Richesse_tot_best_param$shrinkage
Richesse_tot_best_interaction.depth = Richesse_tot_best_param$interaction.depth
Richesse_tot_best_n.minobsinnode = Richesse_tot_best_param$n.minobsinnode


GBM_result_Richesse_tot =  GBM(var_rep ="Richesse_tot", 
                         df_app=Richesse_tot_train, 
                         df_valid = Richesse_tot_test,
                         distribution = 'gaussian',
                         n.trees = Richesse_tot_best_n.trees,
                         shrinkage = Richesse_tot_best_shrinkage,
                         interaction.depth = Richesse_tot_best_interaction.depth,
                         n.minobsinnode = Richesse_tot_best_n.minobsinnode)
# GBM_result_Richesse_tot$RMSE
# GBM_result_Richesse_tot$MAE
# GBM_result_Richesse_tot$R_squared
# GBM_result_Richesse_tot$predit
# GBM_result_Richesse_tot$model



GBM_Richesse_tot_pred = round(GBM_result_Richesse_tot$predit)

GBM_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = GBM_Richesse_tot_pred)

cor_GBM_Richesse_tot <- cor(GBM_df_Richesse_tot$Observed, GBM_df_Richesse_tot$Predicted)

# graphique avec ggplot
GBM_Richesse_tot <- ggplot(GBM_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GBM: R² = ", round(cor_GBM_Richesse_tot^2,2), 
                           "; RMSE = ", GBM_result_Richesse_tot$RMSE),
           x = "Real values", y = "Predicted values") + 
      theme_classic() 



df_tot = GBM_df_Richesse_tot
df_tot$observation = seq(1,nrow(df_tot))

# Calcul des quartiles
q1 <- quantile(df_tot$Observed, 0.25)
median <- quantile(df_tot$Observed, 0.50)
q3 <- quantile(df_tot$Observed, 0.75)
max_value <- max(df_tot$Observed)

# Création des DataFrames en fonction des quartiles
df1 <- df_tot[df_tot$Observed <= q1,]
df2 <- df_tot[df_tot$Observed > q1 & df_tot$Observed <= median,]
df3 <- df_tot[df_tot$Observed > median & df_tot$Observed <= q3,]
df4 <- df_tot[df_tot$Observed > q3,]




Richesse_tot_p1 = plot_comp(df = df1,ylabel = "",title_class = "  min to Q1",legende = TRUE,xlabel = "",title = "GBM: Richness predicted and observed values \n for different quartiles")

Richesse_tot_p2 = plot_comp(df = df2,ylabel = "" ,title_class = "Q1 to median",legende = FALSE,xlabel = "")
Richesse_tot_p3 = plot_comp(df = df3,ylabel = "" ,title_class = "median to Q3" ,legende = FALSE,xlabel = "")
Richesse_tot_p4 = plot_comp(df = df4,ylabel = "" ,title_class = " Q3 to max" ,legende = FALSE)


GBM_Richesse_tot_fig = ggarrange(Richesse_tot_p1, Richesse_tot_p2, Richesse_tot_p3, Richesse_tot_p4,
  # labels = c('(a)', '(b)','(c)', '(d)'),
  ncol = 1,vjust = 0.5,
  common.legend = TRUE,
  legend = 'right'
)


GBM_Richesse_tot_fig
# ggsave("Results/GBM_Richesse_tot_fig.png", plot = GBM_Richesse_tot_fig, dpi = 300)




# Prediction avec ANN -----------------------------------------
# ANN_tune_Richesse_tot_results$mse
# ANN_tune_Richesse_tot_results$mae
# ANN_tune_Richesse_tot_results$rmse
# ANN_tune_Richesse_tot_results$cor_pred_obs

ANN_Richesse_tot_pred = ANN_tune_Richesse_tot_pred

ANN_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = ANN_Richesse_tot_pred)

cor_ANN_Richesse_tot <- cor(ANN_df_Richesse_tot$Observed, ANN_df_Richesse_tot$Predicted)

  # graphique avec ggplot
ANN_Richesse_tot <- ggplot(ANN_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") +
      labs(subtitle =paste("ANN: R² = ", round(cor_ANN_Richesse_tot^2,2), 
                           "; RMSE = ", round(ANN_tune_Richesse_tot_results$rmse,2)),
           x = "Real values", y = "Predicted values") +
      theme_classic()
```

```{r predit Richesse_tot 2 , fig.align='center', eval=FALSE}

Richesse_tot_reel =  Richesse_tot_test[,1]

Richesse_tot_algo <-data.frame(algo = rep(c("Real_value","GLM","GAM","RF","GBM","ANN"),
      each = length(Richesse_tot_reel)), pred_values = c(
                  Richesse_tot_reel, 
                  GLM_Richesse_tot_pred, 
                  GAM_Richesse_tot_pred, 
                  RF_Richesse_tot_pred, 
                  GBM_Richesse_tot_pred, 
                  ANN_Richesse_tot_pred))

Richesse_tot_algo$algo <- fct_relevel(Richesse_tot_algo$algo,c("Real_value","GLM","GAM","RF","GBM","ANN"))


Richesse_tot_boxplot = plot_boxplot(
  donnee = Richesse_tot_algo,
  x_col = "algo",
  y_col = "pred_values",
  x_label = "Models",
  y_label = "Richness",
  title = "Richness",
  legend_title = "Models",
  couleurs = couleurs,
  affiche_point = T
)


Richesse_tot_Kteste = kruskal.test(Richesse_tot_algo$pred_values~Richesse_tot_algo$algo)
Richesse_tot_p_value = round(Richesse_tot_Kteste$p.value,2)
if (Richesse_tot_p_value==0){
  Richesse_tot_p_value = 0.001
}

Richesse_tot_pp <-pairwise.wilcox.test(
        Richesse_tot_algo$pred_values,
        Richesse_tot_algo$algo,
        p.adjust.method = "bonferroni",
        paired = FALSE,
        pool.sd = FALSE
      )
Richesse_tot_mymat <- tri.to.squ(Richesse_tot_pp$p.value)
nom_stat = paste0("Kruskal-Wallis, chi-squared = ",
                      round(Richesse_tot_Kteste$statistic, 2),
                      "; p-value = ",
                      Richesse_tot_p_value)

Richesse_tot_myletters <-multcompLetters(Richesse_tot_mymat,
                      compare = "<=",
                      threshold = 0.05,
                      Letters = letters)

Richesse_tot_myletters <-data.frame(group = names(Richesse_tot_myletters$Letters),
                 letter = Richesse_tot_myletters$Letters)



Richesse_tot_myletters$algo = Richesse_tot_myletters$group  
# Richesse_tot_boxplot = Richesse_tot_boxplot + labs(subtitle = paste0(nom_stat)) +
#       geom_text(data = Richesse_tot_myletters,
#                 aes(label = letter, y = max(Richesse_tot_algo$pred_values + 3)))

Richesse_tot_boxplot

graphe_Richesse_tot= ggarrange(GLM_Richesse_tot, GAM_Richesse_tot, RF_Richesse_tot, GBM_Richesse_tot, ANN_Richesse_tot,
  labels = c('(a)', '(b)','(c)', '(d)','(e)'),
  common.legend = TRUE,
  legend = 'right'
)

# ggsave("Results/Richesse_tot_boxplot.png", plot = Richesse_tot_boxplot, dpi = 300,width = 5,height = 3)
# ggsave("Results/graphe_Richesse_tot.png", plot = graphe_Richesse_tot, dpi = 300,width = 8,height = 4.6)


```

<p align="center" >
  <img src="Results/Richesse_tot_boxplot.png">
</p>


<p align="center">
  <img src="Results/graphe_Richesse_tot.png">
</p>


**Avec interaction** (`r subtitle`)
```{r predit Richesse_tot_inter , fig.align='center' ,eval=FALSE}
# Prediction avec GLM -----------------------------------------
# GLM_result_Richesse_tot_inter$RMSE
# GLM_result_Richesse_tot_inter$MAE
# GLM_result_Richesse_tot_inter$R_squared
# GLM_result_Richesse_tot_inter$predit
# GLM_result_Richesse_tot_inter$model


GLM_Richesse_tot_inter_pred <- GLM_result_Richesse_tot_inter$predit

GLM_df_Richesse_tot_inter = data.frame(Observed=Richesse_tot_inter_test[,1],Predicted = GLM_Richesse_tot_inter_pred)

cor_GLM_Richesse_tot_inter <- cor(GLM_df_Richesse_tot_inter$Observed, GLM_df_Richesse_tot_inter$Predicted)

  # graphique avec ggplot
GLM_Richesse_tot_inter <- ggplot(GLM_df_Richesse_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GLM: R² = ", round(cor_GLM_Richesse_tot_inter^2,2), 
                           "; RMSE = ",  GLM_result_Richesse_tot_inter$RMSE),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 


# Prediction avec GAM -----------------------------------------
# GAM_result_Richesse_tot_inter$RMSE
# GAM_result_Richesse_tot_inter$MAE
# GAM_result_Richesse_tot_inter$R_squared
# GAM_result_Richesse_tot_inter$predit
# GAM_result_Richesse_tot_inter$model


GAM_Richesse_tot_inter_pred <- GAM_result_Richesse_tot_inter$predit

GAM_df_Richesse_tot_inter = data.frame(Observed=Richesse_tot_inter_test[,1],Predicted = GAM_Richesse_tot_inter_pred)

cor_GAM_Richesse_tot_inter <- cor(GAM_df_Richesse_tot_inter$Observed, GAM_df_Richesse_tot_inter$Predicted)

  # graphique avec ggplot
GAM_Richesse_tot_inter <- ggplot(GAM_df_Richesse_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GAM: R² = ", round(cor_GAM_Richesse_tot_inter^2,2), 
                           "; RMSE = ",  GAM_result_Richesse_tot_inter$RMSE),
                            x = "Real values", 
                            y = "Predicted values") + 
      theme_classic() 


# Prediction avec RF -----------------------------------------
# RF_result_Richesse_tot_inter$RMSE
# RF_result_Richesse_tot_inter$MAE
# RF_result_Richesse_tot_inter$R_squared
# RF_result_Richesse_tot_inter$predit
# RF_result_Richesse_tot_inter$model


RF_Richesse_tot_inter_pred = RF_result_Richesse_tot_inter$predit

RF_df_Richesse_tot_inter = data.frame(Observed=Richesse_tot_inter_test[,1],Predicted = RF_Richesse_tot_inter_pred)


cor_RF_Richesse_tot_inter <- cor(RF_df_Richesse_tot_inter$Observed, RF_df_Richesse_tot_inter$Predicted)

# graphique avec ggplot
RF_Richesse_tot_inter <- ggplot(RF_df_Richesse_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("RF: R² = ", round(cor_RF_Richesse_tot_inter^2,2),
                           "; RMSE = ", RF_result_Richesse_tot_inter$RMSE),
           x = "Real values", y = "Predicted values") + 
      theme_classic() 

 



# Prediction avec GBM -----------------------------------------
# GBM_result_Richesse_tot_inter$RMSE
# GBM_result_Richesse_tot_inter$MAE
# GBM_result_Richesse_tot_inter$R_squared
# GBM_result_Richesse_tot_inter$predit
# GBM_result_Richesse_tot_inter$model



GBM_Richesse_tot_inter_pred = GBM_result_Richesse_tot_inter$predit

GBM_df_Richesse_tot_inter = data.frame(Observed=Richesse_tot_inter_test[,1],Predicted = GBM_Richesse_tot_inter_pred)

cor_GBM_Richesse_tot_inter <- cor(GBM_df_Richesse_tot_inter$Observed, GBM_df_Richesse_tot_inter$Predicted)

# graphique avec ggplot
GBM_Richesse_tot_inter <- ggplot(GBM_df_Richesse_tot_inter, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste("GBM: R² = ", round(cor_GBM_Richesse_tot_inter^2,2), 
                           "; RMSE = ", GBM_result_Richesse_tot_inter$RMSE),
           x = "Real values", y = "Predicted values") + 
      theme_classic() 




# Prediction avec ANN -----------------------------------------
# ANN_tune_Richesse_tot_inter_results$mse
# ANN_tune_Richesse_tot_inter_results$mae
# ANN_tune_Richesse_tot_inter_results$rmse
# ANN_tune_Richesse_tot_inter_results$cor_pred_obs

# ANN_Richesse_tot_inter_pred = ANN_tune_Richesse_tot_inter_pred
# 
# ANN_df_Richesse_tot_inter = data.frame(Observed=Richesse_tot_inter_test[,1],Predicted = ANN_Richesse_tot_inter_pred)
# 
# cor_ANN_Richesse_tot_inter <- cor(ANN_df_Richesse_tot_inter$Observed, ANN_df_Richesse_tot_inter$Predicted)
# 
#   # graphique avec ggplot
# ANN_Richesse_tot_inter <- ggplot(ANN_df_Richesse_tot_inter, aes(x = Observed, y = Predicted)) +
#       geom_point() + # Ajout des points
#       geom_smooth(method = "lm", se = TRUE, color = "red") +
#       labs(subtitle =paste("ANN: R² = ", round(cor_ANN_Richesse_tot_inter^2,2), 
#                            "; RMSE = ", round(ANN_tune_Richesse_tot_inter_results$rmse,2)),
#            x = "Real values", y = "Predicted values") +
#       theme_classic()
```

```{r predit Richesse_tot_inter 2 , fig.align='center' ,eval=FALSE}

Richesse_tot_inter_reel =  Richesse_tot_inter_test[,1]

Richesse_tot_inter_algo <-data.frame(algo = rep(c("Real_value","GLM","GAM","RF","GBM"),
      each = length(Richesse_tot_inter_reel)), pred_values = c(
                  Richesse_tot_inter_reel, 
                  GLM_Richesse_tot_inter_pred, 
                  GAM_Richesse_tot_inter_pred, 
                  RF_Richesse_tot_inter_pred, 
                  GBM_Richesse_tot_inter_pred 
                  ))

Richesse_tot_inter_algo$algo <- fct_relevel(Richesse_tot_inter_algo$algo,c("Real_value","GLM","GAM","RF","GBM"))


Richesse_tot_inter_boxplot = plot_boxplot(
  donnee = Richesse_tot_inter_algo,
  x_col = "algo",
  y_col = "pred_values",
  x_label = "Models",
  y_label = "Richness",
  title = "Richness",
  legend_title = "Models",
  couleurs = couleurs,
  affiche_point = T
)


Richesse_tot_inter_Kteste = kruskal.test(Richesse_tot_inter_algo$pred_values~Richesse_tot_inter_algo$algo)
Richesse_tot_inter_p_value = round(Richesse_tot_inter_Kteste$p.value,2)
if (Richesse_tot_inter_p_value==0){
  Richesse_tot_inter_p_value = 0.001
}

Richesse_tot_inter_pp <-pairwise.wilcox.test(
        Richesse_tot_inter_algo$pred_values,
        Richesse_tot_inter_algo$algo,
        p.adjust.method = "bonferroni",
        paired = FALSE,
        pool.sd = FALSE
      )
Richesse_tot_inter_mymat <- tri.to.squ(Richesse_tot_inter_pp$p.value)
nom_stat = paste0("Kruskal-Wallis, chi-squared = ",
                      round(Richesse_tot_inter_Kteste$statistic, 2),
                      "; p-value = ",
                      Richesse_tot_inter_p_value)

Richesse_tot_inter_myletters <-multcompLetters(Richesse_tot_inter_mymat,
                      compare = "<=",
                      threshold = 0.05,
                      Letters = letters)

Richesse_tot_inter_myletters <-data.frame(group = names(Richesse_tot_inter_myletters$Letters),
                 letter = Richesse_tot_inter_myletters$Letters)



Richesse_tot_inter_myletters$algo = Richesse_tot_inter_myletters$group  
# Richesse_tot_inter_boxplot = Richesse_tot_inter_boxplot + labs(subtitle = paste0(nom_stat)) +
#       geom_text(data = Richesse_tot_inter_myletters,
#                 aes(label = letter, y = max(Richesse_tot_inter_algo$pred_values + 3)))

Richesse_tot_inter_boxplot

graphe_Richesse_tot_inter = ggarrange(GLM_Richesse_tot_inter, GAM_Richesse_tot_inter, RF_Richesse_tot_inter, GBM_Richesse_tot_inter,
  labels = c('(a)', '(b)','(c)', '(d)'),
  common.legend = TRUE,
  legend = 'right'
)


# ggsave("Results/Richesse_tot_inter_boxplot.png", plot = Richesse_tot_inter_boxplot, dpi = 300,width = 5,height = 3)
# ggsave("Results/graphe_Richesse_tot_inter.png", plot = graphe_Richesse_tot_inter, dpi = 300,width = 7,height = 5)

# ![](Results/Richesse_tot_inter_boxplot.png){width="1000",aligne="center"}
# ![](Results/graphe_Richesse_tot_inter.png){width="1000",aligne="center"}

```



<p align="center" >
  <img src="Results/Richesse_tot_inter_boxplot.png">
</p>


<p align="center">
  <img src="Results/graphe_Richesse_tot_inter.png">
</p>



<p align="center">
  <img src="Results/GBM_Richesse_tot_fig.png">
</p>




# Results: Case 2 -> non-repeated data


# To do next

-   

    1.  Rédaction, protocol ODMAP;

-   

    2.  Case 2: models without temporal data repetition;

-   

    3.  Idées améliorations models:

    -   Augmentation des données;

    -   Création des models par OS ou equilibree les levels des OS;





