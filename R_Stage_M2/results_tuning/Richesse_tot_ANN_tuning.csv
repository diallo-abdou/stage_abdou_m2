"run_dir";"metric_loss";"metric_mae";"metric_val_loss";"metric_val_mae";"flag_dense_units1";"flag_dense_units2";"flag_dense_units3";"flag_dense_units4";"flag_dropout1";"flag_dropout2";"flag_dropout3";"flag_dropout4";"flag_batch_size";"epochs";"epochs_completed";"metrics";"model";"loss_function";"optimizer";"learning_rate";"script";"start";"end";"completed";"output";"source_code";"context";"type"
"runs/2024-03-14T15-11-09Z";4,7239;1,6467;7,3597;2,2014;64;32;16;8;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T15-11-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfa7c7d90>";0,00100000004749745;"Experiment.R";2024-03-14 15:11:10.43462;2024-03-14 15:11:23.90128;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-11-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-11-01Z";5,2694;1,7574;8,4083;2,351;32;32;16;8;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T15-11-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfba49e70>";0,00100000004749745;"Experiment.R";2024-03-14 15:11:02.82614;2024-03-14 15:11:09.61772;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-11-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-10-53Z";5,0407;1,7212;9,0984;2,4383;64;16;16;8;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T15-10-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfa07cfa0>";0,00100000004749745;"Experiment.R";2024-03-14 15:10:54.95397;2024-03-14 15:11:01.7906;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-10-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-10-41Z";5,1887;1,754;8,3704;2,362;32;16;16;8;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T15-10-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfbf1a0b0>";0,00100000004749745;"Experiment.R";2024-03-14 15:10:42.65305;2024-03-14 15:10:53.51548;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-10-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-10-34Z";5,5488;1,7906;8,2584;2,3367;64;32;8;8;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T15-10-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfbed6b30>";0,00100000004749745;"Experiment.R";2024-03-14 15:10:35.55039;2024-03-14 15:10:41.23786;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-10-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-10-26Z";5,7041;1,7977;8,8104;2,408;32;32;8;8;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T15-10-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfc0ebcd0>";0,00100000004749745;"Experiment.R";2024-03-14 15:10:27.60794;2024-03-14 15:10:34.77266;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-10-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-10-16Z";5,2129;1,7438;8,0718;2,3008;64;16;8;8;0,2;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T15-10-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfc1865f0>";0,00100000004749745;"Experiment.R";2024-03-14 15:10:18.05536;2024-03-14 15:10:26.80607;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-10-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-10-02Z";5,5682;1,8066;8,4026;2,3508;32;16;8;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T15-10-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfa1b2200>";0,00100000004749745;"Experiment.R";2024-03-14 15:10:03.65254;2024-03-14 15:10:16.68092;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-10-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-09-56Z";5,9498;1,8319;7,6369;2,2522;64;32;16;4;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T15-09-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfc59ea10>";0,00100000004749745;"Experiment.R";2024-03-14 15:09:57.4204;2024-03-14 15:10:02.84071;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-09-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-09-45Z";5,6699;1,7949;7,1066;2,1814;32;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-09-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfc80d5d0>";0,00100000004749745;"Experiment.R";2024-03-14 15:09:46.60599;2024-03-14 15:09:56.6425;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-09-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-09-37Z";7,0281;1,9636;8,4442;2,3569;64;16;16;4;0,2;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T15-09-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfca06770>";0,00100000004749745;"Experiment.R";2024-03-14 15:09:38.51951;2024-03-14 15:09:45.81296;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-09-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-09-27Z";19,1395;3,5444;22,0068;3,8582;32;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-09-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfce74b50>";0,00100000004749745;"Experiment.R";2024-03-14 15:09:28.42269;2024-03-14 15:09:37.57593;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-09-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-09-12Z";6,4829;1,892;8,2119;2,3346;64;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-09-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfd9d5f00>";0,00100000004749745;"Experiment.R";2024-03-14 15:09:13.92139;2024-03-14 15:09:27.25781;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-09-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-09-06Z";7,0832;2,0096;7,7576;2,2706;32;32;8;4;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T15-09-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfdbef340>";0,00100000004749745;"Experiment.R";2024-03-14 15:09:06.90003;2024-03-14 15:09:12.63395;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-09-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-08-55Z";5,2571;1,7374;7,4966;2,2387;64;16;8;4;0,2;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T15-08-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfde21240>";0,00100000004749745;"Experiment.R";2024-03-14 15:08:56.51447;2024-03-14 15:09:06.13721;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-08-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-08-50Z";6,5448;1,9361;7,9013;2,2845;32;16;8;4;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T15-08-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfe06a620>";0,00100000004749745;"Experiment.R";2024-03-14 15:08:50.91643;2024-03-14 15:08:55.70766;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-08-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-08-41Z";5,0058;1,6982;7,2584;2,179;64;32;16;8;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T15-08-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfcb98370>";0,00100000004749745;"Experiment.R";2024-03-14 15:08:41.92475;2024-03-14 15:08:50.12613;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-08-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-08-28Z";4,8576;1,6846;7,6247;2,2478;32;32;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-08-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfc3c4340>";0,00100000004749745;"Experiment.R";2024-03-14 15:08:29.01198;2024-03-14 15:08:41.1306;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-08-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-08-18Z";5,2596;1,7603;8,6706;2,3787;64;16;16;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T15-08-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfce4a440>";0,00100000004749745;"Experiment.R";2024-03-14 15:08:19.58159;2024-03-14 15:08:28.2084;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-08-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-08-07Z";5,463;1,7831;7,8449;2,2654;32;16;16;8;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T15-08-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfd0327a0>";0,00100000004749745;"Experiment.R";2024-03-14 15:08:08.34371;2024-03-14 15:08:18.789;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-08-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-07-59Z";6,7929;1,9868;9,3135;2,4712;64;32;8;8;0,2;0,3;0,2;0,1;64;50;19;"runs/2024-03-14T15-07-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9df8f8a470>";0,00100000004749745;"Experiment.R";2024-03-14 15:08:00.29695;2024-03-14 15:08:07.52749;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-07-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-07-48Z";5,1442;1,7206;9,0767;2,4332;32;32;8;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T15-07-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfd2825f0>";0,00100000004749745;"Experiment.R";2024-03-14 15:07:49.55103;2024-03-14 15:07:59.49844;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-07-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-07-38Z";5,5257;1,778;8,4341;2,3524;64;16;8;8;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T15-07-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfd4b9e10>";0,00100000004749745;"Experiment.R";2024-03-14 15:07:39.60961;2024-03-14 15:07:48.76546;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-07-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-07-32Z";6,2838;1,8835;8,2522;2,3345;32;16;8;8;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T15-07-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfe23a230>";0,00100000004749745;"Experiment.R";2024-03-14 15:07:33.81508;2024-03-14 15:07:38.82704;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-07-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-07-24Z";5,9084;1,8006;8,1848;2,3339;64;32;16;4;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T15-07-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfe289780>";0,00100000004749745;"Experiment.R";2024-03-14 15:07:25.49725;2024-03-14 15:07:32.55085;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-07-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-07-15Z";7,0726;1,9466;8,0193;2,2956;32;32;16;4;0,2;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T15-07-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfe5e5ae0>";0,00100000004749745;"Experiment.R";2024-03-14 15:07:16.2959;2024-03-14 15:07:24.70975;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-07-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-07-05Z";5,3304;1,7314;7,5793;2,2272;64;16;16;4;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T15-07-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfe6d5b10>";0,00100000004749745;"Experiment.R";2024-03-14 15:07:06.33574;2024-03-14 15:07:15.4948;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-07-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-06-55Z";5,3855;1,7756;7,4715;2,2203;32;16;16;4;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T15-06-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfd5bff40>";0,00100000004749745;"Experiment.R";2024-03-14 15:06:56.08114;2024-03-14 15:07:05.09253;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-06-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-06-42Z";5,4684;1,759;7,7763;2,2545;64;32;8;4;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T15-06-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfea29750>";0,00100000004749745;"Experiment.R";2024-03-14 15:06:43.55403;2024-03-14 15:06:55.31401;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-06-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-06-34Z";5,5834;1,8033;6,8919;2,1591;32;32;8;4;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T15-06-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfec6c8b0>";0,00100000004749745;"Experiment.R";2024-03-14 15:06:35.16493;2024-03-14 15:06:42.77465;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-06-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-06-19Z";4,7821;1,6663;7,6984;2,2612;64;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-06-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfece4ac0>";0,00100000004749745;"Experiment.R";2024-03-14 15:06:19.81458;2024-03-14 15:06:34.41843;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-06-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-06-06Z";6,0229;1,8665;7,9137;2,2985;32;16;8;4;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T15-06-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfeede350>";0,00100000004749745;"Experiment.R";2024-03-14 15:06:07.54048;2024-03-14 15:06:19.07595;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-06-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-05-57Z";5,2729;1,7337;8,1894;2,3198;64;32;16;8;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T15-05-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dffe463b0>";0,00100000004749745;"Experiment.R";2024-03-14 15:05:58.44006;2024-03-14 15:06:06.75366;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-05-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-05-50Z";6,7893;1,9959;8,4234;2,3726;32;32;16;8;0,2;0,3;0,2;0,1;64;50;13;"runs/2024-03-14T15-05-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfd78e500>";0,00100000004749745;"Experiment.R";2024-03-14 15:05:51.33092;2024-03-14 15:05:57.65187;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-05-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-05-41Z";5,1232;1,7225;8,001;2,2994;64;16;16;8;0,2;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T15-05-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dfd0c26e0>";0,00100000004749745;"Experiment.R";2024-03-14 15:05:42.11271;2024-03-14 15:05:49.95875;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-05-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-05-24Z";5,0435;1,7048;7,8595;2,2698;32;16;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-05-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dff4c3760>";0,00100000004749745;"Experiment.R";2024-03-14 15:05:25.09509;2024-03-14 15:05:41.3586;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-05-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-05-17Z";5,5362;1,801;8,501;2,3524;64;32;8;8;0,2;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T15-05-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dff749ab0>";0,00100000004749745;"Experiment.R";2024-03-14 15:05:17.93803;2024-03-14 15:05:24.34832;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-05-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-05-01Z";4,968;1,71;7,0357;2,1585;32;32;8;8;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T15-05-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dff784ee0>";0,00100000004749745;"Experiment.R";2024-03-14 15:05:03.29401;2024-03-14 15:05:17.17302;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-05-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-04-53Z";7,4795;2,087;8,967;2,4299;64;16;8;8;0,2;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T15-04-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dff9a6410>";0,00100000004749745;"Experiment.R";2024-03-14 15:04:54.66278;2024-03-14 15:05:01.93275;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-04-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-04-41Z";5,5496;1,7878;8,3174;2,3225;32;16;8;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T15-04-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dff1e2e30>";0,00100000004749745;"Experiment.R";2024-03-14 15:04:41.82964;2024-03-14 15:04:53.883;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-04-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-04-32Z";7,1327;1,9701;8,6689;2,3687;64;32;16;4;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T15-04-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dffbff9d0>";0,00100000004749745;"Experiment.R";2024-03-14 15:04:32.83273;2024-03-14 15:04:41.05884;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-04-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-04-22Z";6,2991;1,9338;7,5673;2,2443;32;32;16;4;0,2;0,3;0,2;0,1;64;50;14;"runs/2024-03-14T15-04-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dffe46bf0>";0,00100000004749745;"Experiment.R";2024-03-14 15:04:22.98975;2024-03-14 15:04:32.1046;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-04-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-04-16Z";5,8267;1,8142;7,8812;2,2788;64;16;16;4;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T15-04-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9dffe9a590>";0,00100000004749745;"Experiment.R";2024-03-14 15:04:16.75819;2024-03-14 15:04:22.22186;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-04-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-04-05Z";5,3423;1,7508;6,5655;2,1261;32;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-04-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e001d8bb0>";0,00100000004749745;"Experiment.R";2024-03-14 15:04:05.94411;2024-03-14 15:04:15.98348;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-04-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-03-52Z";5,4067;1,7537;8,2738;2,335;64;32;8;4;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T15-03-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0043c160>";0,00100000004749745;"Experiment.R";2024-03-14 15:03:53.66684;2024-03-14 15:04:05.17759;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-03-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-03-40Z";5,9407;1,8201;8,1361;2,3234;32;32;8;4;0,2;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T15-03-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e00662800>";0,00100000004749745;"Experiment.R";2024-03-14 15:03:41.67039;2024-03-14 15:03:52.91995;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-03-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-03-31Z";5,9549;1,8277;7,3034;2,2091;64;16;8;4;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T15-03-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e032b7820>";0,00100000004749745;"Experiment.R";2024-03-14 15:03:32.09945;2024-03-14 15:03:40.89209;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-03-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-03-20Z";6,8044;1,9378;8,1215;2,318;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-03-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e00bc6a40>";0,00100000004749745;"Experiment.R";2024-03-14 15:03:21.72545;2024-03-14 15:03:31.33047;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-03-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-03-15Z";5,7007;1,8349;7,8675;2,2914;64;32;16;8;0,2;0,3;0,2;0,1;64;50;15;"runs/2024-03-14T15-03-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e00e565c0>";0,00100000004749745;"Experiment.R";2024-03-14 15:03:16.06075;2024-03-14 15:03:20.39586;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-03-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-03-05Z";5,0334;1,7218;7,5896;2,2424;32;32;16;8;0,2;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T15-03-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e00ea27a0>";0,00100000004749745;"Experiment.R";2024-03-14 15:03:06.45719;2024-03-14 15:03:15.2608;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-03-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-02-57Z";5,5452;1,7756;7,6523;2,2454;64;16;16;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T15-02-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e010abd90>";0,00100000004749745;"Experiment.R";2024-03-14 15:02:58.60388;2024-03-14 15:03:05.67492;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-02-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-02-44Z";5,0288;1,7191;8,7002;2,3695;32;16;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-02-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e007f3940>";0,00100000004749745;"Experiment.R";2024-03-14 15:02:45.60893;2024-03-14 15:02:57.84186;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-02-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-02-38Z";5,4532;1,7774;8,7516;2,3951;64;32;8;8;0,2;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T15-02-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e00928070>";0,00100000004749745;"Experiment.R";2024-03-14 15:02:39.02946;2024-03-14 15:02:44.44777;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-02-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-02-27Z";4,8891;1,6944;7,774;2,2571;32;32;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-02-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e01366f20>";0,00100000004749745;"Experiment.R";2024-03-14 15:02:28.56757;2024-03-14 15:02:38.27588;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-02-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-02-22Z";6,3745;1,9127;9,0596;2,4291;64;16;8;8;0,2;0,3;0,2;0,1;64;50;19;"runs/2024-03-14T15-02-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e01504d60>";0,00100000004749745;"Experiment.R";2024-03-14 15:02:23.08536;2024-03-14 15:02:27.8016;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-02-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-02-10Z";6,6507;1,961;8,1526;2,3162;32;16;8;8;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T15-02-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e018f9f00>";0,00100000004749745;"Experiment.R";2024-03-14 15:02:11.66362;2024-03-14 15:02:22.34258;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-02-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-02-03Z";5,7827;1,8097;7,7483;2,2804;64;32;16;4;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T15-02-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e01c69450>";0,00100000004749745;"Experiment.R";2024-03-14 15:02:04.73407;2024-03-14 15:02:10.90677;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-02-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-01-49Z";5,5133;1,7864;7,8643;2,288;32;32;16;4;0,2;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T15-01-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e01e55c30>";0,00100000004749745;"Experiment.R";2024-03-14 15:01:50.64797;2024-03-14 15:02:03.87855;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-01-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-01-39Z";5,9641;1,849;9,7113;2,526;64;16;16;4;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T15-01-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e01ee23e0>";0,00100000004749745;"Experiment.R";2024-03-14 15:01:40.62642;2024-03-14 15:01:49.85706;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-01-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-01-32Z";5,8752;1,8397;7,4845;2,2242;32;16;16;4;0,2;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T15-01-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e021255a0>";0,00100000004749745;"Experiment.R";2024-03-14 15:01:32.94902;2024-03-14 15:01:39.83862;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-01-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-01-22Z";5,1891;1,7195;7,9805;2,2964;64;32;8;4;0,2;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T15-01-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0308d360>";0,00100000004749745;"Experiment.R";2024-03-14 15:01:22.94144;2024-03-14 15:01:32.22184;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-01-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-01-11Z";5,7132;1,7971;8,2772;2,3266;32;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-01-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e01ac93f0>";0,00100000004749745;"Experiment.R";2024-03-14 15:01:12.36672;2024-03-14 15:01:22.15414;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-01-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-01-00Z";5,3408;1,7541;8,0267;2,3087;64;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-01-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e024bee60>";0,00100000004749745;"Experiment.R";2024-03-14 15:01:01.3846;2024-03-14 15:01:11.60387;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-01-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-00-47Z";5,9022;1,841;8,4987;2,3576;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-00-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e02701c90>";0,00100000004749745;"Experiment.R";2024-03-14 15:00:48.54806;2024-03-14 15:01:00.63699;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-00-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-00-35Z";5,1111;1,7184;7,3242;2,2026;64;32;16;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T15-00-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0173fe80>";0,00100000004749745;"Experiment.R";2024-03-14 15:00:36.14003;2024-03-14 15:00:47.80569;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-00-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-00-28Z";5,5888;1,8069;7,7483;2,2708;32;32;16;8;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T15-00-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0298e6e0>";0,00100000004749745;"Experiment.R";2024-03-14 15:00:29.08358;2024-03-14 15:00:35.37752;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-00-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-00-22Z";6,4199;1,9171;8,1096;2,3098;64;16;16;8;0,2;0,3;0,2;0,1;64;50;13;"runs/2024-03-14T15-00-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e02bceb90>";0,00100000004749745;"Experiment.R";2024-03-14 15:00:23.23279;2024-03-14 15:00:27.97724;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-00-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-00-11Z";5,2975;1,7634;7,1015;2,1813;32;16;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T15-00-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e02e44e20>";0,00100000004749745;"Experiment.R";2024-03-14 15:00:12.60352;2024-03-14 15:00:22.47001;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-00-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T15-00-04Z";6,1248;1,88;7,7252;2,261;64;32;8;8;0,2;0,3;0,2;0,1;64;50;19;"runs/2024-03-14T15-00-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e03247d60>";0,00100000004749745;"Experiment.R";2024-03-14 15:00:04.74253;2024-03-14 15:00:11.85724;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T15-00-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-59-53Z";5,2598;1,7412;8,4949;2,3593;32;32;8;8;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T14-59-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e032b66e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:59:54.52842;2024-03-14 15:00:04.00007;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-59-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-59-41Z";5,529;1,7798;8,2726;2,3149;64;16;8;8;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-59-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e036ee0b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:59:41.87622;2024-03-14 14:59:53.77604;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-59-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-59-31Z";5,2852;1,7493;8,0741;2,3089;32;16;8;8;0,2;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T14-59-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e03903280>";0,00100000004749745;"Experiment.R";2024-03-14 14:59:32.5914;2024-03-14 14:59:41.11281;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-59-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-59-14Z";4,7726;1,659;7,2684;2,1947;64;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-59-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e039a25f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:59:15.6614;2024-03-14 14:59:31.83139;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-59-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-59-07Z";6,2366;1,8872;6,9212;2,1384;32;32;16;4;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T14-59-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e03bb1a80>";0,00100000004749745;"Experiment.R";2024-03-14 14:59:08.36067;2024-03-14 14:59:14.89639;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-59-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-59-03Z";7,4075;2,0504;9,0863;2,4372;64;16;16;4;0,2;0,3;0,2;0,1;64;50;12;"runs/2024-03-14T14-59-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e03e17880>";0,00100000004749745;"Experiment.R";2024-03-14 14:59:03.92313;2024-03-14 14:59:07.61815;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-59-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-58-56Z";7,5269;2,04;8,4821;2,3596;32;16;16;4;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T14-58-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0366a0e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:58:57.19174;2024-03-14 14:59:03.16154;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-58-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-58-47Z";5,5337;1,7667;7,4026;2,2063;64;32;8;4;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-58-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0493e5c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:58:48.55035;2024-03-14 14:58:56.44672;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-58-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-58-37Z";6,2629;1,8792;7,7594;2,2641;32;32;8;4;0,2;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T14-58-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e02f04550>";0,00100000004749745;"Experiment.R";2024-03-14 14:58:38.7136;2024-03-14 14:58:47.78786;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-58-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-58-27Z";5,8271;1,8313;7,7014;2,2627;64;16;8;4;0,2;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T14-58-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e02fa1c00>";0,00100000004749745;"Experiment.R";2024-03-14 14:58:28.33554;2024-03-14 14:58:37.96294;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-58-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-58-13Z";5,5405;1,7769;7,0432;2,1643;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-58-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e027a75e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:58:13.78237;2024-03-14 14:58:27.56413;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-58-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-58-04Z";5,046;1,6988;7,9079;2,2919;64;32;16;8;0,2;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T14-58-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0422e4d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:58:04.70843;2024-03-14 14:58:13.03523;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-58-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-57-55Z";6,3026;1,902;7,9654;2,3038;32;32;16;8;0,2;0,3;0,2;0,1;64;50;14;"runs/2024-03-14T14-57-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e04446fb0>";0,00100000004749745;"Experiment.R";2024-03-14 14:57:56.55336;2024-03-14 14:58:03.97123;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-57-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-57-47Z";5,3729;1,7457;8,5877;2,3825;64;16;16;8;0,2;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T14-57-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0469de40>";0,00100000004749745;"Experiment.R";2024-03-14 14:57:48.60691;2024-03-14 14:57:55.26173;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-57-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-57-38Z";5,5611;1,7844;7,7643;2,296;32;16;16;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T14-57-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0493e5f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:57:39.49051;2024-03-14 14:57:47.88113;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-57-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-57-25Z";4,9169;1,6724;7,7657;2,2491;64;32;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-57-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e04b73250>";0,00100000004749745;"Experiment.R";2024-03-14 14:57:26.62134;2024-03-14 14:57:38.7328;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-57-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-57-21Z";6,2126;1,8932;8,8044;2,4357;32;32;8;8;0,2;0,3;0,2;0,1;64;50;13;"runs/2024-03-14T14-57-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e04bc75e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:57:21.98877;2024-03-14 14:57:25.86855;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-57-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-57-08Z";5,517;1,797;7,3874;2,2153;64;16;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-57-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e04e6a500>";0,00100000004749745;"Experiment.R";2024-03-14 14:57:09.56551;2024-03-14 14:57:21.2225;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-57-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-56-55Z";5,1804;1,7393;8,2031;2,3188;32;16;8;8;0,2;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T14-56-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e01374070>";0,00100000004749745;"Experiment.R";2024-03-14 14:56:55.99757;2024-03-14 14:57:08.83423;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-56-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-56-45Z";5,6224;1,7925;8,5331;2,3744;64;32;16;4;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T14-56-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e04eeacb0>";0,00100000004749745;"Experiment.R";2024-03-14 14:56:45.97924;2024-03-14 14:56:55.1927;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-56-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-56-36Z";5,8314;1,8208;7,75;2,2577;32;32;16;4;0,2;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T14-56-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0511bd90>";0,00100000004749745;"Experiment.R";2024-03-14 14:56:37.27773;2024-03-14 14:56:45.20788;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-56-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-56-21Z";5,8103;1,7895;7,7714;2,2664;64;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-56-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e051ca620>";0,00100000004749745;"Experiment.R";2024-03-14 14:56:22.52417;2024-03-14 14:56:36.54119;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-56-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-56-11Z";5,7126;1,8172;7,3402;2,2011;32;16;16;4;0,2;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T14-56-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0541e260>";0,00100000004749745;"Experiment.R";2024-03-14 14:56:12.35473;2024-03-14 14:56:21.79379;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-56-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-56-04Z";6,1138;1,8746;8,2996;2,3186;64;32;8;4;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T14-56-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e04521b70>";0,00100000004749745;"Experiment.R";2024-03-14 14:56:05.12488;2024-03-14 14:56:11.63024;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-56-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-55-54Z";6,2594;1,8877;8,4916;2,3435;32;32;8;4;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-55-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e06183880>";0,00100000004749745;"Experiment.R";2024-03-14 14:55:55.31849;2024-03-14 14:56:04.39852;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-55-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-55-45Z";5,5433;1,806;8,3057;2,345;64;16;8;4;0,2;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T14-55-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e064264d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:55:45.88042;2024-03-14 14:55:54.54405;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-55-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-55-34Z";5,9001;1,8404;7,1579;2,1903;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-55-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0667a6b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:55:35.02317;2024-03-14 14:55:45.14241;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-55-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-55-25Z";6,1018;1,8426;9,4159;2,4771;64;32;16;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T14-55-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0669bca0>";0,00100000004749745;"Experiment.R";2024-03-14 14:55:26.27071;2024-03-14 14:55:34.28006;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-55-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-55-16Z";5,1747;1,7268;8,083;2,3272;32;32;16;8;0,2;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T14-55-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e069407f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:55:16.88967;2024-03-14 14:55:25.44931;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-55-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-55-03Z";5,0458;1,7053;8,4325;2,3536;64;16;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-55-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0c6f4b80>";0,00100000004749745;"Experiment.R";2024-03-14 14:55:04.08808;2024-03-14 14:55:16.16122;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-55-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-54-48Z";5,2931;1,7659;7,5137;2,2322;32;16;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-54-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e059c2320>";0,00100000004749745;"Experiment.R";2024-03-14 14:54:49.1296;2024-03-14 14:55:03.3716;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-54-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-54-41Z";5,5409;1,8069;8,4507;2,3653;64;32;8;8;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T14-54-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e05be7d30>";0,00100000004749745;"Experiment.R";2024-03-14 14:54:41.83284;2024-03-14 14:54:48.40787;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-54-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-54-31Z";5,4715;1,7786;7,0399;2,1709;32;32;8;8;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-54-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e05e49000>";0,00100000004749745;"Experiment.R";2024-03-14 14:54:32.22497;2024-03-14 14:54:41.11066;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-54-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-54-22Z";5,0419;1,6907;9,0663;2,4335;64;16;8;8;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T14-54-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e05ebf3d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:54:22.95409;2024-03-14 14:54:31.51204;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-54-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-54-15Z";6,967;2,0088;8,5856;2,3603;32;16;8;8;0,2;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T14-54-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0613d180>";0,00100000004749745;"Experiment.R";2024-03-14 14:54:16.25383;2024-03-14 14:54:21.96135;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-54-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-54-08Z";8,1825;2,0953;8,9257;2,4169;64;32;16;4;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T14-54-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e06a4f5e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:54:09.51511;2024-03-14 14:54:15.51703;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-54-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-53-56Z";5,2089;1,7279;7,804;2,2845;32;32;16;4;0,2;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T14-53-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e06ad4eb0>";0,00100000004749745;"Experiment.R";2024-03-14 14:53:57.45083;2024-03-14 14:54:08.22789;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-53-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-53-47Z";5,2747;1,725;7,56;2,2471;64;16;16;4;0,2;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T14-53-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e06d163e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:53:47.83035;2024-03-14 14:53:56.50246;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-53-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-53-37Z";7,2477;1,9986;8,3965;2,3474;32;16;16;4;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T14-53-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e06f66d70>";0,00100000004749745;"Experiment.R";2024-03-14 14:53:38.34151;2024-03-14 14:53:47.06938;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-53-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-53-28Z";5,1591;1,7308;7,188;2,1582;64;32;8;4;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T14-53-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e070061a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:53:28.86817;2024-03-14 14:53:37.59631;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-53-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-53-19Z";5,0987;1,7403;7,4318;2,2248;32;32;8;4;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T14-53-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0722afb0>";0,00100000004749745;"Experiment.R";2024-03-14 14:53:20.42276;2024-03-14 14:53:28.12358;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-53-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-53-09Z";5,1254;1,7021;7,9871;2,3019;64;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-53-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e252e3700>";0,00100000004749745;"Experiment.R";2024-03-14 14:53:09.70347;2024-03-14 14:53:19.69472;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-53-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-52-51Z";5,5663;1,7914;7,4425;2,2341;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-52-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2054d9f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:52:53.07159;2024-03-14 14:53:08.96608;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-52-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-52-44Z";5,4445;1,7544;7,8529;2,2642;64;32;16;8;0,2;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T14-52-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1e813400>";0,00100000004749745;"Experiment.R";2024-03-14 14:52:45.50386;2024-03-14 14:52:51.88643;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-52-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-52-31Z";4,8241;1,6754;7,8504;2,2746;32;32;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-52-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e17980430>";0,00100000004749745;"Experiment.R";2024-03-14 14:52:32.55028;2024-03-14 14:52:44.74978;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-52-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-52-22Z";5,0643;1,7013;7,9164;2,2818;64;16;16;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T14-52-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c8fe1d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:52:22.74661;2024-03-14 14:52:31.84249;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-52-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-52-16Z";6,7958;1,9893;7,4165;2,1985;32;16;16;8;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T14-52-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e26c01150>";0,00100000004749745;"Experiment.R";2024-03-14 14:52:17.21375;2024-03-14 14:52:22.03482;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-52-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-52-09Z";5,419;1,7755;10,2774;2,5927;64;32;8;8;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T14-52-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1e24b280>";0,00100000004749745;"Experiment.R";2024-03-14 14:52:10.06547;2024-03-14 14:52:16.18228;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-52-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-52-02Z";5,9849;1,8457;7,2378;2,1666;32;32;8;8;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T14-52-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1d06e050>";0,00100000004749745;"Experiment.R";2024-03-14 14:52:04.04458;2024-03-14 14:52:09.32667;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-52-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-51-52Z";5,3546;1,7488;9,0584;2,4368;64;16;8;8;0,2;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T14-51-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1fed0b50>";0,00100000004749745;"Experiment.R";2024-03-14 14:51:53.4805;2024-03-14 14:52:02.81318;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-51-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-51-45Z";6,4409;1,9431;8,7718;2,3983;32;16;8;8;0,2;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T14-51-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e238dc880>";0,00100000004749745;"Experiment.R";2024-03-14 14:51:45.85446;2024-03-14 14:51:52.75406;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-51-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-51-34Z";5,255;1,7249;7,8595;2,2525;64;32;16;4;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T14-51-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25dc4700>";0,00100000004749745;"Experiment.R";2024-03-14 14:51:35.5874;2024-03-14 14:51:45.13038;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-51-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-51-23Z";5,7006;1,8051;7,511;2,2344;32;32;16;4;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T14-51-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42f807c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:51:24.55217;2024-03-14 14:51:34.8631;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-51-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-51-14Z";5,0757;1,723;8,1291;2,3118;64;16;16;4;0,2;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T14-51-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e417ae080>";0,00100000004749745;"Experiment.R";2024-03-14 14:51:15.68996;2024-03-14 14:51:23.74208;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-51-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-51-03Z";6,1228;1,864;8,0473;2,312;32;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-51-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3701e1d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:51:04.29787;2024-03-14 14:51:14.46446;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-51-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-50-50Z";19,1374;3,5444;22,0051;3,858;64;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-50-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e397553c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:50:51.32395;2024-03-14 14:51:03.59241;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-50-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-50-39Z";6,0635;1,8703;9,1825;2,4586;32;32;8;4;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T14-50-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b91b6d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:50:40.35624;2024-03-14 14:50:50.57955;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-50-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-50-30Z";5,3348;1,7439;7,6484;2,2564;64;16;8;4;0,2;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T14-50-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b5360b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:50:31.58602;2024-03-14 14:50:39.64588;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-50-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-50-20Z";6,012;1,8784;7,0568;2,1664;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-50-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1f783520>";0,00100000004749745;"Experiment.R";2024-03-14 14:50:20.85188;2024-03-14 14:50:30.82383;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-50-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-50-14Z";6,2523;1,9079;7,4805;2,2344;64;32;16;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T14-50-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21815cf0>";0,00100000004749745;"Experiment.R";2024-03-14 14:50:15.27804;2024-03-14 14:50:20.14383;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-50-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-50-07Z";5,397;1,772;7,3805;2,2193;32;32;16;8;0,1;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T14-50-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e229cb070>";0,00100000004749745;"Experiment.R";2024-03-14 14:50:07.75294;2024-03-14 14:50:14.56058;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-50-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-50-02Z";6,4486;1,9429;9,404;2,4853;64;16;16;8;0,1;0,3;0,2;0,1;64;50;15;"runs/2024-03-14T14-50-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e23567e80>";0,00100000004749745;"Experiment.R";2024-03-14 14:50:02.86695;2024-03-14 14:50:07.03574;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-50-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-49-52Z";5,1592;1,7231;8,7465;2,399;32;16;16;8;0,1;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T14-49-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e24f1cd90>";0,00100000004749745;"Experiment.R";2024-03-14 14:49:53.23998;2024-03-14 14:50:02.15854;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-49-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-49-47Z";5,9634;1,8545;8,7831;2,3947;64;32;8;8;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T14-49-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e26235b10>";0,00100000004749745;"Experiment.R";2024-03-14 14:49:48.04668;2024-03-14 14:49:52.52395;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-49-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-49-37Z";5,1279;1,7228;7,9651;2,2906;32;32;8;8;0,1;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T14-49-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5f5d1a80>";0,00100000004749745;"Experiment.R";2024-03-14 14:49:38.31991;2024-03-14 14:49:47.34681;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-49-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-49-27Z";5,3759;1,7657;7,8043;2,265;64;16;8;8;0,1;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T14-49-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e41ca5d20>";0,00100000004749745;"Experiment.R";2024-03-14 14:49:28.67319;2024-03-14 14:49:37.60202;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-49-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-49-18Z";5,7682;1,8294;7,9394;2,2913;32;16;8;8;0,1;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T14-49-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b6cc6d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:49:18.95579;2024-03-14 14:49:27.95377;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-49-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-49-12Z";5,7727;1,822;8,3524;2,3482;64;32;16;4;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T14-49-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3deaa170>";0,00100000004749745;"Experiment.R";2024-03-14 14:49:13.17625;2024-03-14 14:49:18.24309;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-49-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-49-00Z";5,3814;1,7339;8,1733;2,313;32;32;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-49-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e377d6da0>";0,00100000004749745;"Experiment.R";2024-03-14 14:49:01.59673;2024-03-14 14:49:12.44564;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-49-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-48-50Z";5,536;1,7562;7,7238;2,2605;64;16;16;4;0,1;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T14-48-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e36c59de0>";0,00100000004749745;"Experiment.R";2024-03-14 14:48:51.16754;2024-03-14 14:49:00.88349;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-48-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-48-43Z";6,329;1,9317;8,6479;2,3885;32;16;16;4;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T14-48-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3a4c0130>";0,00100000004749745;"Experiment.R";2024-03-14 14:48:44.81955;2024-03-14 14:48:50.4215;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-48-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-48-38Z";6,9227;1,9961;8,3705;2,3494;64;32;8;4;0,1;0,3;0,2;0,1;64;50;15;"runs/2024-03-14T14-48-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e17981e10>";0,00100000004749745;"Experiment.R";2024-03-14 14:48:38.69658;2024-03-14 14:48:43.72636;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-48-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-48-28Z";5,4759;1,7571;6,6324;2,0908;32;32;8;4;0,1;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T14-48-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16fc5570>";0,00100000004749745;"Experiment.R";2024-03-14 14:48:29.88931;2024-03-14 14:48:37.98275;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-48-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-48-16Z";5,6809;1,8176;7,7613;2,2693;64;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-48-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16f36b60>";0,00100000004749745;"Experiment.R";2024-03-14 14:48:17.25844;2024-03-14 14:48:28.83052;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-48-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-48-07Z";5,5672;1,7671;7,537;2,2325;32;16;8;4;0,1;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T14-48-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1ef35d50>";0,00100000004749745;"Experiment.R";2024-03-14 14:48:07.94269;2024-03-14 14:48:16.55238;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-48-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-47-51Z";4,5066;1,5878;7,5253;2,2001;64;32;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-47-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16879cc0>";0,00100000004749745;"Experiment.R";2024-03-14 14:47:52.28182;2024-03-14 14:48:07.09168;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-47-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-47-44Z";5,4572;1,7669;7,5788;2,2171;32;32;16;8;0,1;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T14-47-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e162b4310>";0,00100000004749745;"Experiment.R";2024-03-14 14:47:45.67707;2024-03-14 14:47:51.55899;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-47-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-47-37Z";5,9456;1,8336;8,2884;2,3319;64;16;16;8;0,1;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T14-47-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e15f3f850>";0,00100000004749745;"Experiment.R";2024-03-14 14:47:37.75068;2024-03-14 14:47:44.95154;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-47-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-47-27Z";4,7676;1,6783;8,0043;2,3032;32;16;16;8;0,1;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T14-47-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e15920460>";0,00100000004749745;"Experiment.R";2024-03-14 14:47:28.94685;2024-03-14 14:47:37.04388;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-47-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-47-18Z";5,3014;1,7279;9,7868;2,5346;64;32;8;8;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-47-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1532cdf0>";0,00100000004749745;"Experiment.R";2024-03-14 14:47:19.16522;2024-03-14 14:47:27.70847;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-47-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-47-07Z";5,6789;1,8046;7,4975;2,241;32;32;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-47-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e147cfa00>";0,00100000004749745;"Experiment.R";2024-03-14 14:47:08.46784;2024-03-14 14:47:18.45365;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-47-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-46-59Z";5,7643;1,8348;8,642;2,3739;64;16;8;8;0,1;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T14-46-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e14b51d50>";0,00100000004749745;"Experiment.R";2024-03-14 14:46:59.72712;2024-03-14 14:47:07.76363;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-46-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-46-45Z";5,0965;1,7295;6,8846;2,1727;32;16;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-46-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e144699f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:46:46.12017;2024-03-14 14:46:59.0453;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-46-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-46-36Z";6,5352;1,8732;8,3322;2,3373;64;32;16;4;0,1;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T14-46-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e13cf0be0>";0,00100000004749745;"Experiment.R";2024-03-14 14:46:37.41664;2024-03-14 14:46:45.41058;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-46-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-46-23Z";6,0444;1,8349;7,8607;2,287;32;32;16;4;0,1;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T14-46-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e13885ba0>";0,00100000004749745;"Experiment.R";2024-03-14 14:46:24.02163;2024-03-14 14:46:36.23981;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-46-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-46-16Z";5,7534;1,825;8,6765;2,3786;64;16;16;4;0,1;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T14-46-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e130aa2c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:46:16.98249;2024-03-14 14:46:23.3297;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-46-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-46-04Z";5,3646;1,7471;7,3345;2,2108;32;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-46-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e12bbab00>";0,00100000004749745;"Experiment.R";2024-03-14 14:46:05.44117;2024-03-14 14:46:16.26753;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-46-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-45-54Z";6,0204;1,7971;7,9583;2,2811;64;32;8;4;0,1;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T14-45-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1273be80>";0,00100000004749745;"Experiment.R";2024-03-14 14:45:54.8904;2024-03-14 14:46:04.75465;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-45-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-45-48Z";6,5109;1,9588;9,0642;2,4541;32;32;8;4;0,1;0,3;0,2;0,1;64;50;16;"runs/2024-03-14T14-45-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1204a3b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:45:49.81124;2024-03-14 14:45:54.18588;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-45-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-45-38Z";5,3374;1,7565;7,7352;2,2798;64;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-45-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e11a6da80>";0,00100000004749745;"Experiment.R";2024-03-14 14:45:38.85273;2024-03-14 14:45:48.78121;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-45-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-45-27Z";5,8356;1,8204;6,9309;2,157;32;16;8;4;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T14-45-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e112b24a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:45:27.99554;2024-03-14 14:45:38.12893;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-45-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-45-17Z";4,4812;1,615;8,203;2,3017;64;32;16;8;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-45-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e10d2d1b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:45:18.36358;2024-03-14 14:45:27.29534;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-45-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-45-09Z";6,5336;1,9365;8,7173;2,3843;32;32;16;8;0,1;0,3;0,2;0,1;64;50;14;"runs/2024-03-14T14-45-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e10ae6aa0>";0,00100000004749745;"Experiment.R";2024-03-14 14:45:10.01487;2024-03-14 14:45:17.62461;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-45-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-45-00Z";5,4934;1,7903;7,6182;2,2522;64;16;16;8;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T14-45-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1022ad70>";0,00100000004749745;"Experiment.R";2024-03-14 14:45:00.88824;2024-03-14 14:45:09.30174;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-45-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-44-50Z";4,7966;1,6724;7,2472;2,1834;32;16;16;8;0,1;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T14-44-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0f8a0a00>";0,00100000004749745;"Experiment.R";2024-03-14 14:44:50.8175;2024-03-14 14:45:00.18133;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-44-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-44-39Z";4,7695;1,645;8,0835;2,3017;64;32;8;8;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T14-44-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1f086e90>";0,00100000004749745;"Experiment.R";2024-03-14 14:44:39.87673;2024-03-14 14:44:50.09949;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-44-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-44-29Z";4,9136;1,6835;7,8307;2,2675;32;32;8;8;0,1;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T14-44-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0c6f6680>";0,00100000004749745;"Experiment.R";2024-03-14 14:44:30.61276;2024-03-14 14:44:39.19147;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-44-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-44-22Z";6,3735;1,92;9,7666;2,5126;64;16;8;8;0,1;0,3;0,2;0,1;64;50;13;"runs/2024-03-14T14-44-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ccfbb80>";0,00100000004749745;"Experiment.R";2024-03-14 14:44:22.89071;2024-03-14 14:44:29.91052;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-44-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-44-13Z";5,2404;1,7566;6,7517;2,1325;32;16;8;8;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T14-44-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ceb60e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:44:14.57581;2024-03-14 14:44:22.04959;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-44-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-44-03Z";5,3766;1,765;7,7193;2,2595;64;32;16;4;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T14-44-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f3be260>";0,00100000004749745;"Experiment.R";2024-03-14 14:44:04.5173;2024-03-14 14:44:13.87518;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-44-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-43-49Z";4,993;1,7097;7,1077;2,169;32;32;16;4;0,1;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T14-43-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2421cdc0>";0,00100000004749745;"Experiment.R";2024-03-14 14:43:50.59482;2024-03-14 14:44:03.79801;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-43-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-43-41Z";5,9479;1,8425;8,5037;2,3535;64;16;16;4;0,1;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T14-43-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21bb5d80>";0,00100000004749745;"Experiment.R";2024-03-14 14:43:42.81084;2024-03-14 14:43:49.91733;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-43-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-43-36Z";7,0438;1,9867;8,2521;2,3416;32;16;16;4;0,1;0,3;0,2;0,1;64;50;15;"runs/2024-03-14T14-43-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1ff727a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:43:37.0597;2024-03-14 14:43:41.72832;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-43-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-43-29Z";5,8639;1,8321;8,2548;2,3244;64;32;8;4;0,1;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T14-43-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1fa349a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:43:30.56547;2024-03-14 14:43:36.34799;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-43-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-43-15Z";5,1751;1,717;7,5528;2,2297;32;32;8;4;0,1;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T14-43-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1e0ac5e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:43:16.02557;2024-03-14 14:43:29.27103;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-43-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-43-06Z";6,5677;1,928;8,4089;2,3661;64;16;8;4;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T14-43-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1eebc490>";0,00100000004749745;"Experiment.R";2024-03-14 14:43:07.69689;2024-03-14 14:43:15.28387;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-43-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-42-57Z";5,5442;1,8007;7,2118;2,1889;32;16;8;4;0,1;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T14-42-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1de851b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:42:58.00556;2024-03-14 14:43:06.60496;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-42-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-42-45Z";5,2611;1,7331;8,2106;2,322;64;32;16;8;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T14-42-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1cf870d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:42:46.53212;2024-03-14 14:42:57.32042;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-42-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-42-34Z";5,3827;1,7614;7,7532;2,2585;32;32;16;8;0,1;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T14-42-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c33d7e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:42:34.88855;2024-03-14 14:42:45.84589;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-42-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-42-25Z";4,9228;1,6836;8,165;2,3132;64;16;16;8;0,1;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T14-42-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c186620>";0,00100000004749745;"Experiment.R";2024-03-14 14:42:25.79266;2024-03-14 14:42:34.19987;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-42-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-42-12Z";4,8669;1,6869;7,76;2,2762;32;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-42-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2161a500>";0,00100000004749745;"Experiment.R";2024-03-14 14:42:12.66443;2024-03-14 14:42:25.07177;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-42-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-42-06Z";6,0519;1,8663;8,9679;2,4256;64;32;8;8;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T14-42-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63a88be0>";0,00100000004749745;"Experiment.R";2024-03-14 14:42:07.19873;2024-03-14 14:42:11.99658;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-42-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-41-55Z";4,8604;1,663;8,3179;2,3471;32;32;8;8;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T14-41-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e603e3cd0>";0,00100000004749745;"Experiment.R";2024-03-14 14:41:56.17265;2024-03-14 14:42:06.51937;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-41-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-41-46Z";6,0913;1,8807;8,9124;2,4277;64;16;8;8;0,1;0,3;0,2;0,1;64;50;19;"runs/2024-03-14T14-41-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b745f90>";0,00100000004749745;"Experiment.R";2024-03-14 14:41:46.67348;2024-03-14 14:41:55.48958;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-41-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-41-37Z";5,3379;1,7703;8,3762;2,3413;32;16;8;8;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T14-41-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e70c74b20>";0,00100000004749745;"Experiment.R";2024-03-14 14:41:38.47572;2024-03-14 14:41:46.00261;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-41-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-41-27Z";5,9948;1,8045;8,4359;2,3495;64;32;16;4;0,1;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T14-41-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a72e110>";0,00100000004749745;"Experiment.R";2024-03-14 14:41:28.19011;2024-03-14 14:41:37.34314;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-41-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-41-12Z";6,4738;1,8762;7,7562;2,2624;32;32;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-41-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37dcb400>";0,00100000004749745;"Experiment.R";2024-03-14 14:41:13.82472;2024-03-14 14:41:27.49818;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-41-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-41-03Z";5,515;1,7592;8,6981;2,3807;64;16;16;4;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-41-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b0b9c30>";0,00100000004749745;"Experiment.R";2024-03-14 14:41:03.69125;2024-03-14 14:41:12.62267;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-41-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-40-47Z";5,8363;1,7938;6,8746;2,1511;32;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-40-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21d2d480>";0,00100000004749745;"Experiment.R";2024-03-14 14:40:48.42937;2024-03-14 14:41:02.98493;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-40-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-40-36Z";4,8967;1,6794;7,4889;2,2352;64;32;8;4;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-40-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25b71a80>";0,00100000004749745;"Experiment.R";2024-03-14 14:40:36.91409;2024-03-14 14:40:47.73135;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-40-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-40-24Z";6,7268;1,9273;8,1453;2,3213;32;32;8;4;0,1;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T14-40-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f41bdf0>";0,00100000004749745;"Experiment.R";2024-03-14 14:40:24.79649;2024-03-14 14:40:36.18271;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-40-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-40-14Z";6,0543;1,8468;8,8062;2,3938;64;16;8;4;0,1;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T14-40-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5ab09e70>";0,00100000004749745;"Experiment.R";2024-03-14 14:40:15.55518;2024-03-14 14:40:24.07943;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-40-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-40-03Z";5,5217;1,7714;7,7558;2,2461;32;16;8;4;0,1;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T14-40-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e14a590>";0,00100000004749745;"Experiment.R";2024-03-14 14:40:03.87697;2024-03-14 14:40:14.36362;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-40-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-39-56Z";6,6121;1,9587;8,6614;2,3876;64;32;16;8;0,1;0,3;0,2;0,1;64;50;16;"runs/2024-03-14T14-39-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e35cf05e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:39:56.84499;2024-03-14 14:40:03.17079;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-39-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-39-41Z";4,9376;1,6962;7,7824;2,2664;32;32;16;8;0,1;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T14-39-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e105df550>";0,00100000004749745;"Experiment.R";2024-03-14 14:39:41.87511;2024-03-14 14:39:56.16014;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-39-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-39-32Z";5,7415;1,8038;8,7095;2,3867;64;16;16;8;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T14-39-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e176b7af0>";0,00100000004749745;"Experiment.R";2024-03-14 14:39:33.41898;2024-03-14 14:39:41.17229;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-39-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-39-26Z";5,9978;1,8734;8,4337;2,3722;32;16;16;8;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T14-39-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1662a4a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:39:26.9248;2024-03-14 14:39:32.7099;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-39-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-39-18Z";5,945;1,8347;8,9004;2,4259;64;32;8;8;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T14-39-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e156fa440>";0,00100000004749745;"Experiment.R";2024-03-14 14:39:19.44571;2024-03-14 14:39:26.2273;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-39-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-39-01Z";7,0155;1,9855;9,0034;2,428;32;32;8;8;0,1;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T14-39-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e14841390>";0,00100000004749745;"Experiment.R";2024-03-14 14:39:01.65527;2024-03-14 14:39:18.75914;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-39-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-38-49Z";4,9062;1,6939;8,2393;2,312;64;16;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-38-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e12de2a40>";0,00100000004749745;"Experiment.R";2024-03-14 14:38:49.66008;2024-03-14 14:39:00.95389;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-38-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-38-36Z";5,2482;1,7524;6,5773;2,0987;32;16;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-38-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1308a920>";0,00100000004749745;"Experiment.R";2024-03-14 14:38:36.96442;2024-03-14 14:38:48.95461;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-38-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-38-29Z";5,9855;1,8329;8,1054;2,3232;64;32;16;4;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T14-38-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e122eeb00>";0,00100000004749745;"Experiment.R";2024-03-14 14:38:29.81589;2024-03-14 14:38:36.25371;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-38-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-38-17Z";5,0576;1,7111;6,8422;2,1347;32;32;16;4;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T14-38-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1104dc60>";0,00100000004749745;"Experiment.R";2024-03-14 14:38:18.1586;2024-03-14 14:38:29.12204;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-38-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-38-07Z";6,0804;1,809;8,8007;2,3983;64;16;16;4;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-38-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e109dcbb0>";0,00100000004749745;"Experiment.R";2024-03-14 14:38:07.62149;2024-03-14 14:38:17.45231;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-38-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-37-46Z";6,764;1,9758;8,1863;2,3204;32;16;16;4;0,1;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T14-37-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0c439f60>";0,00100000004749745;"Experiment.R";2024-03-14 14:37:47.61899;2024-03-14 14:38:06.94031;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-37-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-37-36Z";7,1802;1,9675;8,5489;2,3617;64;32;8;4;0,1;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T14-37-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0bc6c310>";0,00100000004749745;"Experiment.R";2024-03-14 14:37:36.96904;2024-03-14 14:37:46.92301;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-37-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-37-28Z";5,7069;1,8028;7,8455;2,274;32;32;8;4;0,1;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T14-37-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0c49f0d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:37:29.0673;2024-03-14 14:37:36.28482;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-37-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-37-23Z";6,1614;1,8776;9,7202;2,5272;64;16;8;4;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T14-37-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0b62e740>";0,00100000004749745;"Experiment.R";2024-03-14 14:37:23.89126;2024-03-14 14:37:28.36846;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-37-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-37-09Z";5,2601;1,7521;7,3714;2,2131;32;16;8;4;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T14-37-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ca12590>";0,00100000004749745;"Experiment.R";2024-03-14 14:37:09.70624;2024-03-14 14:37:23.18278;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-37-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-37-01Z";5,2978;1,7444;7,1186;2,1736;64;32;16;8;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T14-37-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0cc7a3e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:37:02.5163;2024-03-14 14:37:09.0288;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-37-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-36-56Z";5,5361;1,8048;7,9235;2,2921;32;32;16;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T14-36-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0d06ac20>";0,00100000004749745;"Experiment.R";2024-03-14 14:36:56.99407;2024-03-14 14:37:01.84581;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-36-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-36-47Z";5,5474;1,8003;8,7193;2,3996;64;16;16;8;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T14-36-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0d0a7850>";0,00100000004749745;"Experiment.R";2024-03-14 14:36:48.22345;2024-03-14 14:36:56.31125;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-36-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-36-36Z";5,1494;1,7043;7,2044;2,1902;32;16;16;8;0,1;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T14-36-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0d7bded0>";0,00100000004749745;"Experiment.R";2024-03-14 14:36:37.52911;2024-03-14 14:36:47.54126;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-36-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-36-31Z";6,3026;1,9023;8,1879;2,344;64;32;8;8;0,1;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T14-36-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0d959f60>";0,00100000004749745;"Experiment.R";2024-03-14 14:36:32.40493;2024-03-14 14:36:36.85633;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-36-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-36-22Z";5,9639;1,8515;8,8408;2,4202;32;32;8;8;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T14-36-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0d9d6380>";0,00100000004749745;"Experiment.R";2024-03-14 14:36:23.46961;2024-03-14 14:36:31.73644;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-36-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-36-13Z";5,093;1,734;9,0431;2,426;64;16;8;8;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-36-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0dc0a560>";0,00100000004749745;"Experiment.R";2024-03-14 14:36:13.96267;2024-03-14 14:36:22.81116;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-36-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-36-05Z";6,5233;1,9521;8,2603;2,3431;32;16;8;8;0,1;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T14-36-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0d20eaa0>";0,00100000004749745;"Experiment.R";2024-03-14 14:36:06.39731;2024-03-14 14:36:13.29348;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-36-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-35-56Z";5,3683;1,7443;7,3823;2,2019;64;32;16;4;0,1;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T14-35-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0d4cfc40>";0,00100000004749745;"Experiment.R";2024-03-14 14:35:57.59472;2024-03-14 14:36:05.735;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-35-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-35-44Z";19,1385;3,5442;22,0064;3,8581;32;32;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-35-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0d48e6e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:35:44.82913;2024-03-14 14:35:56.89484;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-35-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-35-37Z";6,3095;1,9271;8,4614;2,3604;64;16;16;4;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T14-35-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ccbb5b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:35:38.80877;2024-03-14 14:35:44.1484;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-35-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-35-30Z";5,3237;1,7672;8,1114;2,3155;32;16;16;4;0,1;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T14-35-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0df26500>";0,00100000004749745;"Experiment.R";2024-03-14 14:35:31.18745;2024-03-14 14:35:37.60331;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-35-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-35-23Z";5,854;1,832;7,6975;2,2534;64;32;8;4;0,1;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T14-35-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0c713a00>";0,00100000004749745;"Experiment.R";2024-03-14 14:35:24.43747;2024-03-14 14:35:30.50775;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-35-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-35-17Z";6,2822;1,9057;9,775;2,5411;32;32;8;4;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T14-35-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0e143370>";0,00100000004749745;"Experiment.R";2024-03-14 14:35:17.68404;2024-03-14 14:35:23.76674;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-35-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-35-07Z";5,5485;1,7666;7,8902;2,2927;64;16;8;4;0,1;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T14-35-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0e36da80>";0,00100000004749745;"Experiment.R";2024-03-14 14:35:07.99446;2024-03-14 14:35:17.00447;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-35-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-34-54Z";7,0167;1,9619;7,8526;2,2708;32;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-34-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0aaea2f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:34:55.29624;2024-03-14 14:35:07.31566;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-34-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-34-44Z";4,4616;1,5999;6,5184;2,0367;64;32;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-34-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0e8254b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:34:44.9106;2024-03-14 14:34:54.64043;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-34-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-34-33Z";5,0764;1,7146;7,8121;2,2613;32;32;16;8;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T14-34-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ea22b60>";0,00100000004749745;"Experiment.R";2024-03-14 14:34:34.33049;2024-03-14 14:34:44.2501;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-34-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-34-19Z";5,6148;1,7893;8,5562;2,3765;64;16;16;8;0,1;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T14-34-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ee56080>";0,00100000004749745;"Experiment.R";2024-03-14 14:34:20.24847;2024-03-14 14:34:33.66191;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-34-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-34-11Z";5,4498;1,7776;8,3161;2,3471;32;16;16;8;0,1;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T14-34-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0f08a0b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:34:12.77646;2024-03-14 14:34:19.59149;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-34-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-34-01Z";4,656;1,626;8,0064;2,2934;64;32;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-34-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0f09e260>";0,00100000004749745;"Experiment.R";2024-03-14 14:34:02.34957;2024-03-14 14:34:11.67322;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-34-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-33-52Z";5,3005;1,7455;7,4065;2,1973;32;32;8;8;0,1;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T14-33-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0f32d240>";0,00100000004749745;"Experiment.R";2024-03-14 14:33:53.26216;2024-03-14 14:34:01.69445;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-33-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-33-38Z";4,9042;1,6825;8,2623;2,3314;64;16;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-33-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0f816c50>";0,00100000004749745;"Experiment.R";2024-03-14 14:33:39.62256;2024-03-14 14:33:52.59428;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-33-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-33-28Z";5,5538;1,8178;8,6437;2,4047;32;16;8;8;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T14-33-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0fa80ee0>";0,00100000004749745;"Experiment.R";2024-03-14 14:33:29.07714;2024-03-14 14:33:38.93781;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-33-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-33-18Z";5,317;1,7629;7,072;2,1644;64;32;16;4;0,1;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T14-33-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0fc73e20>";0,00100000004749745;"Experiment.R";2024-03-14 14:33:19.18637;2024-03-14 14:33:28.41676;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-33-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-33-13Z";5,7697;1,8235;8,2147;2,3348;32;32;16;4;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T14-33-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e10228f70>";0,00100000004749745;"Experiment.R";2024-03-14 14:33:13.68327;2024-03-14 14:33:18.53742;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-33-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-33-02Z";5,9034;1,8032;8,2638;2,3417;64;16;16;4;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T14-33-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0f412200>";0,00100000004749745;"Experiment.R";2024-03-14 14:33:03.08032;2024-03-14 14:33:13.00893;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-33-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-32-52Z";6,3687;1,8919;7,7074;2,257;32;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-32-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ec42da0>";0,00100000004749745;"Experiment.R";2024-03-14 14:32:52.66458;2024-03-14 14:33:02.40403;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-32-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-32-44Z";5,3302;1,7526;8,1855;2,3134;64;32;8;4;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T14-32-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ecc2230>";0,00100000004749745;"Experiment.R";2024-03-14 14:32:45.23572;2024-03-14 14:32:52.00187;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-32-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-32-36Z";6,4647;1,9422;7,9116;2,2864;32;32;8;4;0,1;0,3;0,2;0,1;64;50;12;"runs/2024-03-14T14-32-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0e4093f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:32:36.71109;2024-03-14 14:32:44.10374;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-32-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-32-27Z";5,3757;1,7445;8,1612;2,31;64;16;8;4;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T14-32-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1000af80>";0,00100000004749745;"Experiment.R";2024-03-14 14:32:28.48957;2024-03-14 14:32:36.04355;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-32-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-32-18Z";5,5939;1,781;6,8867;2,1365;32;16;8;4;0,1;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T14-32-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1021bb20>";0,00100000004749745;"Experiment.R";2024-03-14 14:32:19.52104;2024-03-14 14:32:27.82377;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-32-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-32-09Z";5,8943;1,8199;9,0313;2,4312;64;32;16;8;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T14-32-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e10463580>";0,00100000004749745;"Experiment.R";2024-03-14 14:32:09.84918;2024-03-14 14:32:18.39946;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-32-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-32-01Z";5,0539;1,7229;8,3774;2,364;32;32;16;8;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T14-32-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e104ecca0>";0,00100000004749745;"Experiment.R";2024-03-14 14:32:01.69483;2024-03-14 14:32:09.20114;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-32-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-31-53Z";5,3035;1,7571;8,4953;2,3561;64;16;16;8;0,1;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T14-31-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e108dfdc0>";0,00100000004749745;"Experiment.R";2024-03-14 14:31:54.60761;2024-03-14 14:32:01.01707;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-31-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-31-47Z";6,1475;1,8717;8,3014;2,3546;32;16;16;8;0,1;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T14-31-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e10b1dcc0>";0,00100000004749745;"Experiment.R";2024-03-14 14:31:48.30423;2024-03-14 14:31:53.43684;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-31-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-31-41Z";5,1356;1,7182;8,1912;2,3015;64;32;8;8;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T14-31-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e10d75bd0>";0,00100000004749745;"Experiment.R";2024-03-14 14:31:42.21927;2024-03-14 14:31:47.6457;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-31-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-31-27Z";4,8675;1,6858;6,9488;2,1543;32;32;8;8;0,1;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T14-31-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e10dbcf10>";0,00100000004749745;"Experiment.R";2024-03-14 14:31:28.541;2024-03-14 14:31:41.12089;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-31-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-31-21Z";5,6873;1,8087;9,0579;2,4285;64;16;8;8;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T14-31-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e105de530>";0,00100000004749745;"Experiment.R";2024-03-14 14:31:21.83401;2024-03-14 14:31:27.46405;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-31-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-31-10Z";6,2114;1,8852;7,1997;2,1871;32;16;8;8;0,1;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T14-31-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e11251270>";0,00100000004749745;"Experiment.R";2024-03-14 14:31:11.47315;2024-03-14 14:31:21.18322;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-31-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-31-00Z";6,3321;1,8546;8,363;2,3478;64;32;16;4;0,1;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T14-31-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e11472620>";0,00100000004749745;"Experiment.R";2024-03-14 14:31:01.16215;2024-03-14 14:31:10.78134;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-31-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-30-55Z";5,9302;1,8473;7,7576;2,2484;32;32;16;4;0,1;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T14-30-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e114a5d80>";0,00100000004749745;"Experiment.R";2024-03-14 14:30:56.20963;2024-03-14 14:31:00.4938;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-30-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-30-44Z";6,4015;1,8216;7,7179;2,2431;64;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-30-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e11ca7eb0>";0,00100000004749745;"Experiment.R";2024-03-14 14:30:44.70843;2024-03-14 14:30:55.55584;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-30-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-30-30Z";5,0426;1,6954;8,7858;2,3908;32;16;16;4;0,1;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T14-30-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ff6a500>";0,00100000004749745;"Experiment.R";2024-03-14 14:30:30.89422;2024-03-14 14:30:44.05973;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-30-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-30-21Z";5,5541;1,7839;7,2021;2,1745;64;32;8;4;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T14-30-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e0ff6ae60>";0,00100000004749745;"Experiment.R";2024-03-14 14:30:22.4317;2024-03-14 14:30:30.24684;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-30-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-30-07Z";19,133;3,5438;22,0004;3,8574;32;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T14-30-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e10fcbdf0>";0,00100000004749745;"Experiment.R";2024-03-14 14:30:08.07281;2024-03-14 14:30:21.57866;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-30-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-29-59Z";5,8608;1,8359;8,591;2,3642;64;16;8;4;0,1;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T14-29-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e11a32740>";0,00100000004749745;"Experiment.R";2024-03-14 14:30:00.73316;2024-03-14 14:30:07.44069;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-29-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-29-50Z";7,5646;2,083;10,0864;2,6001;32;16;8;4;0,1;0,3;0,2;0,1;64;50;16;"runs/2024-03-14T14-29-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e11c3df60>";0,00100000004749745;"Experiment.R";2024-03-14 14:29:50.79644;2024-03-14 14:29:59.62903;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-29-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-29-43Z";5,834;1,8507;9,6564;2,516;64;32;16;8;0,2;0,3;0,2;0,1;32;50;15;"runs/2024-03-14T14-29-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e11ca54e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:29:43.65894;2024-03-14 14:29:50.14425;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-29-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-29-31Z";5,3431;1,7527;6,9735;2,1538;32;32;16;8;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T14-29-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e120aa7a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:29:32.34932;2024-03-14 14:29:43.00255;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-29-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-29-22Z";4,9521;1,6847;8,1922;2,3207;64;16;16;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T14-29-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e122ef880>";0,00100000004749745;"Experiment.R";2024-03-14 14:29:23.11158;2024-03-14 14:29:31.6933;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-29-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-29-13Z";5,1157;1,7457;7,7667;2,282;32;16;16;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T14-29-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e125764d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:29:14.56336;2024-03-14 14:29:21.96551;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-29-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-29-00Z";4,7659;1,6677;8,0123;2,3005;64;32;8;8;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T14-29-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e125ae6b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:29:01.47228;2024-03-14 14:29:13.89287;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-29-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-28-49Z";5,1909;1,7194;6,7515;2,1389;32;32;8;8;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T14-28-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e11da7ca0>";0,00100000004749745;"Experiment.R";2024-03-14 14:28:50.25043;2024-03-14 14:29:00.78271;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-28-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-28-40Z";5,2611;1,7345;7,4151;2,2185;64;16;8;8;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T14-28-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e13812ce0>";0,00100000004749745;"Experiment.R";2024-03-14 14:28:41.59745;2024-03-14 14:28:49.59685;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-28-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-28-29Z";5,7772;1,8396;7,6825;2,256;32;16;8;8;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T14-28-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e12b328c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:28:30.192;2024-03-14 14:28:40.93364;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-28-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-28-17Z";6,0611;1,8381;8,3592;2,3522;64;32;16;4;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T14-28-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e12d68250>";0,00100000004749745;"Experiment.R";2024-03-14 14:28:18.39602;2024-03-14 14:28:29.55081;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-28-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-28-09Z";5,1726;1,7489;8,0846;2,3432;32;32;16;4;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T14-28-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1308be20>";0,00100000004749745;"Experiment.R";2024-03-14 14:28:10.40253;2024-03-14 14:28:17.73164;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-28-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-27-55Z";4,6262;1,6484;7,5081;2,2214;64;16;16;4;0,2;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T14-27-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e130fcd60>";0,00100000004749745;"Experiment.R";2024-03-14 14:27:56.90708;2024-03-14 14:28:09.72027;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-27-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-27-38Z";5,5334;1,7968;7,6561;2,2579;32;16;16;4;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T14-27-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e132cbca0>";0,00100000004749745;"Experiment.R";2024-03-14 14:27:38.85418;2024-03-14 14:27:55.72402;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-27-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-27-16Z";5,0612;1,7039;6,9675;2,123;64;32;8;4;0,2;0,3;0,2;0,1;32;50;46;"runs/2024-03-14T14-27-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e13536620>";0,00100000004749745;"Experiment.R";2024-03-14 14:27:16.74063;2024-03-14 14:27:38.19343;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-27-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-27-02Z";4,7999;1,6713;7,0989;2,1606;32;32;8;4;0,2;0,3;0,2;0,1;32;50;44;"runs/2024-03-14T14-27-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1386e800>";0,00100000004749745;"Experiment.R";2024-03-14 14:27:02.82645;2024-03-14 14:27:16.07951;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-27-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-26-51Z";6,0686;1,8468;7,3095;2,2013;64;16;8;4;0,2;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T14-26-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e13a67df0>";0,00100000004749745;"Experiment.R";2024-03-14 14:26:52.33777;2024-03-14 14:27:02.17916;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-26-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-26-39Z";5,2977;1,7384;7,6038;2,2462;32;16;8;4;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T14-26-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e13af8940>";0,00100000004749745;"Experiment.R";2024-03-14 14:26:40.59595;2024-03-14 14:26:51.68273;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-26-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-26-28Z";5,5097;1,7841;8,4591;2,3713;64;32;16;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T14-26-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e13d3d000>";0,00100000004749745;"Experiment.R";2024-03-14 14:26:29.75032;2024-03-14 14:26:39.79025;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-26-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-26-10Z";5,5166;1,7793;6,8476;2,1434;32;32;16;8;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T14-26-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e13f4b370>";0,00100000004749745;"Experiment.R";2024-03-14 14:26:11.57438;2024-03-14 14:26:28.70029;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-26-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-25-57Z";4,9707;1,6923;8,3644;2,3555;64;16;16;8;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T14-25-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e13782ec0>";0,00100000004749745;"Experiment.R";2024-03-14 14:25:58.03094;2024-03-14 14:26:10.96127;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-25-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-25-47Z";5,4586;1,7777;8,2256;2,3286;32;16;16;8;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T14-25-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e141c15d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:25:47.66498;2024-03-14 14:25:57.40805;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-25-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-25-36Z";4,7247;1,6751;7,0478;2,1719;64;32;8;8;0,2;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T14-25-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1444a560>";0,00100000004749745;"Experiment.R";2024-03-14 14:25:37.32139;2024-03-14 14:25:47.04339;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-25-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-25-15Z";5,554;1,7984;6,9576;2,1703;32;32;8;8;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T14-25-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1463a7a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:25:16.58439;2024-03-14 14:25:36.69735;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-25-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-24-55Z";5,1741;1,7284;7,2565;2,1947;64;16;8;8;0,2;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T14-24-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e146be200>";0,00100000004749745;"Experiment.R";2024-03-14 14:24:55.69985;2024-03-14 14:25:15.94812;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-24-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-24-39Z";4,887;1,697;7,3534;2,2164;32;16;8;8;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T14-24-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e15529120>";0,00100000004749745;"Experiment.R";2024-03-14 14:24:39.77867;2024-03-14 14:24:55.06123;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-24-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-24-31Z";5,868;1,8334;7,9461;2,2805;64;32;16;4;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T14-24-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e14e134f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:24:31.77636;2024-03-14 14:24:39.14754;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-24-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-24-24Z";7,2349;2,0185;7,6682;2,2498;32;32;16;4;0,2;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T14-24-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e15069fc0>";0,00100000004749745;"Experiment.R";2024-03-14 14:24:25.282;2024-03-14 14:24:31.12499;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-24-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-24-08Z";6,1151;1,8724;8,7685;2,413;64;16;16;4;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T14-24-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e151063e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:24:09.56863;2024-03-14 14:24:24.1835;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-24-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-23-55Z";5,1359;1,7375;7,8924;2,2881;32;16;16;4;0,2;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T14-23-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e148425c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:23:56.1277;2024-03-14 14:24:08.9258;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-23-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-23-32Z";5,1615;1,6871;7,4022;2,1963;64;32;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-23-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1403a6e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:23:33.28517;2024-03-14 14:23:55.49535;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-23-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-23-20Z";5,5289;1,7744;7,5232;2,2428;32;32;8;4;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T14-23-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e14a8fb50>";0,00100000004749745;"Experiment.R";2024-03-14 14:23:20.79597;2024-03-14 14:23:32.6578;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-23-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-23-10Z";5,5222;1,7566;8,1361;2,3166;64;16;8;4;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T14-23-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e15580e50>";0,00100000004749745;"Experiment.R";2024-03-14 14:23:11.73151;2024-03-14 14:23:20.18585;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-23-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-22-54Z";5,2066;1,7309;7,789;2,2685;32;16;8;4;0,2;0,3;0,2;0,1;32;50;46;"runs/2024-03-14T14-22-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e15528490>";0,00100000004749745;"Experiment.R";2024-03-14 14:22:55.39523;2024-03-14 14:23:10.64416;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-22-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-22-45Z";5,6623;1,8204;8,3898;2,3405;64;32;16;8;0,2;0,3;0,2;0,1;32;50;12;"runs/2024-03-14T14-22-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e156c5120>";0,00100000004749745;"Experiment.R";2024-03-14 14:22:46.84574;2024-03-14 14:22:54.75458;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-22-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-22-36Z";5,6138;1,8131;7,0773;2,1756;32;32;16;8;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T14-22-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e15d6c9d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:22:37.15934;2024-03-14 14:22:45.69015;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-22-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-22-26Z";5,1415;1,7289;8,9052;2,4152;64;16;16;8;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T14-22-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e15d2a800>";0,00100000004749745;"Experiment.R";2024-03-14 14:22:27.25685;2024-03-14 14:22:36.49478;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-22-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-22-10Z";5,8912;1,8424;8,0722;2,2966;32;16;16;8;0,2;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T14-22-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16033fd0>";0,00100000004749745;"Experiment.R";2024-03-14 14:22:11.87;2024-03-14 14:22:26.61935;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-22-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-21-50Z";4,9746;1,6705;7,869;2,2752;64;32;8;8;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T14-21-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16005ea0>";0,00100000004749745;"Experiment.R";2024-03-14 14:21:51.27253;2024-03-14 14:22:10.78716;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-21-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-21-29Z";4,8768;1,6962;7,8009;2,2752;32;32;8;8;0,2;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T14-21-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16244fd0>";0,00100000004749745;"Experiment.R";2024-03-14 14:21:30.28354;2024-03-14 14:21:50.62289;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-21-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-21-15Z";4,7183;1,6545;7,4199;2,2055;64;16;8;8;0,2;0,3;0,2;0,1;32;50;44;"runs/2024-03-14T14-21-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16447340>";0,00100000004749745;"Experiment.R";2024-03-14 14:21:16.17609;2024-03-14 14:21:29.63906;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-21-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-21-02Z";5,1021;1,7265;7,607;2,2351;32;16;8;8;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T14-21-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e15c81b10>";0,00100000004749745;"Experiment.R";2024-03-14 14:21:03.22925;2024-03-14 14:21:15.55414;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-21-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-20-44Z";5,1156;1,7146;7,0661;2,1551;64;32;16;4;0,2;0,3;0,2;0,1;32;50;49;"runs/2024-03-14T14-20-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1651e2c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:20:44.831;2024-03-14 14:21:02.60933;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-20-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-20-31Z";5,5776;1,8033;8,4011;2,3709;32;32;16;4;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T14-20-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e168e3d90>";0,00100000004749745;"Experiment.R";2024-03-14 14:20:31.63862;2024-03-14 14:20:44.18896;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-20-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-20-22Z";6,7462;1,9326;8,591;2,3766;64;16;16;4;0,2;0,3;0,2;0,1;32;50;13;"runs/2024-03-14T14-20-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16a785e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:20:23.4038;2024-03-14 14:20:30.99894;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-20-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-20-03Z";5,3804;1,7597;7,3161;2,2071;32;16;16;4;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T14-20-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16ab3910>";0,00100000004749745;"Experiment.R";2024-03-14 14:20:03.93992;2024-03-14 14:20:22.77745;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-20-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-19-50Z";5,044;1,6864;8,2838;2,3235;64;32;8;4;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T14-19-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16d58e20>";0,00100000004749745;"Experiment.R";2024-03-14 14:19:51.76033;2024-03-14 14:20:03.08973;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-19-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-19-35Z";6,341;1,8695;7,326;2,2141;32;32;8;4;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T14-19-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16f4bca0>";0,00100000004749745;"Experiment.R";2024-03-14 14:19:36.3384;2024-03-14 14:19:50.68863;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-19-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-19-19Z";5,7226;1,8089;8,6176;2,3864;64;16;8;4;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T14-19-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e399b51b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:19:19.96069;2024-03-14 14:19:35.73711;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-19-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-19-02Z";5,3228;1,7521;7,0493;2,1662;32;16;8;4;0,2;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T14-19-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e16fda5c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:19:03.96361;2024-03-14 14:19:19.367;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-19-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-18-54Z";4,8642;1,6886;7,6688;2,2588;64;32;16;8;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T14-18-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e17225db0>";0,00100000004749745;"Experiment.R";2024-03-14 14:18:55.06471;2024-03-14 14:19:02.84914;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-18-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-18-43Z";4,9235;1,6936;7,0797;2,1859;32;32;16;8;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T14-18-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e129ba560>";0,00100000004749745;"Experiment.R";2024-03-14 14:18:44.52163;2024-03-14 14:18:54.43197;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-18-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-18-36Z";5,5781;1,812;7,6877;2,2525;64;16;16;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T14-18-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1771d720>";0,00100000004749745;"Experiment.R";2024-03-14 14:18:37.20946;2024-03-14 14:18:43.904;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-18-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-18-25Z";5,2259;1,7363;8,2187;2,3473;32;16;16;8;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T14-18-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e179334f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:18:26.49384;2024-03-14 14:18:36.17047;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-18-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-18-11Z";4,7311;1,6639;7,97;2,2747;64;32;8;8;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T14-18-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e17d7e8f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:18:12.88433;2024-03-14 14:18:25.33334;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-18-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-18-01Z";5,6774;1,8117;8,5142;2,3708;32;32;8;8;0,2;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T14-18-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b2f7400>";0,00100000004749745;"Experiment.R";2024-03-14 14:18:01.66475;2024-03-14 14:18:11.82444;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-18-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-17-34Z";4,7421;1,6681;7,3067;2,1931;64;16;8;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-17-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3ae35cc0>";0,00100000004749745;"Experiment.R";2024-03-14 14:17:35.73164;2024-03-14 14:18:01.05408;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-17-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-17-26Z";5,5108;1,7966;6,841;2,1485;32;16;8;8;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T14-17-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e38e655d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:17:27.39506;2024-03-14 14:17:34.7207;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-17-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-17-13Z";5,6625;1,7981;8,371;2,3483;64;32;16;4;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T14-17-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37d81a50>";0,00100000004749745;"Experiment.R";2024-03-14 14:17:14.43541;2024-03-14 14:17:26.79574;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-17-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-17-07Z";7,1687;1,9876;8,3433;2,3561;32;32;16;4;0,2;0,3;0,2;0,1;32;50;13;"runs/2024-03-14T14-17-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37699030>";0,00100000004749745;"Experiment.R";2024-03-14 14:17:07.81876;2024-03-14 14:17:13.82413;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-17-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-16-55Z";4,5459;1,6168;8,3916;2,3474;64;16;16;4;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T14-16-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e506f9600>";0,00100000004749745;"Experiment.R";2024-03-14 14:16:55.59147;2024-03-14 14:17:07.21379;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-16-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-16-40Z";5,5597;1,7611;8,8769;2,4128;32;16;16;4;0,2;0,3;0,2;0,1;32;50;44;"runs/2024-03-14T14-16-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37bd0f10>";0,00100000004749745;"Experiment.R";2024-03-14 14:16:41.55896;2024-03-14 14:16:54.97679;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-16-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-16-16Z";4,5937;1,6242;8,1323;2,29;64;32;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-16-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e393ad2d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:16:17.46222;2024-03-14 14:16:40.92071;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-16-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-16-03Z";5,2215;1,7484;8,1235;2,3195;32;32;8;4;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T14-16-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e35cf35e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:16:04.29733;2024-03-14 14:16:16.84169;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-16-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-15-53Z";5,8516;1,8138;7,567;2,2344;64;16;8;4;0,2;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T14-15-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b4397e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:15:54.52104;2024-03-14 14:16:03.66159;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-15-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-15-40Z";5,9245;1,8453;7,3547;2,2165;32;16;8;4;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T14-15-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40efa470>";0,00100000004749745;"Experiment.R";2024-03-14 14:15:40.65865;2024-03-14 14:15:53.49732;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-15-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-15-33Z";5,0088;1,7138;7,0518;2,1675;64;32;16;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T14-15-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e58ec6ef0>";0,00100000004749745;"Experiment.R";2024-03-14 14:15:33.7831;2024-03-14 14:15:40.04672;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-15-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-15-22Z";4,824;1,6817;7,6546;2,246;32;32;16;8;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T14-15-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3deffd30>";0,00100000004749745;"Experiment.R";2024-03-14 14:15:23.22383;2024-03-14 14:15:33.19875;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-15-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-15-15Z";5,4046;1,7816;7,5307;2,2288;64;16;16;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T14-15-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5964acb0>";0,00100000004749745;"Experiment.R";2024-03-14 14:15:15.57586;2024-03-14 14:15:22.59954;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-15-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-14-59Z";5,9405;1,8512;7,3996;2,2118;32;16;16;8;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T14-14-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e387e0a30>";0,00100000004749745;"Experiment.R";2024-03-14 14:14:59.84438;2024-03-14 14:15:14.96222;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-14-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-14-45Z";4,6608;1,6407;7,8961;2,2684;64;32;8;8;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T14-14-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b366020>";0,00100000004749745;"Experiment.R";2024-03-14 14:14:46.29883;2024-03-14 14:14:59.22672;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-14-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-14-34Z";5,4149;1,746;8,0117;2,2996;32;32;8;8;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T14-14-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5ad11240>";0,00100000004749745;"Experiment.R";2024-03-14 14:14:35.40329;2024-03-14 14:14:45.69725;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-14-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-14-24Z";5,2975;1,7486;7,5814;2,2466;64;16;8;8;0,2;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T14-14-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59e58b50>";0,00100000004749745;"Experiment.R";2024-03-14 14:14:24.75693;2024-03-14 14:14:34.78774;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-14-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-14-01Z";5,0323;1,7114;6,6368;2,1072;32;16;8;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-14-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21d2cac0>";0,00100000004749745;"Experiment.R";2024-03-14 14:14:02.33753;2024-03-14 14:14:24.15992;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-14-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-13-47Z";4,7933;1,6373;7,8737;2,2671;64;32;16;4;0,2;0,3;0,2;0,1;32;50;46;"runs/2024-03-14T14-13-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42bba7a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:13:47.73262;2024-03-14 14:14:01.7385;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-13-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-13-29Z";5,1896;1,7257;7,4306;2,2247;32;32;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-13-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3ed84d30>";0,00100000004749745;"Experiment.R";2024-03-14 14:13:29.81767;2024-03-14 14:13:47.10668;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-13-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-13-20Z";6,3248;1,8613;9,1733;2,4442;64;16;16;4;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T14-13-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6288c8e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:13:20.94938;2024-03-14 14:13:29.20928;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-13-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-13-08Z";5,003;1,7231;7,6751;2,2582;32;16;16;4;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T14-13-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e409e55a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:13:08.60048;2024-03-14 14:13:20.3159;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-13-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-12-45Z";4,8046;1,6605;6,6431;2,1081;64;32;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-12-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40051c60>";0,00100000004749745;"Experiment.R";2024-03-14 14:12:45.80161;2024-03-14 14:13:07.99045;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-12-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-12-33Z";5,4961;1,7479;7,3807;2,2195;32;32;8;4;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T14-12-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e0bd6f0>";0,00100000004749745;"Experiment.R";2024-03-14 14:12:33.77649;2024-03-14 14:12:45.21713;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-12-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-12-10Z";5,4489;1,7439;6,7468;2,1267;64;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-12-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e26b82ad0>";0,00100000004749745;"Experiment.R";2024-03-14 14:12:10.6487;2024-03-14 14:12:33.16439;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-12-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-11-54Z";5,495;1,7623;7,5665;2,2512;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-11-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e26708e50>";0,00100000004749745;"Experiment.R";2024-03-14 14:11:54.82458;2024-03-14 14:12:10.03058;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-11-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-11-48Z";5,6776;1,8066;7,6819;2,2539;64;32;16;8;0,2;0,3;0,2;0,1;32;50;13;"runs/2024-03-14T14-11-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e26216350>";0,00100000004749745;"Experiment.R";2024-03-14 14:11:49.18058;2024-03-14 14:11:54.21996;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-11-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-11-34Z";4,7307;1,6573;8,5976;2,3882;32;32;16;8;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T14-11-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25b71120>";0,00100000004749745;"Experiment.R";2024-03-14 14:11:35.83176;2024-03-14 14:11:48.4984;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-11-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-11-18Z";5,4815;1,7793;9,18;2,4648;64;16;16;8;0,2;0,3;0,2;0,1;32;50;15;"runs/2024-03-14T14-11-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e250ebfa0>";0,00100000004749745;"Experiment.R";2024-03-14 14:11:19.5114;2024-03-14 14:11:34.81956;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-11-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-11-06Z";4,8324;1,6753;7,5569;2,2312;32;16;16;8;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T14-11-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e22f5d780>";0,00100000004749745;"Experiment.R";2024-03-14 14:11:07.22269;2024-03-14 14:11:18.90906;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-11-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-10-51Z";5,4115;1,7295;7,7247;2,2499;64;32;8;8;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T14-10-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e248a94b0>";0,00100000004749745;"Experiment.R";2024-03-14 14:10:51.63141;2024-03-14 14:11:06.60959;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-10-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-10-43Z";5,4518;1,7913;8,2332;2,3259;32;32;8;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T14-10-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e24200ee0>";0,00100000004749745;"Experiment.R";2024-03-14 14:10:44.05296;2024-03-14 14:10:51.02211;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-10-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-10-26Z";5,3677;1,7683;7,978;2,2979;64;16;8;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T14-10-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2354a140>";0,00100000004749745;"Experiment.R";2024-03-14 14:10:27.30695;2024-03-14 14:10:43.47383;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-10-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-10-12Z";5,3648;1,7622;8,4698;2,3638;32;16;8;8;0,2;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T14-10-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2383e710>";0,00100000004749745;"Experiment.R";2024-03-14 14:10:13.52969;2024-03-14 14:10:26.72257;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-10-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-10-03Z";6,0082;1,848;7,9525;2,2929;64;32;16;4;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T14-10-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e23204640>";0,00100000004749745;"Experiment.R";2024-03-14 14:10:04.42709;2024-03-14 14:10:12.9409;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-10-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-09-49Z";5,1063;1,7364;7,2114;2,1785;32;32;16;4;0,2;0,3;0,2;0,1;32;50;44;"runs/2024-03-14T14-09-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e22b6ad70>";0,00100000004749745;"Experiment.R";2024-03-14 14:09:50.28381;2024-03-14 14:10:03.83185;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-09-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-09-41Z";6,3576;1,9242;9,6462;2,5019;64;16;16;4;0,2;0,3;0,2;0,1;32;50;15;"runs/2024-03-14T14-09-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e20ad3280>";0,00100000004749745;"Experiment.R";2024-03-14 14:09:41.76013;2024-03-14 14:09:49.6857;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-09-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-09-31Z";5,7155;1,83;7,7169;2,2635;32;16;16;4;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T14-09-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e222a5c00>";0,00100000004749745;"Experiment.R";2024-03-14 14:09:32.05367;2024-03-14 14:09:41.17766;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-09-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-09-21Z";5,6033;1,7549;7,4823;2,2279;64;32;8;4;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T14-09-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21c6fcd0>";0,00100000004749745;"Experiment.R";2024-03-14 14:09:21.5829;2024-03-14 14:09:31.02968;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-09-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-09-00Z";5,843;1,8477;7,5623;2,2458;32;32;8;4;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T14-09-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21618580>";0,00100000004749745;"Experiment.R";2024-03-14 14:09:01.50622;2024-03-14 14:09:20.99854;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-09-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-08-39Z";5,209;1,7272;6,9724;2,1335;64;16;8;4;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T14-08-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e20a5ef80>";0,00100000004749745;"Experiment.R";2024-03-14 14:08:40.20746;2024-03-14 14:09:00.91115;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-08-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-08-26Z";4,9924;1,7089;6,9747;2,1802;32;16;8;4;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T14-08-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1fcc06a0>";0,00100000004749745;"Experiment.R";2024-03-14 14:08:27.40984;2024-03-14 14:08:39.60081;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-08-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-08-10Z";5,0641;1,6912;7,6875;2,24;64;32;16;8;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T14-08-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1f2cb610>";0,00100000004749745;"Experiment.R";2024-03-14 14:08:11.35652;2024-03-14 14:08:26.80149;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-08-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-08-00Z";5,8681;1,8412;7,7327;2,2521;32;32;16;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T14-08-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3aa2d7e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:08:00.62094;2024-03-14 14:08:10.72249;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-08-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-07-47Z";5,2136;1,7452;8,2226;2,3373;64;16;16;8;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T14-07-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1dc332e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:07:48.13545;2024-03-14 14:08:00.00063;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-07-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-07-38Z";5,4064;1,764;8,6486;2,381;32;16;16;8;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T14-07-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c560730>";0,00100000004749745;"Experiment.R";2024-03-14 14:07:38.93102;2024-03-14 14:07:47.55527;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-07-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-07-32Z";6,3989;1,8952;9,3041;2,4845;64;32;8;8;0,2;0,3;0,2;0,1;32;50;12;"runs/2024-03-14T14-07-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c1645e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:07:33.47176;2024-03-14 14:07:38.34791;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-07-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-07-24Z";5,4705;1,7922;7,6776;2,2582;32;32;8;8;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T14-07-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e52189840>";0,00100000004749745;"Experiment.R";2024-03-14 14:07:24.6101;2024-03-14 14:07:32.89895;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-07-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-07-17Z";5,4202;1,7697;8,5043;2,3607;64;16;8;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T14-07-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3bba85e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:07:17.81999;2024-03-14 14:07:24.03148;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-07-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-07-07Z";5,318;1,7674;7,9812;2,2976;32;16;8;8;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T14-07-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b794d30>";0,00100000004749745;"Experiment.R";2024-03-14 14:07:08.50341;2024-03-14 14:07:17.24185;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-07-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-06-59Z";6,033;1,841;7,7391;2,2591;64;32;16;4;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T14-06-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3ae1ee90>";0,00100000004749745;"Experiment.R";2024-03-14 14:07:00.19174;2024-03-14 14:07:07.92776;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-06-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-06-50Z";5,352;1,7632;8,0208;2,2921;32;32;16;4;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T14-06-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3a75c820>";0,00100000004749745;"Experiment.R";2024-03-14 14:06:50.99002;2024-03-14 14:06:59.61211;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-06-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-06-40Z";5,0538;1,7152;8,679;2,4024;64;16;16;4;0,2;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T14-06-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e39a7a350>";0,00100000004749745;"Experiment.R";2024-03-14 14:06:40.54962;2024-03-14 14:06:50.0266;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-06-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-06-28Z";5,1825;1,7359;7,6596;2,2461;32;16;16;4;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T14-06-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e393c40d0>";0,00100000004749745;"Experiment.R";2024-03-14 14:06:29.40447;2024-03-14 14:06:39.96545;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-06-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-06-14Z";5,1024;1,7033;7,8984;2,2646;64;32;8;4;0,2;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T14-06-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37dc81c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:06:15.00585;2024-03-14 14:06:28.81676;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-06-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-05-54Z";5,9609;1,8585;7,7022;2,2677;32;32;8;4;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T14-05-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e38288070>";0,00100000004749745;"Experiment.R";2024-03-14 14:05:55.55871;2024-03-14 14:06:14.43089;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-05-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-05-43Z";5,0421;1,7082;6,9763;2,1506;64;16;8;4;0,2;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T14-05-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e35dc8940>";0,00100000004749745;"Experiment.R";2024-03-14 14:05:43.64606;2024-03-14 14:05:54.94341;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-05-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-05-16Z";11,374;2,5419;13,0591;2,8076;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-05-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37299360>";0,00100000004749745;"Experiment.R";2024-03-14 14:05:17.22161;2024-03-14 14:05:43.05114;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-05-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-05-07Z";5,6006;1,8008;7,113;2,1765;64;32;16;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T14-05-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a5682e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:05:07.95601;2024-03-14 14:05:16.65386;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-05-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-04-52Z";4,797;1,6693;7,0772;2,1814;32;32;16;8;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T14-04-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46e11630>";0,00100000004749745;"Experiment.R";2024-03-14 14:04:53.31172;2024-03-14 14:05:07.38276;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-04-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-04-36Z";5,6326;1,7999;7,9305;2,2816;64;16;16;8;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T14-04-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e41458f10>";0,00100000004749745;"Experiment.R";2024-03-14 14:04:36.58917;2024-03-14 14:04:52.72645;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-04-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-04-22Z";5,136;1,7302;7,3925;2,2107;32;16;16;8;0,2;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T14-04-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4aeea290>";0,00100000004749745;"Experiment.R";2024-03-14 14:04:22.92072;2024-03-14 14:04:36.00821;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-04-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-04-09Z";4,8831;1,6821;8,5896;2,39;64;32;8;8;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T14-04-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5778c670>";0,00100000004749745;"Experiment.R";2024-03-14 14:04:09.86636;2024-03-14 14:04:22.33843;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-04-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-03-54Z";5,8295;1,8702;8,0452;2,2958;32;32;8;8;0,2;0,3;0,2;0,1;32;50;13;"runs/2024-03-14T14-03-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3cb4e3e0>";0,00100000004749745;"Experiment.R";2024-03-14 14:03:54.81453;2024-03-14 14:04:09.20734;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-03-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-03-40Z";4,8387;1,6688;7,2558;2,1998;64;16;8;8;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T14-03-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e0a2860>";0,00100000004749745;"Experiment.R";2024-03-14 14:03:41.20252;2024-03-14 14:03:54.20261;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-03-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-03-30Z";5,1964;1,7467;8,0504;2,2894;32;16;8;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T14-03-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42ec47c0>";0,00100000004749745;"Experiment.R";2024-03-14 14:03:30.5821;2024-03-14 14:03:40.62953;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-03-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-03-16Z";4,9458;1,6952;8,3673;2,3447;64;32;16;4;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T14-03-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b7b8a00>";0,00100000004749745;"Experiment.R";2024-03-14 14:03:17.19635;2024-03-14 14:03:29.96071;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-03-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-03-05Z";5,3699;1,7706;7,6905;2,2695;32;32;16;4;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T14-03-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42374790>";0,00100000004749745;"Experiment.R";2024-03-14 14:03:06.86658;2024-03-14 14:03:16.55849;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-03-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-02-57Z";6,3718;1,84;9,3259;2,4594;64;16;16;4;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T14-02-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6939fdc0>";0,00100000004749745;"Experiment.R";2024-03-14 14:02:58.27514;2024-03-14 14:03:05.85871;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-02-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-02-37Z";6,4032;1,8765;8,2919;2,3344;32;16;16;4;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T14-02-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3fbcf520>";0,00100000004749745;"Experiment.R";2024-03-14 14:02:38.37575;2024-03-14 14:02:57.69998;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-02-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-02-23Z";5,0955;1,7206;8,0497;2,3033;64;32;8;4;0,2;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T14-02-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e26897280>";0,00100000004749745;"Experiment.R";2024-03-14 14:02:23.82374;2024-03-14 14:02:37.78703;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-02-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-02-12Z";6,1202;1,8589;7,1016;2,1707;32;32;8;4;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T14-02-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e266beda0>";0,00100000004749745;"Experiment.R";2024-03-14 14:02:13.74394;2024-03-14 14:02:23.22834;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-02-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-01-49Z";4,922;1,6757;7,7585;2,2618;64;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-01-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e258cdf00>";0,00100000004749745;"Experiment.R";2024-03-14 14:01:50.15747;2024-03-14 14:02:12.73553;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-01-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-01-26Z";5,2831;1,7263;6,7436;2,1213;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T14-01-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21f2a680>";0,00100000004749745;"Experiment.R";2024-03-14 14:01:26.84512;2024-03-14 14:01:49.55581;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-01-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-01-11Z";4,6411;1,6239;8,9061;2,4329;64;32;16;8;0,1;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T14-01-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e246bdba0>";0,00100000004749745;"Experiment.R";2024-03-14 14:01:11.93647;2024-03-14 14:01:26.25242;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-01-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-01-04Z";6,0539;1,838;6,9478;2,1603;32;32;16;8;0,1;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T14-01-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e238dc550>";0,00100000004749745;"Experiment.R";2024-03-14 14:01:05.12304;2024-03-14 14:01:11.3383;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-01-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-00-38Z";4,9002;1,678;7,9302;2,2852;64;16;16;8;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T14-00-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e229eeb90>";0,00100000004749745;"Experiment.R";2024-03-14 14:00:39.40702;2024-03-14 14:01:04.06918;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-00-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-00-26Z";4,7559;1,6755;8,4183;2,3569;32;16;16;8;0,1;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T14-00-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e22116680>";0,00100000004749745;"Experiment.R";2024-03-14 14:00:26.91824;2024-03-14 14:00:38.46183;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-00-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-00-17Z";5,3671;1,7577;9,2128;2,4748;64;32;8;8;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T14-00-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1fe9a470>";0,00100000004749745;"Experiment.R";2024-03-14 14:00:18.27441;2024-03-14 14:00:25.95739;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-00-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T14-00-00Z";5,2211;1,7306;8,6654;2,3888;32;32;8;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T14-00-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c165ff0>";0,00100000004749745;"Experiment.R";2024-03-14 14:00:00.71612;2024-03-14 14:00:17.67272;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T14-00-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-59-51Z";5,2721;1,7628;8,0603;2,2897;64;16;8;8;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T13-59-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c1129e0>";0,00100000004749745;"Experiment.R";2024-03-14 13:59:51.5698;2024-03-14 14:00:00.13773;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-59-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-59-40Z";5,1311;1,7164;7,2487;2,1961;32;16;8;8;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T13-59-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1d20b8b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:59:41.2804;2024-03-14 13:59:50.97115;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-59-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-59-31Z";4,9221;1,6802;8,3705;2,3641;64;32;16;4;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T13-59-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1d4a2530>";0,00100000004749745;"Experiment.R";2024-03-14 13:59:31.68932;2024-03-14 13:59:40.69566;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-59-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-59-20Z";5,3102;1,7725;7,4151;2,2207;32;32;16;4;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T13-59-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1d675fc0>";0,00100000004749745;"Experiment.R";2024-03-14 13:59:20.91881;2024-03-14 13:59:31.10375;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-59-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-59-10Z";6,4389;1,8693;8,8925;2,4159;64;16;16;4;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T13-59-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1d6ed540>";0,00100000004749745;"Experiment.R";2024-03-14 13:59:11.70881;2024-03-14 13:59:20.34107;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-59-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-58-58Z";5,1957;1,7282;8,0086;2,308;32;16;16;4;0,1;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T13-58-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c625990>";0,00100000004749745;"Experiment.R";2024-03-14 13:58:59.64113;2024-03-14 13:59:10.76961;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-58-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-58-35Z";4,3936;1,6107;7,6985;2,2633;64;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-58-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c5344f0>";0,00100000004749745;"Experiment.R";2024-03-14 13:58:36.28808;2024-03-14 13:58:58.63671;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-58-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-58-19Z";4,8901;1,6717;7,9072;2,2955;32;32;8;4;0,1;0,3;0,2;0,1;32;50;46;"runs/2024-03-14T13-58-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c95d150>";0,00100000004749745;"Experiment.R";2024-03-14 13:58:20.86194;2024-03-14 13:58:35.71149;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-58-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-58-06Z";4,9434;1,7039;8,0187;2,2847;64;16;8;4;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T13-58-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1cb4ef80>";0,00100000004749745;"Experiment.R";2024-03-14 13:58:06.58267;2024-03-14 13:58:19.76816;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-58-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-57-51Z";6,0166;1,8256;8,0795;2,3061;32;16;8;4;0,1;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T13-57-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1cd71c90>";0,00100000004749745;"Experiment.R";2024-03-14 13:57:52.49013;2024-03-14 13:58:06.00371;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-57-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-57-40Z";4,7805;1,6587;8,7541;2,3788;64;32;16;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T13-57-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1cdf2440>";0,00100000004749745;"Experiment.R";2024-03-14 13:57:41.17463;2024-03-14 13:57:51.93268;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-57-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-57-31Z";5,1078;1,7246;6,7802;2,1045;32;32;16;8;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T13-57-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1d06ff10>";0,00100000004749745;"Experiment.R";2024-03-14 13:57:32.71241;2024-03-14 13:57:40.60935;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-57-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-57-23Z";5,5683;1,7995;9,2334;2,4806;64;16;16;8;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T13-57-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1cff8850>";0,00100000004749745;"Experiment.R";2024-03-14 13:57:24.20636;2024-03-14 13:57:31.76073;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-57-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-57-12Z";5,062;1,7052;8,6154;2,3769;32;16;16;8;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T13-57-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1da1af80>";0,00100000004749745;"Experiment.R";2024-03-14 13:57:13.40572;2024-03-14 13:57:23.62811;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-57-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-56-53Z";4,8767;1,6705;7,9488;2,3074;64;32;8;8;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T13-56-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1dab0fa0>";0,00100000004749745;"Experiment.R";2024-03-14 13:56:54.60108;2024-03-14 13:57:12.86486;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-56-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-56-41Z";5,1147;1,7066;7,3611;2,2131;32;32;8;8;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T13-56-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1de87af0>";0,00100000004749745;"Experiment.R";2024-03-14 13:56:42.22025;2024-03-14 13:56:53.65008;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-56-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-56-33Z";5,0434;1,7251;8,7003;2,3928;64;16;8;8;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T13-56-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1deea7a0>";0,00100000004749745;"Experiment.R";2024-03-14 13:56:33.88423;2024-03-14 13:56:41.3041;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-56-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-56-24Z";5,0761;1,7197;9,4863;2,5174;32;16;8;8;0,1;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T13-56-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1e2afd90>";0,00100000004749745;"Experiment.R";2024-03-14 13:56:25.02538;2024-03-14 13:56:33.32185;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-56-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-56-01Z";5,0675;1,6805;7,6677;2,2401;64;32;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-56-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1e509cc0>";0,00100000004749745;"Experiment.R";2024-03-14 13:56:02.01902;2024-03-14 13:56:24.46254;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-56-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-55-46Z";5,8165;1,7877;7,42;2,2196;32;32;16;4;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T13-55-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1ec8e470>";0,00100000004749745;"Experiment.R";2024-03-14 13:55:46.60735;2024-03-14 13:56:01.44372;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-55-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-55-37Z";5,7332;1,805;8,1431;2,3133;64;16;16;4;0,1;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T13-55-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1ecd1630>";0,00100000004749745;"Experiment.R";2024-03-14 13:55:37.9219;2024-03-14 13:55:46.02436;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-55-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-55-26Z";5,2651;1,7301;7,6409;2,2514;32;16;16;4;0,1;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T13-55-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1eebe7d0>";0,00100000004749745;"Experiment.R";2024-03-14 13:55:26.97924;2024-03-14 13:55:37.35083;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-55-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-55-16Z";5,515;1,7608;7,856;2,2752;64;32;8;4;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T13-55-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1f0dbfd0>";0,00100000004749745;"Experiment.R";2024-03-14 13:55:17.35445;2024-03-14 13:55:26.40337;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-55-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-54-53Z";4,9648;1,6709;7,0842;2,1691;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-54-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1e888130>";0,00100000004749745;"Experiment.R";2024-03-14 13:54:54.03172;2024-03-14 13:55:16.58806;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-54-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-54-37Z";4,9633;1,6893;7,8697;2,2822;64;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-54-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1e810220>";0,00100000004749745;"Experiment.R";2024-03-14 13:54:38.46865;2024-03-14 13:54:53.47618;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-54-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-54-18Z";5,5498;1,7836;7,3248;2,1892;32;16;8;4;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T13-54-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1ea3db10>";0,00100000004749745;"Experiment.R";2024-03-14 13:54:19.09347;2024-03-14 13:54:37.50013;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-54-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-54-04Z";4,4031;1,6089;8,1233;2,3022;64;32;16;8;0,1;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T13-54-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1e0ad060>";0,00100000004749745;"Experiment.R";2024-03-14 13:54:04.94027;2024-03-14 13:54:18.52775;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-54-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-53-53Z";4,7642;1,6525;7,8473;2,25;32;32;16;8;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T13-53-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1f783550>";0,00100000004749745;"Experiment.R";2024-03-14 13:53:54.44915;2024-03-14 13:54:04.41672;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-53-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-53-44Z";5,8678;1,8421;8,0459;2,2771;64;16;16;8;0,1;0,3;0,2;0,1;32;50;13;"runs/2024-03-14T13-53-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1f7ea4a0>";0,00100000004749745;"Experiment.R";2024-03-14 13:53:44.97314;2024-03-14 13:53:53.89915;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-53-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-53-35Z";5,4631;1,7825;7,9718;2,2916;32;16;16;8;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T13-53-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1f9ef5b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:53:36.24125;2024-03-14 13:53:44.44085;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-53-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-53-28Z";5,5456;1,7772;7,9101;2,2962;64;32;8;8;0,1;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T13-53-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1fc66560>";0,00100000004749745;"Experiment.R";2024-03-14 13:53:29.0123;2024-03-14 13:53:35.31266;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-53-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-53-18Z";5,3419;1,7575;8,1335;2,3046;32;32;8;8;0,1;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T13-53-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1fe99720>";0,00100000004749745;"Experiment.R";2024-03-14 13:53:18.83852;2024-03-14 13:53:28.48348;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-53-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-53-05Z";4,8573;1,6908;7,5536;2,243;64;16;8;8;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T13-53-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e20d40220>";0,00100000004749745;"Experiment.R";2024-03-14 13:53:06.72238;2024-03-14 13:53:18.30828;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-53-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-52-55Z";4,9201;1,6875;8,0707;2,3169;32;16;8;8;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T13-52-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1f5d3310>";0,00100000004749745;"Experiment.R";2024-03-14 13:52:56.20655;2024-03-14 13:53:05.93807;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-52-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-52-43Z";5,3408;1,7426;8,4711;2,3463;64;32;16;4;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T13-52-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e200ff460>";0,00100000004749745;"Experiment.R";2024-03-14 13:52:44.28728;2024-03-14 13:52:55.66937;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-52-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-52-32Z";4,6569;1,6575;7,1058;2,1911;32;32;16;4;0,1;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T13-52-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e203c0430>";0,00100000004749745;"Experiment.R";2024-03-14 13:52:32.82782;2024-03-14 13:52:43.74262;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-52-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-52-19Z";5,7191;1,765;7,9205;2,2895;64;16;16;4;0,1;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T13-52-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2053ac20>";0,00100000004749745;"Experiment.R";2024-03-14 13:52:19.79255;2024-03-14 13:52:32.27991;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-52-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-52-09Z";5,3788;1,7466;8,58;2,3582;32;16;16;4;0,1;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T13-52-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2076e710>";0,00100000004749745;"Experiment.R";2024-03-14 13:52:10.61429;2024-03-14 13:52:19.24006;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-52-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-51-55Z";4,9539;1,6572;8,7741;2,357;64;32;8;4;0,1;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T13-51-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1fed1de0>";0,00100000004749745;"Experiment.R";2024-03-14 13:51:56.86242;2024-03-14 13:52:09.92191;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-51-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-51-40Z";11,3684;2,5407;13,0526;2,8068;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-51-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e20a87a00>";0,00100000004749745;"Experiment.R";2024-03-14 13:51:40.93873;2024-03-14 13:51:55.90474;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-51-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-51-16Z";5,0486;1,7101;7,7182;2,2511;64;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-51-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e1c1ea200>";0,00100000004749745;"Experiment.R";2024-03-14 13:51:17.01223;2024-03-14 13:51:40.41512;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-51-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-51-01Z";5,2174;1,7276;7,8314;2,2857;32;16;8;4;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T13-51-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e20d2d750>";0,00100000004749745;"Experiment.R";2024-03-14 13:51:01.99651;2024-03-14 13:51:16.46596;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-51-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-50-51Z";5,0899;1,6978;8,3977;2,3492;64;32;16;8;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T13-50-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e20f1b340>";0,00100000004749745;"Experiment.R";2024-03-14 13:50:51.7608;2024-03-14 13:51:01.45959;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-50-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-50-41Z";4,9916;1,682;7,5336;2,2505;32;32;16;8;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T13-50-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2115a5c0>";0,00100000004749745;"Experiment.R";2024-03-14 13:50:42.28981;2024-03-14 13:50:51.20616;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-50-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-50-28Z";4,6795;1,6349;7,4777;2,2127;64;16;16;8;0,1;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T13-50-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21397a90>";0,00100000004749745;"Experiment.R";2024-03-14 13:50:28.94665;2024-03-14 13:50:41.34392;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-50-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-50-18Z";5,2217;1,7517;7,4836;2,236;32;16;16;8;0,1;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T13-50-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e215c6410>";0,00100000004749745;"Experiment.R";2024-03-14 13:50:19.44912;2024-03-14 13:50:27.99312;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-50-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-50-06Z";4,7509;1,6393;7,7401;2,2655;64;32;8;8;0,1;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T13-50-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e217fc7c0>";0,00100000004749745;"Experiment.R";2024-03-14 13:50:07.11912;2024-03-14 13:50:18.72978;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-50-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-49-55Z";5,6194;1,7987;8,8004;2,4174;32;32;8;8;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T13-49-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21a0be20>";0,00100000004749745;"Experiment.R";2024-03-14 13:49:55.98073;2024-03-14 13:50:06.52124;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-49-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-49-45Z";5,6621;1,812;7,9858;2,3025;64;16;8;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T13-49-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21abe530>";0,00100000004749745;"Experiment.R";2024-03-14 13:49:45.68628;2024-03-14 13:49:55.43453;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-49-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-49-36Z";5,0464;1,7528;6,9972;2,1626;32;16;8;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T13-49-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e220a2920>";0,00100000004749745;"Experiment.R";2024-03-14 13:49:37.11554;2024-03-14 13:49:45.12406;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-49-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-49-25Z";4,8222;1,6458;7,9404;2,2894;64;32;16;4;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T13-49-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e221158a0>";0,00100000004749745;"Experiment.R";2024-03-14 13:49:25.7156;2024-03-14 13:49:36.57411;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-49-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-49-01Z";5,0245;1,6781;7,8981;2,2732;32;32;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-49-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e222d6080>";0,00100000004749745;"Experiment.R";2024-03-14 13:49:02.46641;2024-03-14 13:49:25.17312;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-49-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-48-39Z";5,3264;1,7365;8,3669;2,3404;64;16;16;4;0,1;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T13-48-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2255e4a0>";0,00100000004749745;"Experiment.R";2024-03-14 13:48:40.40194;2024-03-14 13:49:01.51999;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-48-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-48-27Z";5,071;1,7351;7,5413;2,2366;32;16;16;4;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T13-48-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e21d96680>";0,00100000004749745;"Experiment.R";2024-03-14 13:48:28.49053;2024-03-14 13:48:39.86087;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-48-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-47-55Z";11,3642;2,5402;13,0474;2,8061;64;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-47-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2147bc70>";0,00100000004749745;"Experiment.R";2024-03-14 13:47:56.26339;2024-03-14 13:48:27.94342;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-47-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-47-43Z";5,1345;1,7345;7,6947;2,2574;32;32;8;4;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T13-47-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e226e1780>";0,00100000004749745;"Experiment.R";2024-03-14 13:47:43.69541;2024-03-14 13:47:55.69915;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-47-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-47-32Z";5,0653;1,7049;8,3806;2,3616;64;16;8;4;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T13-47-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2274d330>";0,00100000004749745;"Experiment.R";2024-03-14 13:47:32.95838;2024-03-14 13:47:43.15384;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-47-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-47-22Z";5,1491;1,7449;7,709;2,2392;32;16;8;4;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T13-47-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2294ed40>";0,00100000004749745;"Experiment.R";2024-03-14 13:47:22.74906;2024-03-14 13:47:32.4247;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-47-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-47-11Z";5,0215;1,6847;8,0846;2,2956;64;32;16;8;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T13-47-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e22b7f8e0>";0,00100000004749745;"Experiment.R";2024-03-14 13:47:12.69007;2024-03-14 13:47:22.20183;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-47-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-46-58Z";4,94;1,6837;6,4118;2,0714;32;32;16;8;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T13-46-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e22dad1e0>";0,00100000004749745;"Experiment.R";2024-03-14 13:46:58.57364;2024-03-14 13:47:11.71965;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-46-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-46-50Z";5,323;1,7386;8,0517;2,2929;64;16;16;8;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T13-46-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e22e226b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:46:51.07657;2024-03-14 13:46:58.03868;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-46-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-46-36Z";5,4543;1,7796;7,9967;2,3044;32;16;16;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T13-46-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e232196c0>";0,00100000004749745;"Experiment.R";2024-03-14 13:46:36.97758;2024-03-14 13:46:50.56526;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-46-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-46-11Z";4,6884;1,6333;7,7066;2,2671;64;32;8;8;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T13-46-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e234866b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:46:12.45841;2024-03-14 13:46:36.07114;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-46-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-45-58Z";4,5732;1,6344;7,3444;2,2166;32;32;8;8;0,1;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T13-45-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2384e800>";0,00100000004749745;"Experiment.R";2024-03-14 13:45:59.44199;2024-03-14 13:46:11.93054;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-45-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-45-48Z";5,099;1,7157;7,6232;2,245;64;16;8;8;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T13-45-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e238de620>";0,00100000004749745;"Experiment.R";2024-03-14 13:45:48.58064;2024-03-14 13:45:58.91771;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-45-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-45-36Z";5,3452;1,758;7,0381;2,1743;32;16;8;8;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T13-45-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e23b1a800>";0,00100000004749745;"Experiment.R";2024-03-14 13:45:37.11145;2024-03-14 13:45:48.02817;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-45-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-45-17Z";5,1703;1,7275;7,541;2,2212;64;32;16;4;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T13-45-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e23d16d40>";0,00100000004749745;"Experiment.R";2024-03-14 13:45:18.21104;2024-03-14 13:45:36.57361;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-45-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-45-05Z";4,6913;1,6386;7,885;2,2885;32;32;16;4;0,1;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T13-45-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e235a4190>";0,00100000004749745;"Experiment.R";2024-03-14 13:45:06.44897;2024-03-14 13:45:17.69267;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-45-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-44-52Z";6,0071;1,8587;7,6614;2,2568;64;16;16;4;0,1;0,3;0,2;0,1;32;50;13;"runs/2024-03-14T13-44-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2617e380>";0,00100000004749745;"Experiment.R";2024-03-14 13:44:52.69364;2024-03-14 13:45:05.89664;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-44-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-44-38Z";5,0201;1,7055;7,5054;2,2326;32;16;16;4;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T13-44-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e23fd4280>";0,00100000004749745;"Experiment.R";2024-03-14 13:44:39.23417;2024-03-14 13:44:52.16484;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-44-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-44-16Z";11,3655;2,5403;13,0487;2,8062;64;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-44-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e24200610>";0,00100000004749745;"Experiment.R";2024-03-14 13:44:16.61795;2024-03-14 13:44:38.7274;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-44-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-44-00Z";4,7795;1,6666;6,823;2,1211;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-44-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2441fc10>";0,00100000004749745;"Experiment.R";2024-03-14 13:44:01.49114;2024-03-14 13:44:16.10308;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-44-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-43-46Z";4,6492;1,6304;8,336;2,3383;64;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-43-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e244c53f0>";0,00100000004749745;"Experiment.R";2024-03-14 13:43:46.54916;2024-03-14 13:44:00.96134;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-43-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-43-36Z";5,6666;1,816;8,1613;2,3118;32;16;8;4;0,1;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T13-43-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e246bdb10>";0,00100000004749745;"Experiment.R";2024-03-14 13:43:36.74977;2024-03-14 13:43:46.01319;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-43-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-43-22Z";4,6121;1,6468;8,2686;2,3412;64;32;16;8;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T13-43-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e22f41120>";0,00100000004749745;"Experiment.R";2024-03-14 13:43:23.25569;2024-03-14 13:43:36.21848;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-43-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-43-04Z";5,9321;1,8365;7,3179;2,2129;32;32;16;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T13-43-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e24a4abf0>";0,00100000004749745;"Experiment.R";2024-03-14 13:43:05.70582;2024-03-14 13:43:22.72493;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-43-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-42-47Z";4,7741;1,6655;7,6797;2,2383;64;16;16;8;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T13-42-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e24aea020>";0,00100000004749745;"Experiment.R";2024-03-14 13:42:47.93428;2024-03-14 13:43:04.77534;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-42-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-42-23Z";4,776;1,6712;7,8428;2,2702;32;16;16;8;0,1;0,3;0,2;0,1;32;50;47;"runs/2024-03-14T13-42-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e24d2d270>";0,00100000004749745;"Experiment.R";2024-03-14 13:42:23.79526;2024-03-14 13:42:47.39827;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-42-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-42-10Z";4,2276;1,5677;8,3688;2,3252;64;32;8;8;0,1;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T13-42-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e24f32f20>";0,00100000004749745;"Experiment.R";2024-03-14 13:42:10.68586;2024-03-14 13:42:23.26903;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-42-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-41-58Z";4,565;1,6165;7,283;2,2004;32;32;8;8;0,1;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T13-41-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25281db0>";0,00100000004749745;"Experiment.R";2024-03-14 13:41:58.53382;2024-03-14 13:42:10.16511;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-41-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-41-47Z";5,2961;1,7246;7,5619;2,2256;64;16;8;8;0,1;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T13-41-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25513e80>";0,00100000004749745;"Experiment.R";2024-03-14 13:41:48.29298;2024-03-14 13:41:58.0355;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-41-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-41-37Z";5,3401;1,7528;7,7557;2,256;32;16;8;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T13-41-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e255d5cc0>";0,00100000004749745;"Experiment.R";2024-03-14 13:41:37.53908;2024-03-14 13:41:47.76178;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-41-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-41-27Z";5,4129;1,7531;7,8217;2,2842;64;32;16;4;0,1;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T13-41-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e2578efb0>";0,00100000004749745;"Experiment.R";2024-03-14 13:41:28.09765;2024-03-14 13:41:37.01142;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-41-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-41-18Z";5,3187;1,7347;7,96;2,2693;32;32;16;4;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T13-41-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25aa34c0>";0,00100000004749745;"Experiment.R";2024-03-14 13:41:19.29563;2024-03-14 13:41:27.46911;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-41-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-41-08Z";5,0174;1,686;9,4841;2,4886;64;16;16;4;0,1;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T13-41-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25b4d570>";0,00100000004749745;"Experiment.R";2024-03-14 13:41:09.30448;2024-03-14 13:41:18.78087;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-41-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-40-59Z";5,5634;1,8132;7,0701;2,1635;32;16;16;4;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T13-40-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25d45c90>";0,00100000004749745;"Experiment.R";2024-03-14 13:40:59.65934;2024-03-14 13:41:08.79845;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-40-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-40-46Z";5,5671;1,765;8,3251;2,3277;64;32;8;4;0,1;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T13-40-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25dc5210>";0,00100000004749745;"Experiment.R";2024-03-14 13:40:47.2288;2024-03-14 13:40:59.14693;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-40-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-40-39Z";6,8601;1,9293;8,3097;2,3551;32;32;8;4;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T13-40-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e261bed70>";0,00100000004749745;"Experiment.R";2024-03-14 13:40:40.16818;2024-03-14 13:40:46.70407;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-40-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-40-26Z";5,3049;1,7481;7,26;2,1978;64;16;8;4;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T13-40-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e264621a0>";0,00100000004749745;"Experiment.R";2024-03-14 13:40:26.7181;2024-03-14 13:40:39.64705;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-40-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-40-03Z";5,7388;1,8224;7,051;2,1852;32;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-40-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e266a9360>";0,00100000004749745;"Experiment.R";2024-03-14 13:40:04.09735;2024-03-14 13:40:26.18807;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-40-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-39-54Z";4,7439;1,6464;8,0798;2,2894;64;32;16;8;0,1;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T13-39-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e266be740>";0,00100000004749745;"Experiment.R";2024-03-14 13:39:54.95695;2024-03-14 13:40:03.58619;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-39-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-39-44Z";5,3816;1,7654;8,1722;2,3295;32;32;16;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T13-39-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e25f11f30>";0,00100000004749745;"Experiment.R";2024-03-14 13:39:45.28773;2024-03-14 13:39:54.45779;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-39-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-39-36Z";5,554;1,7894;8,3338;2,3423;64;16;16;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T13-39-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e269b2350>";0,00100000004749745;"Experiment.R";2024-03-14 13:39:37.43343;2024-03-14 13:39:44.77224;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-39-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-39-26Z";4,6601;1,6326;9,0701;2,4455;32;16;16;8;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T13-39-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e26c01d80>";0,00100000004749745;"Experiment.R";2024-03-14 13:39:26.96958;2024-03-14 13:39:36.91565;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-39-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-38-59Z";4,4961;1,5964;8,5077;2,3633;64;32;8;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-38-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5ed28d00>";0,00100000004749745;"Experiment.R";2024-03-14 13:39:00.05395;2024-03-14 13:39:26.47485;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-38-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-38-52Z";5,7834;1,8311;8,426;2,3627;32;32;8;8;0,1;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T13-38-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40555c30>";0,00100000004749745;"Experiment.R";2024-03-14 13:38:53.0876;2024-03-14 13:38:59.20506;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-38-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-38-44Z";5,6403;1,797;8,4837;2,3512;64;16;8;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T13-38-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f0268f0>";0,00100000004749745;"Experiment.R";2024-03-14 13:38:44.87875;2024-03-14 13:38:52.57022;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-38-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-38-32Z";4,7345;1,668;7,9519;2,2778;32;16;8;8;0,1;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T13-38-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e0bf040>";0,00100000004749745;"Experiment.R";2024-03-14 13:38:33.05015;2024-03-14 13:38:44.36808;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-38-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-38-26Z";5,7128;1,8341;7,5837;2,2489;64;32;16;4;0,1;0,3;0,2;0,1;32;50;13;"runs/2024-03-14T13-38-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e602081c0>";0,00100000004749745;"Experiment.R";2024-03-14 13:38:27.2424;2024-03-14 13:38:32.40248;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-38-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-38-07Z";6,0445;1,8386;7,0647;2,1781;32;32;16;4;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T13-38-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e405a2140>";0,00100000004749745;"Experiment.R";2024-03-14 13:38:08.18556;2024-03-14 13:38:26.72817;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-38-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-37-54Z";4,6395;1,6244;7,6169;2,2393;64;16;16;4;0,1;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T13-37-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3eb2eef0>";0,00100000004749745;"Experiment.R";2024-03-14 13:37:54.87344;2024-03-14 13:38:07.68692;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-37-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-37-46Z";5,8718;1,8323;7,3688;2,2222;32;16;16;4;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T13-37-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3cef3130>";0,00100000004749745;"Experiment.R";2024-03-14 13:37:46.71701;2024-03-14 13:37:54.36593;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-37-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-37-30Z";5,3225;1,7143;7,3832;2,2038;64;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-37-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3d96dae0>";0,00100000004749745;"Experiment.R";2024-03-14 13:37:30.57535;2024-03-14 13:37:46.14327;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-37-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-37-14Z";5,2441;1,7277;7,2686;2,2083;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-37-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42097220>";0,00100000004749745;"Experiment.R";2024-03-14 13:37:15.07841;2024-03-14 13:37:30.00639;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-37-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-36-59Z";4,6939;1,653;7,3617;2,1989;64;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-36-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0554e20>";0,00100000004749745;"Experiment.R";2024-03-14 13:36:59.71612;2024-03-14 13:37:14.53939;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-36-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-36-42Z";5,3198;1,7489;8,2491;2,3378;32;16;8;4;0,1;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T13-36-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e471c7910>";0,00100000004749745;"Experiment.R";2024-03-14 13:36:42.95117;2024-03-14 13:36:59.1953;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-36-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-36-25Z";5,1287;1,729;9,6726;2,5311;64;32;16;8;0,1;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T13-36-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4907d9f0>";0,00100000004749745;"Experiment.R";2024-03-14 13:36:26.22401;2024-03-14 13:36:42.09659;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-36-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-36-08Z";4,8668;1,6839;6,6504;2,0944;32;32;16;8;0,1;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T13-36-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a77a140>";0,00100000004749745;"Experiment.R";2024-03-14 13:36:08.97094;2024-03-14 13:36:25.70253;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-36-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-36-00Z";5,4023;1,7887;9,03;2,4422;64;16;16;8;0,1;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T13-36-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69867730>";0,00100000004749745;"Experiment.R";2024-03-14 13:36:01.1628;2024-03-14 13:36:08.46139;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-36-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-35-50Z";5,0954;1,7204;7,6272;2,2487;32;16;16;8;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T13-35-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e765e94e0>";0,00100000004749745;"Experiment.R";2024-03-14 13:35:51.27535;2024-03-14 13:36:00.65749;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-35-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-35-27Z";4,7364;1,6369;8,3234;2,3328;64;32;8;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T13-35-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3c909ba0>";0,00100000004749745;"Experiment.R";2024-03-14 13:35:27.56296;2024-03-14 13:35:50.7793;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-35-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-35-14Z";5,4517;1,7698;8,2579;2,3417;32;32;8;8;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T13-35-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f615720>";0,00100000004749745;"Experiment.R";2024-03-14 13:35:15.28449;2024-03-14 13:35:27.03889;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-35-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-35-01Z";4,9114;1,684;8,5725;2,354;64;16;8;8;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T13-35-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e413aafe0>";0,00100000004749745;"Experiment.R";2024-03-14 13:35:02.08395;2024-03-14 13:35:14.78391;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-35-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-34-50Z";5,4631;1,7646;7,4381;2,2201;32;16;8;8;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T13-34-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e420aded0>";0,00100000004749745;"Experiment.R";2024-03-14 13:34:50.50759;2024-03-14 13:35:01.53811;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-34-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-34-31Z";5,121;1,7034;8,8254;2,3966;64;32;16;4;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T13-34-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42f81f60>";0,00100000004749745;"Experiment.R";2024-03-14 13:34:32.42104;2024-03-14 13:34:50.00208;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-34-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-34-19Z";5,1751;1,726;7,1066;2,176;32;32;16;4;0,1;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T13-34-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e595f9120>";0,00100000004749745;"Experiment.R";2024-03-14 13:34:19.79064;2024-03-14 13:34:31.93948;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-34-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-34-01Z";6,3291;1,8661;9,0765;2,4377;64;16;16;4;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T13-34-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e49b7d750>";0,00100000004749745;"Experiment.R";2024-03-14 13:34:02.27745;2024-03-14 13:34:19.31595;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-34-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-33-47Z";5,0605;1,7047;8,3355;2,3125;32;16;16;4;0,1;0,3;0,2;0,1;32;50;45;"runs/2024-03-14T13-33-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4afdd2d0>";0,00100000004749745;"Experiment.R";2024-03-14 13:33:48.43631;2024-03-14 13:34:01.78988;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-33-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-33-35Z";5,2492;1,7265;7,4232;2,2064;64;32;8;4;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T13-33-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4bc4bc70>";0,00100000004749745;"Experiment.R";2024-03-14 13:33:36.43501;2024-03-14 13:33:47.94065;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-33-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-33-17Z";5,766;1,8217;7,6219;2,2383;32;32;8;4;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T13-33-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e473ab460>";0,00100000004749745;"Experiment.R";2024-03-14 13:33:17.63884;2024-03-14 13:33:35.92657;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-33-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-33-03Z";5,2148;1,7028;8,1014;2,3235;64;16;8;4;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T13-33-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e468f70d0>";0,00100000004749745;"Experiment.R";2024-03-14 13:33:04.18932;2024-03-14 13:33:17.1338;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-33-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-32-51Z";5,5527;1,7782;7,9125;2,2865;32;16;8;4;0,1;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T13-32-51Z/tfruns.d/metrics.json";"Model: ""sequential_1""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_6 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_5 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_4 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_3 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense_2 (Dense)                    (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a9bf1f0>";0,00100000004749745;"Experiment.R";2024-03-14 13:32:52.02714;2024-03-14 13:33:03.66659;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-32-51Z/tfruns.d/source.tar.gz";"local";"training"
