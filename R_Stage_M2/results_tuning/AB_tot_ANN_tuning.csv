"run_dir";"metric_loss";"metric_mae";"metric_val_loss";"metric_val_mae";"flag_dense_units1";"flag_dense_units2";"flag_dense_units3";"flag_dense_units4";"flag_dropout1";"flag_dropout2";"flag_dropout3";"flag_dropout4";"flag_batch_size";"epochs";"epochs_completed";"metrics";"model";"loss_function";"optimizer";"learning_rate";"script";"start";"end";"completed";"output";"source_code";"context";"type"
"runs/2024-03-14T11-15-55Z";53,7522;5,776;31,9577;4,3338;64;32;16;8;0,2;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T11-15-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e58bd7ac0>";0,00100000004749745;"Experiment.R";2024-03-14 11:15:55.4153;2024-03-14 11:16:00.16218;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-15-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-15-44Z";52,1995;5,7086;32,6296;4,4137;32;32;16;8;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T11-15-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e58ddf0a0>";0,00100000004749745;"Experiment.R";2024-03-14 11:15:45.01764;2024-03-14 11:15:55.00918;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-15-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-15-34Z";51,4083;5,6097;32,096;4,2552;64;16;16;8;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T11-15-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5841f5e0>";0,00100000004749745;"Experiment.R";2024-03-14 11:15:34.49988;2024-03-14 11:15:44.61309;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-15-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-15-26Z";48,4694;5,4576;32,1589;4,3379;32;16;16;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T11-15-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e58ea1240>";0,00100000004749745;"Experiment.R";2024-03-14 11:15:26.61811;2024-03-14 11:15:34.22537;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-15-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-15-16Z";50,3313;5,5519;39,253;4,7224;64;32;8;8;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T11-15-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e591ab3a0>";0,00100000004749745;"Experiment.R";2024-03-14 11:15:16.76123;2024-03-14 11:15:26.3601;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-15-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-15-09Z";48,638;5,4668;32,7779;4,3576;32;32;8;8;0,2;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T11-15-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e593dd870>";0,00100000004749745;"Experiment.R";2024-03-14 11:15:09.53691;2024-03-14 11:15:16.32416;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-15-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-15-02Z";51,3481;5,6706;36,2891;4,5405;64;16;8;8;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T11-15-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59427010>";0,00100000004749745;"Experiment.R";2024-03-14 11:15:02.95469;2024-03-14 11:15:09.26488;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-15-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-14-56Z";53,5622;5,8004;31,898;4,3055;32;16;8;8;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T11-14-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5964bbe0>";0,00100000004749745;"Experiment.R";2024-03-14 11:14:56.98171;2024-03-14 11:15:02.69622;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-14-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-14-50Z";53,8515;5,7191;32,7022;4,4132;64;32;16;4;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T11-14-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e58fd4e80>";0,00100000004749745;"Experiment.R";2024-03-14 11:14:51.19222;2024-03-14 11:14:56.70907;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-14-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-14-45Z";52,9825;5,7152;31,4917;4,4004;32;32;16;4;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T11-14-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e599cb8e0>";0,00100000004749745;"Experiment.R";2024-03-14 11:14:46.15567;2024-03-14 11:14:50.80312;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-14-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-14-34Z";52,1957;5,6641;33,1428;4,4104;64;16;16;4;0,2;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T11-14-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59a2ce80>";0,00100000004749745;"Experiment.R";2024-03-14 11:14:35.12138;2024-03-14 11:14:45.88927;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-14-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-14-23Z";53,1766;5,7441;30,7931;4,2785;32;16;16;4;0,2;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T11-14-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59c23f40>";0,00100000004749745;"Experiment.R";2024-03-14 11:14:23.42986;2024-03-14 11:14:34.87305;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-14-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-14-16Z";56,6077;5,9189;30,7704;4,221;64;32;8;4;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T11-14-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59ea2050>";0,00100000004749745;"Experiment.R";2024-03-14 11:14:16.64439;2024-03-14 11:14:23.1627;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-14-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-14-08Z";67,6192;6,3197;31,7722;4,2078;32;32;8;4;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T11-14-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a0e5480>";0,00100000004749745;"Experiment.R";2024-03-14 11:14:08.59359;2024-03-14 11:14:16.24011;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-14-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-14-02Z";59,7753;5,9716;41,788;4,8751;64;16;8;4;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T11-14-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a1ee770>";0,00100000004749745;"Experiment.R";2024-03-14 11:14:02.22494;2024-03-14 11:14:08.33794;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-14-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-13-53Z";61,5369;6,0393;32,446;4,2877;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T11-13-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a22b970>";0,00100000004749745;"Experiment.R";2024-03-14 11:13:53.29086;2024-03-14 11:14:01.97935;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-13-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-13-45Z";49,4513;5,4882;31,5944;4,3039;64;32;16;8;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T11-13-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e606b57b0>";0,00100000004749745;"Experiment.R";2024-03-14 11:13:45.52988;2024-03-14 11:13:53.04567;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-13-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-13-40Z";50,6038;5,6212;30,9989;4,2099;32;32;16;8;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T11-13-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61e10f10>";0,00100000004749745;"Experiment.R";2024-03-14 11:13:40.35434;2024-03-14 11:13:45.28651;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-13-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-13-32Z";52,6197;5,6767;31,8463;4,2849;64;16;16;8;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T11-13-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60bacca0>";0,00100000004749745;"Experiment.R";2024-03-14 11:13:33.15304;2024-03-14 11:13:39.95713;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-13-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-13-27Z";51,3175;5,6406;33,6581;4,4823;32;16;16;8;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T11-13-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60b667a0>";0,00100000004749745;"Experiment.R";2024-03-14 11:13:28.16335;2024-03-14 11:13:32.91508;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-13-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-13-16Z";50,6173;5,5843;37,6111;4,5982;64;32;8;8;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T11-13-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63ac6620>";0,00100000004749745;"Experiment.R";2024-03-14 11:13:17.15937;2024-03-14 11:13:27.77185;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-13-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-13-10Z";54,34;5,7268;31,0032;4,296;32;32;8;8;0,2;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T11-13-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63cbbdc0>";0,00100000004749745;"Experiment.R";2024-03-14 11:13:10.8249;2024-03-14 11:13:16.91216;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-13-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-13-03Z";54,1131;5,7749;36,7655;4,5836;64;16;8;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T11-13-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63d40400>";0,00100000004749745;"Experiment.R";2024-03-14 11:13:04.07703;2024-03-14 11:13:10.58717;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-13-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-12-54Z";50,6993;5,5522;32,4631;4,3184;32;16;8;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T11-12-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63f730d0>";0,00100000004749745;"Experiment.R";2024-03-14 11:12:54.65313;2024-03-14 11:13:03.67681;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-12-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-12-49Z";66,9306;6,3092;34,601;4,4154;64;32;16;4;0,2;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T11-12-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60c6ea10>";0,00100000004749745;"Experiment.R";2024-03-14 11:12:49.63467;2024-03-14 11:12:54.40782;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-12-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-12-40Z";205,5319;12,5213;158,1742;10,5731;32;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T11-12-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60faff10>";0,00100000004749745;"Experiment.R";2024-03-14 11:12:40.57834;2024-03-14 11:12:49.3891;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-12-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-12-30Z";63,4567;6,1282;34,687;4,5582;64;16;16;4;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T11-12-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61038f10>";0,00100000004749745;"Experiment.R";2024-03-14 11:12:31.09964;2024-03-14 11:12:40.31747;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-12-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-12-23Z";61,8114;6,0949;33,9137;4,521;32;16;16;4;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T11-12-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e615d1ea0>";0,00100000004749745;"Experiment.R";2024-03-14 11:12:23.35225;2024-03-14 11:12:30.85358;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-12-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-12-16Z";66,0853;6,2108;34,314;4,4238;64;32;8;4;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T11-12-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61823250>";0,00100000004749745;"Experiment.R";2024-03-14 11:12:16.26313;2024-03-14 11:12:23.10847;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-12-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-12-09Z";57,4532;5,9265;32,6705;4,3296;32;32;8;4;0,2;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T11-12-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61a64520>";0,00100000004749745;"Experiment.R";2024-03-14 11:12:09.86673;2024-03-14 11:12:16.02214;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-12-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-12-04Z";58,8034;6,0396;29,8455;4,2217;64;16;8;4;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T11-12-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61a47c70>";0,00100000004749745;"Experiment.R";2024-03-14 11:12:04.75161;2024-03-14 11:12:09.63127;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-12-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-11-58Z";58,6786;5,9676;33,7496;4,4902;32;16;8;4;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T11-11-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61c47f10>";0,00100000004749745;"Experiment.R";2024-03-14 11:11:58.61693;2024-03-14 11:12:04.50706;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-11-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-11-53Z";52,032;5,6313;29,7773;4,2043;64;32;16;8;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T11-11-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e620b7c70>";0,00100000004749745;"Experiment.R";2024-03-14 11:11:53.8464;2024-03-14 11:11:58.38074;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-11-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-11-45Z";51,8336;5,665;29,9852;4,2313;32;32;16;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T11-11-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e622aff10>";0,00100000004749745;"Experiment.R";2024-03-14 11:11:45.48538;2024-03-14 11:11:53.61488;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-11-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-11-39Z";49,3967;5,5;31,4175;4,2843;64;16;16;8;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T11-11-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62331120>";0,00100000004749745;"Experiment.R";2024-03-14 11:11:40.18114;2024-03-14 11:11:45.24919;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-11-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-11-31Z";50,4482;5,507;32,9603;4,4483;32;16;16;8;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T11-11-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6254a3b0>";0,00100000004749745;"Experiment.R";2024-03-14 11:11:31.87449;2024-03-14 11:11:39.94723;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-11-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-11-25Z";49,7977;5,5117;33,5697;4,4759;64;32;8;8;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T11-11-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61d87a30>";0,00100000004749745;"Experiment.R";2024-03-14 11:11:26.27445;2024-03-14 11:11:31.63508;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-11-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-11-18Z";53,884;5,7272;32,2646;4,3335;32;32;8;8;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T11-11-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61e11270>";0,00100000004749745;"Experiment.R";2024-03-14 11:11:18.23818;2024-03-14 11:11:25.90167;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-11-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-11-12Z";56,0981;5,8048;37,8069;4,6181;64;16;8;8;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T11-11-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e785f5ae0>";0,00100000004749745;"Experiment.R";2024-03-14 11:11:12.90842;2024-03-14 11:11:18.00492;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-11-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-11-06Z";58,7524;6,0526;32,7423;4,3452;32;16;8;8;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T11-11-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6293cca0>";0,00100000004749745;"Experiment.R";2024-03-14 11:11:06.58443;2024-03-14 11:11:12.29583;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-11-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-10-57Z";64,9474;6,1826;32,5326;4,2943;64;32;16;4;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T11-10-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62ad7310>";0,00100000004749745;"Experiment.R";2024-03-14 11:10:57.61248;2024-03-14 11:11:06.33576;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-10-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-10-51Z";49,2457;5,4921;31,0315;4,2607;32;32;16;4;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-10-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61212500>";0,00100000004749745;"Experiment.R";2024-03-14 11:10:51.85909;2024-03-14 11:10:57.37126;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-10-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-10-43Z";57,5632;5,9688;31,4071;4,2617;64;16;16;4;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T11-10-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62e8f220>";0,00100000004749745;"Experiment.R";2024-03-14 11:10:43.35506;2024-03-14 11:10:51.61876;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-10-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-10-34Z";56,5476;5,8642;29,5668;4,1658;32;16;16;4;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T11-10-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63072500>";0,00100000004749745;"Experiment.R";2024-03-14 11:10:34.23527;2024-03-14 11:10:43.11337;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-10-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-10-27Z";53,7026;5,6318;32,6402;4,2953;64;32;8;4;0,2;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T11-10-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e632e3220>";0,00100000004749745;"Experiment.R";2024-03-14 11:10:27.56438;2024-03-14 11:10:34.00229;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-10-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-10-19Z";59,2832;5,9816;31,5303;4,3502;32;32;8;4;0,2;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T11-10-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63507340>";0,00100000004749745;"Experiment.R";2024-03-14 11:10:19.45563;2024-03-14 11:10:27.31698;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-10-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-10-09Z";57,5992;5,905;30,862;4,1926;64;16;8;4;0,2;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T11-10-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62b53e50>";0,00100000004749745;"Experiment.R";2024-03-14 11:10:09.63059;2024-03-14 11:10:19.21896;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-10-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-59Z";56,7069;5,8733;32,3976;4,3201;32;16;8;4;0,2;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T11-09-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e635f5180>";0,00100000004749745;"Experiment.R";2024-03-14 11:10:00.20901;2024-03-14 11:10:09.38777;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-53Z";54,6877;5,7685;29,3088;4,2594;64;32;16;8;0,2;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T11-09-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6362f250>";0,00100000004749745;"Experiment.R";2024-03-14 11:09:54.04253;2024-03-14 11:09:59.96615;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-48Z";54,2889;5,7795;30,0952;4,1951;32;32;16;8;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T11-09-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6418bb20>";0,00100000004749745;"Experiment.R";2024-03-14 11:09:48.53025;2024-03-14 11:09:53.80673;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-43Z";50,3627;5,5058;35,4149;4,5034;64;16;16;8;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T11-09-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6432acb0>";0,00100000004749745;"Experiment.R";2024-03-14 11:09:43.4725;2024-03-14 11:09:48.29201;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-35Z";56,5241;5,8171;38,7838;4,7617;32;16;16;8;0,2;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T11-09-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e64442110>";0,00100000004749745;"Experiment.R";2024-03-14 11:09:35.84404;2024-03-14 11:09:43.23997;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-30Z";59,1461;5,9915;32,4019;4,3587;64;32;8;8;0,2;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T11-09-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69a373d0>";0,00100000004749745;"Experiment.R";2024-03-14 11:09:30.86156;2024-03-14 11:09:35.61081;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-21Z";46,3963;5,3725;34,0778;4,4422;32;32;8;8;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T11-09-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e75c80040>";0,00100000004749745;"Experiment.R";2024-03-14 11:09:21.64808;2024-03-14 11:09:30.6121;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-16Z";58,3402;5,9454;34,7378;4,4415;64;16;8;8;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T11-09-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77c60940>";0,00100000004749745;"Experiment.R";2024-03-14 11:09:16.30942;2024-03-14 11:09:21.40364;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-09Z";55,031;5,7602;35,2172;4,4381;32;16;8;8;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-09-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78f2bc70>";0,00100000004749745;"Experiment.R";2024-03-14 11:09:09.75646;2024-03-14 11:09:16.0816;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-09-02Z";54,2676;5,6588;30,1431;4,2603;64;32;16;4;0,2;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T11-09-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e693f5810>";0,00100000004749745;"Experiment.R";2024-03-14 11:09:02.73153;2024-03-14 11:09:09.52689;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-09-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-08-57Z";56,0184;5,8693;31,1323;4,2224;32;32;16;4;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T11-08-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e65a9e020>";0,00100000004749745;"Experiment.R";2024-03-14 11:08:57.2105;2024-03-14 11:09:02.50734;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-08-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-08-49Z";68,6601;6,369;37,1746;4,6048;64;16;16;4;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T11-08-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e97924dc0>";0,00100000004749745;"Experiment.R";2024-03-14 11:08:50.06625;2024-03-14 11:08:56.96717;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-08-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-08-43Z";55,813;5,8704;31,0346;4,2674;32;16;16;4;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T11-08-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7690abf0>";0,00100000004749745;"Experiment.R";2024-03-14 11:08:44.01396;2024-03-14 11:08:49.69317;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-08-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-08-36Z";53,7862;5,7152;32,7413;4,3418;64;32;8;4;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T11-08-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e815fe1a0>";0,00100000004749745;"Experiment.R";2024-03-14 11:08:37.29317;2024-03-14 11:08:43.77501;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-08-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-08-32Z";64,0177;6,2355;34,0141;4,3681;32;32;8;4;0,2;0,3;0,2;0,1;64;50;19;"runs/2024-03-14T11-08-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6642bd90>";0,00100000004749745;"Experiment.R";2024-03-14 11:08:32.42881;2024-03-14 11:08:36.90526;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-08-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-08-24Z";53,205;5,6686;30,1675;4,1718;64;16;8;4;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T11-08-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e650e1db0>";0,00100000004749745;"Experiment.R";2024-03-14 11:08:24.41015;2024-03-14 11:08:32.19765;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-08-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-08-14Z";64,9615;6,3096;32,6064;4,3069;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T11-08-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67e60790>";0,00100000004749745;"Experiment.R";2024-03-14 11:08:14.23903;2024-03-14 11:08:24.04351;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-08-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-08-08Z";51,1925;5,6533;29,5442;4,2412;64;32;16;8;0,2;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T11-08-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67b97010>";0,00100000004749745;"Experiment.R";2024-03-14 11:08:09.11191;2024-03-14 11:08:13.98226;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-08-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-08-02Z";49,0712;5,5107;29,6378;4,2536;32;32;16;8;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-08-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e82fabeb0>";0,00100000004749745;"Experiment.R";2024-03-14 11:08:02.28642;2024-03-14 11:08:08.8798;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-08-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-07-56Z";55,3343;5,8149;34,2004;4,4463;64;16;16;8;0,2;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T11-07-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77c33a00>";0,00100000004749745;"Experiment.R";2024-03-14 11:07:56.95626;2024-03-14 11:08:02.03974;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-07-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-07-50Z";47,868;5,4521;36,3766;4,6259;32;16;16;8;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-07-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7bfcb700>";0,00100000004749745;"Experiment.R";2024-03-14 11:07:50.31266;2024-03-14 11:07:56.71562;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-07-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-07-43Z";59,4621;5,967;38,1423;4,6526;64;32;8;8;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T11-07-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d1b9f90>";0,00100000004749745;"Experiment.R";2024-03-14 11:07:44.0116;2024-03-14 11:07:50.06853;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-07-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-07-37Z";49,7066;5,5367;33,0548;4,3988;32;32;8;8;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T11-07-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e71959e70>";0,00100000004749745;"Experiment.R";2024-03-14 11:07:37.71453;2024-03-14 11:07:43.77261;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-07-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-07-21Z";46,9082;5,4177;30,4212;4,1855;64;16;8;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T11-07-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6517e1a0>";0,00100000004749745;"Experiment.R";2024-03-14 11:07:21.30481;2024-03-14 11:07:37.30351;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-07-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-07-13Z";58,7075;6,0023;30,1824;4,1835;32;16;8;8;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T11-07-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e653c3df0>";0,00100000004749745;"Experiment.R";2024-03-14 11:07:13.82394;2024-03-14 11:07:21.06842;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-07-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-07-06Z";69,787;6,3582;34,3017;4,426;64;32;16;4;0,2;0,3;0,2;0,1;64;50;19;"runs/2024-03-14T11-07-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e654331c0>";0,00100000004749745;"Experiment.R";2024-03-14 11:07:07.09979;2024-03-14 11:07:13.44643;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-07-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-07-02Z";54,1169;5,7432;31,2794;4,3784;32;32;16;4;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T11-07-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6583fdf0>";0,00100000004749745;"Experiment.R";2024-03-14 11:07:02.43169;2024-03-14 11:07:06.86644;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-07-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-06-55Z";57,0792;5,918;32,8881;4,3245;64;16;16;4;0,2;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T11-06-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e65a9f1c0>";0,00100000004749745;"Experiment.R";2024-03-14 11:06:55.39011;2024-03-14 11:07:02.17484;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-06-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-06-49Z";58,6627;6,0089;31,709;4,3123;32;16;16;4;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T11-06-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e65cf7dc0>";0,00100000004749745;"Experiment.R";2024-03-14 11:06:49.66003;2024-03-14 11:06:55.15413;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-06-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-06-43Z";59,2027;5,9369;32,4107;4,2879;64;32;8;4;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T11-06-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e650cfee0>";0,00100000004749745;"Experiment.R";2024-03-14 11:06:44.08317;2024-03-14 11:06:49.28287;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-06-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-06-37Z";57,6772;5,9163;32,3802;4,4404;32;32;8;4;0,2;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T11-06-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e65fbd750>";0,00100000004749745;"Experiment.R";2024-03-14 11:06:37.80556;2024-03-14 11:06:43.8463;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-06-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-06-28Z";57,805;5,9623;31,9977;4,3262;64;16;8;4;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T11-06-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e66442470>";0,00100000004749745;"Experiment.R";2024-03-14 11:06:28.37925;2024-03-14 11:06:37.42351;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-06-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-06-20Z";54,742;5,7073;30,0184;4,2374;32;16;8;4;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T11-06-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e650ce5f0>";0,00100000004749745;"Experiment.R";2024-03-14 11:06:20.4999;2024-03-14 11:06:28.13886;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-06-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-06-12Z";55,064;5,814;32,9405;4,3325;64;32;16;8;0,2;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T11-06-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e650e0040>";0,00100000004749745;"Experiment.R";2024-03-14 11:06:13.1565;2024-03-14 11:06:20.27572;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-06-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-06-08Z";51,5194;5,7111;32,7982;4,5205;32;32;16;8;0,2;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T11-06-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6617ca60>";0,00100000004749745;"Experiment.R";2024-03-14 11:06:08.62784;2024-03-14 11:06:12.78763;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-06-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-06-02Z";55,7145;5,8278;31,7084;4,3102;64;16;16;8;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-06-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6499aad0>";0,00100000004749745;"Experiment.R";2024-03-14 11:06:02.85376;2024-03-14 11:06:08.40269;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-06-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-05-56Z";51,4968;5,6751;34,5273;4,4368;32;16;16;8;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-05-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e64a20a60>";0,00100000004749745;"Experiment.R";2024-03-14 11:05:56.33716;2024-03-14 11:06:02.59732;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-05-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-05-49Z";53,3727;5,7144;34,7756;4,4382;64;32;8;8;0,2;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T11-05-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e66443220>";0,00100000004749745;"Experiment.R";2024-03-14 11:05:49.78007;2024-03-14 11:05:56.10901;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-05-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-05-43Z";54,1069;5,8202;32,6575;4,3883;32;32;8;8;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T11-05-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e70bee650>";0,00100000004749745;"Experiment.R";2024-03-14 11:05:44.10385;2024-03-14 11:05:49.3977;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-05-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-05-39Z";56,3357;5,8281;32,6042;4,3673;64;16;8;8;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T11-05-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e70c5f310>";0,00100000004749745;"Experiment.R";2024-03-14 11:05:39.38039;2024-03-14 11:05:43.8874;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-05-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-05-30Z";52,724;5,6781;34,8146;4,4732;32;16;8;8;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-05-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e70e93b50>";0,00100000004749745;"Experiment.R";2024-03-14 11:05:30.77747;2024-03-14 11:05:39.15332;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-05-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-05-22Z";58,7859;5,9631;33,1036;4,4914;64;32;16;4;0,2;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T11-05-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e70f34400>";0,00100000004749745;"Experiment.R";2024-03-14 11:05:22.78128;2024-03-14 11:05:30.55588;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-05-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-05-14Z";48,4904;5,4507;28,7374;4,1525;32;32;16;4;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T11-05-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e71295270>";0,00100000004749745;"Experiment.R";2024-03-14 11:05:15.11495;2024-03-14 11:05:22.54801;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-05-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-05-08Z";60,8401;6,1132;33,4366;4,3294;64;16;16;4;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T11-05-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7155a320>";0,00100000004749745;"Experiment.R";2024-03-14 11:05:08.79577;2024-03-14 11:05:14.89475;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-05-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-04-58Z";64,026;6,2077;35,1577;4,5074;32;16;16;4;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-04-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e716660b0>";0,00100000004749745;"Experiment.R";2024-03-14 11:04:58.4535;2024-03-14 11:05:08.55988;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-04-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-04-51Z";51,5183;5,5957;30,4393;4,242;64;32;8;4;0,2;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T11-04-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e71ac3940>";0,00100000004749745;"Experiment.R";2024-03-14 11:04:51.64355;2024-03-14 11:04:58.22969;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-04-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-04-38Z";57,9904;6,0055;31,1654;4,2783;32;32;8;4;0,2;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T11-04-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7860b2e0>";0,00100000004749745;"Experiment.R";2024-03-14 11:04:38.49744;2024-03-14 11:04:51.42363;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-04-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-04-30Z";56,8118;5,8049;32,1191;4,2959;64;16;8;4;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T11-04-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77450580>";0,00100000004749745;"Experiment.R";2024-03-14 11:04:31.04948;2024-03-14 11:04:38.13601;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-04-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-04-23Z";60,9659;6,0921;31,9797;4,3276;32;16;8;4;0,2;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T11-04-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77e71810>";0,00100000004749745;"Experiment.R";2024-03-14 11:04:23.84655;2024-03-14 11:04:30.83095;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-04-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-04-13Z";52,7355;5,6787;31,3296;4,2521;64;32;16;8;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T11-04-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e75313880>";0,00100000004749745;"Experiment.R";2024-03-14 11:04:13.84348;2024-03-14 11:04:23.61899;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-04-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-04-06Z";50,0353;5,5832;28,9328;4,178;32;32;16;8;0,2;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T11-04-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e73b563e0>";0,00100000004749745;"Experiment.R";2024-03-14 11:04:06.40648;2024-03-14 11:04:13.48386;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-04-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-03-58Z";54,891;5,7482;29,6518;4,1417;64;16;16;8;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T11-03-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76bb4c40>";0,00100000004749745;"Experiment.R";2024-03-14 11:03:59.04827;2024-03-14 11:04:06.18681;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-03-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-03-53Z";52,9861;5,6804;34,2992;4,5424;32;16;16;8;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T11-03-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e74e90190>";0,00100000004749745;"Experiment.R";2024-03-14 11:03:54.0941;2024-03-14 11:03:58.80784;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-03-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-03-43Z";58,3073;5,9435;32,6533;4,3951;64;32;8;8;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T11-03-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6bae5150>";0,00100000004749745;"Experiment.R";2024-03-14 11:03:43.65328;2024-03-14 11:03:53.86917;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-03-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-03-34Z";53,7719;5,7025;37,2875;4,628;32;32;8;8;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T11-03-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76126ef0>";0,00100000004749745;"Experiment.R";2024-03-14 11:03:34.86843;2024-03-14 11:03:43.43281;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-03-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-03-29Z";58,9426;5,9697;34,2627;4,4582;64;16;8;8;0,2;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T11-03-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6dca6080>";0,00100000004749745;"Experiment.R";2024-03-14 11:03:29.18699;2024-03-14 11:03:34.64566;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-03-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-03-21Z";55,7051;5,8051;42,2442;4,9499;32;16;8;8;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T11-03-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d7867a0>";0,00100000004749745;"Experiment.R";2024-03-14 11:03:21.83161;2024-03-14 11:03:28.96283;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-03-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-03-16Z";52,8425;5,7665;29,4118;4,1958;64;32;16;4;0,2;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T11-03-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79af4490>";0,00100000004749745;"Experiment.R";2024-03-14 11:03:16.6278;2024-03-14 11:03:21.61128;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-03-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-03-10Z";53,8217;5,7519;31,4894;4,3532;32;32;16;4;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T11-03-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6e187e80>";0,00100000004749745;"Experiment.R";2024-03-14 11:03:10.93496;2024-03-14 11:03:16.41964;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-03-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-03-02Z";54,7243;5,7576;30,887;4,2448;64;16;16;4;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T11-03-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e3595a0>";0,00100000004749745;"Experiment.R";2024-03-14 11:03:02.38328;2024-03-14 11:03:10.713;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-03-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-02-49Z";60,9635;6,0583;32,4115;4,3782;32;16;16;4;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T11-02-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f7e5510>";0,00100000004749745;"Experiment.R";2024-03-14 11:02:49.59354;2024-03-14 11:03:02.02853;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-02-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-02-42Z";53,5892;5,7045;31,0462;4,2753;64;32;8;4;0,2;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T11-02-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e1584f0>";0,00100000004749745;"Experiment.R";2024-03-14 11:02:43.0161;2024-03-14 11:02:49.2593;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-02-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-02-35Z";57,7948;5,8999;30,9223;4,1987;32;32;8;4;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T11-02-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6bdaa260>";0,00100000004749745;"Experiment.R";2024-03-14 11:02:35.96784;2024-03-14 11:02:42.81314;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-02-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-02-29Z";67,7239;6,3457;33,4236;4,326;64;16;8;4;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T11-02-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6bae4250>";0,00100000004749745;"Experiment.R";2024-03-14 11:02:30.16556;2024-03-14 11:02:35.62111;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-02-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-02-22Z";63,8253;6,3285;29,5891;4,1078;32;16;8;4;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-02-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6a1d1060>";0,00100000004749745;"Experiment.R";2024-03-14 11:02:22.51833;2024-03-14 11:02:29.95054;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-02-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-02-17Z";50,6436;5,5952;32,0019;4,3111;64;32;16;8;0,2;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T11-02-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6a159810>";0,00100000004749745;"Experiment.R";2024-03-14 11:02:17.64505;2024-03-14 11:02:22.30782;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-02-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-02-08Z";51,2293;5,5396;31,4559;4,2217;32;32;16;8;0,2;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T11-02-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6938feb0>";0,00100000004749745;"Experiment.R";2024-03-14 11:02:08.95945;2024-03-14 11:02:17.42366;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-02-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-02-03Z";53,7901;5,7545;33,5129;4,32;64;16;16;8;0,2;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T11-02-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e68b0fbe0>";0,00100000004749745;"Experiment.R";2024-03-14 11:02:03.9586;2024-03-14 11:02:08.75117;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-02-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-01-57Z";52,323;5,6696;31,7287;4,3226;32;16;16;8;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T11-01-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67ee5150>";0,00100000004749745;"Experiment.R";2024-03-14 11:01:58.1613;2024-03-14 11:02:03.72901;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-01-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-01-52Z";49,2736;5,4802;35,3205;4,5013;64;32;8;8;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-01-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e674d83d0>";0,00100000004749745;"Experiment.R";2024-03-14 11:01:52.47441;2024-03-14 11:01:57.94013;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-01-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-01-43Z";47,2739;5,387;39,0769;4,7034;32;32;8;8;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T11-01-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7ec4afb0>";0,00100000004749745;"Experiment.R";2024-03-14 11:01:43.64931;2024-03-14 11:01:52.27331;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-01-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-01-36Z";53,3424;5,7177;33,9901;4,3734;64;16;8;8;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T11-01-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7bf62da0>";0,00100000004749745;"Experiment.R";2024-03-14 11:01:36.20628;2024-03-14 11:01:43.43099;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-01-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-01-31Z";66,5867;6,3656;35,0462;4,4349;32;16;8;8;0,2;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T11-01-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78f59690>";0,00100000004749745;"Experiment.R";2024-03-14 11:01:31.50628;2024-03-14 11:01:35.99551;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-01-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-01-27Z";57,3838;5,9717;30,2352;4,2361;64;32;16;4;0,2;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T11-01-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb3e59030>";0,00100000004749745;"Experiment.R";2024-03-14 11:01:27.27038;2024-03-14 11:01:31.26674;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-01-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-01-19Z";53,2282;5,6648;29,3591;4,1748;32;32;16;4;0,2;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T11-01-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96b9f640>";0,00100000004749745;"Experiment.R";2024-03-14 11:01:19.62971;2024-03-14 11:01:27.05348;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-01-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-01-10Z";60,1551;6,0488;30,6749;4,2565;64;16;16;4;0,2;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T11-01-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7afe0880>";0,00100000004749745;"Experiment.R";2024-03-14 11:01:10.81951;2024-03-14 11:01:19.42936;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-01-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-01-01Z";48,4112;5,4732;31,9976;4,3849;32;16;16;4;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T11-01-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e773f0430>";0,00100000004749745;"Experiment.R";2024-03-14 11:01:02.04082;2024-03-14 11:01:10.60487;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-01-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-00-56Z";56,025;5,8143;35,9467;4,5172;64;32;8;4;0,2;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T11-00-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e75ee5c30>";0,00100000004749745;"Experiment.R";2024-03-14 11:00:56.95118;2024-03-14 11:01:01.72413;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-00-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-00-50Z";52,8585;5,6982;33,6812;4,3817;32;32;8;4;0,2;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T11-00-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76195630>";0,00100000004749745;"Experiment.R";2024-03-14 11:00:50.88664;2024-03-14 11:00:56.7348;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-00-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-00-43Z";59,9729;6,0719;32,8675;4,3281;64;16;8;4;0,2;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T11-00-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e75a6f0a0>";0,00100000004749745;"Experiment.R";2024-03-14 11:00:43.77417;2024-03-14 11:00:50.56974;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-00-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-00-37Z";63,3865;6,2347;32,4235;4,2754;32;16;8;4;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T11-00-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e74570d00>";0,00100000004749745;"Experiment.R";2024-03-14 11:00:38.14631;2024-03-14 11:00:43.57861;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-00-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-00-33Z";50,35;5,5438;30,0181;4,2011;64;32;16;8;0,1;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T11-00-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e745e5e10>";0,00100000004749745;"Experiment.R";2024-03-14 11:00:33.40013;2024-03-14 11:00:37.80048;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-00-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-00-26Z";63,3234;6,117;33,7188;4,4472;32;32;16;8;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T11-00-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6ff736d0>";0,00100000004749745;"Experiment.R";2024-03-14 11:00:26.46502;2024-03-14 11:00:33.1883;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-00-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-00-21Z";50,4583;5,4988;31,3305;4,3147;64;16;16;8;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T11-00-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95d5e470>";0,00100000004749745;"Experiment.R";2024-03-14 11:00:21.23557;2024-03-14 11:00:26.12093;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-00-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-00-16Z";50,7324;5,5258;32,4129;4,4422;32;16;16;8;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T11-00-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e019f00>";0,00100000004749745;"Experiment.R";2024-03-14 11:00:16.34493;2024-03-14 11:00:21.03013;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-00-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-00-01Z";52,1379;5,6578;28,6992;4,1431;64;32;8;8;0,1;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T11-00-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e82743670>";0,00100000004749745;"Experiment.R";2024-03-14 11:00:02.1599;2024-03-14 11:00:16.11378;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-00-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-59-53Z";54,4807;5,7585;31,549;4,3821;32;32;8;8;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T10-59-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0b21ed0>";0,00100000004749745;"Experiment.R";2024-03-14 10:59:53.75579;2024-03-14 11:00:01.85032;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-59-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-59-47Z";62,4772;6,1935;31,0145;4,2554;64;16;8;8;0,1;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T10-59-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f0032e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:59:47.82673;2024-03-14 10:59:53.53161;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-59-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-59-37Z";51,5606;5,6778;38,4832;4,6891;32;16;8;8;0,1;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T10-59-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d3d0100>";0,00100000004749745;"Experiment.R";2024-03-14 10:59:37.95218;2024-03-14 10:59:47.62143;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-59-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-59-30Z";56,2928;5,8176;29,8714;4,2237;64;32;16;4;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T10-59-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d0767d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:59:30.54024;2024-03-14 10:59:37.61994;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-59-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-59-25Z";56,4995;5,8848;32,0204;4,2361;32;32;16;4;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T10-59-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6c268550>";0,00100000004749745;"Experiment.R";2024-03-14 10:59:25.35439;2024-03-14 10:59:30.33445;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-59-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-59-19Z";55,835;5,8011;30,8566;4,2591;64;16;16;4;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T10-59-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67629b70>";0,00100000004749745;"Experiment.R";2024-03-14 10:59:19.79662;2024-03-14 10:59:25.0284;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-59-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-59-09Z";53,5803;5,6535;30,2991;4,1754;32;16;16;4;0,1;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T10-59-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e668e6650>";0,00100000004749745;"Experiment.R";2024-03-14 10:59:09.80664;2024-03-14 10:59:19.58921;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-59-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-59-01Z";61,3863;6,0202;32,8417;4,3359;64;32;8;4;0,1;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T10-59-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6691bf10>";0,00100000004749745;"Experiment.R";2024-03-14 10:59:01.73949;2024-03-14 10:59:09.61479;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-59-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-58-51Z";54,0819;5,7531;33,37;4,3511;32;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T10-58-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e66ea71f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:58:51.70842;2024-03-14 10:59:01.44279;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-58-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-58-46Z";57,9537;5,8808;33,7092;4,3356;64;16;8;4;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-58-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67046320>";0,00100000004749745;"Experiment.R";2024-03-14 10:58:46.57843;2024-03-14 10:58:51.52232;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-58-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-58-34Z";59,2658;5,8721;34,0383;4,5123;32;16;8;4;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T10-58-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e671e06a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:58:35.09988;2024-03-14 10:58:46.39361;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-58-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-58-30Z";58,1478;6,0053;31,0601;4,2474;64;32;16;8;0,1;0,3;0,2;0,1;64;50;19;"runs/2024-03-14T10-58-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67258d90>";0,00100000004749745;"Experiment.R";2024-03-14 10:58:30.75601;2024-03-14 10:58:34.91613;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-58-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-58-23Z";53,0066;5,703;28,736;4,0156;32;32;16;8;0,1;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T10-58-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e66a4f010>";0,00100000004749745;"Experiment.R";2024-03-14 10:58:23.39161;2024-03-14 10:58:30.56454;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-58-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-58-17Z";48,979;5,4594;36,3269;4,5996;64;16;16;8;0,1;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T10-58-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e674b71f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:58:17.20362;2024-03-14 10:58:23.20527;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-58-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-58-11Z";53,2185;5,7092;29,9131;4,1124;32;16;16;8;0,1;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T10-58-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e677ee2c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:58:11.65039;2024-03-14 10:58:17.0148;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-58-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-58-02Z";53,8771;5,7654;31,2007;4,3399;64;32;8;8;0,1;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T10-58-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6782ef20>";0,00100000004749745;"Experiment.R";2024-03-14 10:58:02.77826;2024-03-14 10:58:11.47384;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-58-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-57-53Z";49,7116;5,498;32,3836;4,3134;32;32;8;8;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T10-57-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67c3fa30>";0,00100000004749745;"Experiment.R";2024-03-14 10:57:53.47712;2024-03-14 10:58:02.60429;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-57-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-57-48Z";56,9411;5,9312;29,8435;4,1633;64;16;8;8;0,1;0,3;0,2;0,1;64;50;16;"runs/2024-03-14T10-57-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67ebe530>";0,00100000004749745;"Experiment.R";2024-03-14 10:57:48.61802;2024-03-14 10:57:53.29932;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-57-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-57-43Z";49,1916;5,4835;36,3878;4,5268;32;16;8;8;0,1;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T10-57-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e684071f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:57:43.16692;2024-03-14 10:57:48.43288;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-57-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-57-38Z";60,569;6,0615;32,6708;4,2992;64;32;16;4;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T10-57-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6841eb00>";0,00100000004749745;"Experiment.R";2024-03-14 10:57:38.9966;2024-03-14 10:57:42.96471;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-57-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-57-33Z";55,6286;5,8167;32,0777;4,3772;32;32;16;4;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T10-57-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6864bfd0>";0,00100000004749745;"Experiment.R";2024-03-14 10:57:33.2121;2024-03-14 10:57:38.80674;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-57-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-57-26Z";55,4174;5,789;34,6925;4,4693;64;16;16;4;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T10-57-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e68939090>";0,00100000004749745;"Experiment.R";2024-03-14 10:57:26.65338;2024-03-14 10:57:33.03116;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-57-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-57-17Z";54,498;5,743;32,5226;4,3503;32;16;16;4;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-57-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6803a200>";0,00100000004749745;"Experiment.R";2024-03-14 10:57:17.55312;2024-03-14 10:57:26.42636;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-57-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-57-10Z";55,4608;5,817;33,3038;4,3874;64;32;8;4;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T10-57-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e681ffdc0>";0,00100000004749745;"Experiment.R";2024-03-14 10:57:10.3026;2024-03-14 10:57:17.37775;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-57-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-57-04Z";54,2167;5,8026;31,6291;4,2413;32;32;8;4;0,1;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T10-57-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6826b430>";0,00100000004749745;"Experiment.R";2024-03-14 10:57:04.98073;2024-03-14 10:57:10.12129;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-57-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-57Z";54,1053;5,7504;30,9326;4,2362;64;16;8;4;0,1;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T10-56-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67a4bdc0>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:57.19003;2024-03-14 10:57:04.78514;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-48Z";54,3154;5,7122;33,3405;4,458;32;16;8;4;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T10-56-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e68cb3430>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:49.06687;2024-03-14 10:56:57.00669;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-44Z";48,2259;5,48;30,0743;4,1548;64;32;16;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-56-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e675cbf40>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:44.63262;2024-03-14 10:56:48.88781;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-39Z";52,1058;5,7054;30,6233;4,2906;32;32;16;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-56-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e68f55ff0>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:39.36958;2024-03-14 10:56:44.4567;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-33Z";54,4128;5,7654;34,299;4,3896;64;16;16;8;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T10-56-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e691a10f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:33.68305;2024-03-14 10:56:39.1833;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-27Z";50,9499;5,5947;34,1988;4,3442;32;16;16;8;0,1;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T10-56-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e693b3a90>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:27.33193;2024-03-14 10:56:33.50077;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-21Z";52,2135;5,6151;36,2377;4,5478;64;32;8;8;0,1;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T10-56-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69852b90>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:21.68763;2024-03-14 10:56:27.15723;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-17Z";57,7795;6,0007;35,361;4,4768;32;32;8;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-56-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69d0e6e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:17.3247;2024-03-14 10:56:21.50821;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-10Z";50,2878;5,6061;31,6003;4,2601;64;16;8;8;0,1;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T10-56-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69c9b100>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:10.22802;2024-03-14 10:56:17.14369;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-56-04Z";50,9648;5,6046;33,8182;4,3887;32;16;8;8;0,1;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T10-56-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69d351e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:56:04.92498;2024-03-14 10:56:10.03578;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-56-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-55-56Z";53,1308;5,7637;30,6128;4,2163;64;32;16;4;0,1;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T10-55-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69f377c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:55:56.24979;2024-03-14 10:56:04.74382;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-55-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-55-48Z";52,0786;5,6569;31,9315;4,2579;32;32;16;4;0,1;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T10-55-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6a1b9120>";0,00100000004749745;"Experiment.R";2024-03-14 10:55:48.48027;2024-03-14 10:55:56.07031;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-55-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-55-43Z";54,0593;5,7508;35,265;4,4487;64;16;16;4;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T10-55-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6a3b37c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:55:44.00164;2024-03-14 10:55:48.29861;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-55-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-55-36Z";56,6955;5,8516;35,8166;4,5388;32;16;16;4;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T10-55-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69a36260>";0,00100000004749745;"Experiment.R";2024-03-14 10:55:36.63409;2024-03-14 10:55:43.82577;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-55-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-55-31Z";55,8388;5,8193;30,4774;4,3337;64;32;8;4;0,1;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T10-55-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6a4894e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:55:32.01343;2024-03-14 10:55:36.44274;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-55-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-55-24Z";54,1598;5,7599;30,6078;4,2298;32;32;8;4;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T10-55-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e694a3f40>";0,00100000004749745;"Experiment.R";2024-03-14 10:55:24.57002;2024-03-14 10:55:31.82961;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-55-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-55-14Z";49,9198;5,5057;33,05;4,3763;64;16;8;4;0,1;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T10-55-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6a6efa00>";0,00100000004749745;"Experiment.R";2024-03-14 10:55:15.21495;2024-03-14 10:55:24.38806;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-55-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-55-08Z";58,9776;6,0207;31,803;4,2602;32;16;8;4;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T10-55-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e68e6ccd0>";0,00100000004749745;"Experiment.R";2024-03-14 10:55:08.39962;2024-03-14 10:55:14.90969;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-55-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-55-01Z";49,6913;5,4901;31,2015;4,2422;64;32;16;8;0,1;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T10-55-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6ac15d80>";0,00100000004749745;"Experiment.R";2024-03-14 10:55:01.57257;2024-03-14 10:55:08.22546;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-55-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-54-55Z";56,9677;5,8156;30,5828;4,2487;32;32;16;8;0,1;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T10-54-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6abcf5b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:54:55.59464;2024-03-14 10:55:01.38373;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-54-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-54-49Z";55,0012;5,7898;32,7461;4,4419;64;16;16;8;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T10-54-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6aec0250>";0,00100000004749745;"Experiment.R";2024-03-14 10:54:49.25928;2024-03-14 10:54:55.41616;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-54-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-54-42Z";49,6582;5,543;31,0363;4,2807;32;16;16;8;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T10-54-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6ae674f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:54:42.18471;2024-03-14 10:54:49.08243;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-54-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-54-36Z";51,5179;5,5989;31,6002;4,311;64;32;8;8;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T10-54-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6b8e25f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:54:36.87936;2024-03-14 10:54:42.01664;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-54-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-54-30Z";55,687;5,8736;32,2972;4,3858;32;32;8;8;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T10-54-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6baf4160>";0,00100000004749745;"Experiment.R";2024-03-14 10:54:31.03483;2024-03-14 10:54:36.69911;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-54-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-54-21Z";53,4724;5,696;33,6527;4,4434;64;16;8;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-54-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6bb81150>";0,00100000004749745;"Experiment.R";2024-03-14 10:54:21.40248;2024-03-14 10:54:30.85486;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-54-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-54-14Z";50,2736;5,5067;33,2841;4,4031;32;16;8;8;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T10-54-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6bfb3e50>";0,00100000004749745;"Experiment.R";2024-03-14 10:54:14.45606;2024-03-14 10:54:21.2149;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-54-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-54-09Z";54,4827;5,7756;30,51;4,2131;64;32;16;4;0,1;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T10-54-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6c046080>";0,00100000004749745;"Experiment.R";2024-03-14 10:54:09.37986;2024-03-14 10:54:14.17062;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-54-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-54-02Z";56,3181;5,8297;29,8513;4,2258;32;32;16;4;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T10-54-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6c2a14b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:54:02.91619;2024-03-14 10:54:09.20748;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-54-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-56Z";53,2125;5,7063;32,8332;4,4486;64;16;16;4;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-53-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6c4d7f10>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:56.59286;2024-03-14 10:54:02.63105;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-51Z";56,0183;5,812;31,0949;4,2654;32;16;16;4;0,1;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T10-53-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78f6d8a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:51.89961;2024-03-14 10:53:56.40722;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-46Z";59,2558;5,9891;32,0418;4,3199;64;32;8;4;0,1;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T10-53-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6bd96ec0>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:46.19265;2024-03-14 10:53:51.73216;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-41Z";54,3834;5,7598;33,6621;4,4025;32;32;8;4;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T10-53-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6c803220>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:41.21992;2024-03-14 10:53:46.01627;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-34Z";60,0954;6,0327;34,5075;4,4616;64;16;8;4;0,1;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T10-53-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a56a5c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:34.62634;2024-03-14 10:53:41.03739;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-30Z";58,039;5,9237;35,8703;4,5106;32;16;8;4;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T10-53-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb13efc40>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:30.143;2024-03-14 10:53:34.45798;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-23Z";50,5321;5,5437;30,9118;4,3178;64;32;16;8;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T10-53-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e81b55240>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:24.07698;2024-03-14 10:53:29.96867;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-18Z";49,605;5,4818;27,8393;4,0855;32;32;16;8;0,1;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T10-53-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78d8bac0>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:18.75107;2024-03-14 10:53:23.90398;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-12Z";52,9293;5,7217;30,4792;4,2303;64;16;16;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-53-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96b9f460>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:12.62848;2024-03-14 10:53:18.58302;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-53-07Z";55,3523;5,8389;30,6737;4,2265;32;16;16;8;0,1;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T10-53-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6e2ffd00>";0,00100000004749745;"Experiment.R";2024-03-14 10:53:07.39244;2024-03-14 10:53:12.46184;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-53-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-52-56Z";49,7495;5,5294;32,3159;4,3554;64;32;8;8;0,1;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T10-52-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d7e7dc0>";0,00100000004749745;"Experiment.R";2024-03-14 10:52:56.78479;2024-03-14 10:53:07.224;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-52-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-52-49Z";49,843;5,5595;31,4603;4,2301;32;32;8;8;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T10-52-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a3c2ef0>";0,00100000004749745;"Experiment.R";2024-03-14 10:52:49.15738;2024-03-14 10:52:56.61469;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-52-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-52-42Z";54,1176;5,7309;35,8184;4,5172;64;16;8;8;0,1;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T10-52-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb301dc30>";0,00100000004749745;"Experiment.R";2024-03-14 10:52:42.20294;2024-03-14 10:52:48.97976;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-52-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-52-33Z";53,8762;5,8157;36,2949;4,6209;32;16;8;8;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T10-52-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb3c25c30>";0,00100000004749745;"Experiment.R";2024-03-14 10:52:33.75169;2024-03-14 10:52:41.96401;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-52-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-52-28Z";53,7677;5,6855;29,516;4,161;64;32;16;4;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T10-52-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7cd2d570>";0,00100000004749745;"Experiment.R";2024-03-14 10:52:29.07185;2024-03-14 10:52:33.57594;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-52-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-52-18Z";52,5677;5,6996;30,2148;4,1851;32;32;16;4;0,1;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T10-52-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d187370>";0,00100000004749745;"Experiment.R";2024-03-14 10:52:19.0645;2024-03-14 10:52:28.90142;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-52-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-52-13Z";57,6043;5,9464;31,6151;4,3309;64;16;16;4;0,1;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T10-52-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6cad2a70>";0,00100000004749745;"Experiment.R";2024-03-14 10:52:13.91011;2024-03-14 10:52:18.89985;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-52-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-52-05Z";53,1499;5,7023;32,9776;4,437;32;16;16;4;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T10-52-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d5711b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:52:05.50846;2024-03-14 10:52:13.63716;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-52-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-52-00Z";58,4755;5,9526;32,1648;4,2697;64;32;8;4;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T10-52-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d79fc10>";0,00100000004749745;"Experiment.R";2024-03-14 10:52:00.60865;2024-03-14 10:52:05.34355;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-52-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-51-52Z";53,3048;5,6724;30,0959;4,1423;32;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T10-51-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d9fa860>";0,00100000004749745;"Experiment.R";2024-03-14 10:51:52.26738;2024-03-14 10:52:00.44549;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-51-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-51-46Z";61,6588;6,1345;33,44;4,4302;64;16;8;4;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T10-51-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6da961d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:51:46.97718;2024-03-14 10:51:52.10186;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-51-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-51-38Z";57,9786;5,8782;32,0252;4,3349;32;16;8;4;0,1;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T10-51-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6dca4d30>";0,00100000004749745;"Experiment.R";2024-03-14 10:51:39.13172;2024-03-14 10:51:46.80226;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-51-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-51-33Z";52,3573;5,6664;29,1631;4,2017;64;32;16;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-51-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d4eb4f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:51:33.42049;2024-03-14 10:51:38.86067;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-51-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-51-27Z";50,5993;5,5673;31,5607;4,2153;32;32;16;8;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T10-51-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a347610>";0,00100000004749745;"Experiment.R";2024-03-14 10:51:27.86225;2024-03-14 10:51:33.24942;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-51-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-51-22Z";50,454;5,5533;30,4719;4,1722;64;16;16;8;0,1;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T10-51-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6dfc7e20>";0,00100000004749745;"Experiment.R";2024-03-14 10:51:22.22137;2024-03-14 10:51:27.69381;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-51-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-51-14Z";54,4187;5,7488;30,3051;4,2022;32;16;16;8;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T10-51-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6e14f310>";0,00100000004749745;"Experiment.R";2024-03-14 10:51:15.10254;2024-03-14 10:51:22.0514;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-51-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-51-05Z";56,5032;5,8335;34,2545;4,3887;64;32;8;8;0,1;0,3;0,2;0,1;64;50;16;"runs/2024-03-14T10-51-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94fbe560>";0,00100000004749745;"Experiment.R";2024-03-14 10:51:05.67644;2024-03-14 10:51:14.9106;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-51-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-50-57Z";48,7635;5,4352;35,3571;4,5082;32;32;8;8;0,1;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T10-50-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f002b00>";0,00100000004749745;"Experiment.R";2024-03-14 10:50:57.89709;2024-03-14 10:51:05.52236;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-50-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-50-52Z";57,6533;5,9376;32,9291;4,3518;64;16;8;8;0,1;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T10-50-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e566710>";0,00100000004749745;"Experiment.R";2024-03-14 10:50:53.06975;2024-03-14 10:50:57.7395;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-50-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-50-44Z";57,2762;5,9183;33,8658;4,4732;32;16;8;8;0,1;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T10-50-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8369a8c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:50:44.56238;2024-03-14 10:50:52.90845;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-50-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-50-36Z";54,6768;5,7595;31,4549;4,2342;64;32;16;4;0,1;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T10-50-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7cd2dd20>";0,00100000004749745;"Experiment.R";2024-03-14 10:50:36.29391;2024-03-14 10:50:44.39271;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-50-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-50-29Z";49,306;5,4699;29,8394;4,261;32;32;16;4;0,1;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T10-50-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95603220>";0,00100000004749745;"Experiment.R";2024-03-14 10:50:29.32843;2024-03-14 10:50:36.12412;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-50-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-50-23Z";56,4954;5,865;31,9425;4,2692;64;16;16;4;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T10-50-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e81412d10>";0,00100000004749745;"Experiment.R";2024-03-14 10:50:23.44188;2024-03-14 10:50:29.16629;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-50-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-50-13Z";56,0849;5,8584;32,2156;4,3098;32;16;16;4;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T10-50-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7b1cb280>";0,00100000004749745;"Experiment.R";2024-03-14 10:50:13.53709;2024-03-14 10:50:23.29223;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-50-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-50-07Z";65,0396;6,1859;32,4862;4,3066;64;32;8;4;0,1;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T10-50-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e9509d630>";0,00100000004749745;"Experiment.R";2024-03-14 10:50:07.15536;2024-03-14 10:50:13.28185;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-50-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-49-53Z";58,9134;5,9979;31,2823;4,3367;32;32;8;4;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T10-49-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7ad2b880>";0,00100000004749745;"Experiment.R";2024-03-14 10:49:53.81733;2024-03-14 10:50:06.99233;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-49-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-49-42Z";47,7196;5,4256;32,3624;4,3356;64;16;8;4;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T10-49-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79952b60>";0,00100000004749745;"Experiment.R";2024-03-14 10:49:42.66325;2024-03-14 10:49:53.66915;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-49-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-49-33Z";61,7072;6,0701;32,4865;4,3339;32;16;8;4;0,1;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T10-49-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb17c16f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:49:33.21453;2024-03-14 10:49:42.50234;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-49-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-49-29Z";53,8366;5,747;31,4442;4,3379;64;32;16;8;0,1;0,3;0,2;0,1;64;50;15;"runs/2024-03-14T10-49-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a806410>";0,00100000004749745;"Experiment.R";2024-03-14 10:49:29.58239;2024-03-14 10:49:33.03894;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-49-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-49-23Z";48,0656;5,3671;30,4009;4,2153;32;32;16;8;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T10-49-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e966a2920>";0,00100000004749745;"Experiment.R";2024-03-14 10:49:23.64013;2024-03-14 10:49:29.42473;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-49-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-49-18Z";48,3776;5,4222;35,8696;4,5362;64;16;16;8;0,1;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T10-49-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb31fb580>";0,00100000004749745;"Experiment.R";2024-03-14 10:49:18.3044;2024-03-14 10:49:23.48486;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-49-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-49-11Z";53,8783;5,7645;28,8312;4,1209;32;16;16;8;0,1;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T10-49-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76b50820>";0,00100000004749745;"Experiment.R";2024-03-14 10:49:12.02918;2024-03-14 10:49:18.14679;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-49-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-49-01Z";55,5941;5,8308;34,1212;4,349;64;32;8;8;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T10-49-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7813afe0>";0,00100000004749745;"Experiment.R";2024-03-14 10:49:01.33695;2024-03-14 10:49:11.87771;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-49-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-48-54Z";54,9079;5,8074;32,6017;4,3169;32;32;8;8;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T10-48-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76151960>";0,00100000004749745;"Experiment.R";2024-03-14 10:48:54.99546;2024-03-14 10:49:01.1847;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-48-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-48-47Z";54,081;5,7302;36,3972;4,5505;64;16;8;8;0,1;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T10-48-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e2ea8f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:48:48.09535;2024-03-14 10:48:54.847;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-48-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-48-41Z";50,5624;5,5731;33,4888;4,4354;32;16;8;8;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T10-48-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e700265c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:48:41.88235;2024-03-14 10:48:47.93362;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-48-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-48-36Z";54,6972;5,7309;33,235;4,3878;64;32;16;4;0,1;0,3;0,2;0,1;64;50;17;"runs/2024-03-14T10-48-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6fff3550>";0,00100000004749745;"Experiment.R";2024-03-14 10:48:36.91998;2024-03-14 10:48:41.73442;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-48-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-48-30Z";61,1547;5,9916;31,6132;4,3077;32;32;16;4;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T10-48-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2fd71c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:48:30.9337;2024-03-14 10:48:36.77317;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-48-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-48-25Z";57,9637;5,9509;34,3174;4,4648;64;16;16;4;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-48-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e951fd930>";0,00100000004749745;"Experiment.R";2024-03-14 10:48:25.85694;2024-03-14 10:48:30.7795;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-48-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-48-19Z";54,7851;5,8223;33,3816;4,3683;32;16;16;4;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T10-48-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e949406a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:48:19.62678;2024-03-14 10:48:25.62168;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-48-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-48-12Z";51,7288;5,5969;29,9504;4,2008;64;32;8;4;0,1;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T10-48-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e82a211e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:48:12.50946;2024-03-14 10:48:19.47637;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-48-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-48-06Z";61,5429;6,0414;32,0982;4,3144;32;32;8;4;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T10-48-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8046e170>";0,00100000004749745;"Experiment.R";2024-03-14 10:48:06.75208;2024-03-14 10:48:12.36465;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-48-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-57Z";59,2445;5,971;30,9989;4,2341;64;16;8;4;0,1;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T10-47-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7ebe9bd0>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:57.58233;2024-03-14 10:48:06.59456;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-48Z";57,0551;5,7874;33,7575;4,3942;32;16;8;4;0,1;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T10-47-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f3315a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:48.80269;2024-03-14 10:47:57.43313;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-43Z";51,9571;5,5818;32,5679;4,3519;64;32;16;8;0,1;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T10-47-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7dfbc0a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:43.86224;2024-03-14 10:47:48.65512;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-39Z";50,3101;5,5762;29,4937;4,0978;32;32;16;8;0,1;0,3;0,2;0,1;64;50;18;"runs/2024-03-14T10-47-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e0b8370>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:39.7105;2024-03-14 10:47:43.69789;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-33Z";53,3626;5,7582;31,6741;4,2865;64;16;16;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-47-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e81488670>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:33.4761;2024-03-14 10:47:39.56871;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-26Z";51,6031;5,6286;32,1488;4,3333;32;16;16;8;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T10-47-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb13eef50>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:27.0917;2024-03-14 10:47:33.3256;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-21Z";56,5184;5,8265;31,075;4,2343;64;32;8;8;0,1;0,3;0,2;0,1;64;50;20;"runs/2024-03-14T10-47-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9ec8b35f90>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:22.00681;2024-03-14 10:47:26.8701;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-13Z";53,5509;5,7205;30,6429;4,2643;32;32;8;8;0,1;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T10-47-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95d5e9b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:14.03836;2024-03-14 10:47:21.85631;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-09Z";51,0359;5,6413;39,0241;4,6911;64;16;8;8;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T10-47-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1284220>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:09.19342;2024-03-14 10:47:13.87632;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-47-00Z";55,2726;5,8157;36,7455;4,5811;32;16;8;8;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T10-47-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e769a6a40>";0,00100000004749745;"Experiment.R";2024-03-14 10:47:00.52077;2024-03-14 10:47:09.0279;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-47-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-46-54Z";59,16;5,9939;32,2113;4,3429;64;32;16;4;0,1;0,3;0,2;0,1;64;50;23;"runs/2024-03-14T10-46-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a8508b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:46:54.97702;2024-03-14 10:47:00.36427;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-46-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-46-47Z";59,9002;5,8828;31,6311;4,2418;32;32;16;4;0,1;0,3;0,2;0,1;64;50;27;"runs/2024-03-14T10-46-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a3ad390>";0,00100000004749745;"Experiment.R";2024-03-14 10:46:47.3929;2024-03-14 10:46:54.79726;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-46-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-46-36Z";205,5246;12,5209;158,166;10,5727;64;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T10-46-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79732290>";0,00100000004749745;"Experiment.R";2024-03-14 10:46:36.3451;2024-03-14 10:46:47.23307;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-46-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-46-30Z";55,0965;5,8074;31,3631;4,3048;32;16;16;4;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T10-46-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e744fdc90>";0,00100000004749745;"Experiment.R";2024-03-14 10:46:30.37089;2024-03-14 10:46:36.18994;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-46-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-46-23Z";56,1685;5,8803;32,7605;4,3337;64;32;8;4;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T10-46-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77015630>";0,00100000004749745;"Experiment.R";2024-03-14 10:46:23.96348;2024-03-14 10:46:30.21825;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-46-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-46-15Z";54,5185;5,8083;35,0626;4,4412;32;32;8;4;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T10-46-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7076ba00>";0,00100000004749745;"Experiment.R";2024-03-14 10:46:15.57633;2024-03-14 10:46:23.82331;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-46-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-46-10Z";64,3415;6,2269;34,3717;4,4096;64;16;8;4;0,1;0,3;0,2;0,1;64;50;19;"runs/2024-03-14T10-46-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6ffd7130>";0,00100000004749745;"Experiment.R";2024-03-14 10:46:10.46104;2024-03-14 10:46:15.4316;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-46-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-46-04Z";65,556;6,169;35,1376;4,5071;32;16;8;4;0,1;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T10-46-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e709d7130>";0,00100000004749745;"Experiment.R";2024-03-14 10:46:04.42126;2024-03-14 10:46:10.30735;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-46-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-45-56Z";47,1426;5,3479;29,0866;4,1838;64;32;16;8;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-45-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6f20bd60>";0,00100000004749745;"Experiment.R";2024-03-14 10:45:56.32641;2024-03-14 10:46:04.28591;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-45-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-45-49Z";49,3573;5,5326;30,5134;4,2608;32;32;16;8;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-45-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e73b98fd0>";0,00100000004749745;"Experiment.R";2024-03-14 10:45:49.84665;2024-03-14 10:45:56.19057;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-45-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-45-43Z";49,4255;5,5451;32,643;4,3915;64;16;16;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-45-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e73da7f10>";0,00100000004749745;"Experiment.R";2024-03-14 10:45:43.62538;2024-03-14 10:45:49.62461;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-45-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-45-36Z";48,2626;5,4971;33,1457;4,3723;32;16;16;8;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-45-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e740d3d90>";0,00100000004749745;"Experiment.R";2024-03-14 10:45:36.88469;2024-03-14 10:45:43.48665;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-45-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-45-30Z";49,0562;5,4805;35,2619;4,4563;64;32;8;8;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-45-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e742f4a60>";0,00100000004749745;"Experiment.R";2024-03-14 10:45:30.38535;2024-03-14 10:45:36.75269;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-45-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-45-19Z";45,9175;5,306;35,2158;4,5155;32;32;8;8;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T10-45-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e745200d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:45:19.43906;2024-03-14 10:45:30.23924;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-45-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-45-12Z";49,602;5,5076;34,0364;4,3669;64;16;8;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-45-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e74550bb0>";0,00100000004749745;"Experiment.R";2024-03-14 10:45:12.59169;2024-03-14 10:45:19.30387;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-45-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-45-03Z";54,147;5,7428;30,8536;4,2549;32;16;8;8;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T10-45-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e747ce260>";0,00100000004749745;"Experiment.R";2024-03-14 10:45:03.96399;2024-03-14 10:45:12.45469;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-45-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-44-56Z";57,2253;5,8782;29,8684;4,2168;64;32;16;4;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-44-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e74ab3a00>";0,00100000004749745;"Experiment.R";2024-03-14 10:44:56.91523;2024-03-14 10:45:03.83411;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-44-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-44-42Z";51,6675;5,6418;30,8772;4,2382;32;32;16;4;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T10-44-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e74d06260>";0,00100000004749745;"Experiment.R";2024-03-14 10:44:42.50081;2024-03-14 10:44:56.77241;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-44-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-44-32Z";54,9936;5,7547;32,9583;4,3808;64;16;16;4;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-44-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e750f23e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:44:33.04937;2024-03-14 10:44:42.36853;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-44-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-44-23Z";55,1664;5,8713;30,2022;4,2131;32;16;16;4;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T10-44-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e75133f70>";0,00100000004749745;"Experiment.R";2024-03-14 10:44:23.89599;2024-03-14 10:44:32.92143;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-44-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-44-16Z";57,519;5,9019;32,2008;4,2652;64;32;8;4;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-44-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e753b67a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:44:16.42168;2024-03-14 10:44:23.765;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-44-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-44-05Z";57,1163;5,853;31,2958;4,2616;32;32;8;4;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T10-44-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76689930>";0,00100000004749745;"Experiment.R";2024-03-14 10:44:06.06333;2024-03-14 10:44:16.28681;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-44-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-43-56Z";60,6639;6,0319;39,1461;4,7206;64;16;8;4;0,2;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T10-43-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e75639180>";0,00100000004749745;"Experiment.R";2024-03-14 10:43:56.96843;2024-03-14 10:44:05.93181;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-43-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-43-47Z";55,6124;5,8277;34,1887;4,4849;32;16;8;4;0,2;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-43-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e74e4a410>";0,00100000004749745;"Experiment.R";2024-03-14 10:43:47.87319;2024-03-14 10:43:56.83852;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-43-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-43-42Z";50,3828;5,5498;30,919;4,2841;64;32;16;8;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-43-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e75a6f730>";0,00100000004749745;"Experiment.R";2024-03-14 10:43:42.24885;2024-03-14 10:43:47.74513;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-43-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-43-34Z";44,7882;5,3254;29,489;4,1711;32;32;16;8;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-43-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e75c57f10>";0,00100000004749745;"Experiment.R";2024-03-14 10:43:34.20654;2024-03-14 10:43:42.10866;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-43-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-43-26Z";51,3738;5,5908;32,6761;4,438;64;16;16;8;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-43-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76171900>";0,00100000004749745;"Experiment.R";2024-03-14 10:43:26.95957;2024-03-14 10:43:34.07848;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-43-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-43-14Z";47,3861;5,4194;34,2608;4,5457;32;16;16;8;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-43-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76307d90>";0,00100000004749745;"Experiment.R";2024-03-14 10:43:14.92909;2024-03-14 10:43:26.83249;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-43-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-43-07Z";49,5422;5,4786;34,8942;4,4209;64;32;8;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-43-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77a713c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:43:08.02264;2024-03-14 10:43:14.80151;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-43-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-43-02Z";54,3068;5,8325;32,7132;4,2928;32;32;8;8;0,2;0,3;0,2;0,1;32;50;15;"runs/2024-03-14T10-43-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77c63d90>";0,00100000004749745;"Experiment.R";2024-03-14 10:43:02.50005;2024-03-14 10:43:07.89509;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-43-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-42-56Z";56,2799;5,8699;32,0478;4,3409;64;16;8;8;0,2;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-42-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77ec1480>";0,00100000004749745;"Experiment.R";2024-03-14 10:42:56.69611;2024-03-14 10:43:02.37387;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-42-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-42-44Z";49,3784;5,4906;32,0413;4,4597;32;16;8;8;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-42-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e780b3f70>";0,00100000004749745;"Experiment.R";2024-03-14 10:42:44.72312;2024-03-14 10:42:56.57269;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-42-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-42-36Z";52,7128;5,6671;32,454;4,33;64;32;16;4;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-42-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e763cff70>";0,00100000004749745;"Experiment.R";2024-03-14 10:42:36.45488;2024-03-14 10:42:44.60038;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-42-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-42-18Z";172,117;11,1841;129,8986;9,1798;32;32;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-42-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76450bb0>";0,00100000004749745;"Experiment.R";2024-03-14 10:42:18.39032;2024-03-14 10:42:36.26883;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-42-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-42-07Z";60,46;5,9737;32,3889;4,3248;64;16;16;4;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-42-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7668bc40>";0,00100000004749745;"Experiment.R";2024-03-14 10:42:07.14471;2024-03-14 10:42:18.26387;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-42-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-41-58Z";51,4673;5,6217;32,5372;4,4064;32;16;16;4;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-41-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e75e7b460>";0,00100000004749745;"Experiment.R";2024-03-14 10:41:58.97214;2024-03-14 10:42:07.02429;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-41-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-41-49Z";52,9182;5,6464;33,3521;4,4429;64;32;8;4;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T10-41-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78608b50>";0,00100000004749745;"Experiment.R";2024-03-14 10:41:49.67552;2024-03-14 10:41:58.84933;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-41-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-41-38Z";58,1667;5,8771;32,663;4,4654;32;32;8;4;0,2;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T10-41-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78b0d510>";0,00100000004749745;"Experiment.R";2024-03-14 10:41:38.98151;2024-03-14 10:41:49.54221;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-41-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-41-28Z";51,0734;5,6767;31,4628;4,3078;64;16;8;4;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T10-41-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76b1c460>";0,00100000004749745;"Experiment.R";2024-03-14 10:41:28.75739;2024-03-14 10:41:38.85688;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-41-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-41-18Z";61,6435;6,0062;33,103;4,4037;32;16;8;4;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T10-41-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76b924a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:41:18.81147;2024-03-14 10:41:28.63356;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-41-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-41-08Z";51,363;5,5649;30,9181;4,231;64;32;16;8;0,2;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-41-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e76f878b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:41:08.8396;2024-03-14 10:41:18.68482;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-41-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-41-01Z";45,3733;5,2819;32,1989;4,491;32;32;16;8;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-41-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e771f50f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:41:02.07438;2024-03-14 10:41:08.70082;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-41-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-40-54Z";56,1865;5,938;31,9538;4,3062;64;16;16;8;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-40-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e773f3a90>";0,00100000004749745;"Experiment.R";2024-03-14 10:40:54.62446;2024-03-14 10:41:01.93678;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-40-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-40-46Z";48,2396;5,4331;37,851;4,7101;32;16;16;8;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-40-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7748e200>";0,00100000004749745;"Experiment.R";2024-03-14 10:40:47.01373;2024-03-14 10:40:54.50493;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-40-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-40-41Z";51,3777;5,5285;34,6311;4,4321;64;32;8;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-40-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e776f2ec0>";0,00100000004749745;"Experiment.R";2024-03-14 10:40:41.34824;2024-03-14 10:40:46.88532;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-40-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-40-27Z";52,0321;5,6179;32,4843;4,3129;32;32;8;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-40-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7860ab60>";0,00100000004749745;"Experiment.R";2024-03-14 10:40:27.80314;2024-03-14 10:40:41.22481;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-40-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-40-18Z";47,4969;5,3751;31,9767;4,3673;64;16;8;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-40-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7bf604f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:40:18.7464;2024-03-14 10:40:27.6836;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-40-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-40-10Z";56,3105;5,8071;37,5101;4,6494;32;16;8;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-40-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7b287730>";0,00100000004749745;"Experiment.R";2024-03-14 10:40:10.11582;2024-03-14 10:40:18.62662;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-40-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-40-01Z";60,5465;5,9909;31,21;4,2813;64;32;16;4;0,2;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-40-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a0a8340>";0,00100000004749745;"Experiment.R";2024-03-14 10:40:01.93565;2024-03-14 10:40:09.99737;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-40-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-39-50Z";51,3398;5,6025;29,345;4,125;32;32;16;4;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-39-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79568d90>";0,00100000004749745;"Experiment.R";2024-03-14 10:39:50.19066;2024-03-14 10:40:01.81618;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-39-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-39-43Z";59,6205;5,9774;32,0859;4,3247;64;16;16;4;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-39-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78cce050>";0,00100000004749745;"Experiment.R";2024-03-14 10:39:43.82614;2024-03-14 10:39:50.07294;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-39-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-39-33Z";52,5435;5,6563;31,6923;4,3947;32;16;16;4;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T10-39-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7b8781c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:39:33.6325;2024-03-14 10:39:43.70084;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-39-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-39-23Z";57,5777;5,9277;34,6052;4,4388;64;32;8;4;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-39-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78463340>";0,00100000004749745;"Experiment.R";2024-03-14 10:39:23.36564;2024-03-14 10:39:33.50665;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-39-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-39-15Z";52,0278;5,6133;31,7487;4,2981;32;32;8;4;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T10-39-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e799ad930>";0,00100000004749745;"Experiment.R";2024-03-14 10:39:15.70422;2024-03-14 10:39:23.24554;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-39-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-39-07Z";53,3968;5,7031;31,8212;4,3098;64;16;8;4;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T10-39-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78abfee0>";0,00100000004749745;"Experiment.R";2024-03-14 10:39:07.18571;2024-03-14 10:39:15.56489;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-39-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-38-54Z";61,6409;6,0045;32,5064;4,4157;32;16;8;4;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T10-38-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78ce3b50>";0,00100000004749745;"Experiment.R";2024-03-14 10:38:54.24753;2024-03-14 10:39:07.06133;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-38-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-38-44Z";51,8175;5,6133;31,3752;4,2584;64;32;16;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-38-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78fd06a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:38:45.03411;2024-03-14 10:38:54.12932;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-38-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-38-40Z";49,4266;5,4672;32,9447;4,4092;32;32;16;8;0,2;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T10-38-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78f6c2e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:38:40.14792;2024-03-14 10:38:44.91309;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-38-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-38-34Z";51,1639;5,5872;34,9033;4,5057;64;16;16;8;0,2;0,3;0,2;0,1;32;50;15;"runs/2024-03-14T10-38-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e787ac100>";0,00100000004749745;"Experiment.R";2024-03-14 10:38:34.49942;2024-03-14 10:38:40.03287;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-38-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-38-24Z";49,1175;5,503;34,4888;4,459;32;16;16;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-38-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e78832470>";0,00100000004749745;"Experiment.R";2024-03-14 10:38:24.18646;2024-03-14 10:38:34.37789;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-38-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-38-16Z";53,2869;5,6499;32,2239;4,3199;64;32;8;8;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-38-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e794d7e50>";0,00100000004749745;"Experiment.R";2024-03-14 10:38:17.06885;2024-03-14 10:38:24.06992;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-38-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-38-08Z";47,7817;5,4131;32,7224;4,3741;32;32;8;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-38-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7954a3b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:38:08.61275;2024-03-14 10:38:16.93533;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-38-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-38-00Z";51,7052;5,571;33,9813;4,4262;64;16;8;8;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T10-38-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79733dc0>";0,00100000004749745;"Experiment.R";2024-03-14 10:38:00.1061;2024-03-14 10:38:08.48797;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-38-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-37-48Z";53,7266;5,7425;32,3471;4,4421;32;16;8;8;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-37-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79967880>";0,00100000004749745;"Experiment.R";2024-03-14 10:37:48.47895;2024-03-14 10:37:59.98663;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-37-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-37-41Z";64,363;6,1477;34,7341;4,4753;64;32;16;4;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-37-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79af4a60>";0,00100000004749745;"Experiment.R";2024-03-14 10:37:41.67909;2024-03-14 10:37:48.36064;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-37-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-37-26Z";58,4877;5,8632;32,1049;4,361;32;32;16;4;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T10-37-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79d23a30>";0,00100000004749745;"Experiment.R";2024-03-14 10:37:26.64501;2024-03-14 10:37:41.56325;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-37-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-37-19Z";51,5316;5,5779;30,2173;4,2103;64;16;16;4;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-37-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79f2bbe0>";0,00100000004749745;"Experiment.R";2024-03-14 10:37:19.59635;2024-03-14 10:37:26.4576;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-37-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-37-09Z";48,3082;5,4707;30,2469;4,2316;32;16;16;4;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T10-37-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a3ae0b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:37:09.74531;2024-03-14 10:37:19.47281;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-37-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-37-00Z";54,6682;5,779;31,2955;4,2429;64;32;8;4;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T10-37-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a56a1d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:37:00.42046;2024-03-14 10:37:09.63781;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-37-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-36-38Z";61,7128;6,038;37,9464;4,638;32;32;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-36-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a7b7040>";0,00100000004749745;"Experiment.R";2024-03-14 10:36:38.47188;2024-03-14 10:37:00.30731;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-36-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-36-14Z";48,9153;5,5032;31,3056;4,2875;64;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-36-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a850c10>";0,00100000004749745;"Experiment.R";2024-03-14 10:36:14.18383;2024-03-14 10:36:38.25541;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-36-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-36-05Z";57,2834;5,8361;34,4539;4,4895;32;16;8;4;0,2;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T10-36-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7a04eb60>";0,00100000004749745;"Experiment.R";2024-03-14 10:36:05.21558;2024-03-14 10:36:14.01761;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-36-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-35-55Z";53,2672;5,7465;32,628;4,4413;64;32;16;8;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-35-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7aaccc10>";0,00100000004749745;"Experiment.R";2024-03-14 10:35:55.48027;2024-03-14 10:36:05.10389;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-35-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-35-47Z";45,8847;5,2668;29,6074;4,2414;32;32;16;8;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-35-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7acdb8b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:35:47.1669;2024-03-14 10:35:55.37259;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-35-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-35-41Z";47,6519;5,409;32,9883;4,3269;64;16;16;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-35-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7ad2bdf0>";0,00100000004749745;"Experiment.R";2024-03-14 10:35:41.53889;2024-03-14 10:35:47.05624;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-35-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-35-30Z";45,416;5,3367;33,2252;4,4439;32;16;16;8;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T10-35-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7afc9150>";0,00100000004749745;"Experiment.R";2024-03-14 10:35:31.04262;2024-03-14 10:35:41.42262;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-35-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-35-21Z";47,2759;5,4145;32,6452;4,3058;64;32;8;8;0,2;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T10-35-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7b1e7ac0>";0,00100000004749745;"Experiment.R";2024-03-14 10:35:21.85154;2024-03-14 10:35:30.93744;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-35-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-35-12Z";48,8036;5,4899;34,0819;4,5268;32;32;8;8;0,2;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T10-35-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7b2438e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:35:12.88501;2024-03-14 10:35:21.7449;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-35-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-35-06Z";49,7757;5,5556;35,936;4,5209;64;16;8;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-35-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7abde7a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:35:06.67195;2024-03-14 10:35:12.77671;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-35-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-35-00Z";56,4223;5,8601;34,1859;4,4669;32;16;8;8;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-35-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7692fac0>";0,00100000004749745;"Experiment.R";2024-03-14 10:35:00.08757;2024-03-14 10:35:06.54786;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-35-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-34-41Z";172,1151;11,1841;129,9065;9,1802;64;32;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-34-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7b8d38e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:34:41.74341;2024-03-14 10:34:59.96017;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-34-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-34-33Z";55,807;5,808;31,6344;4,2976;32;32;16;4;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-34-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7b924a90>";0,00100000004749745;"Experiment.R";2024-03-14 10:34:33.81686;2024-03-14 10:34:41.63995;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-34-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-34-26Z";49,4628;5,5049;32,7232;4,403;64;16;16;4;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-34-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7bae3430>";0,00100000004749745;"Experiment.R";2024-03-14 10:34:26.49076;2024-03-14 10:34:33.71368;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-34-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-34-19Z";53,4063;5,6541;31,0728;4,2422;32;16;16;4;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-34-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8021f6d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:34:19.12333;2024-03-14 10:34:26.32512;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-34-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-34-08Z";48,8486;5,4287;36,6076;4,557;64;32;8;4;0,2;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T10-34-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7bfafa60>";0,00100000004749745;"Experiment.R";2024-03-14 10:34:08.65649;2024-03-14 10:34:19.01433;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-34-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-34-01Z";59,0086;6,0301;31,142;4,2421;32;32;8;4;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-34-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2fd6620>";0,00100000004749745;"Experiment.R";2024-03-14 10:34:02.03773;2024-03-14 10:34:08.5568;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-34-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-33-55Z";54,8843;5,7533;31,1876;4,3235;64;16;8;4;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-33-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e838294b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:33:55.23158;2024-03-14 10:34:01.88122;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-33-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-33-40Z";65,8749;6,2597;32,367;4,3482;32;16;8;4;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T10-33-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9ec8b35180>";0,00100000004749745;"Experiment.R";2024-03-14 10:33:40.8884;2024-03-14 10:33:55.12952;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-33-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-33-33Z";46,598;5,2774;34,2372;4,452;64;32;16;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-33-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96d108e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:33:33.98072;2024-03-14 10:33:40.78686;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-33-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-33-22Z";50,1576;5,5543;30,2154;4,2814;32;32;16;8;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-33-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1a56b30>";0,00100000004749745;"Experiment.R";2024-03-14 10:33:22.39669;2024-03-14 10:33:33.87604;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-33-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-33-09Z";47,9018;5,4506;34,4929;4,4681;64;16;16;8;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-33-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e57c400>";0,00100000004749745;"Experiment.R";2024-03-14 10:33:10.04992;2024-03-14 10:33:22.28998;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-33-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-33-02Z";48,8625;5,4877;32,2675;4,4298;32;16;16;8;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-33-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7ed06890>";0,00100000004749745;"Experiment.R";2024-03-14 10:33:02.48641;2024-03-14 10:33:09.93725;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-33-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-32-55Z";52,6963;5,6799;35,1237;4,492;64;32;8;8;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-32-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2324070>";0,00100000004749745;"Experiment.R";2024-03-14 10:32:55.38131;2024-03-14 10:33:02.30879;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-32-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-32-47Z";52,4185;5,6899;31,1968;4,2456;32;32;8;8;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-32-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0cf3280>";0,00100000004749745;"Experiment.R";2024-03-14 10:32:48.06599;2024-03-14 10:32:55.28213;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-32-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-32-43Z";54,58;5,6984;29,9568;4,1555;64;16;8;8;0,2;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T10-32-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1184c70>";0,00100000004749745;"Experiment.R";2024-03-14 10:32:43.28258;2024-03-14 10:32:47.9629;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-32-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-32-34Z";50,4374;5,5806;36,2457;4,5863;32;16;8;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-32-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e976b4f10>";0,00100000004749745;"Experiment.R";2024-03-14 10:32:34.76364;2024-03-14 10:32:43.18229;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-32-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-32-28Z";52,0278;5,6218;31,5478;4,3795;64;32;16;4;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-32-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e968dd450>";0,00100000004749745;"Experiment.R";2024-03-14 10:32:28.75248;2024-03-14 10:32:34.66108;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-32-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-32-22Z";56,6455;5,8796;31,2922;4,3277;32;32;16;4;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-32-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e966a1300>";0,00100000004749745;"Experiment.R";2024-03-14 10:32:22.62415;2024-03-14 10:32:28.65526;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-32-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-32-14Z";58,2976;5,9169;33,1649;4,4876;64;16;16;4;0,2;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-32-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94f59ff0>";0,00100000004749745;"Experiment.R";2024-03-14 10:32:14.97929;2024-03-14 10:32:22.52015;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-32-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-32-03Z";57,9887;5,7846;32,6231;4,363;32;16;16;4;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T10-32-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95d5d570>";0,00100000004749745;"Experiment.R";2024-03-14 10:32:03.30771;2024-03-14 10:32:14.82828;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-32-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-31-51Z";52,7145;5,6246;31,8749;4,3835;64;32;8;4;0,2;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-31-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e82cc96f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:31:51.17398;2024-03-14 10:32:03.15635;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-31-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-31-43Z";53,0865;5,6834;33,9282;4,4009;32;32;8;4;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T10-31-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94ccb760>";0,00100000004749745;"Experiment.R";2024-03-14 10:31:43.50866;2024-03-14 10:31:51.06936;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-31-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-31-34Z";50,3305;5,5343;35,5558;4,4913;64;16;8;4;0,2;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-31-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8138b790>";0,00100000004749745;"Experiment.R";2024-03-14 10:31:34.52904;2024-03-14 10:31:43.41223;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-31-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-31-25Z";53,3373;5,6992;30,9175;4,2223;32;16;8;4;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-31-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e834d9fc0>";0,00100000004749745;"Experiment.R";2024-03-14 10:31:25.88171;2024-03-14 10:31:34.42843;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-31-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-31-20Z";51,5928;5,6364;30,9188;4,3219;64;32;16;8;0,2;0,3;0,2;0,1;32;50;15;"runs/2024-03-14T10-31-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96731900>";0,00100000004749745;"Experiment.R";2024-03-14 10:31:20.87109;2024-03-14 10:31:25.78506;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-31-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-31-09Z";50,5722;5,5833;31,3233;4,3839;32;32;16;8;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T10-31-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e80248970>";0,00100000004749745;"Experiment.R";2024-03-14 10:31:09.91945;2024-03-14 10:31:20.76867;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-31-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-31-02Z";49,0782;5,4721;30,731;4,2551;64;16;16;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-31-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f8383a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:31:02.99232;2024-03-14 10:31:09.82308;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-31-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-30-57Z";51,418;5,5932;32,2275;4,3394;32;16;16;8;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-30-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e8aded0>";0,00100000004749745;"Experiment.R";2024-03-14 10:30:57.44945;2024-03-14 10:31:02.89105;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-30-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-30-49Z";51,0749;5,5841;30,0239;4,1789;64;32;8;8;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-30-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7ddeb7f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:30:49.65169;2024-03-14 10:30:57.35369;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-30-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-30-43Z";51,8638;5,6602;30,2468;4,2816;32;32;8;8;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-30-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb39f42b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:30:43.39745;2024-03-14 10:30:49.54062;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-30-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-30-34Z";55,5406;5,8766;32,2457;4,3241;64;16;8;8;0,2;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-30-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb3ce45e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:30:34.12273;2024-03-14 10:30:43.30163;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-30-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-30-25Z";49,8788;5,5227;31,4185;4,4376;32;16;8;8;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-30-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb25525c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:30:25.48714;2024-03-14 10:30:34.02564;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-30-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-30-19Z";54,1107;5,7149;28,9479;4,0982;64;32;16;4;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-30-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9ec8b36410>";0,00100000004749745;"Experiment.R";2024-03-14 10:30:19.84611;2024-03-14 10:30:25.39263;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-30-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-30-11Z";50,6896;5,5597;31,1013;4,3388;32;32;16;4;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-30-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1397220>";0,00100000004749745;"Experiment.R";2024-03-14 10:30:12.05383;2024-03-14 10:30:19.75099;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-30-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-30-06Z";62,4297;6,1486;31,557;4,2445;64;16;16;4;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-30-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0d183a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:30:06.17671;2024-03-14 10:30:11.95176;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-30-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-29-59Z";51,9927;5,5989;32,6034;4,4492;32;16;16;4;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-29-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e97926ec0>";0,00100000004749745;"Experiment.R";2024-03-14 10:29:59.54738;2024-03-14 10:30:06.0823;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-29-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-29-53Z";57,4182;5,9032;29,0554;4,1493;64;32;8;4;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-29-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96c04d00>";0,00100000004749745;"Experiment.R";2024-03-14 10:29:53.57631;2024-03-14 10:29:59.45389;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-29-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-29-46Z";58,4251;5,9342;32,2323;4,4435;32;32;8;4;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-29-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96220580>";0,00100000004749745;"Experiment.R";2024-03-14 10:29:46.36752;2024-03-14 10:29:53.48471;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-29-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-29-38Z";54,533;5,7483;32,3301;4,3828;64;16;8;4;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-29-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e9580bc40>";0,00100000004749745;"Experiment.R";2024-03-14 10:29:38.15387;2024-03-14 10:29:46.26713;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-29-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-29-21Z";172,1288;11,1845;129,921;9,1809;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-29-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94b2f220>";0,00100000004749745;"Experiment.R";2024-03-14 10:29:21.93398;2024-03-14 10:29:38.06135;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-29-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-29-17Z";51,6934;5,6327;29,7017;4,1792;64;32;16;8;0,2;0,3;0,2;0,1;32;50;13;"runs/2024-03-14T10-29-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e941373a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:29:17.24556;2024-03-14 10:29:21.84405;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-29-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-29-08Z";50,1432;5,5756;31,6988;4,2957;32;32;16;8;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-29-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e83870940>";0,00100000004749745;"Experiment.R";2024-03-14 10:29:08.25651;2024-03-14 10:29:17.12898;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-29-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-28-55Z";49,4688;5,4804;31,569;4,3389;64;16;16;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-28-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e82741690>";0,00100000004749745;"Experiment.R";2024-03-14 10:28:55.32945;2024-03-14 10:29:08.15783;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-28-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-28-42Z";49,3333;5,4844;32,1825;4,4068;32;16;16;8;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-28-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e80861ea0>";0,00100000004749745;"Experiment.R";2024-03-14 10:28:42.59706;2024-03-14 10:28:55.22533;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-28-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-28-35Z";54,6688;5,7517;33,7367;4,4119;64;32;8;8;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-28-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8112ac80>";0,00100000004749745;"Experiment.R";2024-03-14 10:28:35.8948;2024-03-14 10:28:42.49702;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-28-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-28-17Z";46,8481;5,3361;33,1789;4,3617;32;32;8;8;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T10-28-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7db60b50>";0,00100000004749745;"Experiment.R";2024-03-14 10:28:17.74515;2024-03-14 10:28:35.80622;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-28-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-28-11Z";55,8435;5,8616;36,5517;4,584;64;16;8;8;0,2;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-28-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7d3a3b80>";0,00100000004749745;"Experiment.R";2024-03-14 10:28:11.5189;2024-03-14 10:28:17.65923;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-28-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-28-04Z";49,6031;5,5106;34,8672;4,5744;32;16;8;8;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-28-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7dd9b8e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:28:04.52418;2024-03-14 10:28:11.42655;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-28-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-27-58Z";54,8195;5,8028;30,6733;4,1913;64;32;16;4;0,2;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-27-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7cc1e200>";0,00100000004749745;"Experiment.R";2024-03-14 10:27:58.47277;2024-03-14 10:28:04.40091;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-27-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-27-51Z";55,1514;5,7082;31,4764;4,3314;32;32;16;4;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-27-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e39d480>";0,00100000004749745;"Experiment.R";2024-03-14 10:27:51.86077;2024-03-14 10:27:58.38545;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-27-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-27-43Z";63,0983;6,0947;31,6694;4,2986;64;16;16;4;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T10-27-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e330b50>";0,00100000004749745;"Experiment.R";2024-03-14 10:27:43.99147;2024-03-14 10:27:51.73141;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-27-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-27-35Z";50,1864;5,546;32,0786;4,4024;32;16;16;4;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T10-27-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e55bdc0>";0,00100000004749745;"Experiment.R";2024-03-14 10:27:35.83627;2024-03-14 10:27:43.90896;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-27-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-27-28Z";61,7322;5,9625;33,1439;4,342;64;32;8;4;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-27-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e7cd2d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:27:28.77651;2024-03-14 10:27:35.75066;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-27-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-27-17Z";50,0444;5,5439;37,3053;4,6265;32;32;8;4;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-27-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7debf250>";0,00100000004749745;"Experiment.R";2024-03-14 10:27:17.90892;2024-03-14 10:27:28.69076;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-27-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-27-08Z";62,0256;6,2138;34,2623;4,4192;64;16;8;4;0,2;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-27-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7df2d2d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:27:08.6548;2024-03-14 10:27:17.81506;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-27-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-26-57Z";52,5037;5,6462;32,4481;4,3786;32;16;8;4;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T10-26-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7e8fffa0>";0,00100000004749745;"Experiment.R";2024-03-14 10:26:57.91817;2024-03-14 10:27:08.56083;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-26-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-26-46Z";56,2486;5,7687;30,1709;4,1834;64;32;16;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-26-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e80d86ef0>";0,00100000004749745;"Experiment.R";2024-03-14 10:26:46.95014;2024-03-14 10:26:57.82969;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-26-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-26-39Z";49,6422;5,4961;34,0372;4,5327;32;32;16;8;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-26-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7eee5300>";0,00100000004749745;"Experiment.R";2024-03-14 10:26:39.88515;2024-03-14 10:26:46.86289;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-26-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-26-32Z";54,8075;5,7244;33,7747;4,4724;64;16;16;8;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-26-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f2f3e20>";0,00100000004749745;"Experiment.R";2024-03-14 10:26:32.69751;2024-03-14 10:26:39.75269;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-26-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-26-25Z";46,8438;5,4361;32,0932;4,4374;32;16;16;8;0,1;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-26-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f3337c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:26:25.14908;2024-03-14 10:26:32.61626;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-26-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-26-19Z";49,0493;5,4572;33,8961;4,4076;64;32;8;8;0,1;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-26-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f5a89d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:26:19.71314;2024-03-14 10:26:25.06471;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-26-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-26-13Z";52,5533;5,6433;31,6474;4,3848;32;32;8;8;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-26-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f8eb7c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:26:13.20842;2024-03-14 10:26:19.62912;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-26-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-26-07Z";47,5983;5,4066;35,1779;4,5408;64;16;8;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-26-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f9c4100>";0,00100000004749745;"Experiment.R";2024-03-14 10:26:07.33628;2024-03-14 10:26:13.12747;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-26-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-26-00Z";51,2501;5,5977;31,2089;4,3016;32;16;8;8;0,1;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-26-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7f1f7e20>";0,00100000004749745;"Experiment.R";2024-03-14 10:26:00.75332;2024-03-14 10:26:07.25568;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-26-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-25-53Z";62,5453;6,0262;30,0496;4,2522;64;32;16;4;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-25-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7fa87280>";0,00100000004749745;"Experiment.R";2024-03-14 10:25:53.62973;2024-03-14 10:26:00.66884;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-25-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-25-41Z";62,2841;6,091;32,0366;4,3554;32;32;16;4;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-25-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7eb5e560>";0,00100000004749745;"Experiment.R";2024-03-14 10:25:41.65991;2024-03-14 10:25:53.55382;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-25-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-25-35Z";56,9532;5,9139;31,8065;4,374;64;16;16;4;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-25-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7ffd7280>";0,00100000004749745;"Experiment.R";2024-03-14 10:25:35.34432;2024-03-14 10:25:41.58164;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-25-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-25-29Z";56,9952;5,8515;30,2301;4,2288;32;16;16;4;0,1;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-25-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e801ab940>";0,00100000004749745;"Experiment.R";2024-03-14 10:25:29.44259;2024-03-14 10:25:35.26205;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-25-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-25-20Z";61,4697;6,0611;34,2378;4,375;64;32;8;4;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-25-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8021cbe0>";0,00100000004749745;"Experiment.R";2024-03-14 10:25:20.36862;2024-03-14 10:25:29.36125;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-25-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-25-10Z";50,9787;5,5856;31,4206;4,2654;32;32;8;4;0,1;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T10-25-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8046fc70>";0,00100000004749745;"Experiment.R";2024-03-14 10:25:10.54463;2024-03-14 10:25:20.28597;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-25-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-25-03Z";53,35;5,6906;33,8966;4,387;64;16;8;4;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-25-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7fc83880>";0,00100000004749745;"Experiment.R";2024-03-14 10:25:03.3837;2024-03-14 10:25:10.46808;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-25-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-24-55Z";56,2113;5,8471;32,1384;4,3238;32;16;8;4;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-24-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e83f15900>";0,00100000004749745;"Experiment.R";2024-03-14 10:24:55.83213;2024-03-14 10:25:03.27542;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-24-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-24-50Z";49,8884;5,5071;30,5923;4,182;64;32;16;8;0,1;0,3;0,2;0,1;32;50;13;"runs/2024-03-14T10-24-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8345dff0>";0,00100000004749745;"Experiment.R";2024-03-14 10:24:50.29383;2024-03-14 10:24:55.75248;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-24-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-24-44Z";50,4115;5,5559;30,6546;4,2302;32;32;16;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-24-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e809030d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:24:44.68093;2024-03-14 10:24:50.18961;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-24-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-24-37Z";49,9477;5,489;29,9931;4,2145;64;16;16;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-24-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e81134be0>";0,00100000004749745;"Experiment.R";2024-03-14 10:24:38.02386;2024-03-14 10:24:44.60238;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-24-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-24-32Z";50,6148;5,5041;32,2243;4,301;32;16;16;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-24-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e831e9c60>";0,00100000004749745;"Experiment.R";2024-03-14 10:24:32.25347;2024-03-14 10:24:37.94368;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-24-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-24-19Z";51,4982;5,5699;34,9732;4,457;64;32;8;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-24-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e80b227d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:24:19.8043;2024-03-14 10:24:32.17593;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-24-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-24-12Z";62,2884;6,0994;34,3268;4,4134;32;32;8;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-24-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e80d63940>";0,00100000004749745;"Experiment.R";2024-03-14 10:24:12.23527;2024-03-14 10:24:19.72843;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-24-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-24-07Z";53,9514;5,7317;35,5143;4,4811;64;16;8;8;0,1;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-24-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e81155420>";0,00100000004749745;"Experiment.R";2024-03-14 10:24:07.09826;2024-03-14 10:24:12.15978;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-24-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-23-52Z";49,1237;5,4971;32,6685;4,327;32;16;8;8;0,1;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T10-23-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8138bcd0>";0,00100000004749745;"Experiment.R";2024-03-14 10:23:52.546;2024-03-14 10:24:07.02366;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-23-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-23-42Z";49,4366;5,4777;29,7968;4,2192;64;32;16;4;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-23-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e81669120>";0,00100000004749745;"Experiment.R";2024-03-14 10:23:42.469;2024-03-14 10:23:52.46901;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-23-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-23-34Z";52,0489;5,6575;33,0748;4,336;32;32;16;4;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-23-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e815fc1c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:23:34.14163;2024-03-14 10:23:42.39518;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-23-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-23-28Z";56,1903;5,8766;32,9347;4,47;64;16;16;4;0,1;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-23-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e80e2fdc0>";0,00100000004749745;"Experiment.R";2024-03-14 10:23:28.21236;2024-03-14 10:23:34.06632;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-23-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-23-20Z";52,826;5,6671;29,5616;4,1421;32;16;16;4;0,1;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-23-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8188fa90>";0,00100000004749745;"Experiment.R";2024-03-14 10:23:20.26572;2024-03-14 10:23:28.07333;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-23-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-23-08Z";51,4693;5,6203;31,4623;4,3027;64;32;8;4;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-23-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e80877d00>";0,00100000004749745;"Experiment.R";2024-03-14 10:23:08.88928;2024-03-14 10:23:20.19571;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-23-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-23-02Z";55,3169;5,8141;32,3562;4,4172;32;32;8;4;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-23-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e81ae7a90>";0,00100000004749745;"Experiment.R";2024-03-14 10:23:02.17063;2024-03-14 10:23:08.81662;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-23-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-22-55Z";53,0504;5,6217;38,5758;4,7052;64;16;8;4;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-22-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e81ce32b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:22:55.12936;2024-03-14 10:23:02.10054;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-22-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-22-46Z";61,5386;6,1107;32,046;4,3017;32;16;8;4;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-22-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8256e110>";0,00100000004749745;"Experiment.R";2024-03-14 10:22:47.02189;2024-03-14 10:22:55.05815;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-22-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-22-41Z";50,1076;5,5313;30,0797;4,1741;64;32;16;8;0,1;0,3;0,2;0,1;32;50;15;"runs/2024-03-14T10-22-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e827a5540>";0,00100000004749745;"Experiment.R";2024-03-14 10:22:42.03358;2024-03-14 10:22:46.94658;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-22-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-22-35Z";46,7136;5,3402;29,932;4,2998;32;32;16;8;0,1;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-22-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e829ab610>";0,00100000004749745;"Experiment.R";2024-03-14 10:22:35.4775;2024-03-14 10:22:41.96477;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-22-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-22-27Z";45,8801;5,3148;33,4921;4,4084;64;16;16;8;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-22-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e82fd39d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:22:27.07473;2024-03-14 10:22:35.41078;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-22-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-22-17Z";45,85;5,3582;37,4447;4,6651;32;16;16;8;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T10-22-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e831eaa40>";0,00100000004749745;"Experiment.R";2024-03-14 10:22:17.509;2024-03-14 10:22:27.0064;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-22-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-22-07Z";50,4863;5,5519;33,6369;4,3765;64;32;8;8;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-22-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8323a260>";0,00100000004749745;"Experiment.R";2024-03-14 10:22:07.39816;2024-03-14 10:22:17.44015;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-22-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-22-00Z";43,9188;5,1666;31,9161;4,3268;32;32;8;8;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-22-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e834bc3d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:22:00.18615;2024-03-14 10:22:07.33007;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-22-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-21-51Z";51,6405;5,6249;40,0794;4,7943;64;16;8;8;0,1;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T10-21-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e836b76a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:21:51.46116;2024-03-14 10:22:00.11992;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-21-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-21-44Z";48,2936;5,4246;34,4644;4,4825;32;16;8;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-21-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e82b21240>";0,00100000004749745;"Experiment.R";2024-03-14 10:21:44.207;2024-03-14 10:21:51.39413;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-21-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-21-34Z";50,7465;5,5189;30,0582;4,1772;64;32;16;4;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T10-21-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8382be20>";0,00100000004749745;"Experiment.R";2024-03-14 10:21:34.64931;2024-03-14 10:21:44.13781;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-21-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-21-29Z";50,6494;5,5704;30,5619;4,2613;32;32;16;4;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-21-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e83a6bf40>";0,00100000004749745;"Experiment.R";2024-03-14 10:21:29.37095;2024-03-14 10:21:34.58381;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-21-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-21-16Z";58,3706;5,8434;34,6874;4,495;64;16;16;4;0,1;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T10-21-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e966a03d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:21:16.83159;2024-03-14 10:21:29.30216;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-21-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-21-03Z";51,3055;5,5724;32,8379;4,3414;32;16;16;4;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T10-21-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e9509f970>";0,00100000004749745;"Experiment.R";2024-03-14 10:21:03.3109;2024-03-14 10:21:16.76657;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-21-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-20-46Z";61,3485;6,1028;33,0391;4,3709;64;32;8;4;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-20-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95868be0>";0,00100000004749745;"Experiment.R";2024-03-14 10:20:46.80713;2024-03-14 10:21:03.23865;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-20-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-20-34Z";49,8887;5,4908;32,6982;4,3466;32;32;8;4;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T10-20-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e9676b8b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:20:34.74876;2024-03-14 10:20:46.74541;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-20-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-20-28Z";57,8967;5,9718;34,4982;4,459;64;16;8;4;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-20-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e82df6da0>";0,00100000004749745;"Experiment.R";2024-03-14 10:20:28.35131;2024-03-14 10:20:34.67749;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-20-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-20-06Z";49,0886;5,4554;30,5327;4,2585;32;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-20-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e837bb970>";0,00100000004749745;"Experiment.R";2024-03-14 10:20:06.6855;2024-03-14 10:20:28.28742;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-20-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-19-59Z";49,9301;5,4891;29,4454;4,149;64;32;16;8;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-19-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e941366e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:19:59.88261;2024-03-14 10:20:06.62389;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-19-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-19-51Z";51,2667;5,5419;31,1707;4,3002;32;32;16;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-19-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e9446f3a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:19:51.935;2024-03-14 10:19:59.81916;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-19-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-19-46Z";47,7961;5,4295;31,8947;4,3176;64;16;16;8;0,1;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T10-19-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e946775e0>";0,00100000004749745;"Experiment.R";2024-03-14 10:19:46.74757;2024-03-14 10:19:51.85089;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-19-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-19-40Z";49,6788;5,476;35,2261;4,5915;32;16;16;8;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-19-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e946fdcf0>";0,00100000004749745;"Experiment.R";2024-03-14 10:19:40.31393;2024-03-14 10:19:46.68799;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-19-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-19-31Z";48,85;5,3904;35,1492;4,498;64;32;8;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-19-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94b2ecb0>";0,00100000004749745;"Experiment.R";2024-03-14 10:19:31.98582;2024-03-14 10:19:40.22372;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-19-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-19-26Z";51,9053;5,6662;30,25;4,2799;32;32;8;8;0,1;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-19-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94f46e90>";0,00100000004749745;"Experiment.R";2024-03-14 10:19:26.19782;2024-03-14 10:19:31.92565;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-19-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-19-15Z";44,8136;5,2956;32,3455;4,3305;64;16;8;8;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T10-19-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94f58d90>";0,00100000004749745;"Experiment.R";2024-03-14 10:19:15.66465;2024-03-14 10:19:26.13762;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-19-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-19-10Z";52,7521;5,7359;35,0642;4,6079;32;16;8;8;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-19-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95377b50>";0,00100000004749745;"Experiment.R";2024-03-14 10:19:10.22675;2024-03-14 10:19:15.60697;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-19-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-19-01Z";52,8353;5,7025;29,8196;4,1655;64;32;16;4;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-19-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95419120>";0,00100000004749745;"Experiment.R";2024-03-14 10:19:01.62198;2024-03-14 10:19:10.16949;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-19-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-18-55Z";53,0955;5,6855;32,327;4,431;32;32;16;4;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-18-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95603b50>";0,00100000004749745;"Experiment.R";2024-03-14 10:18:55.67346;2024-03-14 10:19:01.56328;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-18-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-18-49Z";66,4747;6,2102;34,9162;4,4496;64;16;16;4;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-18-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e9586b910>";0,00100000004749745;"Experiment.R";2024-03-14 10:18:49.62451;2024-03-14 10:18:55.5997;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-18-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-18-41Z";54,8511;5,8377;31,318;4,3792;32;16;16;4;0,1;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-18-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e9504fdc0>";0,00100000004749745;"Experiment.R";2024-03-14 10:18:41.29312;2024-03-14 10:18:49.56798;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-18-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-18-29Z";55,5078;5,7825;28,8233;4,13;64;32;8;4;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-18-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95adcd90>";0,00100000004749745;"Experiment.R";2024-03-14 10:18:29.12246;2024-03-14 10:18:41.20164;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-18-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-18-21Z";57,2169;5,9349;30,9184;4,3336;32;32;8;4;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-18-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95cce110>";0,00100000004749745;"Experiment.R";2024-03-14 10:18:21.2873;2024-03-14 10:18:29.02806;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-18-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-18-07Z";172,1156;11,1844;129,9078;9,1802;64;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-18-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95ee3d00>";0,00100000004749745;"Experiment.R";2024-03-14 10:18:07.35684;2024-03-14 10:18:21.23203;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-18-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-17-57Z";54,9362;5,7495;31,1578;4,2598;32;16;8;4;0,1;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T10-17-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96166470>";0,00100000004749745;"Experiment.R";2024-03-14 10:17:57.1978;2024-03-14 10:18:07.29944;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-17-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-17-47Z";48,872;5,4269;31,378;4,3309;64;32;16;8;0,1;0,3;0,2;0,1;32;50;15;"runs/2024-03-14T10-17-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e963bf100>";0,00100000004749745;"Experiment.R";2024-03-14 10:17:47.91864;2024-03-14 10:17:57.12796;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-17-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-17-38Z";50,9876;5,5647;29,7204;4,1612;32;32;16;8;0,1;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T10-17-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e971cece0>";0,00100000004749745;"Experiment.R";2024-03-14 10:17:38.64431;2024-03-14 10:17:47.85574;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-17-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-17-33Z";48,539;5,4285;31,195;4,2752;64;16;16;8;0,1;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-17-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95bab9d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:17:33.57856;2024-03-14 10:17:38.58331;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-17-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-17-27Z";51,5642;5,5899;32,2646;4,3909;32;16;16;8;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-17-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9ec8cbf790>";0,00100000004749745;"Experiment.R";2024-03-14 10:17:27.29698;2024-03-14 10:17:33.51868;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-17-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-17-12Z";50,6103;5,6227;40,6475;4,8028;64;32;8;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-17-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e967320b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:17:12.74186;2024-03-14 10:17:25.05239;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-17-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-17-03Z";47,8278;5,4023;37,4512;4,675;32;32;8;8;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-17-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95f69420>";0,00100000004749745;"Experiment.R";2024-03-14 10:17:03.96711;2024-03-14 10:17:12.68172;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-17-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-16-57Z";49,3915;5,452;37,7903;4,6546;64;16;8;8;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-16-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e97975600>";0,00100000004749745;"Experiment.R";2024-03-14 10:16:57.47864;2024-03-14 10:17:03.91315;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-16-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-16-49Z";46,8165;5,3471;34,9843;4,5248;32;16;8;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-16-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96bf1330>";0,00100000004749745;"Experiment.R";2024-03-14 10:16:49.10667;2024-03-14 10:16:57.42235;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-16-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-16-41Z";53,869;5,7221;28,2285;4,0443;64;32;16;4;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-16-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e95bdb280>";0,00100000004749745;"Experiment.R";2024-03-14 10:16:41.61353;2024-03-14 10:16:49.05413;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-16-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-16-16Z";172,1195;11,1845;129,9117;9,1804;32;32;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-16-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94303940>";0,00100000004749745;"Experiment.R";2024-03-14 10:16:16.45982;2024-03-14 10:16:41.53457;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-16-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-16-04Z";53,3049;5,6809;30,9419;4,266;64;16;16;4;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-16-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96edfe80>";0,00100000004749745;"Experiment.R";2024-03-14 10:16:04.92233;2024-03-14 10:16:16.40785;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-16-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-15-57Z";61,4294;6,0982;32,954;4,359;32;16;16;4;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-15-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e971f1b40>";0,00100000004749745;"Experiment.R";2024-03-14 10:15:57.29383;2024-03-14 10:16:04.86857;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-15-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-15-50Z";56,0862;5,8158;29,5029;4,1808;64;32;8;4;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-15-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e971cdcf0>";0,00100000004749745;"Experiment.R";2024-03-14 10:15:50.56336;2024-03-14 10:15:57.23746;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-15-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-15-45Z";54,2133;5,7617;28,4576;4,1265;32;32;8;4;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-15-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e973fbca0>";0,00100000004749745;"Experiment.R";2024-03-14 10:15:45.13392;2024-03-14 10:15:50.51266;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-15-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-15-36Z";50,3499;5,5477;35,6761;4,552;64;16;8;4;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-15-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e976b7d30>";0,00100000004749745;"Experiment.R";2024-03-14 10:15:36.71004;2024-03-14 10:15:45.07691;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-15-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-15-22Z";172,1137;11,1842;129,9074;9,1802;32;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-15-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e97727c40>";0,00100000004749745;"Experiment.R";2024-03-14 10:15:22.99525;2024-03-14 10:15:36.65826;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-15-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-15-16Z";51,5031;5,635;30,0781;4,2322;64;32;16;8;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-15-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e979271c0>";0,00100000004749745;"Experiment.R";2024-03-14 10:15:16.1995;2024-03-14 10:15:22.94405;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-15-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-15-10Z";48,8178;5,4476;30,0396;4,1981;32;32;16;8;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-15-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e97bae230>";0,00100000004749745;"Experiment.R";2024-03-14 10:15:10.07299;2024-03-14 10:15:16.14979;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-15-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-15-00Z";47,7061;5,3756;29,7767;4,252;64;16;16;8;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T10-15-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e974f6ef0>";0,00100000004749745;"Experiment.R";2024-03-14 10:15:00.82018;2024-03-14 10:15:10.0208;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-15-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-14-53Z";48,1471;5,4218;33,8768;4,4553;32;16;16;8;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-14-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb34ad210>";0,00100000004749745;"Experiment.R";2024-03-14 10:14:53.40821;2024-03-14 10:15:00.76876;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-14-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-14-46Z";51,2062;5,5616;30,9394;4,2126;64;32;8;8;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-14-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0546950>";0,00100000004749745;"Experiment.R";2024-03-14 10:14:46.2663;2024-03-14 10:14:53.3549;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-14-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-14-39Z";49,9309;5,5318;29,2381;4,109;32;32;8;8;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-14-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1380250>";0,00100000004749745;"Experiment.R";2024-03-14 10:14:39.24892;2024-03-14 10:14:46.21465;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-14-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-14-29Z";54,2922;5,7812;31,8388;4,2608;64;16;8;8;0,1;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T10-14-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1ad4340>";0,00100000004749745;"Experiment.R";2024-03-14 10:14:29.38567;2024-03-14 10:14:39.194;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-14-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-14-20Z";52,925;5,6891;30,8582;4,245;32;16;8;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-14-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0877df0>";0,00100000004749745;"Experiment.R";2024-03-14 10:14:20.26775;2024-03-14 10:14:29.33576;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-14-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-14-06Z";49,5129;5,5117;32,069;4,3647;64;32;16;4;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T10-14-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0aa3fa0>";0,00100000004749745;"Experiment.R";2024-03-14 10:14:06.20563;2024-03-14 10:14:20.20271;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-14-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-13-57Z";49,4666;5,4897;29,4803;4,1562;32;32;16;4;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-13-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0b20e50>";0,00100000004749745;"Experiment.R";2024-03-14 10:13:57.50733;2024-03-14 10:14:06.15497;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-13-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-13-47Z";53,7413;5,7461;28,4015;4,0812;64;16;16;4;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T10-13-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0d1be50>";0,00100000004749745;"Experiment.R";2024-03-14 10:13:47.31935;2024-03-14 10:13:57.43352;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-13-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-13-36Z";50,987;5,5705;32,5785;4,3829;32;16;16;4;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T10-13-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb034b670>";0,00100000004749745;"Experiment.R";2024-03-14 10:13:36.93394;2024-03-14 10:13:47.27034;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-13-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-13-31Z";58,8849;6,045;33,2414;4,334;64;32;8;4;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-13-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb03ce3b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:13:31.02053;2024-03-14 10:13:36.88756;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-13-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-13-08Z";46,3224;5,2757;29,926;4,2136;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-13-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1185750>";0,00100000004749745;"Experiment.R";2024-03-14 10:13:08.99748;2024-03-14 10:13:30.97049;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-13-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-12-59Z";57,6003;5,9654;33,6551;4,3572;64;16;8;4;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-12-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1124970>";0,00100000004749745;"Experiment.R";2024-03-14 10:12:59.81985;2024-03-14 10:13:08.92351;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-12-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-12-51Z";50,2619;5,4995;34,8803;4,4467;32;16;8;4;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T10-12-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb136b430>";0,00100000004749745;"Experiment.R";2024-03-14 10:12:51.55931;2024-03-14 10:12:59.77407;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-12-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-12-41Z";44,9316;5,2435;30,851;4,3367;64;32;16;8;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T10-12-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9ec8a6a620>";0,00100000004749745;"Experiment.R";2024-03-14 10:12:41.41306;2024-03-14 10:12:51.51606;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-12-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-12-28Z";44,5695;5,2459;31,4471;4,2484;32;32;16;8;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-12-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb3fbb4f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:12:28.24934;2024-03-14 10:12:41.36746;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-12-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-12-20Z";47,477;5,4041;30,323;4,2148;64;16;16;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-12-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb238a320>";0,00100000004749745;"Experiment.R";2024-03-14 10:12:20.72763;2024-03-14 10:12:28.19589;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-12-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-12-14Z";50,6208;5,592;30,2236;4,1747;32;16;16;8;0,1;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-12-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9ec8a87c40>";0,00100000004749745;"Experiment.R";2024-03-14 10:12:14.32029;2024-03-14 10:12:20.51106;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-12-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-12-06Z";51,7048;5,5969;32,5579;4,2884;64;32;8;8;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-12-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1a8feb0>";0,00100000004749745;"Experiment.R";2024-03-14 10:12:06.87487;2024-03-14 10:12:14.26534;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-12-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-12-00Z";51,8503;5,6408;30,0702;4,2153;32;32;8;8;0,1;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-12-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1eab370>";0,00100000004749745;"Experiment.R";2024-03-14 10:12:00.55951;2024-03-14 10:12:06.82991;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-12-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-11-50Z";48,0955;5,4008;30,309;4,2307;64;16;8;8;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T10-11-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb32a2830>";0,00100000004749745;"Experiment.R";2024-03-14 10:11:50.61278;2024-03-14 10:12:00.50232;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-11-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-11-40Z";50,0105;5,5385;31,2839;4,3464;32;16;8;8;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T10-11-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2161ff0>";0,00100000004749745;"Experiment.R";2024-03-14 10:11:40.08868;2024-03-14 10:11:50.56607;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-11-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-11-30Z";57,8089;5,8459;34,7841;4,4304;64;32;16;4;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T10-11-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2347e20>";0,00100000004749745;"Experiment.R";2024-03-14 10:11:30.28395;2024-03-14 10:11:40.04464;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-11-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-11-20Z";57,7134;5,9195;32,4101;4,443;32;32;16;4;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-11-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb1b91ff0>";0,00100000004749745;"Experiment.R";2024-03-14 10:11:20.35474;2024-03-14 10:11:30.23803;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-11-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-11-08Z";54,4765;5,7487;33,9457;4,4694;64;16;16;4;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-11-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2583e20>";0,00100000004749745;"Experiment.R";2024-03-14 10:11:08.56543;2024-03-14 10:11:20.29837;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-11-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-10-57Z";49,9333;5,5386;32,9867;4,4352;32;16;16;4;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-10-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb27ab250>";0,00100000004749745;"Experiment.R";2024-03-14 10:10:57.64819;2024-03-14 10:11:08.5241;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-10-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-10-50Z";55,7524;5,8519;31,51;4,2199;64;32;8;4;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-10-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb162a2f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:10:50.31631;2024-03-14 10:10:57.60714;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-10-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-10-34Z";47,3512;5,3852;31,5613;4,2947;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T10-10-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb284f0d0>";0,00100000004749745;"Experiment.R";2024-03-14 10:10:34.94411;2024-03-14 10:10:50.27372;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-10-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-10-26Z";55,7226;5,8412;38,3157;4,6547;64;16;8;4;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T10-10-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2a577f0>";0,00100000004749745;"Experiment.R";2024-03-14 10:10:26.46665;2024-03-14 10:10:34.88399;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-10-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-10-19Z";59,9852;6,1156;33,9087;4,4258;32;16;8;4;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-10-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb3fbada0>";0,00100000004749745;"Experiment.R";2024-03-14 10:10:19.59172;2024-03-14 10:10:26.4225;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-10-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-10-13Z";50,4841;5,5616;29,0594;4,125;64;32;16;8;0,1;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T10-10-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb306baf0>";0,00100000004749745;"Experiment.R";2024-03-14 10:10:13.26452;2024-03-14 10:10:19.55228;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-10-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-10-05Z";49,3589;5,5104;30,5374;4,2272;32;32;16;8;0,1;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-10-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2d07df0>";0,00100000004749745;"Experiment.R";2024-03-14 10:10:05.2321;2024-03-14 10:10:13.2073;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-10-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-10-00Z";50,5578;5,5534;33,8666;4,4291;64;16;16;8;0,1;0,3;0,2;0,1;32;50;14;"runs/2024-03-14T10-10-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb301d8a0>";0,00100000004749745;"Experiment.R";2024-03-14 10:10:00.56335;2024-03-14 10:10:05.19102;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-10-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-09-52Z";45,1517;5,3092;34,1173;4,4133;32;16;16;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-09-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb32a0700>";0,00100000004749745;"Experiment.R";2024-03-14 10:09:52.91291;2024-03-14 10:10:00.52135;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-09-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-09-47Z";50,2027;5,5329;30,5695;4,283;64;32;8;8;0,1;0,3;0,2;0,1;32;50;15;"runs/2024-03-14T10-09-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb34affa0>";0,00100000004749745;"Experiment.R";2024-03-14 10:09:47.54775;2024-03-14 10:09:52.85369;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-09-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-09-40Z";46,9092;5,4021;32,8504;4,3393;32;32;8;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-09-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb36cfc40>";0,00100000004749745;"Experiment.R";2024-03-14 10:09:40.24624;2024-03-14 10:09:47.49303;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-09-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-09-30Z";55,5127;5,7412;40,2103;4,7733;64;16;8;8;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T10-09-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2e52680>";0,00100000004749745;"Experiment.R";2024-03-14 10:09:30.95344;2024-03-14 10:09:40.20697;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-09-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-09-23Z";50,636;5,5664;35,0546;4,5015;32;16;8;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T10-09-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb37a4ac0>";0,00100000004749745;"Experiment.R";2024-03-14 10:09:23.67341;2024-03-14 10:09:30.91437;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-09-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-09-17Z";51,52;5,6385;30,8852;4,241;64;32;16;4;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-09-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb3b811b0>";0,00100000004749745;"Experiment.R";2024-03-14 10:09:17.55943;2024-03-14 10:09:23.61694;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-09-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-09-11Z";52,2127;5,7024;34,3184;4,4442;32;32;16;4;0,1;0,3;0,2;0,1;32;50;18;"runs/2024-03-14T10-09-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb3dba830>";0,00100000004749745;"Experiment.R";2024-03-14 10:09:11.35565;2024-03-14 10:09:17.50077;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-09-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-09-05Z";58,9081;5,9306;34,1595;4,4504;64;16;16;4;0,1;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T10-09-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb3ff5f00>";0,00100000004749745;"Experiment.R";2024-03-14 10:09:05.08812;2024-03-14 10:09:11.3048;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-09-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-08-56Z";52,8611;5,6905;31,6768;4,2885;32;16;16;4;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T10-08-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0eee020>";0,00100000004749745;"Experiment.R";2024-03-14 10:08:56.52135;2024-03-14 10:09:05.05007;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-08-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-08-51Z";55,6781;5,79;31,7091;4,2611;64;32;8;4;0,1;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T10-08-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9ec88b4e50>";0,00100000004749745;"Experiment.R";2024-03-14 10:08:51.05613;2024-03-14 10:08:56.4804;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-08-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-08-43Z";56,9583;5,9623;31,4304;4,2894;32;32;8;4;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T10-08-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9ec8ab3e20>";0,00100000004749745;"Experiment.R";2024-03-14 10:08:43.95216;2024-03-14 10:08:51.01723;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-08-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-08-34Z";59,8796;6,0556;34,384;4,4432;64;16;8;4;0,1;0,3;0,2;0,1;32;50;17;"runs/2024-03-14T10-08-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9ec8ceffa0>";0,00100000004749745;"Experiment.R";2024-03-14 10:08:34.41686;2024-03-14 10:08:43.89889;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-08-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T10-08-27Z";50,8548;5,5603;31,0841;4,2205;32;16;8;4;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T10-08-27Z/tfruns.d/metrics.json";"Model: ""sequential_1""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_6 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_5 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_4 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_3 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense_2 (Dense)                    (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb0f7b010>";0,00100000004749745;"Experiment.R";2024-03-14 10:08:27.15793;2024-03-14 10:08:34.37832;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T10-08-27Z/tfruns.d/source.tar.gz";"local";"training"
