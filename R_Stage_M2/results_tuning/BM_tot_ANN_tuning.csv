"run_dir";"metric_loss";"metric_mae";"metric_val_loss";"metric_val_mae";"flag_dense_units1";"flag_dense_units2";"flag_dense_units3";"flag_dense_units4";"flag_dropout1";"flag_dropout2";"flag_dropout3";"flag_dropout4";"flag_batch_size";"epochs";"epochs_completed";"metrics";"model";"loss_function";"optimizer";"learning_rate";"script";"start";"end";"completed";"output";"source_code";"context";"type"
"runs/2024-03-14T13-14-39Z";15,3396;3,0632;14,6192;2,8868;64;32;16;8;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T13-14-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b8c6830>";0,00100000004749745;"Experiment.R";2024-03-14 13:14:40.4801;2024-03-14 13:14:45.92161;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-14-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-14-32Z";15,2048;3,0527;15,5266;3,0123;32;32;16;8;0,2;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T13-14-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b3c0d90>";0,00100000004749745;"Experiment.R";2024-03-14 13:14:32.90881;2024-03-14 13:14:39.96003;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-14-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-14-26Z";16,5865;3,2321;16,1735;3,1397;64;16;16;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T13-14-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5aceb2b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:14:27.21199;2024-03-14 13:14:32.41022;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-14-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-14-20Z";17,8673;3,3641;14,948;2,9938;32;16;16;8;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T13-14-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a5c40d0>";0,00100000004749745;"Experiment.R";2024-03-14 13:14:20.63453;2024-03-14 13:14:26.69357;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-14-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-14-13Z";16,1209;3,0894;17,9564;3,2792;64;32;8;8;0,2;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T13-14-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3c19fa60>";0,00100000004749745;"Experiment.R";2024-03-14 13:14:13.94353;2024-03-14 13:14:20.11106;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-14-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-14-05Z";17,9628;3,3303;14,8753;2,8935;32;32;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-14-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b58f190>";0,00100000004749745;"Experiment.R";2024-03-14 13:14:05.96108;2024-03-14 13:14:13.09208;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-14-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-13-58Z";19,2013;3,4111;19,4844;3,507;64;16;8;8;0,2;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T13-13-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e39ca00a0>";0,00100000004749745;"Experiment.R";2024-03-14 13:13:58.88233;2024-03-14 13:14:05.46615;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-13-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-13-52Z";18,6112;3,3728;18,2592;3,3604;32;16;8;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T13-13-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e39c85780>";0,00100000004749745;"Experiment.R";2024-03-14 13:13:53.11392;2024-03-14 13:13:58.3875;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-13-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-13-44Z";16,9174;3,1653;13,8278;2,8844;64;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-13-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e393ac580>";0,00100000004749745;"Experiment.R";2024-03-14 13:13:45.07305;2024-03-14 13:13:52.5876;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-13-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-13-37Z";16,5645;3,16;15,835;3,1065;32;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-13-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e387a33a0>";0,00100000004749745;"Experiment.R";2024-03-14 13:13:37.85547;2024-03-14 13:13:44.55414;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-13-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-13-25Z";22,3992;3,6541;17,7691;3,3138;64;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-13-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e379b0220>";0,00100000004749745;"Experiment.R";2024-03-14 13:13:25.67257;2024-03-14 13:13:37.36613;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-13-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-13-14Z";22,2308;3,5449;19,6246;3,5125;32;16;16;4;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T13-13-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37280640>";0,00100000004749745;"Experiment.R";2024-03-14 13:13:14.74197;2024-03-14 13:13:25.17483;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-13-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-13-06Z";23,0623;3,6667;18,086;3,3427;64;32;8;4;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T13-13-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e598432e0>";0,00100000004749745;"Experiment.R";2024-03-14 13:13:07.21771;2024-03-14 13:13:14.23003;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-13-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-12-54Z";17,6858;3,2478;15,2319;3,0406;32;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-12-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e0a3af0>";0,00100000004749745;"Experiment.R";2024-03-14 13:12:54.85433;2024-03-14 13:13:06.70844;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-12-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-12-48Z";24,8418;3,8473;18,5463;3,3945;64;16;8;4;0,2;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T13-12-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3fdb6ef0>";0,00100000004749745;"Experiment.R";2024-03-14 13:12:48.55839;2024-03-14 13:12:54.35561;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-12-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-12-41Z";21,9763;3,656;16,1872;3,1297;32;16;8;4;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T13-12-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f368d60>";0,00100000004749745;"Experiment.R";2024-03-14 13:12:41.81844;2024-03-14 13:12:48.03702;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-12-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-12-31Z";17,4612;3,3401;15,5568;3,0704;64;32;16;8;0,2;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T13-12-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e8b7eb0>";0,00100000004749745;"Experiment.R";2024-03-14 13:12:32.34579;2024-03-14 13:12:41.29854;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-12-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-12-24Z";16,1459;3,1628;14,616;2,9444;32;32;16;8;0,2;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T13-12-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e0a3760>";0,00100000004749745;"Experiment.R";2024-03-14 13:12:24.69768;2024-03-14 13:12:31.39207;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-12-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-12-14Z";16,1555;3,1502;19,6621;3,4761;64;16;16;8;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T13-12-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3d36b820>";0,00100000004749745;"Experiment.R";2024-03-14 13:12:14.54192;2024-03-14 13:12:24.17948;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-12-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-12-06Z";17,8016;3,322;16,0929;3,1279;32;16;16;8;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T13-12-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3cd8ce50>";0,00100000004749745;"Experiment.R";2024-03-14 13:12:06.64042;2024-03-14 13:12:14.02967;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-12-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-11-58Z";15,438;3,0925;19,8074;3,5144;64;32;8;8;0,2;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T13-11-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40f0b520>";0,00100000004749745;"Experiment.R";2024-03-14 13:11:59.29695;2024-03-14 13:12:06.07114;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-11-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-11-45Z";18,8753;3,3841;16,7188;3,2272;32;32;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-11-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e421045b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:11:45.93255;2024-03-14 13:11:58.80276;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-11-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-11-38Z";17,559;3,2202;15,3427;2,9838;64;16;8;8;0,2;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T13-11-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e409be650>";0,00100000004749745;"Experiment.R";2024-03-14 13:11:39.46234;2024-03-14 13:11:45.41239;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-11-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-11-31Z";15,9983;3,1786;17,4544;3,2928;32;16;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-11-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5947c5b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:11:31.87119;2024-03-14 13:11:38.93034;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-11-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-11-25Z";17,7291;3,3005;15,4265;3,0462;64;32;16;4;0,2;0,3;0,2;0,1;64;50;28;"runs/2024-03-14T13-11-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e586d71c0>";0,00100000004749745;"Experiment.R";2024-03-14 13:11:25.74411;2024-03-14 13:11:31.18761;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-11-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-11-12Z";78,7966;7,987;86,6054;8,3718;32;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-11-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e478f4fa0>";0,00100000004749745;"Experiment.R";2024-03-14 13:11:13.24699;2024-03-14 13:11:25.23821;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-11-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-11-04Z";18,9474;3,4104;16,2692;3,168;64;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-11-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4af7d540>";0,00100000004749745;"Experiment.R";2024-03-14 13:11:04.89163;2024-03-14 13:11:12.74275;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-11-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-10-57Z";16,2505;3,2127;15,7983;3,1064;32;16;16;4;0,2;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T13-10-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4c8d8670>";0,00100000004749745;"Experiment.R";2024-03-14 13:10:57.72037;2024-03-14 13:11:04.16699;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-10-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-10-49Z";25,5295;3,8728;16,7003;3,1549;64;32;8;4;0,2;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T13-10-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6adfdba0>";0,00100000004749745;"Experiment.R";2024-03-14 13:10:49.75815;2024-03-14 13:10:57.21031;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-10-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-10-36Z";20,0842;3,4892;17,6217;3,28;32;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-10-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4145b790>";0,00100000004749745;"Experiment.R";2024-03-14 13:10:37.20616;2024-03-14 13:10:49.24518;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-10-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-10-28Z";18,7308;3,3807;16,652;3,1996;64;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-10-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e432373a0>";0,00100000004749745;"Experiment.R";2024-03-14 13:10:29.26841;2024-03-14 13:10:36.70816;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-10-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-10-15Z";24,0933;3,7449;19,2524;3,4904;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-10-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e471e7c40>";0,00100000004749745;"Experiment.R";2024-03-14 13:10:16.55229;2024-03-14 13:10:28.40186;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-10-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-10-08Z";16,5071;3,1935;16,5553;3,1599;64;32;16;8;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T13-10-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e466bc9a0>";0,00100000004749745;"Experiment.R";2024-03-14 13:10:08.78618;2024-03-14 13:10:15.69442;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-10-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-09-50Z";17,5412;3,3273;15,1184;2,9576;32;32;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-09-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e57ab1180>";0,00100000004749745;"Experiment.R";2024-03-14 13:09:51.50899;2024-03-14 13:10:08.26142;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-09-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-09-43Z";17,7706;3,3318;15,4692;3,0025;64;16;16;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T13-09-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e586eb100>";0,00100000004749745;"Experiment.R";2024-03-14 13:09:44.31256;2024-03-14 13:09:50.7681;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-09-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-09-36Z";20,3836;3,5306;17,4841;3,2755;32;16;16;8;0,2;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T13-09-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e36d52ef0>";0,00100000004749745;"Experiment.R";2024-03-14 13:09:36.84905;2024-03-14 13:09:43.79559;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-09-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-09-23Z";15,5846;3,1217;15,0879;3,0169;64;32;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-09-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a72da80>";0,00100000004749745;"Experiment.R";2024-03-14 13:09:24.18954;2024-03-14 13:09:36.33941;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-09-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-09-11Z";17,8606;3,2751;16,4974;3,1955;32;32;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-09-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b68c670>";0,00100000004749745;"Experiment.R";2024-03-14 13:09:11.51817;2024-03-14 13:09:23.71036;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-09-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-08-56Z";16,5431;3,1806;20,4912;3,5608;64;16;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-08-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e36c430d0>";0,00100000004749745;"Experiment.R";2024-03-14 13:08:56.52753;2024-03-14 13:09:11.02388;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-08-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-08-48Z";18,0985;3,3008;18,7154;3,3828;32;16;8;8;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T13-08-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3635b010>";0,00100000004749745;"Experiment.R";2024-03-14 13:08:49.53101;2024-03-14 13:08:56.03942;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-08-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-08-42Z";18,7691;3,3213;15,1112;2,966;64;32;16;4;0,2;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T13-08-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e36f97e20>";0,00100000004749745;"Experiment.R";2024-03-14 13:08:42.5203;2024-03-14 13:08:48.68946;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-08-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-08-34Z";20,5413;3,4909;15,2998;3,0823;32;32;16;4;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T13-08-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3701e800>";0,00100000004749745;"Experiment.R";2024-03-14 13:08:35.12336;2024-03-14 13:08:42.01147;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-08-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-08-23Z";16,256;3,1357;16,1434;3,1199;64;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-08-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e374a1f00>";0,00100000004749745;"Experiment.R";2024-03-14 13:08:23.49043;2024-03-14 13:08:34.62467;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-08-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-08-16Z";18,9395;3,4012;14,9681;3,0154;32;16;16;4;0,2;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T13-08-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e375ae470>";0,00100000004749745;"Experiment.R";2024-03-14 13:08:16.55625;2024-03-14 13:08:22.97167;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-08-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-08-09Z";21,0973;3,544;18,5234;3,4004;64;32;8;4;0,2;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T13-08-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3765ff40>";0,00100000004749745;"Experiment.R";2024-03-14 13:08:10.39598;2024-03-14 13:08:16.03209;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-08-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-08-02Z";19,4196;3,4465;17,396;3,2321;32;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-08-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e364e2020>";0,00100000004749745;"Experiment.R";2024-03-14 13:08:03.1704;2024-03-14 13:08:09.87602;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-08-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-07-54Z";19,6202;3,4018;16,2717;3,1722;64;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-07-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e35d308b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:07:55.38937;2024-03-14 13:08:02.68971;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-07-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-07-45Z";25,5767;3,9646;21,3006;3,6582;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-07-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3772fe20>";0,00100000004749745;"Experiment.R";2024-03-14 13:07:46.16932;2024-03-14 13:07:54.89836;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-07-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-07-41Z";17,4504;3,2721;14,6297;2,9211;64;32;16;8;0,2;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T13-07-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37994a90>";0,00100000004749745;"Experiment.R";2024-03-14 13:07:41.73378;2024-03-14 13:07:45.65479;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-07-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-07-33Z";15,318;3,0619;15,8513;3,0152;32;32;16;8;0,2;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T13-07-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e350dfa90>";0,00100000004749745;"Experiment.R";2024-03-14 13:07:33.6285;2024-03-14 13:07:41.22405;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-07-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-07-27Z";16,0972;3,1284;15,3349;2,9736;64;16;16;8;0,2;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T13-07-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e38007d00>";0,00100000004749745;"Experiment.R";2024-03-14 13:07:27.81583;2024-03-14 13:07:33.12435;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-07-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-07-19Z";15,9213;3,1099;17,0265;3,2282;32;16;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-07-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e382883d0>";0,00100000004749745;"Experiment.R";2024-03-14 13:07:20.10965;2024-03-14 13:07:27.33714;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-07-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-07-14Z";17,8753;3,3518;14,8411;2,949;64;32;8;8;0,2;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T13-07-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e384931f0>";0,00100000004749745;"Experiment.R";2024-03-14 13:07:14.6523;2024-03-14 13:07:19.55512;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-07-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-07-06Z";17,1684;3,1791;14,428;2,9257;32;32;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-07-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e384fab60>";0,00100000004749745;"Experiment.R";2024-03-14 13:07:06.85909;2024-03-14 13:07:14.15159;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-07-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-06-54Z";17,1347;3,1976;16,1617;3,0521;64;16;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-06-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37a439d0>";0,00100000004749745;"Experiment.R";2024-03-14 13:06:54.55111;2024-03-14 13:07:06.38171;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-06-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-06-46Z";19,8824;3,5391;16,1053;3,0481;32;16;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-06-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37e11120>";0,00100000004749745;"Experiment.R";2024-03-14 13:06:47.32217;2024-03-14 13:06:54.07971;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-06-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-06-33Z";66,5705;7,2008;74,9389;7,6961;64;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-06-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37dcaec0>";0,00100000004749745;"Experiment.R";2024-03-14 13:06:34.30673;2024-03-14 13:06:46.51386;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-06-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-06-27Z";22,0606;3,6201;17,181;3,2315;32;32;16;4;0,2;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T13-06-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e38836800>";0,00100000004749745;"Experiment.R";2024-03-14 13:06:27.95056;2024-03-14 13:06:33.53283;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-06-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-06-20Z";17,4526;3,2802;15,8151;3,0997;64;16;16;4;0,2;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T13-06-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e38a32ec0>";0,00100000004749745;"Experiment.R";2024-03-14 13:06:20.96551;2024-03-14 13:06:27.49078;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-06-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-06-13Z";19,1631;3,3998;15,6889;3,0535;32;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-06-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e38ea2800>";0,00100000004749745;"Experiment.R";2024-03-14 13:06:13.50527;2024-03-14 13:06:20.18557;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-06-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-06-07Z";18,3609;3,312;15,7;3,0679;64;32;8;4;0,2;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T13-06-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e38ef3880>";0,00100000004749745;"Experiment.R";2024-03-14 13:06:07.44316;2024-03-14 13:06:13.02767;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-06-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-05-59Z";78,7814;7,9862;86,5904;8,3709;32;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-05-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e39103fa0>";0,00100000004749745;"Experiment.R";2024-03-14 13:06:00.39495;2024-03-14 13:06:06.96677;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-05-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-05-48Z";19,1757;3,4222;17,5701;3,2875;64;16;8;4;0,2;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T13-05-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e39389ff0>";0,00100000004749745;"Experiment.R";2024-03-14 13:05:49.26039;2024-03-14 13:05:59.9131;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-05-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-05-37Z";23,0927;3,6565;17,8398;3,3401;32;16;8;4;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T13-05-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e393d93f0>";0,00100000004749745;"Experiment.R";2024-03-14 13:05:37.76849;2024-03-14 13:05:48.76472;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-05-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-05-29Z";15,497;3,0852;15,9525;3,0361;64;32;16;8;0,2;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T13-05-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e37aeee60>";0,00100000004749745;"Experiment.R";2024-03-14 13:05:30.43115;2024-03-14 13:05:37.29227;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-05-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-05-17Z";16,1401;3,1591;16,7806;3,1783;32;32;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-05-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e38d27c40>";0,00100000004749745;"Experiment.R";2024-03-14 13:05:17.77374;2024-03-14 13:05:29.94697;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-05-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-05-07Z";19,4418;3,371;14,8796;2,9772;64;16;16;8;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T13-05-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e397716c0>";0,00100000004749745;"Experiment.R";2024-03-14 13:05:07.78382;2024-03-14 13:05:17.30575;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-05-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-04-55Z";16,4249;3,189;17,2961;3,2793;32;16;16;8;0,2;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T13-04-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e399b5030>";0,00100000004749745;"Experiment.R";2024-03-14 13:04:56.25723;2024-03-14 13:05:07.00283;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-04-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-04-48Z";17,806;3,3386;18,6032;3,353;64;32;8;8;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T13-04-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e39a3a020>";0,00100000004749745;"Experiment.R";2024-03-14 13:04:49.37475;2024-03-14 13:04:55.79424;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-04-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-04-42Z";14,6364;2,9825;19,3678;3,4497;32;32;8;8;0,2;0,3;0,2;0,1;64;50;43;"runs/2024-03-14T13-04-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e39c4bca0>";0,00100000004749745;"Experiment.R";2024-03-14 13:04:42.81066;2024-03-14 13:04:48.90048;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-04-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-04-35Z";19,1813;3,4204;17,7441;3,2629;64;16;8;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T13-04-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e39f73c40>";0,00100000004749745;"Experiment.R";2024-03-14 13:04:36.21094;2024-03-14 13:04:42.01364;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-04-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-04-23Z";15,4716;3,0546;16,7828;3,2194;32;16;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-04-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3a002320>";0,00100000004749745;"Experiment.R";2024-03-14 13:04:23.96764;2024-03-14 13:04:35.74565;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-04-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-04-11Z";18,2015;3,3461;16,393;3,1586;64;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-04-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3a549e40>";0,00100000004749745;"Experiment.R";2024-03-14 13:04:11.693;2024-03-14 13:04:23.49135;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-04-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-03-54Z";20,2992;3,4695;16,7604;3,183;32;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-03-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3a75fd90>";0,00100000004749745;"Experiment.R";2024-03-14 13:03:55.38499;2024-03-14 13:04:11.19758;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-03-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-03-47Z";20,143;3,4146;16,5329;3,1289;64;16;16;4;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T13-03-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3a7f2080>";0,00100000004749745;"Experiment.R";2024-03-14 13:03:48.07048;2024-03-14 13:03:54.90126;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-03-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-03-35Z";15,0793;3,0362;15,5581;3,0085;32;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-03-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3aa2f430>";0,00100000004749745;"Experiment.R";2024-03-14 13:03:35.89357;2024-03-14 13:03:47.57162;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-03-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-03-24Z";21,0516;3,6052;17,5293;3,2179;64;32;8;4;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T13-03-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3bb6c040>";0,00100000004749745;"Experiment.R";2024-03-14 13:03:25.3657;2024-03-14 13:03:35.4109;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-03-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-03-13Z";20,2548;3,4804;16,6729;3,1498;32;32;8;4;0,2;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T13-03-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3a42dc30>";0,00100000004749745;"Experiment.R";2024-03-14 13:03:13.77609;2024-03-14 13:03:24.61753;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-03-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-03-06Z";19,0715;3,4054;15,0592;2,991;64;16;8;4;0,2;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T13-03-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3ae039d0>";0,00100000004749745;"Experiment.R";2024-03-14 13:03:06.86033;2024-03-14 13:03:13.31161;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-03-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-02-54Z";17,822;3,3787;17,5423;3,268;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-02-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b0bbc10>";0,00100000004749745;"Experiment.R";2024-03-14 13:02:55.16993;2024-03-14 13:03:06.34361;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-02-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-02-47Z";17,2951;3,2259;14,7232;2,9577;64;32;16;8;0,2;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T13-02-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b2c3f40>";0,00100000004749745;"Experiment.R";2024-03-14 13:02:47.72845;2024-03-14 13:02:54.70634;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-02-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-02-35Z";15,5672;3,0758;15,7205;3,0335;32;32;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-02-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b33fc10>";0,00100000004749745;"Experiment.R";2024-03-14 13:02:35.44773;2024-03-14 13:02:47.25215;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-02-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-02-27Z";15,6049;3,0081;17,2635;3,2319;64;16;16;8;0,2;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T13-02-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b54be80>";0,00100000004749745;"Experiment.R";2024-03-14 13:02:28.15742;2024-03-14 13:02:34.98447;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-02-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-02-20Z";16,4755;3,1496;15,6624;3,0578;32;16;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-02-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b6e1150>";0,00100000004749745;"Experiment.R";2024-03-14 13:02:20.62667;2024-03-14 13:02:27.35672;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-02-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-02-12Z";17,0511;3,2324;17,9544;3,3367;64;32;8;8;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T13-02-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3b91a440>";0,00100000004749745;"Experiment.R";2024-03-14 13:02:13.31573;2024-03-14 13:02:20.15795;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-02-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-02-01Z";16,1245;3,1348;15,6967;3,0508;32;32;8;8;0,2;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T13-02-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3bb6fb80>";0,00100000004749745;"Experiment.R";2024-03-14 13:02:01.99373;2024-03-14 13:02:12.83094;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-02-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-01-54Z";18,1116;3,3675;16,4038;3,0777;64;16;8;8;0,2;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T13-01-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3bc0a7d0>";0,00100000004749745;"Experiment.R";2024-03-14 13:01:55.11792;2024-03-14 13:02:01.51989;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-01-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-01-48Z";18,7855;3,3685;16,3889;3,0694;32;16;8;8;0,2;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T13-01-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3be6f940>";0,00100000004749745;"Experiment.R";2024-03-14 13:01:48.92831;2024-03-14 13:01:54.6547;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-01-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-01-39Z";17,7491;3,3061;15,6955;3,0372;64;32;16;4;0,2;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T13-01-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3a11ada0>";0,00100000004749745;"Experiment.R";2024-03-14 13:01:39.89553;2024-03-14 13:01:48.46904;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-01-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-01-26Z";17,344;3,2594;16,4296;3,131;32;32;16;4;0,2;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T13-01-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3c05a6e0>";0,00100000004749745;"Experiment.R";2024-03-14 13:01:27.30275;2024-03-14 13:01:39.11213;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-01-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-01-20Z";16,8673;3,2709;15,9686;2,9997;64;16;16;4;0,2;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T13-01-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3c11bca0>";0,00100000004749745;"Experiment.R";2024-03-14 13:01:20.99128;2024-03-14 13:01:26.47893;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-01-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-01-12Z";17,0673;3,229;15,0569;2,9964;32;16;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-01-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3c2be290>";0,00100000004749745;"Experiment.R";2024-03-14 13:01:13.152;2024-03-14 13:01:20.52744;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-01-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-01-00Z";20,891;3,4769;14,2775;2,8804;64;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-01-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3c33e0b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:01:00.5354;2024-03-14 13:01:12.67792;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-01-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-00-53Z";21,6582;3,4913;18,8551;3,3889;32;32;8;4;0,2;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T13-00-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a58b640>";0,00100000004749745;"Experiment.R";2024-03-14 13:00:53.83107;2024-03-14 13:01:00.06131;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-00-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-00-45Z";19,5552;3,4109;17,7465;3,3034;64;16;8;4;0,2;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T13-00-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a61e050>";0,00100000004749745;"Experiment.R";2024-03-14 13:00:46.25461;2024-03-14 13:00:53.349;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-00-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-00-38Z";78,7888;7,9866;86,5979;8,3714;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-00-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5aa83400>";0,00100000004749745;"Experiment.R";2024-03-14 13:00:39.07362;2024-03-14 13:00:45.78917;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-00-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-00-32Z";16,2739;3,1975;15,1343;2,9888;64;32;16;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T13-00-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5acab5b0>";0,00100000004749745;"Experiment.R";2024-03-14 13:00:32.42905;2024-03-14 13:00:38.59863;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-00-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-00-23Z";17,2506;3,2254;16,4303;3,1765;32;32;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-00-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5ad4a410>";0,00100000004749745;"Experiment.R";2024-03-14 13:00:24.62387;2024-03-14 13:00:31.97145;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-00-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-00-18Z";15,6707;3,1107;15,278;3,052;64;16;16;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T13-00-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b1ab490>";0,00100000004749745;"Experiment.R";2024-03-14 13:00:18.67153;2024-03-14 13:00:23.82767;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-00-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T13-00-05Z";15,5793;3,1162;14,7763;2,9377;32;16;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T13-00-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b3dbca0>";0,00100000004749745;"Experiment.R";2024-03-14 13:00:06.3363;2024-03-14 13:00:18.21576;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T13-00-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-59-58Z";16,7725;3,1394;16,588;3,1161;64;32;8;8;0,2;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T12-59-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b67dab0>";0,00100000004749745;"Experiment.R";2024-03-14 12:59:59.23338;2024-03-14 13:00:05.86525;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-59-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-59-51Z";15,7396;3,0833;19,0325;3,4334;32;32;8;8;0,2;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T12-59-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b750400>";0,00100000004749745;"Experiment.R";2024-03-14 12:59:52.32819;2024-03-14 12:59:58.78217;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-59-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-59-46Z";19,5453;3,4757;18,6859;3,3977;64;16;8;8;0,2;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T12-59-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b8effa0>";0,00100000004749745;"Experiment.R";2024-03-14 12:59:46.85808;2024-03-14 12:59:51.85321;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-59-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-59-39Z";16,7717;3,1895;17,841;3,31;32;16;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-59-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5af6e650>";0,00100000004749745;"Experiment.R";2024-03-14 12:59:39.71189;2024-03-14 12:59:46.40848;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-59-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-59-28Z";18,933;3,395;16,5058;3,1698;64;32;16;4;0,2;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T12-59-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5b98b610>";0,00100000004749745;"Experiment.R";2024-03-14 12:59:28.95756;2024-03-14 12:59:39.2603;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-59-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-59-16Z";18,8646;3,3307;16,1585;3,0572;32;32;16;4;0,2;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T12-59-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a80e650>";0,00100000004749745;"Experiment.R";2024-03-14 12:59:17.30027;2024-03-14 12:59:28.49576;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-59-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-59-09Z";15,3158;3,0027;14,4;2,8704;64;16;16;4;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T12-59-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4f7e27a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:59:09.83478;2024-03-14 12:59:16.82452;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-59-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-59-03Z";19,5217;3,433;17,6859;3,3067;32;16;16;4;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T12-59-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e574f30a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:59:04.20724;2024-03-14 12:59:09.34961;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-59-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-58-55Z";17,4666;3,2881;16,1289;3,1416;64;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-58-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4aff3250>";0,00100000004749745;"Experiment.R";2024-03-14 12:58:56.3748;2024-03-14 12:59:03.74521;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-58-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-58-44Z";21,7904;3,6177;17,3992;3,2968;32;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-58-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b2aaa70>";0,00100000004749745;"Experiment.R";2024-03-14 12:58:44.47316;2024-03-14 12:58:55.91417;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-58-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-58-37Z";19,2237;3,3929;16,4186;3,1481;64;16;8;4;0,2;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T12-58-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a2d5c60>";0,00100000004749745;"Experiment.R";2024-03-14 12:58:37.93346;2024-03-14 12:58:43.99142;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-58-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-58-29Z";16,9477;3,1935;19,959;3,5076;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-58-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e500bf370>";0,00100000004749745;"Experiment.R";2024-03-14 12:58:29.91209;2024-03-14 12:58:37.46838;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-58-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-58-18Z";16,7274;3,1852;17,1693;3,2483;64;32;16;8;0,2;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T12-58-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e475cf070>";0,00100000004749745;"Experiment.R";2024-03-14 12:58:18.79151;2024-03-14 12:58:29.4519;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-58-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-58-12Z";16,214;3,1679;18,2457;3,3009;32;32;16;8;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T12-58-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e477de9b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:58:12.50983;2024-03-14 12:58:18.32803;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-58-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-58-05Z";15,1218;3,0479;15,9961;3,0309;64;16;16;8;0,2;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T12-58-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46281780>";0,00100000004749745;"Experiment.R";2024-03-14 12:58:06.30512;2024-03-14 12:58:12.05511;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-58-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-57-58Z";15,4591;3,0724;17,1226;3,2459;32;16;16;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-57-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59426590>";0,00100000004749745;"Experiment.R";2024-03-14 12:57:59.40469;2024-03-14 12:58:05.85903;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-57-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-57-47Z";17,2583;3,2579;16,0151;3,0871;64;32;8;8;0,2;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T12-57-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e493eb580>";0,00100000004749745;"Experiment.R";2024-03-14 12:57:47.51717;2024-03-14 12:57:58.64768;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-57-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-57-36Z";18,8223;3,3669;16,8338;3,1082;32;32;8;8;0,2;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T12-57-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e49ba9300>";0,00100000004749745;"Experiment.R";2024-03-14 12:57:36.66481;2024-03-14 12:57:47.06534;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-57-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-57-28Z";16,813;3,1551;19,5905;3,5072;64;16;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-57-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48384bb0>";0,00100000004749745;"Experiment.R";2024-03-14 12:57:29.05855;2024-03-14 12:57:36.19754;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-57-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-57-19Z";16,901;3,2137;21,8346;3,7478;32;16;8;8;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-57-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e466bdd20>";0,00100000004749745;"Experiment.R";2024-03-14 12:57:20.22868;2024-03-14 12:57:28.60904;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-57-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-57-15Z";20,1625;3,4975;18,164;3,351;64;32;16;4;0,2;0,3;0,2;0,1;64;50;22;"runs/2024-03-14T12-57-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79f29270>";0,00100000004749745;"Experiment.R";2024-03-14 12:57:15.89645;2024-03-14 12:57:19.76398;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-57-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-57-03Z";22,1301;3,5746;14,7859;2,9339;32;32;16;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-57-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e500a28c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:57:03.63335;2024-03-14 12:57:15.41114;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-57-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-56-51Z";16,6602;3,1295;15,2484;2,9358;64;16;16;4;0,2;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T12-56-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51780040>";0,00100000004749745;"Experiment.R";2024-03-14 12:56:51.63515;2024-03-14 12:57:03.17344;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-56-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-56-43Z";19,1296;3,4453;14,9983;2,9525;32;16;16;4;0,2;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T12-56-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59df7fd0>";0,00100000004749745;"Experiment.R";2024-03-14 12:56:44.62598;2024-03-14 12:56:51.17407;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-56-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-56-38Z";20,6913;3,5577;16,2291;3,0855;64;32;8;4;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T12-56-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e47e5fcd0>";0,00100000004749745;"Experiment.R";2024-03-14 12:56:39.10718;2024-03-14 12:56:43.86932;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-56-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-56-25Z";20,9629;3,576;16,2004;3,0634;32;32;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-56-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a358bb0>";0,00100000004749745;"Experiment.R";2024-03-14 12:56:25.76244;2024-03-14 12:56:38.6453;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-56-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-56-19Z";21,4071;3,6339;15,7164;3,1665;64;16;8;4;0,2;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T12-56-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60b46020>";0,00100000004749745;"Experiment.R";2024-03-14 12:56:20.33095;2024-03-14 12:56:25.31094;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-56-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-56-06Z";19,926;3,4064;18,726;3,3;32;16;8;4;0,2;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-56-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e612104c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:56:07.67018;2024-03-14 12:56:19.56128;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-56-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-56-00Z";14,9166;3,0347;14,4955;2,8411;64;32;16;8;0,1;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T12-56-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3cd12da0>";0,00100000004749745;"Experiment.R";2024-03-14 12:56:01.35243;2024-03-14 12:56:06.85094;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-56-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-55-54Z";15,2422;3,0479;15,5481;2,9811;32;32;16;8;0,1;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T12-55-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e52dea4d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:55:54.56547;2024-03-14 12:56:00.93093;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-55-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-55-47Z";15,0391;2,9839;15,7433;3,0737;64;16;16;8;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T12-55-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5218a290>";0,00100000004749745;"Experiment.R";2024-03-14 12:55:47.80982;2024-03-14 12:55:54.10081;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-55-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-55-39Z";17,4959;3,3179;17,482;3,1918;32;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-55-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e433a9a50>";0,00100000004749745;"Experiment.R";2024-03-14 12:55:40.12331;2024-03-14 12:55:47.37992;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-55-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-55-28Z";17,454;3,2852;15,015;2,9269;64;32;8;8;0,1;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T12-55-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42f12d10>";0,00100000004749745;"Experiment.R";2024-03-14 12:55:29.12315;2024-03-14 12:55:39.69405;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-55-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-55-17Z";16,7139;3,2053;16,2525;3,2088;32;32;8;8;0,1;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T12-55-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42c1bb50>";0,00100000004749745;"Experiment.R";2024-03-14 12:55:17.72617;2024-03-14 12:55:28.69116;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-55-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-55-10Z";16,666;3,1389;18,5781;3,3462;64;16;8;8;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T12-55-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42104700>";0,00100000004749745;"Experiment.R";2024-03-14 12:55:10.97669;2024-03-14 12:55:17.29941;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-55-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-55-03Z";19,1973;3,4304;17,5673;3,2855;32;16;8;8;0,1;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T12-55-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40310fa0>";0,00100000004749745;"Experiment.R";2024-03-14 12:55:04.15441;2024-03-14 12:55:10.53685;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-55-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-54-51Z";21,3073;3,4611;19,2382;3,4463;64;32;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-54-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e41a48b80>";0,00100000004749745;"Experiment.R";2024-03-14 12:54:51.94347;2024-03-14 12:55:03.71812;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-54-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-54-44Z";16,7204;3,1571;16,0236;3,1465;32;32;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-54-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4179a3b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:54:44.83987;2024-03-14 12:54:51.48755;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-54-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-54-38Z";16,5337;3,1296;17,5455;3,3199;64;16;16;4;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T12-54-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e414591e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:54:38.80714;2024-03-14 12:54:44.38812;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-54-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-54-31Z";18,5301;3,3033;15,1867;2,9932;32;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-54-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40f0be80>";0,00100000004749745;"Experiment.R";2024-03-14 12:54:31.91207;2024-03-14 12:54:38.37218;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-54-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-54-23Z";22,8223;3,6732;19,218;3,4862;64;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-54-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3fa45f90>";0,00100000004749745;"Experiment.R";2024-03-14 12:54:23.92545;2024-03-14 12:54:31.1746;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-54-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-54-15Z";18,3034;3,2842;16,9099;3,0997;32;32;8;4;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T12-54-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f8682b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:54:16.23943;2024-03-14 12:54:23.50574;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-54-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-54-03Z";78,7898;7,9867;86,5973;8,3714;64;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-54-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3ee23580>";0,00100000004749745;"Experiment.R";2024-03-14 12:54:03.50338;2024-03-14 12:54:15.59371;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-54-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-53-56Z";18,9855;3,4396;15,2375;2,9708;32;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-53-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e2fcf10>";0,00100000004749745;"Experiment.R";2024-03-14 12:53:56.42656;2024-03-14 12:54:03.06938;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-53-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-53-48Z";13,4521;2,8404;14,6379;2,8558;64;32;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-53-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3da14d60>";0,00100000004749745;"Experiment.R";2024-03-14 12:53:48.78288;2024-03-14 12:53:55.9711;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-53-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-53-36Z";15,5779;3,0874;13,7232;2,8454;32;32;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-53-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3ca8faf0>";0,00100000004749745;"Experiment.R";2024-03-14 12:53:36.54479;2024-03-14 12:53:48.35441;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-53-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-53-28Z";15,9546;3,1387;16,2018;3,1419;64;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-53-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e65cddbd0>";0,00100000004749745;"Experiment.R";2024-03-14 12:53:29.16008;2024-03-14 12:53:36.10498;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-53-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-53-20Z";18,1862;3,336;18,1223;3,3013;32;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-53-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5fe81930>";0,00100000004749745;"Experiment.R";2024-03-14 12:53:21.28942;2024-03-14 12:53:28.44068;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-53-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-53-14Z";17,9401;3,332;17,0041;3,169;64;32;8;8;0,1;0,3;0,2;0,1;64;50;25;"runs/2024-03-14T12-53-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4fb820e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:53:14.93102;2024-03-14 12:53:20.85715;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-53-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-53-09Z";21,0447;3,5784;17,218;3,2433;32;32;8;8;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T12-53-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4fbeab60>";0,00100000004749745;"Experiment.R";2024-03-14 12:53:10.2239;2024-03-14 12:53:14.49541;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-53-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-53-02Z";16,8093;3,1114;19,5011;3,4831;64;16;8;8;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T12-53-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a521f00>";0,00100000004749745;"Experiment.R";2024-03-14 12:53:02.65196;2024-03-14 12:53:09.78892;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-53-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-52-50Z";16,3679;3,1652;20,331;3,5808;32;16;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-52-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62bce740>";0,00100000004749745;"Experiment.R";2024-03-14 12:52:51.05938;2024-03-14 12:53:02.21216;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-52-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-52-39Z";16,8044;3,1955;15,9612;3,0221;64;32;16;4;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T12-52-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63ef2680>";0,00100000004749745;"Experiment.R";2024-03-14 12:52:39.85328;2024-03-14 12:52:50.63763;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-52-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-52-32Z";16,5271;3,1883;15,2708;3,0629;32;32;16;4;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T12-52-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62ec40a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:52:32.84344;2024-03-14 12:52:39.43749;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-52-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-52-24Z";78,795;7,9869;86,6007;8,3715;64;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-52-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61575330>";0,00100000004749745;"Experiment.R";2024-03-14 12:52:24.94109;2024-03-14 12:52:32.42769;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-52-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-52-08Z";19,4211;3,4389;15,2871;3,0707;32;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-52-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4ca5e5f0>";0,00100000004749745;"Experiment.R";2024-03-14 12:52:08.9826;2024-03-14 12:52:24.50486;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-52-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-52-00Z";24,1228;3,7516;16,3796;3,1509;64;32;8;4;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T12-52-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4bf811b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:52:01.32795;2024-03-14 12:52:08.54503;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-52-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-51-50Z";18,5259;3,3492;17,9005;3,3115;32;32;8;4;0,1;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T12-51-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b747580>";0,00100000004749745;"Experiment.R";2024-03-14 12:51:51.46659;2024-03-14 12:52:00.87989;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-51-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-51-43Z";18,871;3,3532;17,4505;3,2524;64;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-51-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e493975b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:51:44.18858;2024-03-14 12:51:50.9497;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-51-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-51-31Z";21,9647;3,6817;16,6345;3,1936;32;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-51-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a226980>";0,00100000004749745;"Experiment.R";2024-03-14 12:51:32.2848;2024-03-14 12:51:43.76926;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-51-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-51-24Z";15,0469;3,0207;15,8306;2,9944;64;32;16;8;0,1;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T12-51-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a04eda0>";0,00100000004749745;"Experiment.R";2024-03-14 12:51:24.90224;2024-03-14 12:51:31.86586;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-51-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-51-17Z";15,6163;3,1377;14,9713;2,8932;32;32;16;8;0,1;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T12-51-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46feb220>";0,00100000004749745;"Experiment.R";2024-03-14 12:51:17.94324;2024-03-14 12:51:24.47296;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-51-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-51-10Z";16,6468;3,2049;19,0684;3,4357;64;16;16;8;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T12-51-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48630280>";0,00100000004749745;"Experiment.R";2024-03-14 12:51:11.36207;2024-03-14 12:51:17.51849;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-51-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-50-54Z";21,203;3,5155;17,1397;3,2425;32;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-50-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48113190>";0,00100000004749745;"Experiment.R";2024-03-14 12:50:54.54264;2024-03-14 12:51:10.91504;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-50-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-50-46Z";14,3976;3,0064;15,7336;3,1049;64;32;8;8;0,1;0,3;0,2;0,1;64;50;39;"runs/2024-03-14T12-50-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4714f490>";0,00100000004749745;"Experiment.R";2024-03-14 12:50:46.99707;2024-03-14 12:50:54.11731;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-50-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-50-40Z";18,2452;3,3898;17,6452;3,2731;32;32;8;8;0,1;0,3;0,2;0,1;64;50;33;"runs/2024-03-14T12-50-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4636ee90>";0,00100000004749745;"Experiment.R";2024-03-14 12:50:41.24802;2024-03-14 12:50:46.58945;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-50-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-50-33Z";16,4517;3,1656;20,0926;3,54;64;16;8;8;0,1;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T12-50-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e467ac4c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:50:33.61637;2024-03-14 12:50:40.8086;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-50-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-50-22Z";17,6482;3,2722;16,23;3,1297;32;16;8;8;0,1;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T12-50-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8024b6a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:50:23.29265;2024-03-14 12:50:33.14711;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-50-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-50-15Z";16,3081;3,106;15,1802;3,025;64;32;16;4;0,1;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T12-50-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e678f6680>";0,00100000004749745;"Experiment.R";2024-03-14 12:50:15.98917;2024-03-14 12:50:22.85635;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-50-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-50-02Z";22,9783;3,6088;16,1591;3,1754;32;32;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-50-02Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e528915d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:50:03.45793;2024-03-14 12:50:15.57617;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-50-02Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-49-56Z";18,0314;3,3286;15,5209;3,0288;64;16;16;4;0,1;0,3;0,2;0,1;64;50;29;"runs/2024-03-14T12-49-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5f79abf0>";0,00100000004749745;"Experiment.R";2024-03-14 12:49:56.94439;2024-03-14 12:50:02.73876;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-49-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-49-43Z";18,1637;3,3399;15,8075;3,0006;32;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-49-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59713a60>";0,00100000004749745;"Experiment.R";2024-03-14 12:49:44.38308;2024-03-14 12:49:56.51394;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-49-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-49-30Z";19,8381;3,4573;15,2925;2,9945;64;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-49-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e506abf10>";0,00100000004749745;"Experiment.R";2024-03-14 12:49:30.55071;2024-03-14 12:49:43.93336;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-49-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-49-22Z";20,9729;3,5898;15,5127;3,0227;32;32;8;4;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T12-49-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e52882290>";0,00100000004749745;"Experiment.R";2024-03-14 12:49:23.21912;2024-03-14 12:49:30.13739;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-49-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-49-16Z";17,3242;3,2171;16,3759;3,1455;64;16;8;4;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T12-49-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42c90490>";0,00100000004749745;"Experiment.R";2024-03-14 12:49:17.17037;2024-03-14 12:49:22.80384;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-49-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-49-08Z";21,0679;3,523;17,8479;3,2943;32;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-49-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e41e0eef0>";0,00100000004749745;"Experiment.R";2024-03-14 12:49:08.47678;2024-03-14 12:49:16.74641;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-49-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-48-55Z";15,798;3,0977;14,3042;2,8664;64;32;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-48-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e409e7310>";0,00100000004749745;"Experiment.R";2024-03-14 12:48:55.70284;2024-03-14 12:49:08.03999;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-48-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-48-48Z";15,4971;3,0699;15,9753;3,0717;32;32;16;8;0,1;0,3;0,2;0,1;64;50;35;"runs/2024-03-14T12-48-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f348310>";0,00100000004749745;"Experiment.R";2024-03-14 12:48:49.11614;2024-03-14 12:48:55.28038;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-48-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-48-28Z";16,4292;3,1425;16,9607;3,1926;64;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-48-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5f5d03d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:48:29.35695;2024-03-14 12:48:48.42463;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-48-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-48-21Z";16,4696;3,1264;18,0631;3,2168;32;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-48-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5ed0d270>";0,00100000004749745;"Experiment.R";2024-03-14 12:48:21.71501;2024-03-14 12:48:28.93792;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-48-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-48-15Z";16,0675;3,1255;16,3411;3,144;64;32;8;8;0,1;0,3;0,2;0,1;64;50;40;"runs/2024-03-14T12-48-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5fa92770>";0,00100000004749745;"Experiment.R";2024-03-14 12:48:15.84171;2024-03-14 12:48:21.31148;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-48-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-48-07Z";18,4655;3,3519;15,1177;2,9943;32;32;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-48-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5fc82920>";0,00100000004749745;"Experiment.R";2024-03-14 12:48:07.75263;2024-03-14 12:48:15.42792;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-48-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-48-01Z";16,7905;3,2067;14,7597;2,9304;64;16;8;8;0,1;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T12-48-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5fef0a00>";0,00100000004749745;"Experiment.R";2024-03-14 12:48:02.05461;2024-03-14 12:48:07.33756;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-48-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-47-50Z";17,2643;3,2359;18,4825;3,3671;32;16;8;8;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T12-47-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e600d7850>";0,00100000004749745;"Experiment.R";2024-03-14 12:47:50.78704;2024-03-14 12:48:01.64805;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-47-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-47-44Z";16,9881;3,2339;15,5917;2,9843;64;32;16;4;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T12-47-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5dd13b80>";0,00100000004749745;"Experiment.R";2024-03-14 12:47:44.45041;2024-03-14 12:47:50.37642;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-47-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-47-37Z";22,6979;3,593;16,2864;3,1374;32;32;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-47-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5f79a740>";0,00100000004749745;"Experiment.R";2024-03-14 12:47:37.53744;2024-03-14 12:47:44.03677;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-47-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-47-29Z";16,9857;3,2455;15,7216;3,0056;64;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-47-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e601bff40>";0,00100000004749745;"Experiment.R";2024-03-14 12:47:29.82059;2024-03-14 12:47:37.12369;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-47-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-47-23Z";17,7689;3,2958;17,9963;3,3505;32;16;16;4;0,1;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T12-47-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3c55a110>";0,00100000004749745;"Experiment.R";2024-03-14 12:47:23.84113;2024-03-14 12:47:29.41102;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-47-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-47-15Z";19,2738;3,4564;14,7725;2,8953;64;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-47-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60482d70>";0,00100000004749745;"Experiment.R";2024-03-14 12:47:16.16337;2024-03-14 12:47:23.4335;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-47-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-47-03Z";16,7879;3,2593;13,9908;2,8891;32;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-47-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3c762b90>";0,00100000004749745;"Experiment.R";2024-03-14 12:47:04.01138;2024-03-14 12:47:15.73438;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-47-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-46-54Z";16,0988;3,1766;16,5482;3,1603;64;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-46-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3ceb5390>";0,00100000004749745;"Experiment.R";2024-03-14 12:46:54.65565;2024-03-14 12:47:03.59827;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-46-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-46-41Z";17,244;3,2064;15,7439;3,0689;32;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-46-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3cf5b3d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:46:42.36901;2024-03-14 12:46:54.24489;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-46-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-46-25Z";15,9027;3,1523;13,7657;2,8057;64;32;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-46-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3cf0fe50>";0,00100000004749745;"Experiment.R";2024-03-14 12:46:25.73501;2024-03-14 12:46:41.94123;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-46-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-46-17Z";14,6576;2,9636;17,2648;3,2321;32;32;16;8;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T12-46-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3d17a290>";0,00100000004749745;"Experiment.R";2024-03-14 12:46:18.25793;2024-03-14 12:46:25.31842;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-46-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-46-10Z";16,7361;3,2167;14,5574;2,8969;64;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-46-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3d36b0a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:46:10.87161;2024-03-14 12:46:17.85898;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-46-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-46-04Z";18,186;3,2667;16,0177;3,085;32;16;16;8;0,1;0,3;0,2;0,1;64;50;31;"runs/2024-03-14T12-46-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3c8de9e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:46:04.66558;2024-03-14 12:46:10.46957;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-46-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-45-58Z";15,8449;3,0933;16,1233;3,1535;64;32;8;8;0,1;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T12-45-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3cae38b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:45:58.94723;2024-03-14 12:46:04.23774;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-45-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-45-51Z";14,2433;2,9658;19,2489;3,4802;32;32;8;8;0,1;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T12-45-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3d96eb60>";0,00100000004749745;"Experiment.R";2024-03-14 12:45:51.82741;2024-03-14 12:45:58.52084;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-45-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-45-45Z";18,9269;3,3928;15,3905;3,0515;64;16;8;8;0,1;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T12-45-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3d96fe80>";0,00100000004749745;"Experiment.R";2024-03-14 12:45:46.2231;2024-03-14 12:45:51.41849;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-45-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-45-38Z";17,5858;3,2917;18,9012;3,3829;32;16;8;8;0,1;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T12-45-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3dbafa30>";0,00100000004749745;"Experiment.R";2024-03-14 12:45:38.98668;2024-03-14 12:45:45.83563;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-45-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-45-31Z";18,2999;3,3269;14,2145;2,9003;64;32;16;4;0,1;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T12-45-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3dc2afe0>";0,00100000004749745;"Experiment.R";2024-03-14 12:45:31.56653;2024-03-14 12:45:38.58668;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-45-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-45-26Z";18,4527;3,3826;17,8224;3,2464;32;32;16;4;0,1;0,3;0,2;0,1;64;50;24;"runs/2024-03-14T12-45-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3d43f430>";0,00100000004749745;"Experiment.R";2024-03-14 12:45:26.37769;2024-03-14 12:45:31.0885;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-45-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-45-13Z";14,6421;2,9704;14,5566;2,9525;64;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-45-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e0a11b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:45:14.1728;2024-03-14 12:45:25.96763;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-45-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-45-06Z";16,7452;3,1312;15,2886;3,0687;32;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-45-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e148e20>";0,00100000004749745;"Experiment.R";2024-03-14 12:45:07.1394;2024-03-14 12:45:13.77489;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-45-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-45-00Z";17,2574;3,2212;14,6791;2,8721;64;32;8;4;0,1;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T12-45-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e0fa980>";0,00100000004749745;"Experiment.R";2024-03-14 12:45:00.76262;2024-03-14 12:45:06.73468;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-45-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-44-53Z";20,5611;3,5921;15,4538;3,109;32;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-44-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e35a590>";0,00100000004749745;"Experiment.R";2024-03-14 12:44:53.69706;2024-03-14 12:45:00.35101;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-44-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-44-45Z";17,5692;3,2267;16,4054;3,09;64;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-44-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e547520>";0,00100000004749745;"Experiment.R";2024-03-14 12:44:46.02769;2024-03-14 12:44:53.03141;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-44-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-44-38Z";20,4061;3,5189;16,3107;3,0883;32;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-44-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3deabb50>";0,00100000004749745;"Experiment.R";2024-03-14 12:44:38.46253;2024-03-14 12:44:45.62512;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-44-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-44-31Z";14,6493;2,9763;17,5759;3,2732;64;32;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-44-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e8b6dd0>";0,00100000004749745;"Experiment.R";2024-03-14 12:44:31.64005;2024-03-14 12:44:38.06451;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-44-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-44-19Z";14,2535;2,9336;15,0066;3,0372;32;32;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-44-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e95e680>";0,00100000004749745;"Experiment.R";2024-03-14 12:44:19.93583;2024-03-14 12:44:31.22544;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-44-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-44-11Z";14,6901;2,9966;15,1232;3,0095;64;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-44-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3eb93700>";0,00100000004749745;"Experiment.R";2024-03-14 12:44:12.30282;2024-03-14 12:44:19.54708;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-44-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-44-04Z";15,2608;3,0497;16,9309;3,1858;32;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-44-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3eda3e50>";0,00100000004749745;"Experiment.R";2024-03-14 12:44:05.27932;2024-03-14 12:44:11.91701;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-44-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-43-54Z";18,5567;3,3242;15,9962;3,1709;64;32;8;8;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T12-43-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e712f80>";0,00100000004749745;"Experiment.R";2024-03-14 12:43:54.65837;2024-03-14 12:44:04.87265;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-43-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-43-47Z";18,6667;3,396;17,711;3,2468;32;32;8;8;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T12-43-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3e710430>";0,00100000004749745;"Experiment.R";2024-03-14 12:43:47.79509;2024-03-14 12:43:54.2367;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-43-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-43-35Z";16,0688;3,076;19,2236;3,4124;64;16;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-43-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f33fb50>";0,00100000004749745;"Experiment.R";2024-03-14 12:43:35.63491;2024-03-14 12:43:47.39373;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-43-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-43-28Z";16,7529;3,1617;19,1463;3,4118;32;16;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-43-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f3d5270>";0,00100000004749745;"Experiment.R";2024-03-14 12:43:28.622;2024-03-14 12:43:35.23897;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-43-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-43-22Z";18,6323;3,3603;16,0261;3,1003;64;32;16;4;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T12-43-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f7d3850>";0,00100000004749745;"Experiment.R";2024-03-14 12:43:22.59428;2024-03-14 12:43:28.22289;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-43-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-43-15Z";16,2891;3,1157;14,7116;2,9446;32;32;16;4;0,1;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T12-43-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f849270>";0,00100000004749745;"Experiment.R";2024-03-14 12:43:15.48764;2024-03-14 12:43:22.18061;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-43-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-43-07Z";17,4658;3,2134;15,8827;3,0517;64;16;16;4;0,1;0,3;0,2;0,1;64;50;49;"runs/2024-03-14T12-43-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3f0431c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:43:07.82169;2024-03-14 12:43:15.01255;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-43-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-42-55Z";78,7799;7,9861;86,5887;8,3708;32;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-42-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3fbce290>";0,00100000004749745;"Experiment.R";2024-03-14 12:42:55.68105;2024-03-14 12:43:07.42017;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-42-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-42-39Z";78,7856;7,9863;86,5906;8,371;64;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-42-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3fc17070>";0,00100000004749745;"Experiment.R";2024-03-14 12:42:39.48934;2024-03-14 12:42:55.2598;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-42-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-42-31Z";20,3156;3,5107;16,5559;3,1442;32;32;8;4;0,1;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T12-42-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e3fe27970>";0,00100000004749745;"Experiment.R";2024-03-14 12:42:32.19432;2024-03-14 12:42:39.06193;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-42-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-42-19Z";23,9172;3,8692;16,4682;3,159;64;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-42-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40073d60>";0,00100000004749745;"Experiment.R";2024-03-14 12:42:20.08026;2024-03-14 12:42:31.79783;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-42-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-42-07Z";21,5618;3,6334;18,4653;3,4038;32;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-42-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40100fa0>";0,00100000004749745;"Experiment.R";2024-03-14 12:42:07.53796;2024-03-14 12:42:19.69468;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-42-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-41-56Z";14,6061;2,9636;16,4322;3,1426;64;32;16;8;0,1;0,3;0,2;0,1;64;50;38;"runs/2024-03-14T12-41-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e405a2050>";0,00100000004749745;"Experiment.R";2024-03-14 12:41:57.22254;2024-03-14 12:42:07.15232;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-41-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-41-48Z";14,9205;3,0166;15,2939;3,0145;32;32;16;8;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T12-41-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40786860>";0,00100000004749745;"Experiment.R";2024-03-14 12:41:48.51913;2024-03-14 12:41:56.81983;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-41-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-41-43Z";17,5317;3,3008;15,5953;3,0735;64;16;16;8;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T12-41-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40794af0>";0,00100000004749745;"Experiment.R";2024-03-14 12:41:44.29453;2024-03-14 12:41:48.12387;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-41-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-41-36Z";16,4097;3,1379;14,8434;2,9241;32;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-41-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4081dcf0>";0,00100000004749745;"Experiment.R";2024-03-14 12:41:36.50276;2024-03-14 12:41:43.89946;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-41-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-41-29Z";16,6143;3,1526;16,9326;3,1665;64;32;8;8;0,1;0,3;0,2;0,1;64;50;46;"runs/2024-03-14T12-41-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40f5a0b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:41:30.06195;2024-03-14 12:41:36.10829;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-41-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-41-20Z";17,6832;3,286;16,4668;3,0993;32;32;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-41-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e41e4c040>";0,00100000004749745;"Experiment.R";2024-03-14 12:41:21.353;2024-03-14 12:41:29.67036;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-41-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-41-15Z";17,2172;3,2274;15,5164;3,0013;64;16;8;8;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T12-41-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e413ab970>";0,00100000004749745;"Experiment.R";2024-03-14 12:41:16.21539;2024-03-14 12:41:20.95095;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-41-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-41-10Z";19,1905;3,4159;16,3239;3,1759;32;16;8;8;0,1;0,3;0,2;0,1;64;50;26;"runs/2024-03-14T12-41-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4141af80>";0,00100000004749745;"Experiment.R";2024-03-14 12:41:10.81034;2024-03-14 12:41:15.81336;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-41-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-41-01Z";17,5785;3,3213;15,8566;3,1116;64;32;16;4;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T12-41-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4163faf0>";0,00100000004749745;"Experiment.R";2024-03-14 12:41:01.85115;2024-03-14 12:41:10.41634;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-41-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-40-53Z";18,8202;3,4029;15,0639;3,0091;32;32;16;4;0,1;0,3;0,2;0,1;64;50;48;"runs/2024-03-14T12-40-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e409e68f0>";0,00100000004749745;"Experiment.R";2024-03-14 12:40:54.28399;2024-03-14 12:41:01.24888;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-40-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-40-47Z";16,0468;3,1333;17,7947;3,3128;64;16;16;4;0,1;0,3;0,2;0,1;64;50;37;"runs/2024-03-14T12-40-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e40d03c10>";0,00100000004749745;"Experiment.R";2024-03-14 12:40:48.40243;2024-03-14 12:40:53.91216;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-40-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-40-40Z";15,8567;3,0927;17,6525;3,33;32;16;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-40-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4174f700>";0,00100000004749745;"Experiment.R";2024-03-14 12:40:40.90315;2024-03-14 12:40:47.76791;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-40-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-40-32Z";19,466;3,4502;14,7672;2,8862;64;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-40-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4196bd60>";0,00100000004749745;"Experiment.R";2024-03-14 12:40:33.24558;2024-03-14 12:40:40.51678;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-40-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-40-25Z";19,2161;3,3731;16,3837;3,1414;32;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-40-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e41cbcd30>";0,00100000004749745;"Experiment.R";2024-03-14 12:40:26.25677;2024-03-14 12:40:32.87061;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-40-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-40-18Z";18,8796;3,3769;15,7619;3,1105;64;16;8;4;0,1;0,3;0,2;0,1;64;50;45;"runs/2024-03-14T12-40-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e41c6b7f0>";0,00100000004749745;"Experiment.R";2024-03-14 12:40:18.50497;2024-03-14 12:40:25.88151;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-40-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-40-12Z";25,3025;3,9018;17,3543;3,2526;32;16;8;4;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T12-40-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e402e5360>";0,00100000004749745;"Experiment.R";2024-03-14 12:40:12.55556;2024-03-14 12:40:18.11675;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-40-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-40-01Z";16,3523;3,1298;16,4711;3,1189;64;32;16;8;0,1;0,3;0,2;0,1;64;50;30;"runs/2024-03-14T12-40-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e41e0fd90>";0,00100000004749745;"Experiment.R";2024-03-14 12:40:02.23318;2024-03-14 12:40:12.10794;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-40-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-39-55Z";15,4936;3,0531;14,3295;2,863;32;32;16;8;0,1;0,3;0,2;0,1;64;50;41;"runs/2024-03-14T12-39-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42096bc0>";0,00100000004749745;"Experiment.R";2024-03-14 12:39:55.58004;2024-03-14 12:40:01.86404;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-39-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-39-42Z";14,899;2,9943;16,3428;3,0434;64;16;16;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-39-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e422c2920>";0,00100000004749745;"Experiment.R";2024-03-14 12:39:43.24933;2024-03-14 12:39:55.21016;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-39-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-39-36Z";18,0335;3,3373;15,8907;3,102;32;16;16;8;0,1;0,3;0,2;0,1;64;50;32;"runs/2024-03-14T12-39-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4231fb50>";0,00100000004749745;"Experiment.R";2024-03-14 12:39:37.29005;2024-03-14 12:39:42.77323;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-39-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-39-30Z";18,0092;3,3536;15,8127;3,0946;64;32;8;8;0,1;0,3;0,2;0,1;64;50;36;"runs/2024-03-14T12-39-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e425bcb50>";0,00100000004749745;"Experiment.R";2024-03-14 12:39:31.16254;2024-03-14 12:39:36.91212;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-39-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-39-24Z";16,1742;3,1723;16,9338;3,2168;32;32;8;8;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T12-39-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42727bb0>";0,00100000004749745;"Experiment.R";2024-03-14 12:39:24.62747;2024-03-14 12:39:30.79327;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-39-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-39-17Z";16,8612;3,1639;17,157;3,2162;64;16;8;8;0,1;0,3;0,2;0,1;64;50;44;"runs/2024-03-14T12-39-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51f3f2b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:39:17.71038;2024-03-14 12:39:24.26868;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-39-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-39-08Z";15,9363;3,151;16,4389;3,1325;32;16;8;8;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-39-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42c01ab0>";0,00100000004749745;"Experiment.R";2024-03-14 12:39:08.93895;2024-03-14 12:39:17.33573;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-39-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-39-04Z";18,8824;3,423;19,0435;3,4055;64;32;16;4;0,1;0,3;0,2;0,1;64;50;21;"runs/2024-03-14T12-39-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42c18070>";0,00100000004749745;"Experiment.R";2024-03-14 12:39:04.82153;2024-03-14 12:39:08.58543;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-39-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-38-52Z";16,266;3,1969;14,6708;2,8799;32;32;16;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-38-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42e631c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:38:52.75096;2024-03-14 12:39:04.46076;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-38-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-38-46Z";15,9727;3,0799;16,2997;3,0805;64;16;16;4;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T12-38-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e41ce6800>";0,00100000004749745;"Experiment.R";2024-03-14 12:38:46.81086;2024-03-14 12:38:52.37997;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-38-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-38-35Z";18,9593;3,4194;16,0661;3,0703;32;16;16;4;0,1;0,3;0,2;0,1;64;50;34;"runs/2024-03-14T12-38-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e42f680a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:38:36.19503;2024-03-14 12:38:46.24423;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-38-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-38-29Z";20,4037;3,5399;15,2402;2,9086;64;32;8;4;0,1;0,3;0,2;0,1;64;50;42;"runs/2024-03-14T12-38-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4317be20>";0,00100000004749745;"Experiment.R";2024-03-14 12:38:29.46274;2024-03-14 12:38:35.80846;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-38-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-38-22Z";19,059;3,3699;13,7225;2,8611;32;32;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-38-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e43200af0>";0,00100000004749745;"Experiment.R";2024-03-14 12:38:22.70897;2024-03-14 12:38:29.07289;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-38-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-38-15Z";16,6949;3,1408;15,9998;3,0779;64;16;8;4;0,1;0,3;0,2;0,1;64;50;47;"runs/2024-03-14T12-38-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63f31de0>";0,00100000004749745;"Experiment.R";2024-03-14 12:38:15.46654;2024-03-14 12:38:22.34227;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-38-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-38-07Z";19,9118;3,4837;16,1526;3,1868;32;16;8;4;0,1;0,3;0,2;0,1;64;50;50;"runs/2024-03-14T12-38-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6a168e20>";0,00100000004749745;"Experiment.R";2024-03-14 12:38:08.00093;2024-03-14 12:38:15.11457;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-38-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-38-00Z";15,1514;2,9918;13,7099;2,798;64;32;16;8;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-38-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e530d7c70>";0,00100000004749745;"Experiment.R";2024-03-14 12:38:00.62517;2024-03-14 12:38:07.36921;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-38-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-37-53Z";18,0686;3,3265;15,0044;3,0249;32;32;16;8;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T12-37-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e523d7cd0>";0,00100000004749745;"Experiment.R";2024-03-14 12:37:54.20472;2024-03-14 12:38:00.24487;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-37-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-37-47Z";15,6688;3,0791;16,0702;3,1342;64;16;16;8;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T12-37-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e510dd240>";0,00100000004749745;"Experiment.R";2024-03-14 12:37:48.07709;2024-03-14 12:37:53.81962;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-37-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-37-35Z";14,8745;3,0141;14,8662;2,9319;32;16;16;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-37-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4fb81300>";0,00100000004749745;"Experiment.R";2024-03-14 12:37:36.04064;2024-03-14 12:37:47.71296;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-37-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-37-28Z";15,4694;3,0582;15,6575;3,0812;64;32;8;8;0,2;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T12-37-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e650f4040>";0,00100000004749745;"Experiment.R";2024-03-14 12:37:29.21635;2024-03-14 12:37:35.67356;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-37-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-37-19Z";13,6183;2,9082;15,841;3,1072;32;32;8;8;0,2;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-37-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51fbc220>";0,00100000004749745;"Experiment.R";2024-03-14 12:37:20.02556;2024-03-14 12:37:28.85845;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-37-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-37-10Z";15,2551;3,0211;18,9262;3,3917;64;16;8;8;0,2;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T12-37-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e50300dc0>";0,00100000004749745;"Experiment.R";2024-03-14 12:37:10.74702;2024-03-14 12:37:19.41368;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-37-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-37-01Z";17,8848;3,3116;16,796;3,263;32;16;8;8;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T12-37-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4fe13ee0>";0,00100000004749745;"Experiment.R";2024-03-14 12:37:01.68147;2024-03-14 12:37:10.36746;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-37-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-36-52Z";15,904;3,0755;16,1436;3,1021;64;32;16;4;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T12-36-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b7a2470>";0,00100000004749745;"Experiment.R";2024-03-14 12:36:53.15767;2024-03-14 12:37:01.31546;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-36-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-36-43Z";15,8003;3,1571;16,0274;3,0258;32;32;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-36-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59669570>";0,00100000004749745;"Experiment.R";2024-03-14 12:36:44.17462;2024-03-14 12:36:52.80878;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-36-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-36-36Z";16,2233;3,1181;16,7338;3,1661;64;16;16;4;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-36-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e580cb4f0>";0,00100000004749745;"Experiment.R";2024-03-14 12:36:36.81882;2024-03-14 12:36:43.79924;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-36-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-36-27Z";16,2361;3,1468;15,2097;3,0409;32;16;16;4;0,2;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T12-36-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e979278e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:36:28.01309;2024-03-14 12:36:36.45388;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-36-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-36-20Z";16,8685;3,2001;17,1841;3,2256;64;32;8;4;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T12-36-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4fda7c10>";0,00100000004749745;"Experiment.R";2024-03-14 12:36:21.28004;2024-03-14 12:36:27.66099;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-36-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-36-08Z";18,4133;3,308;16,8867;3,2519;32;32;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-36-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e65d48f70>";0,00100000004749745;"Experiment.R";2024-03-14 12:36:09.22632;2024-03-14 12:36:20.92461;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-36-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-35-54Z";17,0722;3,2015;15,7667;3,0763;64;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-35-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7afe3130>";0,00100000004749745;"Experiment.R";2024-03-14 12:35:55.21557;2024-03-14 12:36:08.84706;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-35-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-35-45Z";14,5488;2,9643;18,2994;3,373;32;16;8;4;0,2;0,3;0,2;0,1;32;50;48;"runs/2024-03-14T12-35-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69865a20>";0,00100000004749745;"Experiment.R";2024-03-14 12:35:45.84778;2024-03-14 12:35:54.5911;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-35-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-35-39Z";15,9875;3,1189;14,7683;2,8836;64;32;16;8;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T12-35-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69866da0>";0,00100000004749745;"Experiment.R";2024-03-14 12:35:39.84691;2024-03-14 12:35:45.49408;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-35-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-35-32Z";14,9837;3,0316;15,2834;2,9943;32;32;16;8;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-35-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b53ad70>";0,00100000004749745;"Experiment.R";2024-03-14 12:35:32.69271;2024-03-14 12:35:39.48898;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-35-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-35-24Z";15,9255;3,1124;17,4047;3,2792;64;16;16;8;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T12-35-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b35a410>";0,00100000004749745;"Experiment.R";2024-03-14 12:35:25.22513;2024-03-14 12:35:32.33638;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-35-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-35-19Z";19,2918;3,4329;14,2627;2,919;32;16;16;8;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T12-35-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a522260>";0,00100000004749745;"Experiment.R";2024-03-14 12:35:19.45839;2024-03-14 12:35:24.86042;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-35-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-35-11Z";17,2653;3,2541;15,5072;2,9787;64;32;8;8;0,2;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T12-35-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48988a00>";0,00100000004749745;"Experiment.R";2024-03-14 12:35:12.21259;2024-03-14 12:35:19.08223;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-35-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-34-58Z";13,5072;2,8677;16,3239;3,1731;32;32;8;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-34-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e488acb20>";0,00100000004749745;"Experiment.R";2024-03-14 12:34:58.51079;2024-03-14 12:35:11.85273;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-34-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-34-50Z";15,5396;3,1062;16,4759;3,1247;64;16;8;8;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T12-34-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e47ef2050>";0,00100000004749745;"Experiment.R";2024-03-14 12:34:51.0613;2024-03-14 12:34:58.15356;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-34-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-34-41Z";14,8926;3,0241;16,1178;3,1499;32;16;8;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-34-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46e77100>";0,00100000004749745;"Experiment.R";2024-03-14 12:34:42.0456;2024-03-14 12:34:50.69445;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-34-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-34-34Z";17,202;3,2094;16,4999;3,0635;64;32;16;4;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-34-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46764160>";0,00100000004749745;"Experiment.R";2024-03-14 12:34:34.55518;2024-03-14 12:34:41.42409;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-34-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-34-22Z";20,3434;3,446;16,8765;3,1789;32;32;16;4;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-34-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e591f4970>";0,00100000004749745;"Experiment.R";2024-03-14 12:34:22.97627;2024-03-14 12:34:34.18166;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-34-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-34-14Z";16,106;3,1249;14,6596;2,9159;64;16;16;4;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T12-34-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60cc0670>";0,00100000004749745;"Experiment.R";2024-03-14 12:34:14.97658;2024-03-14 12:34:22.61406;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-34-14Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-34-05Z";67,5663;7,2709;74,6768;7,6447;32;16;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-34-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63ca1ba0>";0,00100000004749745;"Experiment.R";2024-03-14 12:34:05.53698;2024-03-14 12:34:14.60204;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-34-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-33-57Z";16,269;3,16;16,3503;3,0643;64;32;8;4;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T12-33-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e646f0820>";0,00100000004749745;"Experiment.R";2024-03-14 12:33:57.61838;2024-03-14 12:34:05.16354;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-33-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-33-47Z";16,6274;3,1488;14,1455;2,8333;32;32;8;4;0,2;0,3;0,2;0,1;32;50;46;"runs/2024-03-14T12-33-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e950c51e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:33:48.06063;2024-03-14 12:33:57.24425;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-33-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-33-40Z";17,2017;3,2114;16,3933;3,1143;64;16;8;4;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-33-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e707a8c40>";0,00100000004749745;"Experiment.R";2024-03-14 12:33:40.72938;2024-03-14 12:33:47.71134;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-33-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-33-27Z";17,4206;3,2431;17,0763;3,2033;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-33-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6888c850>";0,00100000004749745;"Experiment.R";2024-03-14 12:33:27.73646;2024-03-14 12:33:40.11833;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-33-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-33-19Z";14,9031;3,0102;16,3165;3,1131;64;32;16;8;0,2;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-33-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e53838be0>";0,00100000004749745;"Experiment.R";2024-03-14 12:33:19.65453;2024-03-14 12:33:27.14318;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-33-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-33-10Z";17,8522;3,2953;15,6196;3,0006;32;32;16;8;0,2;0,3;0,2;0,1;32;50;19;"runs/2024-03-14T12-33-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e526822c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:33:10.62836;2024-03-14 12:33:19.28302;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-33-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-32-58Z";14,5173;2,9626;15,264;2,9489;64;16;16;8;0,2;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T12-32-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e52931900>";0,00100000004749745;"Experiment.R";2024-03-14 12:32:58.70835;2024-03-14 12:33:10.26184;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-32-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-32-45Z";14,9509;3,0013;16,3138;3,1036;32;16;16;8;0,2;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T12-32-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51f95e70>";0,00100000004749745;"Experiment.R";2024-03-14 12:32:46.24961;2024-03-14 12:32:58.33893;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-32-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-32-37Z";16,2306;3,1375;16,504;3,1446;64;32;8;8;0,2;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T12-32-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51376b90>";0,00100000004749745;"Experiment.R";2024-03-14 12:32:37.50298;2024-03-14 12:32:45.89103;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-32-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-32-24Z";16,4313;3,1632;14,6059;2,9862;32;32;8;8;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T12-32-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e501917b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:32:25.3438;2024-03-14 12:32:36.99888;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-32-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-32-16Z";16,6562;3,1879;17,0415;3,1376;64;16;8;8;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-32-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4fbcc910>";0,00100000004749745;"Experiment.R";2024-03-14 12:32:16.55208;2024-03-14 12:32:24.68084;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-32-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-32-05Z";15,746;3,086;15,3368;2,9663;32;16;8;8;0,2;0,3;0,2;0,1;32;50;48;"runs/2024-03-14T12-32-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4e494790>";0,00100000004749745;"Experiment.R";2024-03-14 12:32:06.10832;2024-03-14 12:32:16.18301;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-32-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-31-52Z";14,5667;3,0102;17,1327;3,2049;64;32;16;4;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T12-31-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e73bbbb50>";0,00100000004749745;"Experiment.R";2024-03-14 12:31:53.29448;2024-03-14 12:32:05.74256;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-31-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-31-43Z";16,7269;3,1993;15,5637;3,1114;32;32;16;4;0,2;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T12-31-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4886fd00>";0,00100000004749745;"Experiment.R";2024-03-14 12:31:43.85015;2024-03-14 12:31:52.9246;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-31-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-31-33Z";15,4212;3,0902;15,1248;3,0116;64;16;16;4;0,2;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T12-31-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5762f040>";0,00100000004749745;"Experiment.R";2024-03-14 12:31:34.08499;2024-03-14 12:31:43.47668;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-31-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-31-21Z";67,5821;7,272;74,6944;7,6457;32;16;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-31-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62a21660>";0,00100000004749745;"Experiment.R";2024-03-14 12:31:21.71899;2024-03-14 12:31:33.71879;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-31-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-31-11Z";19,0214;3,3675;15,3329;2,9544;64;32;8;4;0,2;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T12-31-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8021d1b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:31:12.5197;2024-03-14 12:31:21.36616;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-31-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-30-57Z";18,0248;3,3106;14,6575;2,9755;32;32;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-30-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e470a71c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:30:57.37563;2024-03-14 12:31:11.91251;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-30-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-30-46Z";18,9201;3,4579;17,3742;3,2892;64;16;8;4;0,2;0,3;0,2;0,1;32;50;16;"runs/2024-03-14T12-30-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e460f7e50>";0,00100000004749745;"Experiment.R";2024-03-14 12:30:47.19996;2024-03-14 12:30:56.97846;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-30-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-30-33Z";20,709;3,4753;16,6438;3,1445;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-30-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46280610>";0,00100000004749745;"Experiment.R";2024-03-14 12:30:33.49849;2024-03-14 12:30:46.6069;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-30-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-30-26Z";15,5498;3,0803;14,2902;2,8872;64;32;16;8;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-30-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4650dff0>";0,00100000004749745;"Experiment.R";2024-03-14 12:30:26.84354;2024-03-14 12:30:33.16658;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-30-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-30-17Z";14,3128;2,9577;13,9956;2,9349;32;32;16;8;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-30-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46707e20>";0,00100000004749745;"Experiment.R";2024-03-14 12:30:17.69556;2024-03-14 12:30:26.51732;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-30-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-30-12Z";16,5489;3,1553;18,4881;3,3346;64;16;16;8;0,2;0,3;0,2;0,1;32;50;20;"runs/2024-03-14T12-30-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46959ff0>";0,00100000004749745;"Experiment.R";2024-03-14 12:30:13.01355;2024-03-14 12:30:17.36693;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-30-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-29-59Z";14,3047;2,9677;15,019;3,0016;32;16;16;8;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T12-29-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46b73df0>";0,00100000004749745;"Experiment.R";2024-03-14 12:30:00.43266;2024-03-14 12:30:12.56944;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-29-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-29-53Z";17,3914;3,2219;16,4644;3,1722;64;32;8;8;0,2;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T12-29-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4636f880>";0,00100000004749745;"Experiment.R";2024-03-14 12:29:53.33647;2024-03-14 12:29:59.82686;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-29-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-29-44Z";14,0175;2,9163;17,7821;3,3054;32;32;8;8;0,2;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T12-29-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e463f6470>";0,00100000004749745;"Experiment.R";2024-03-14 12:29:45.03241;2024-03-14 12:29:52.99662;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-29-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-29-33Z";14,0211;2,8999;15,4622;3,0229;64;16;8;8;0,2;0,3;0,2;0,1;32;50;48;"runs/2024-03-14T12-29-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e45c1f130>";0,00100000004749745;"Experiment.R";2024-03-14 12:29:33.46384;2024-03-14 12:29:44.69034;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-29-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-29-24Z";14,841;3,0319;15,6188;3,0759;32;16;8;8;0,2;0,3;0,2;0,1;32;50;48;"runs/2024-03-14T12-29-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46e2fdc0>";0,00100000004749745;"Experiment.R";2024-03-14 12:29:24.94703;2024-03-14 12:29:33.12645;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-29-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-29-18Z";16,0415;3,0856;15,2239;3,0599;64;32;16;4;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T12-29-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e47167d60>";0,00100000004749745;"Experiment.R";2024-03-14 12:29:18.67844;2024-03-14 12:29:24.60578;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-29-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-29-11Z";15,3382;3,0132;15,6855;3,0246;32;32;16;4;0,2;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-29-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e473a9420>";0,00100000004749745;"Experiment.R";2024-03-14 12:29:11.62693;2024-03-14 12:29:18.33614;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-29-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-29-05Z";17,5063;3,246;15,14;3,0048;64;16;16;4;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T12-29-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48e4a1a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:29:05.62073;2024-03-14 12:29:11.0567;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-29-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-28-55Z";18,6215;3,2757;15,3737;3,0263;32;16;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-28-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e47acd330>";0,00100000004749745;"Experiment.R";2024-03-14 12:28:56.01659;2024-03-14 12:29:05.28871;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-28-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-28-45Z";14,5537;2,9923;15,8536;3,0337;64;32;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-28-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e47a5ffa0>";0,00100000004749745;"Experiment.R";2024-03-14 12:28:45.84265;2024-03-14 12:28:55.66018;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-28-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-28-39Z";17,1486;3,2486;17,1725;3,2409;32;32;8;4;0,2;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T12-28-39Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e47ec9150>";0,00100000004749745;"Experiment.R";2024-03-14 12:28:39.33818;2024-03-14 12:28:45.21513;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-28-39Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-28-29Z";19,9735;3,3875;18,0609;3,3134;64;16;8;4;0,2;0,3;0,2;0,1;32;50;49;"runs/2024-03-14T12-28-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e480a7a00>";0,00100000004749745;"Experiment.R";2024-03-14 12:28:29.81506;2024-03-14 12:28:38.97869;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-28-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-28-19Z";15,7053;3,0803;16,1687;3,077;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-28-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48111150>";0,00100000004749745;"Experiment.R";2024-03-14 12:28:20.26787;2024-03-14 12:28:29.47931;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-28-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-28-13Z";13,8409;2,9237;15,6952;3,074;64;32;16;8;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-28-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48326680>";0,00100000004749745;"Experiment.R";2024-03-14 12:28:13.52442;2024-03-14 12:28:19.85314;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-28-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-28-07Z";17,5472;3,2951;17,7801;3,2893;32;32;16;8;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T12-28-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e47b5be80>";0,00100000004749745;"Experiment.R";2024-03-14 12:28:07.90903;2024-03-14 12:28:13.16735;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-28-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-28-01Z";14,5211;2,9664;18,7288;3,3814;64;16;16;8;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T12-28-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e485e27a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:28:01.35456;2024-03-14 12:28:07.51128;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-28-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-27-51Z";17,0944;3,2036;16,7516;3,1287;32;16;16;8;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T12-27-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4741f910>";0,00100000004749745;"Experiment.R";2024-03-14 12:27:52.03054;2024-03-14 12:28:01.01167;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-27-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-27-46Z";16,1762;3,0838;19,7145;3,4803;64;32;8;8;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T12-27-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48633820>";0,00100000004749745;"Experiment.R";2024-03-14 12:27:46.5609;2024-03-14 12:27:51.68386;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-27-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-27-40Z";16,9523;3,1886;18,8721;3,4197;32;32;8;8;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T12-27-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4886fca0>";0,00100000004749745;"Experiment.R";2024-03-14 12:27:40.65495;2024-03-14 12:27:46.22451;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-27-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-27-34Z";15,3964;3,1208;19,4881;3,4291;64;16;8;8;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-27-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48c41120>";0,00100000004749745;"Experiment.R";2024-03-14 12:27:34.3353;2024-03-14 12:27:40.31304;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-27-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-27-26Z";15,3512;2,9741;18,0594;3,3042;32;16;8;8;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T12-27-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48dccac0>";0,00100000004749745;"Experiment.R";2024-03-14 12:27:26.39196;2024-03-14 12:27:34.0027;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-27-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-27-15Z";18,7495;3,3266;14,614;2,8678;64;32;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-27-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e48e0bd60>";0,00100000004749745;"Experiment.R";2024-03-14 12:27:15.54204;2024-03-14 12:27:26.02654;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-27-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-27-10Z";17,586;3,2286;16,7288;3,1768;32;32;16;4;0,2;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T12-27-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4907de70>";0,00100000004749745;"Experiment.R";2024-03-14 12:27:10.3684;2024-03-14 12:27:15.19565;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-27-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-26-58Z";17,973;3,2035;15,4787;3,052;64;16;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-26-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e49fbdd50>";0,00100000004749745;"Experiment.R";2024-03-14 12:26:58.39818;2024-03-14 12:27:10.03708;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-26-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-26-50Z";20,4087;3,441;17,4046;3,2646;32;16;16;4;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T12-26-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e46fea050>";0,00100000004749745;"Experiment.R";2024-03-14 12:26:50.6239;2024-03-14 12:26:58.05207;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-26-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-26-43Z";18,7174;3,3591;18,5693;3,3702;64;32;8;4;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-26-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e49532c50>";0,00100000004749745;"Experiment.R";2024-03-14 12:26:43.54236;2024-03-14 12:26:50.2997;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-26-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-26-29Z";15,8936;3,1146;14,7176;2,9316;32;32;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-26-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e49b37f70>";0,00100000004749745;"Experiment.R";2024-03-14 12:26:29.43165;2024-03-14 12:26:42.98608;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-26-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-26-18Z";17,3768;3,2753;15,0277;2,9375;64;16;8;4;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-26-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e49d77910>";0,00100000004749745;"Experiment.R";2024-03-14 12:26:18.86929;2024-03-14 12:26:29.1147;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-26-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-26-08Z";21,4775;3,5466;21,1055;3,6637;32;16;8;4;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T12-26-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e49e04bb0>";0,00100000004749745;"Experiment.R";2024-03-14 12:26:08.86928;2024-03-14 12:26:18.54893;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-26-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-25-55Z";13,9869;2,8922;14,0995;2,9377;64;32;16;8;0,2;0,3;0,2;0,1;32;50;44;"runs/2024-03-14T12-25-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a04fc40>";0,00100000004749745;"Experiment.R";2024-03-14 12:25:55.858;2024-03-14 12:26:08.33873;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-25-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-25-45Z";15,7123;3,0796;15,7306;3,1101;32;32;16;8;0,2;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-25-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4965b6a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:25:45.57918;2024-03-14 12:25:55.50081;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-25-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-25-37Z";14,1581;2,9382;16,1273;3,082;64;16;16;8;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T12-25-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4986bcd0>";0,00100000004749745;"Experiment.R";2024-03-14 12:25:37.79852;2024-03-14 12:25:45.02303;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-25-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-25-23Z";14,4851;2,9472;17,4343;3,2483;32;16;16;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-25-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a37d3c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:25:24.12984;2024-03-14 12:25:37.45872;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-25-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-25-16Z";16,2346;3,1609;17,4845;3,2074;64;32;8;8;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-25-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a30f580>";0,00100000004749745;"Experiment.R";2024-03-14 12:25:16.81109;2024-03-14 12:25:23.78426;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-25-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-25-04Z";15,7383;3,0907;18,3566;3,3596;32;32;8;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-25-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a580df0>";0,00100000004749745;"Experiment.R";2024-03-14 12:25:04.79736;2024-03-14 12:25:16.46917;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-25-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-24-58Z";15,2864;3,0304;14,6028;2,9351;64;16;8;8;0,2;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T12-24-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a77bc10>";0,00100000004749745;"Experiment.R";2024-03-14 12:24:58.83941;2024-03-14 12:25:04.45349;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-24-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-24-48Z";14,8584;3,005;16,7711;3,0915;32;16;8;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-24-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4a7ea680>";0,00100000004749745;"Experiment.R";2024-03-14 12:24:49.20994;2024-03-14 12:24:58.52465;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-24-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-24-35Z";14,0172;2,9305;14,4965;2,901;64;32;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-24-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4aa03e80>";0,00100000004749745;"Experiment.R";2024-03-14 12:24:36.1449;2024-03-14 12:24:48.88069;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-24-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-24-27Z";18,3321;3,3192;14,641;2,9715;32;32;16;4;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T12-24-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4ac3b3d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:24:28.20363;2024-03-14 12:24:35.82228;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-24-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-24-15Z";15,9022;3,1282;14,5065;2,8891;64;16;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-24-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4c3c4280>";0,00100000004749745;"Experiment.R";2024-03-14 12:24:15.51975;2024-03-14 12:24:27.88738;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-24-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-24-05Z";19,2438;3,4256;15,9217;3,107;32;16;16;4;0,2;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T12-24-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e49449240>";0,00100000004749745;"Experiment.R";2024-03-14 12:24:06.49078;2024-03-14 12:24:15.20282;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-24-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-23-55Z";18,856;3,3688;15,2275;3,0405;64;32;8;4;0,2;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T12-23-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4ae6be80>";0,00100000004749745;"Experiment.R";2024-03-14 12:23:55.47145;2024-03-14 12:24:05.91769;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-23-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-23-46Z";21,9072;3,5768;16,7;3,176;32;32;8;4;0,2;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T12-23-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b2bf3a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:23:47.28657;2024-03-14 12:23:55.14465;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-23-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-23-40Z";23,4072;3,8086;20,2779;3,5638;64;16;8;4;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T12-23-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b4bbe50>";0,00100000004749745;"Experiment.R";2024-03-14 12:23:41.18836;2024-03-14 12:23:46.94218;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-23-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-23-31Z";17,1956;3,2628;15,2791;2,987;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-23-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b8b6470>";0,00100000004749745;"Experiment.R";2024-03-14 12:23:31.90373;2024-03-14 12:23:40.62202;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-23-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-23-19Z";15,4965;3,0698;14,1501;2,8349;64;32;16;8;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-23-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b9b2680>";0,00100000004749745;"Experiment.R";2024-03-14 12:23:20.12542;2024-03-14 12:23:31.55633;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-23-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-23-12Z";15,9307;3,1061;14,6635;2,9353;32;32;16;8;0,2;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T12-23-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4ba39540>";0,00100000004749745;"Experiment.R";2024-03-14 12:23:13.0621;2024-03-14 12:23:19.80549;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-23-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-23-07Z";18,37;3,3332;15,7198;3,0721;64;16;16;8;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T12-23-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4bc4ba00>";0,00100000004749745;"Experiment.R";2024-03-14 12:23:08.25879;2024-03-14 12:23:12.73629;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-23-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-22-56Z";14,9492;2,9858;17,4569;3,2439;32;16;16;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-22-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4becd450>";0,00100000004749745;"Experiment.R";2024-03-14 12:22:56.31528;2024-03-14 12:23:07.94028;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-22-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-22-48Z";14,004;2,9044;17,2333;3,1927;64;32;8;8;0,2;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-22-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b6e75e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:22:48.85165;2024-03-14 12:22:55.99928;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-22-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-22-36Z";16,2011;3,1874;16,7085;3,207;32;32;8;8;0,2;0,3;0,2;0,1;32;50;44;"runs/2024-03-14T12-22-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4bf439a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:22:36.35952;2024-03-14 12:22:48.53399;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-22-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-22-23Z";15,0036;2,9946;18,3528;3,3522;64;16;8;8;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T12-22-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4afdcc40>";0,00100000004749745;"Experiment.R";2024-03-14 12:22:23.30024;2024-03-14 12:22:36.03904;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-22-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-22-16Z";18,3581;3,3443;17,7596;3,273;32;16;8;8;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-22-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4b03bcd0>";0,00100000004749745;"Experiment.R";2024-03-14 12:22:16.60055;2024-03-14 12:22:22.99037;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-22-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-22-09Z";18,2983;3,2995;16,288;3,0918;64;32;16;4;0,2;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T12-22-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4c3778e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:22:10.14393;2024-03-14 12:22:16.08112;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-22-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-22-01Z";19,449;3,4008;14,837;2,9652;32;32;16;4;0,2;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T12-22-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4c8843a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:22:02.15011;2024-03-14 12:22:09.82626;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-22-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-21-53Z";14,2904;2,9637;14,8195;2,9438;64;16;16;4;0,2;0,3;0,2;0,1;32;50;47;"runs/2024-03-14T12-21-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4cad4ac0>";0,00100000004749745;"Experiment.R";2024-03-14 12:21:53.5735;2024-03-14 12:22:01.83901;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-21-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-21-40Z";19,6375;3,3632;16,2614;3,1097;32;16;16;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-21-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4ca6c790>";0,00100000004749745;"Experiment.R";2024-03-14 12:21:40.71884;2024-03-14 12:21:53.02137;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-21-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-21-30Z";67,5701;7,2714;74,6822;7,645;64;32;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-21-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e677a9420>";0,00100000004749745;"Experiment.R";2024-03-14 12:21:31.15857;2024-03-14 12:21:40.16875;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-21-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-21-21Z";21,4319;3,4667;15,7029;2,98;32;32;8;4;0,2;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T12-21-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e643e0c70>";0,00100000004749745;"Experiment.R";2024-03-14 12:21:21.31812;2024-03-14 12:21:30.57438;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-21-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-21-12Z";19,4123;3,3713;17,9238;3,2995;64;16;8;4;0,2;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T12-21-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6288d510>";0,00100000004749745;"Experiment.R";2024-03-14 12:21:13.14881;2024-03-14 12:21:20.98661;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-21-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-21-00Z";16,4035;3,1827;16,1127;3,0944;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-21-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61330df0>";0,00100000004749745;"Experiment.R";2024-03-14 12:21:01.11476;2024-03-14 12:21:12.83985;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-21-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-20-55Z";16,3568;3,1191;15,7632;3,0816;64;32;16;8;0,2;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T12-20-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5a09e140>";0,00100000004749745;"Experiment.R";2024-03-14 12:20:55.75441;2024-03-14 12:21:00.81215;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-20-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-20-46Z";16,3094;3,131;14,5174;2,9014;32;32;16;8;0,2;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T12-20-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e58dc6fe0>";0,00100000004749745;"Experiment.R";2024-03-14 12:20:46.58355;2024-03-14 12:20:55.4528;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-20-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-20-40Z";16,4841;3,2062;17,3788;3,2487;64;16;16;8;0,2;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T12-20-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e55c48820>";0,00100000004749745;"Experiment.R";2024-03-14 12:20:41.153;2024-03-14 12:20:46.27008;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-20-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-20-26Z";13,6229;2,8677;13,8564;2,8303;32;16;16;8;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-20-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62e3f280>";0,00100000004749745;"Experiment.R";2024-03-14 12:20:27.27174;2024-03-14 12:20:40.81857;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-20-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-20-16Z";16,0635;3,1516;16,7488;3,1351;64;32;8;8;0,2;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-20-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63d65510>";0,00100000004749745;"Experiment.R";2024-03-14 12:20:17.06013;2024-03-14 12:20:26.74491;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-20-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-20-08Z";15,9304;3,1171;16,5849;3,1725;32;32;8;8;0,2;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T12-20-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59226140>";0,00100000004749745;"Experiment.R";2024-03-14 12:20:08.87159;2024-03-14 12:20:16.74634;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-20-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-19-59Z";16,2506;3,1696;15,6048;3,0509;64;16;8;8;0,2;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T12-19-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63ac7d30>";0,00100000004749745;"Experiment.R";2024-03-14 12:20:00.27924;2024-03-14 12:20:08.54199;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-19-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-19-50Z";16,0138;3,1035;15,3323;3,0888;32;16;8;8;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T12-19-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77e71f00>";0,00100000004749745;"Experiment.R";2024-03-14 12:19:50.99947;2024-03-14 12:19:59.94548;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-19-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-19-37Z";16,8209;3,193;14,7621;2,9242;64;32;16;4;0,2;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T12-19-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7eb5ce50>";0,00100000004749745;"Experiment.R";2024-03-14 12:19:37.56611;2024-03-14 12:19:50.46617;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-19-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-19-27Z";17,7717;3,2486;15,6292;3,0245;32;32;16;4;0,2;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T12-19-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6963da80>";0,00100000004749745;"Experiment.R";2024-03-14 12:19:28.18956;2024-03-14 12:19:36.97301;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-19-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-19-17Z";19,6874;3,3435;17,4431;3,2319;64;16;16;4;0,2;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T12-19-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6bded690>";0,00100000004749745;"Experiment.R";2024-03-14 12:19:17.51666;2024-03-14 12:19:27.8855;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-19-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-19-04Z";15,1688;3,0141;15,7889;3,0543;32;16;16;4;0,2;0,3;0,2;0,1;32;50;49;"runs/2024-03-14T12-19-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e68c061a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:19:04.89942;2024-03-14 12:19:17.19274;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-19-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-18-56Z";20,3231;3,5344;15,4578;3,0057;64;32;8;4;0,2;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T12-18-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60fef190>";0,00100000004749745;"Experiment.R";2024-03-14 12:18:56.45209;2024-03-14 12:19:04.34065;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-18-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-18-48Z";17,4929;3,2496;14,6197;2,9438;32;32;8;4;0,2;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-18-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e709d7c70>";0,00100000004749745;"Experiment.R";2024-03-14 12:18:49.39151;2024-03-14 12:18:56.06168;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-18-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-18-36Z";19,2937;3,4387;14,3395;2,9015;64;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-18-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e74cbc520>";0,00100000004749745;"Experiment.R";2024-03-14 12:18:36.82118;2024-03-14 12:18:48.90098;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-18-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-18-22Z";17,0686;3,1884;15,0993;2,9259;32;16;8;4;0,2;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-18-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e73f92050>";0,00100000004749745;"Experiment.R";2024-03-14 12:18:22.61353;2024-03-14 12:18:36.29992;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-18-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-18-15Z";15,1808;3,0243;18,031;3,2966;64;32;16;8;0,1;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-18-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5272db70>";0,00100000004749745;"Experiment.R";2024-03-14 12:18:15.34536;2024-03-14 12:18:22.30961;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-18-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-18-05Z";13,9147;2,9469;14,7564;2,9081;32;32;16;8;0,1;0,3;0,2;0,1;32;50;44;"runs/2024-03-14T12-18-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5216d7e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:18:06.12728;2024-03-14 12:18:15.0416;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-18-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-17-55Z";13,8191;2,8755;17,6537;3,2636;64;16;16;8;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-17-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e50f453f0>";0,00100000004749745;"Experiment.R";2024-03-14 12:17:55.34586;2024-03-14 12:18:05.71248;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-17-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-17-44Z";14,7727;3,0014;15,4756;3,0745;32;16;16;8;0,1;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T12-17-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e508db610>";0,00100000004749745;"Experiment.R";2024-03-14 12:17:45.10882;2024-03-14 12:17:55.03605;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-17-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-17-38Z";20,9519;3,522;17,3801;3,2448;64;32;8;8;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T12-17-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4f8aca60>";0,00100000004749745;"Experiment.R";2024-03-14 12:17:39.1344;2024-03-14 12:17:44.79556;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-17-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-17-26Z";12,8595;2,8182;14,9694;2,9531;32;32;8;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-17-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e69cc6ec0>";0,00100000004749745;"Experiment.R";2024-03-14 12:17:27.11442;2024-03-14 12:17:38.8298;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-17-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-17-18Z";15,6972;3,0593;17,1909;3,2135;64;16;8;8;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-17-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e79f2ac20>";0,00100000004749745;"Experiment.R";2024-03-14 12:17:18.60356;2024-03-14 12:17:26.78742;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-17-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-17-07Z";16,6802;3,1926;15,1968;3,0245;32;16;8;8;0,1;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-17-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e64999d50>";0,00100000004749745;"Experiment.R";2024-03-14 12:17:08.02249;2024-03-14 12:17:18.29224;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-17-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-16-59Z";15,3272;3,0627;14,6931;2,8636;64;32;16;4;0,1;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T12-16-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e64429600>";0,00100000004749745;"Experiment.R";2024-03-14 12:16:59.83973;2024-03-14 12:17:07.71659;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-16-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-16-51Z";15,8666;3,0724;16,2924;3,1165;32;32;16;4;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T12-16-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e64706050>";0,00100000004749745;"Experiment.R";2024-03-14 12:16:52.17461;2024-03-14 12:16:59.5299;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-16-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-16-46Z";18,0455;3,3247;16,4074;3,0991;64;16;16;4;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T12-16-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62c13c70>";0,00100000004749745;"Experiment.R";2024-03-14 12:16:47.01181;2024-03-14 12:16:51.87437;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-16-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-16-35Z";17,7201;3,2763;16,0818;3,1134;32;16;16;4;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T12-16-35Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e62ac25c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:16:36.04783;2024-03-14 12:16:46.7136;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-16-35Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-16-28Z";18,3436;3,3466;15,6312;3,0745;64;32;8;4;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T12-16-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e788318d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:16:28.87334;2024-03-14 12:16:35.74066;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-16-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-16-16Z";14,5938;2,999;16,5313;3,0813;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-16-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61566950>";0,00100000004749745;"Experiment.R";2024-03-14 12:16:16.7857;2024-03-14 12:16:28.57343;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-16-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-16-03Z";16,7266;3,1982;14,7057;2,8606;64;16;8;4;0,1;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T12-16-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6065e080>";0,00100000004749745;"Experiment.R";2024-03-14 12:16:03.94338;2024-03-14 12:16:16.487;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-16-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-15-55Z";18,7909;3,3799;15,4505;3,0302;32;16;8;4;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-15-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59cb4ee0>";0,00100000004749745;"Experiment.R";2024-03-14 12:15:55.42383;2024-03-14 12:16:03.64816;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-15-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-15-48Z";19,0279;3,3659;15,847;3,0052;64;32;16;8;0,1;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T12-15-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e599c8fa0>";0,00100000004749745;"Experiment.R";2024-03-14 12:15:49.15546;2024-03-14 12:15:55.04948;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-15-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-15-41Z";15,7114;3,0335;15,1466;2,9107;32;32;16;8;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T12-15-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e590119c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:15:41.71092;2024-03-14 12:15:48.82301;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-15-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-15-24Z";15,6877;3,1466;15,8462;3,0276;64;16;16;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T12-15-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e580c94e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:15:25.0386;2024-03-14 12:15:41.37497;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-15-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-15-08Z";13,1032;2,8027;16,4562;3,185;32;16;16;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-15-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e55c92260>";0,00100000004749745;"Experiment.R";2024-03-14 12:15:08.99854;2024-03-14 12:15:24.70856;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-15-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-14-59Z";14,8921;2,9901;18,069;3,3165;64;32;8;8;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T12-14-59Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e8256fe80>";0,00100000004749745;"Experiment.R";2024-03-14 12:14:59.34492;2024-03-14 12:15:08.45152;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-14-59Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-14-45Z";16,9568;3,2243;15,3595;2,967;32;32;8;8;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-14-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e694731f0>";0,00100000004749745;"Experiment.R";2024-03-14 12:14:45.43736;2024-03-14 12:14:59.03397;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-14-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-14-37Z";16,5227;3,1587;20,5559;3,5891;64;16;8;8;0,1;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T12-14-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e697e10f0>";0,00100000004749745;"Experiment.R";2024-03-14 12:14:38.12735;2024-03-14 12:14:45.11989;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-14-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-14-26Z";18,8872;3,371;18,155;3,3385;32;16;8;8;0,1;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T12-14-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e74b2e560>";0,00100000004749745;"Experiment.R";2024-03-14 12:14:26.85728;2024-03-14 12:14:37.80523;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-14-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-14-12Z";14,9767;2,9993;15,2003;2,9652;64;32;16;4;0,1;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T12-14-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4f88ed70>";0,00100000004749745;"Experiment.R";2024-03-14 12:14:13.04011;2024-03-14 12:14:26.52587;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-14-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-14-01Z";15,8926;3,085;14,7516;2,9342;32;32;16;4;0,1;0,3;0,2;0,1;32;50;47;"runs/2024-03-14T12-14-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4e90aef0>";0,00100000004749745;"Experiment.R";2024-03-14 12:14:02.2146;2024-03-14 12:14:12.73571;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-14-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-13-56Z";17,4191;3,2603;19,8853;3,5318;64;16;16;4;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T12-13-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4f3709a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:13:56.70212;2024-03-14 12:14:01.9171;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-13-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-13-46Z";15,5026;3,0933;17,0661;3,1722;32;16;16;4;0,1;0,3;0,2;0,1;32;50;47;"runs/2024-03-14T12-13-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4e35ea40>";0,00100000004749745;"Experiment.R";2024-03-14 12:13:47.12519;2024-03-14 12:13:56.39195;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-13-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-13-40Z";21,3658;3,5846;16,3098;3,137;64;32;8;4;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T12-13-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4f59bd00>";0,00100000004749745;"Experiment.R";2024-03-14 12:13:40.51167;2024-03-14 12:13:46.84061;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-13-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-13-33Z";18,1224;3,2515;15,4498;3,0895;32;32;8;4;0,1;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-13-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51021720>";0,00100000004749745;"Experiment.R";2024-03-14 12:13:33.43243;2024-03-14 12:13:40.22148;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-13-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-13-20Z";18,8033;3,298;14,8973;2,9522;64;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-13-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4f88e2c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:13:21.20471;2024-03-14 12:13:33.12855;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-13-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-13-08Z";16,2791;3,1505;20,2751;3,5131;32;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-13-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4fbcf0a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:13:09.00764;2024-03-14 12:13:20.91386;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-13-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-13-01Z";13,8152;2,911;16,4842;3,0848;64;32;16;8;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-13-01Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4fdcf0a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:13:01.47339;2024-03-14 12:13:08.65446;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-13-01Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-12-47Z";14,2831;2,9566;14,6619;2,9014;32;32;16;8;0,1;0,3;0,2;0,1;32;50;44;"runs/2024-03-14T12-12-47Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e4fe13970>";0,00100000004749745;"Experiment.R";2024-03-14 12:12:48.0886;2024-03-14 12:13:01.18476;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-12-47Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-12-36Z";14,2972;2,9491;15,4382;3,049;64;16;16;8;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-12-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e50399f60>";0,00100000004749745;"Experiment.R";2024-03-14 12:12:37.04421;2024-03-14 12:12:47.79057;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-12-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-12-28Z";16,2924;3,196;17,7222;3,2415;32;16;16;8;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-12-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e50497fd0>";0,00100000004749745;"Experiment.R";2024-03-14 12:12:29.11572;2024-03-14 12:12:36.76467;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-12-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-12-23Z";15,5765;3,1148;16,2942;3,0799;64;32;8;8;0,1;0,3;0,2;0,1;32;50;21;"runs/2024-03-14T12-12-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e506cb880>";0,00100000004749745;"Experiment.R";2024-03-14 12:12:23.91554;2024-03-14 12:12:28.66717;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-12-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-12-13Z";14,6018;2,9366;13,5885;2,8679;32;32;8;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-12-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e507472e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:12:14.14109;2024-03-14 12:12:23.57632;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-12-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-12-04Z";17,3883;3,2698;16,4723;3,0911;64;16;8;8;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T12-12-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e509265c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:12:04.47814;2024-03-14 12:12:13.8649;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-12-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-11-55Z";14,8956;3,0178;16,6777;3,1622;32;16;8;8;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T12-11-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e501932e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:11:56.1746;2024-03-14 12:12:04.0057;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-11-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-11-48Z";17,0261;3,2329;15,4059;2,9905;64;32;16;4;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T12-11-48Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e50e9fbe0>";0,00100000004749745;"Experiment.R";2024-03-14 12:11:48.70587;2024-03-14 12:11:55.87353;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-11-48Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-11-38Z";67,5812;7,2717;74,696;7,6458;32;32;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-11-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e50f28940>";0,00100000004749745;"Experiment.R";2024-03-14 12:11:38.60416;2024-03-14 12:11:48.1386;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-11-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-11-29Z";14,0211;2,9247;16,3004;3,1169;64;16;16;4;0,1;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-11-29Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51165240>";0,00100000004749745;"Experiment.R";2024-03-14 12:11:30.14945;2024-03-14 12:11:38.30367;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-11-29Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-11-20Z";14,247;2,9109;15,4052;3,0608;32;16;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-11-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51377580>";0,00100000004749745;"Experiment.R";2024-03-14 12:11:20.70342;2024-03-14 12:11:29.67162;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-11-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-11-13Z";16,4097;3,1362;18,298;3,3721;64;32;8;4;0,1;0,3;0,2;0,1;32;50;29;"runs/2024-03-14T12-11-13Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e515ac820>";0,00100000004749745;"Experiment.R";2024-03-14 12:11:14.02959;2024-03-14 12:11:20.4224;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-11-13Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-11-04Z";21,1544;3,542;15,5561;3,0589;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-11-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51af4280>";0,00100000004749745;"Experiment.R";2024-03-14 12:11:04.85501;2024-03-14 12:11:13.74798;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-11-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-10-55Z";14,7318;3,0284;14,9356;2,9993;64;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-10-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e516d74f0>";0,00100000004749745;"Experiment.R";2024-03-14 12:10:55.35908;2024-03-14 12:11:04.37673;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-10-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-10-41Z";16,8159;3,1773;15,1455;2,9695;32;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-10-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51918700>";0,00100000004749745;"Experiment.R";2024-03-14 12:10:41.46115;2024-03-14 12:10:55.04455;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-10-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-10-31Z";14,1947;2,9033;16,7487;3,127;64;32;16;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-10-31Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51ce3d60>";0,00100000004749745;"Experiment.R";2024-03-14 12:10:32.12696;2024-03-14 12:10:40.96736;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-10-31Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-10-23Z";16,8579;3,2049;14,9109;3,0272;32;32;16;8;0,1;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T12-10-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51d58b50>";0,00100000004749745;"Experiment.R";2024-03-14 12:10:23.85557;2024-03-14 12:10:31.82186;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-10-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-10-17Z";17,2281;3,2166;16,1239;3,1045;64;16;16;8;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T12-10-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51f96080>";0,00100000004749745;"Experiment.R";2024-03-14 12:10:17.79692;2024-03-14 12:10:23.57497;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-10-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-10-00Z";13,781;2,905;14,1538;2,8707;32;16;16;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-10-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e521ccb50>";0,00100000004749745;"Experiment.R";2024-03-14 12:10:00.58165;2024-03-14 12:10:17.4804;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-10-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-09-53Z";17,2571;3,2223;15,8134;3,0704;64;32;8;8;0,1;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T12-09-53Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e522252d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:09:54.06492;2024-03-14 12:10:00.3071;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-09-53Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-09-45Z";14,9538;3,0019;15,6784;3,0292;32;32;8;8;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-09-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51a3e5c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:09:46.22062;2024-03-14 12:09:53.60597;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-09-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-09-34Z";14,8801;3,0014;16,3138;3,1102;64;16;8;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-09-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e52893730>";0,00100000004749745;"Experiment.R";2024-03-14 12:09:34.34298;2024-03-14 12:09:45.94373;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-09-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-09-24Z";15,86;3,121;16,215;3,0647;32;16;8;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-09-24Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e52930a00>";0,00100000004749745;"Experiment.R";2024-03-14 12:09:24.79093;2024-03-14 12:09:34.0729;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-09-24Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-09-17Z";16,8889;3,1653;15,9795;3,0855;64;32;16;4;0,1;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T12-09-17Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e52b8ddb0>";0,00100000004749745;"Experiment.R";2024-03-14 12:09:17.98118;2024-03-14 12:09:24.47057;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-09-17Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-09-08Z";14,9207;2,9781;15,9766;3,0528;32;32;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-09-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e52d99060>";0,00100000004749745;"Experiment.R";2024-03-14 12:09:08.39276;2024-03-14 12:09:17.66694;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-09-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-08-56Z";19,1021;3,3568;15,9683;3,0354;64;16;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-08-56Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e52fcbb50>";0,00100000004749745;"Experiment.R";2024-03-14 12:08:56.49385;2024-03-14 12:09:08.1029;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-08-56Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-08-46Z";15,2572;3,0226;16,3615;3,1162;32;16;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-08-46Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5242e860>";0,00100000004749745;"Experiment.R";2024-03-14 12:08:47.02185;2024-03-14 12:08:56.22367;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-08-46Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-08-37Z";19,4504;3,4;16,3659;3,1225;64;32;8;4;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T12-08-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e526e2860>";0,00100000004749745;"Experiment.R";2024-03-14 12:08:38.18596;2024-03-14 12:08:46.74363;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-08-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-08-25Z";16,1865;3,1417;16,4209;3,1594;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-08-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e530eb940>";0,00100000004749745;"Experiment.R";2024-03-14 12:08:26.06348;2024-03-14 12:08:37.91951;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-08-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-08-18Z";17,7439;3,2922;16,8033;3,0808;64;16;8;4;0,1;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T12-08-18Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e51769090>";0,00100000004749745;"Experiment.R";2024-03-14 12:08:19.23595;2024-03-14 12:08:25.77579;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-08-18Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-08-09Z";16,3021;3,117;15,364;2,9223;32;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-08-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5348fc40>";0,00100000004749745;"Experiment.R";2024-03-14 12:08:09.61092;2024-03-14 12:08:18.9488;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-08-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-08-03Z";14,338;2,9695;15,1293;2,8894;64;32;16;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T12-08-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e536e7970>";0,00100000004749745;"Experiment.R";2024-03-14 12:08:03.8867;2024-03-14 12:08:09.32589;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-08-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-07-57Z";15,346;3,0558;16,0812;3,0516;32;32;16;8;0,1;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T12-07-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e537866e0>";0,00100000004749745;"Experiment.R";2024-03-14 12:07:57.81566;2024-03-14 12:08:03.43082;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-07-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-07-49Z";14,8701;3,034;17,5542;3,2988;64;16;16;8;0,1;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T12-07-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e539db760>";0,00100000004749745;"Experiment.R";2024-03-14 12:07:49.47339;2024-03-14 12:07:57.54869;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-07-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-07-37Z";13,7474;2,934;14,3121;2,924;32;16;16;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-07-37Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e53bebac0>";0,00100000004749745;"Experiment.R";2024-03-14 12:07:37.30553;2024-03-14 12:07:49.20783;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-07-37Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-07-28Z";14,4153;2,9504;18,1701;3,3295;64;32;8;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-07-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e758e4820>";0,00100000004749745;"Experiment.R";2024-03-14 12:07:28.72461;2024-03-14 12:07:37.02789;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-07-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-07-22Z";18,3811;3,3236;14,5166;2,9923;32;32;8;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T12-07-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6abbf970>";0,00100000004749745;"Experiment.R";2024-03-14 12:07:22.39161;2024-03-14 12:07:28.46207;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-07-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-07-06Z";17,3902;3,2755;16,9953;3,2054;64;16;8;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-07-06Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67a35900>";0,00100000004749745;"Experiment.R";2024-03-14 12:07:06.2477;2024-03-14 12:07:22.10864;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-07-06Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-06-58Z";16,3576;3,1544;17,6717;3,2454;32;16;8;8;0,1;0,3;0,2;0,1;32;50;33;"runs/2024-03-14T12-06-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6888dc60>";0,00100000004749745;"Experiment.R";2024-03-14 12:06:59.20071;2024-03-14 12:07:05.99188;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-06-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-06-50Z";16,6657;3,169;17,151;3,1367;64;32;16;4;0,1;0,3;0,2;0,1;32;50;28;"runs/2024-03-14T12-06-50Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6ae4d5a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:06:50.56772;2024-03-14 12:06:58.9308;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-06-50Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-06-41Z";20,0644;3,3395;14,323;2,9306;32;32;16;4;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T12-06-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e681ffa90>";0,00100000004749745;"Experiment.R";2024-03-14 12:06:42.16397;2024-03-14 12:06:50.10157;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-06-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-06-34Z";19,7727;3,4271;16,4455;3,1479;64;16;16;4;0,1;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-06-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6d5717b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:06:34.5134;2024-03-14 12:06:41.88721;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-06-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-06-28Z";16,5511;3,1637;15,1985;2,9785;32;16;16;4;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T12-06-28Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e760d4eb0>";0,00100000004749745;"Experiment.R";2024-03-14 12:06:28.51675;2024-03-14 12:06:34.24669;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-06-28Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-06-16Z";20,4431;3,3911;16,3265;3,0592;64;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-06-16Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e63f921a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:06:16.57242;2024-03-14 12:06:28.22674;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-06-16Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-06-03Z";16,6196;3,1722;17,0951;3,2273;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-06-03Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e65cdfa00>";0,00100000004749745;"Experiment.R";2024-03-14 12:06:03.67863;2024-03-14 12:06:16.29015;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-06-03Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-05-55Z";20,1571;3,4026;17,898;3,3052;64;16;8;4;0,1;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T12-05-55Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67c808b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:05:55.48497;2024-03-14 12:06:03.41672;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-05-55Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-05-42Z";15,0759;3,0283;14,6592;2,9475;32;16;8;4;0,1;0,3;0,2;0,1;32;50;45;"runs/2024-03-14T12-05-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e710d96c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:05:42.35135;2024-03-14 12:05:55.19947;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-05-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-05-34Z";13,4109;2,8525;16,1128;3,1228;64;32;16;8;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-05-34Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e743e9300>";0,00100000004749745;"Experiment.R";2024-03-14 12:05:35.18309;2024-03-14 12:05:42.07277;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-05-34Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-05-22Z";16,0359;3,0983;16,108;3,0854;32;32;16;8;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T12-05-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2ac5b10>";0,00100000004749745;"Experiment.R";2024-03-14 12:05:22.57922;2024-03-14 12:05:34.91896;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-05-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-05-15Z";16,1831;3,1538;17,5545;3,1761;64;16;16;8;0,1;0,3;0,2;0,1;32;50;34;"runs/2024-03-14T12-05-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e64a210c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:05:15.97514;2024-03-14 12:05:22.30431;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-05-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-05-08Z";17,1278;3,2569;18,3177;3,3554;32;16;16;8;0,1;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-05-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7692c820>";0,00100000004749745;"Experiment.R";2024-03-14 12:05:08.44595;2024-03-14 12:05:15.69565;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-05-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-04-58Z";16,6981;3,1878;17,8636;3,2856;64;32;8;8;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T12-04-58Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94d26800>";0,00100000004749745;"Experiment.R";2024-03-14 12:04:58.93876;2024-03-14 12:05:08.18378;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-04-58Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-04-51Z";15,4957;3,0519;16,4445;3,1351;32;32;8;8;0,1;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-04-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e632a07c0>";0,00100000004749745;"Experiment.R";2024-03-14 12:04:52.14028;2024-03-14 12:04:58.68151;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-04-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-04-45Z";17,7895;3,2194;15,6405;2,9944;64;16;8;8;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T12-04-45Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e627d8970>";0,00100000004749745;"Experiment.R";2024-03-14 12:04:45.86753;2024-03-14 12:04:51.87622;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-04-45Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-04-33Z";15,9371;3,1372;15,0631;2,9594;32;16;8;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-04-33Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e61ca42b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:04:33.95196;2024-03-14 12:04:45.59893;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-04-33Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-04-21Z";17,237;3,249;14,8845;2,9118;64;32;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-04-21Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60cc2410>";0,00100000004749745;"Experiment.R";2024-03-14 12:04:21.83189;2024-03-14 12:04:33.67678;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-04-21Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-04-08Z";19,8877;3,407;15,0553;2,9747;32;32;16;4;0,1;0,3;0,2;0,1;32;50;49;"runs/2024-03-14T12-04-08Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60bce080>";0,00100000004749745;"Experiment.R";2024-03-14 12:04:08.57864;2024-03-14 12:04:21.56537;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-04-08Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-04-00Z";15,7709;3,0607;15,2978;2,985;64;16;16;4;0,1;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T12-04-00Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59df7820>";0,00100000004749745;"Experiment.R";2024-03-14 12:04:00.49978;2024-03-14 12:04:08.30197;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-04-00Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-03-52Z";17,065;3,2325;15,7402;3,0479;32;16;16;4;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-03-52Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e681cff10>";0,00100000004749745;"Experiment.R";2024-03-14 12:03:53.16559;2024-03-14 12:04:00.22885;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-03-52Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-03-44Z";19,0696;3,3205;17,6666;3,2471;64;32;8;4;0,1;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T12-03-44Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e59173040>";0,00100000004749745;"Experiment.R";2024-03-14 12:03:44.70702;2024-03-14 12:03:52.89768;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-03-44Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-03-36Z";19,5039;3,3683;19,5358;3,5113;32;32;8;4;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-03-36Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e57cf4790>";0,00100000004749745;"Experiment.R";2024-03-14 12:03:36.92448;2024-03-14 12:03:44.45038;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-03-36Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-03-27Z";19,292;3,3467;16,2084;3,1042;64;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-03-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e578e6fb0>";0,00100000004749745;"Experiment.R";2024-03-14 12:03:27.73795;2024-03-14 12:03:36.48858;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-03-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-03-19Z";20,8759;3,5206;17,2405;3,2002;32;16;8;4;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T12-03-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7076a620>";0,00100000004749745;"Experiment.R";2024-03-14 12:03:19.694;2024-03-14 12:03:27.46676;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-03-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-03-12Z";14,5119;2,9356;14,641;2,8732;64;32;16;8;0,1;0,3;0,2;0,1;32;50;30;"runs/2024-03-14T12-03-12Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9eb2196b30>";0,00100000004749745;"Experiment.R";2024-03-14 12:03:13.13339;2024-03-14 12:03:19.42365;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-03-12Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-03-04Z";16,0185;3,1334;16,9423;3,1684;32;32;16;8;0,1;0,3;0,2;0,1;32;50;35;"runs/2024-03-14T12-03-04Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6c4d61d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:03:04.9645;2024-03-14 12:03:12.68661;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-03-04Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-02-51Z";12,6155;2,7912;15,6944;3,0443;64;16;16;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-02-51Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6ae3f880>";0,00100000004749745;"Experiment.R";2024-03-14 12:02:51.99893;2024-03-14 12:03:04.68695;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-02-51Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-02-43Z";15,043;3,06;15,495;2,9581;32;16;16;8;0,1;0,3;0,2;0,1;32;50;39;"runs/2024-03-14T12-02-43Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6a6ed750>";0,00100000004749745;"Experiment.R";2024-03-14 12:02:43.69886;2024-03-14 12:02:51.72101;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-02-43Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-02-38Z";15,4879;3,0555;17,4669;3,2534;64;32;8;8;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T12-02-38Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6a1ba320>";0,00100000004749745;"Experiment.R";2024-03-14 12:02:38.25219;2024-03-14 12:02:43.42537;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-02-38Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-02-27Z";15,85;3,1035;14,0336;2,8185;32;32;8;8;0,1;0,3;0,2;0,1;32;50;25;"runs/2024-03-14T12-02-27Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e696b70d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:02:27.26426;2024-03-14 12:02:37.99492;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-02-27Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-02-20Z";18,6496;3,369;18,8003;3,3744;64;16;8;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T12-02-20Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e67ad4280>";0,00100000004749745;"Experiment.R";2024-03-14 12:02:20.575;2024-03-14 12:02:27.00236;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-02-20Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-02-11Z";16,3318;3,195;16,6375;3,0722;32;16;8;8;0,1;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T12-02-11Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6841e7d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:02:12.00982;2024-03-14 12:02:20.31725;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-02-11Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-02-05Z";20,5811;3,5087;16,775;3,143;64;32;16;4;0,1;0,3;0,2;0,1;32;50;26;"runs/2024-03-14T12-02-05Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e944a06a0>";0,00100000004749745;"Experiment.R";2024-03-14 12:02:05.92221;2024-03-14 12:02:11.55716;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-02-05Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-01-49Z";15,8111;3,0476;13,6983;2,8179;32;32;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-01-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e972d5ed0>";0,00100000004749745;"Experiment.R";2024-03-14 12:01:50.05218;2024-03-14 12:02:05.6604;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-01-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-01-42Z";21,6122;3,4951;18,0455;3,3119;64;16;16;4;0,1;0,3;0,2;0,1;32;50;32;"runs/2024-03-14T12-01-42Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e7ad29630>";0,00100000004749745;"Experiment.R";2024-03-14 12:01:42.56979;2024-03-14 12:01:49.79342;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-01-42Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-01-30Z";67,5797;7,2719;74,6856;7,6452;32;16;16;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-01-30Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e55c49840>";0,00100000004749745;"Experiment.R";2024-03-14 12:01:30.57028;2024-03-14 12:01:42.314;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-01-30Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-01-22Z";15,8;3,0449;18,4416;3,334;64;32;8;4;0,1;0,3;0,2;0,1;32;50;36;"runs/2024-03-14T12-01-22Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e94424490>";0,00100000004749745;"Experiment.R";2024-03-14 12:01:22.54932;2024-03-14 12:01:30.29428;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-01-22Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-01-10Z";20,0567;3,4106;15,9098;3,0967;32;32;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-01-10Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e77033940>";0,00100000004749745;"Experiment.R";2024-03-14 12:01:10.32033;2024-03-14 12:01:22.29221;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-01-10Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-00-57Z";15,658;3,0978;15,8802;2,9513;64;16;8;4;0,1;0,3;0,2;0,1;32;50;43;"runs/2024-03-14T12-00-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e716eb9d0>";0,00100000004749745;"Experiment.R";2024-03-14 12:00:58.04769;2024-03-14 12:01:10.05596;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-00-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-00-49Z";19,614;3,4347;18,6822;3,3723;32;16;8;4;0,1;0,3;0,2;0,1;32;50;38;"runs/2024-03-14T12-00-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e70ed2710>";0,00100000004749745;"Experiment.R";2024-03-14 12:00:50.06685;2024-03-14 12:00:57.78875;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-00-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-00-40Z";16,3938;3,1521;14,9453;2,985;64;32;16;8;0,1;0,3;0,2;0,1;32;50;23;"runs/2024-03-14T12-00-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4417 (17.25 KB)
Trainable params: 4417 (17.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e649997b0>";0,00100000004749745;"Experiment.R";2024-03-14 12:00:40.98075;2024-03-14 12:00:49.69817;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-00-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-00-26Z";14,9823;2,9615;17,0923;3,1259;32;32;16;8;0,1;0,3;0,2;0,1;32;50;40;"runs/2024-03-14T12-00-26Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2561 (10.00 KB)
Trainable params: 2561 (10.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e65d8f340>";0,00100000004749745;"Experiment.R";2024-03-14 12:00:27.05397;2024-03-14 12:00:40.71896;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-00-26Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-00-19Z";15,3375;3,0608;14,4931;2,912;64;16;16;8;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T12-00-19Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 3121 (12.19 KB)
Trainable params: 3121 (12.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e96ab9090>";0,00100000004749745;"Experiment.R";2024-03-14 12:00:20.20093;2024-03-14 12:00:26.77765;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-00-19Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T12-00-09Z";13,8462;2,9136;16,2604;3,1422;32;16;16;8;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T12-00-09Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 8)                       136         
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1777 (6.94 KB)
Trainable params: 1777 (6.94 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e6288c700>";0,00100000004749745;"Experiment.R";2024-03-14 12:00:09.55268;2024-03-14 12:00:19.93616;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T12-00-09Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-59-54Z";14,2478;3,0017;14,4566;2,9163;64;32;8;8;0,1;0,3;0,2;0,1;32;50;42;"runs/2024-03-14T11-59-54Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 4089 (15.97 KB)
Trainable params: 4089 (15.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e60912410>";0,00100000004749745;"Experiment.R";2024-03-14 11:59:55.14089;2024-03-14 12:00:09.28139;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-59-54Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-59-41Z";16,0224;3,102;15,3073;3,0356;32;32;8;8;0,1;0,3;0,2;0,1;32;50;27;"runs/2024-03-14T11-59-41Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2233 (8.72 KB)
Trainable params: 2233 (8.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5630feb0>";0,00100000004749745;"Experiment.R";2024-03-14 11:59:41.54251;2024-03-14 11:59:54.86176;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-59-41Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-59-32Z";12,5874;2,7898;15,6088;2,964;64;16;8;8;0,1;0,3;0,2;0,1;32;50;45;"runs/2024-03-14T11-59-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 2921 (11.41 KB)
Trainable params: 2921 (11.41 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e55c91fc0>";0,00100000004749745;"Experiment.R";2024-03-14 11:59:32.58842;2024-03-14 11:59:41.29482;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-59-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-59-23Z";17,6282;3,3152;17,4415;3,2457;32;16;8;8;0,1;0,3;0,2;0,1;32;50;24;"runs/2024-03-14T11-59-23Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 8)                       72          
 dropout (Dropout)                  (None, 8)                       0           
 dense (Dense)                      (None, 1)                       9           
================================================================================
Total params: 1577 (6.16 KB)
Trainable params: 1577 (6.16 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e578cfa30>";0,00100000004749745;"Experiment.R";2024-03-14 11:59:24.17902;2024-03-14 11:59:32.32326;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-59-23Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-59-15Z";14,4722;2,9485;14,5002;2,8407;64;32;16;4;0,1;0,3;0,2;0,1;32;50;48;"runs/2024-03-14T11-59-15Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4345 (16.97 KB)
Trainable params: 4345 (16.97 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e57ad7940>";0,00100000004749745;"Experiment.R";2024-03-14 11:59:15.28355;2024-03-14 11:59:23.762;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-59-15Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-59-07Z";21,019;3,4788;15,1072;3,0226;32;32;16;4;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T11-59-07Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 16)                      528         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2489 (9.72 KB)
Trainable params: 2489 (9.72 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e57b4a0b0>";0,00100000004749745;"Experiment.R";2024-03-14 11:59:08.1858;2024-03-14 11:59:15.02812;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-59-07Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-58-57Z";15,9275;3,0988;16,9103;3,1793;64;16;16;4;0,1;0,3;0,2;0,1;32;50;31;"runs/2024-03-14T11-58-57Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 3049 (11.91 KB)
Trainable params: 3049 (11.91 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e57d27250>";0,00100000004749745;"Experiment.R";2024-03-14 11:58:58.16592;2024-03-14 11:59:07.94413;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-58-57Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-58-49Z";16,6138;3,151;17,1644;3,2289;32;16;16;4;0,1;0,3;0,2;0,1;32;50;41;"runs/2024-03-14T11-58-49Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 16)                      272         
 dropout_1 (Dropout)                (None, 16)                      0           
 dense_1 (Dense)                    (None, 4)                       68          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1705 (6.66 KB)
Trainable params: 1705 (6.66 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e57580d00>";0,00100000004749745;"Experiment.R";2024-03-14 11:58:50.10152;2024-03-14 11:58:57.9295;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-58-49Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-58-40Z";17,616;3,2553;16,6894;3,1331;64;32;8;4;0,1;0,3;0,2;0,1;32;50;22;"runs/2024-03-14T11-58-40Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 32)                      2080        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 4049 (15.82 KB)
Trainable params: 4049 (15.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e580c8340>";0,00100000004749745;"Experiment.R";2024-03-14 11:58:40.82902;2024-03-14 11:58:49.86178;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-58-40Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-58-32Z";18,528;3,2961;17,2593;3,146;32;32;8;4;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T11-58-32Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 32)                      1056        
 dropout_2 (Dropout)                (None, 32)                      0           
 dense_2 (Dense)                    (None, 8)                       264         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2193 (8.57 KB)
Trainable params: 2193 (8.57 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e58130c40>";0,00100000004749745;"Experiment.R";2024-03-14 11:58:33.09208;2024-03-14 11:58:40.58116;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-58-32Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-58-25Z";21,1209;3,5687;18,0851;3,2962;64;16;8;4;0,1;0,3;0,2;0,1;32;50;37;"runs/2024-03-14T11-58-25Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 64)                      1664        
 dropout_3 (Dropout)                (None, 64)                      0           
 dense_3 (Dense)                    (None, 16)                      1040        
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 2881 (11.25 KB)
Trainable params: 2881 (11.25 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e58313e80>";0,00100000004749745;"Experiment.R";2024-03-14 11:58:26.14517;2024-03-14 11:58:32.85259;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-58-25Z/tfruns.d/source.tar.gz";"local";"training"
"runs/2024-03-14T11-58-14Z";16,3827;3,1193;16,073;3,047;32;16;8;4;0,1;0,3;0,2;0,1;32;50;50;"runs/2024-03-14T11-58-14Z/tfruns.d/metrics.json";"Model: ""sequential""
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_4 (Dense)                    (None, 32)                      832         
 dropout_3 (Dropout)                (None, 32)                      0           
 dense_3 (Dense)                    (None, 16)                      528         
 dropout_2 (Dropout)                (None, 16)                      0           
 dense_2 (Dense)                    (None, 8)                       136         
 dropout_1 (Dropout)                (None, 8)                       0           
 dense_1 (Dense)                    (None, 4)                       36          
 dropout (Dropout)                  (None, 4)                       0           
 dense (Dense)                      (None, 1)                       5           
================================================================================
Total params: 1537 (6.00 KB)
Trainable params: 1537 (6.00 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________";"mse";"<keras.src.optimizers.rmsprop.RMSprop object at 0x7f9e5883cd30>";0,00100000004749745;"Experiment.R";2024-03-14 11:58:14.33336;2024-03-14 11:58:25.90909;TRUE;"
> FLAGS <- flags(flag_integer(""dense_units1"", 64), flag_integer(""dense_units2"", 
+     32), flag_integer(""dense_units3"", 16), flag_integer(""dense_unit ..."" ... [TRUNCATED] 

> model <- keras_model_sequential() %>% layer_dense(units = FLAGS$dense_units1, 
+     activation = ""relu"", input_shape = c(25)) %>% layer_dropout(rat .... [TRUNCATED] 

> model %>% compile(loss = ""mse"", optimizer = ""rmsprop"", 
+     metrics = ""mae"")

> mon_callback <- callback_early_stopping(monitor = ""val_mae"", 
+     patience = 10, restore_best_weights = TRUE)

> history <- model %>% fit(training, trainingtarget, 
+     epochs = 50, batch_size = FLAGS$batch_size, validation_split = 0.2, 
+     callbacks = lis .... [TRUNCATED] ";"runs/2024-03-14T11-58-14Z/tfruns.d/source.tar.gz";"local";"training"
