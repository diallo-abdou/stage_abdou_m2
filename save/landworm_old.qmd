---
title: "Modeling and predicting earthworm diversity and distribution in France"
author: "Abdourahmane Diallo"
date: '`r Sys.Date()`'
format: 
  revealjs
# preview-links: auto
# logo: logo-FRB-Cesab-francais.png
# css: styles.css
footer: "LANDWORM"
# multiplex: true
#smaller: true
scrollable: true
#theme: sky
editor: visual
number-sections: true
toc: FALSE
#toc-expand: false
#toc_float: 'yes'
code_download: 'yes'
slide-number: true
margin: 0.1
#center: true
code-fold: true
width: 1400
height: 800
toc_depth: 1
# execute:
  # cache: true
# quarto render landworm.qmd --cache-refresh 
---

## Setting {.unnumbered}

```{r setup, include=FALSE,fig.align='center',message=FALSE,warning=FALSE,message=FALSE,echo=TRUE}
# rm(list=ls()) # Properly clear workspace
# source("function_abdou.R")
# knitr::opts_chunk$set(echo = TRUE)

```

```{css, echo=FALSE}
.title {
  font-size: 100px;
  font-style: italic;
  color: blue;
  font-family: Arial;
  font-variant: small-caps;
}
```

**Packages**

```{r packages,echo=TRUE}
  library(tidyverse)
  # library(glme)
  # library(lsmeans)
  # library(agricolae)
  # library(RVAideMemoire)
  library(corrplot)
  # library(emmeans)
  library(lme4)
  library(multcomp)
  library(MASS)
  # library(R2WinBUGS)
  library(arm)
  # library(performance)
  # library(AER)
  # library(AICcmodavg)
  # library(MuMIn)
  library(ade4)
  library(Hmisc)
  library(labdsv)
  library(vegan)
  library(cowplot)
  library(ggpubr)
  library(rstatix)
  library(patchwork)
  library(multcompView)
  library(ggsignif)
  library(grid)
  library(FactoMineR)
  library(factoextra)
  library(explore)
  library(ggrepel)
  library(naniar)
  library(outliers)
  library(leaps)
  library(fastDummies)
  library(caret) # pour l'entrainement des models
  library(mgcv)
  library(ggeffects)
  library(gratia)
  library(GGally) # pour ggpair
  # library(caTools)
  # library(rpart)
  # library(rpart.plot)
  library(openxlsx)
  library(readxl)
  library(leaflet) # pour la carto
  library(quarto)
  library(raster)
  library(knitr)
  library(kableExtra)
  library(stringr)
  library(plotly)
  # library(PerformanceAnalytics)
  # library(usdm)
  library(vcd) # pour la distribution des var reponse
  library(prospectr)# pour split data avec kenSton()
  # library(glmnet)
  library(randomForest)
  # library(doParallel)
  library(gbm)
  library(kernlab)
  # library(e1071)
  library(ggforce)
  library(keras)
  library(tensorflow)
  library(neuralnet)
  # library(parallel)
  library(iml) # pour l'interpretabilité des models https://cran.r-project.org/web/packages/iml/vignettes/intro.html
  library(stats)
  # library(Boruta) # importance des predicteurs
  library(bestNormalize)
  library(rmarkdown)
  library(DT)
  library(gtExtras) # pour la
  library(reshape2)
  # library(mapview)
  library(sf)
  library(ggplot2)
  library(maptools)
  library(ggsn)
  library(spThin)
  library(sp)
  library(gstat)

```

**Functions**

```{r fonction, echo=TRUE}

## Identification des NA dans un df -----------------------------------------------
taux_completion<-
  function(df, afficher_zero_percent = FALSE, seuil, trie=FALSE) {
    # Calcule du pourcentage de NA dans le dataframe
    pourcentage_total <-
      round(sum(is.na(df)) / (nrow(df) * ncol(df)) * 100, 1)
    
    # Calcule du pourcentage de NA par colonne
    pourcentage_colonnes <- round(colMeans(is.na(df)) * 100, 1)
    
    # Creation d'un dataframe résultat avec deux colonnes
    result <-
      data.frame(
        Variables = names(df),
        CR = pourcentage_colonnes,
        row.names = NULL
      )
    
    if (afficher_zero_percent) {
      result <- result[result$CR == 0, ]
      result$CR = 100 -result$CR
    } else {
      result <- result[result$CR > 0, ]
      result$CR = 100 -result$CR
      
    }
    
    result <- rbind(result, c("Total", pourcentage_total))
    #result <- rbind(result, c("Total", paste0(pourcentage_total, "")))
    
    result <- result[, c("Variables", "CR")]
    result$CR = as.numeric(result$CR)
    result$CR = round(result$CR,1)
    if (trie){
      result = result %>% arrange(desc(CR))
    }
    result$CR = paste0(result$CR,"%")
    
    return(result)
  }
# Converssion des colonne en num ou factor-----------------------------------------------
conv_col <- function (data, columns_to_convert, to_types) {
  if (to_types == "numeric") {
    # Conversion des colonnes en numeric
    for (col in columns_to_convert) {
      data[, col] <- as.numeric(data[, col])
    }
  } else {
    # Conversion des colonnes en facteurs
    for (col in columns_to_convert) {
      data[, col] <- as.factor(data[, col])
    }
  }
  return(data)
}
#data_converted <- conv_col(data, names(data [, c(1, 3)]), "factor")

# exploration graphiques des variables numeriques -----------------------------------------------
explo_num <- function(nom_col, titre, df = landworm, ligne_col = c(2, 2),mini = min(df[[nom_col]]), maxi=max(df[[nom_col]]) ) {
  par(mfrow = ligne_col)
  
  df[complete.cases(df[[nom_col]]), ]
  df <- df %>%filter(!is.na(df[[nom_col]]))
  df[[nom_col]] = as.numeric(df[[nom_col]])
  # Boxplot
  boxplot(df[[nom_col]], col = 'blue', ylab = titre, ylim = c(mini, maxi))
  # Cleveland plot
  dotchart(df[[nom_col]], pch = 16, col = 'blue', xlab = titre)
  # Histogram
  hist(df[[nom_col]], col = 'blue', xlab = titre, main = "")
  # Quantile-Quantile plot
  qqnorm(df[[nom_col]], pch = 16, col = 'blue', xlab = '')
  qqline(df[[nom_col]], col = 'red') 
}

# Extraction des predictors + moyennes -----------------------------------------------

extraction <- function(nom_col, tif_file_path, df = landworm, conv = 1) {
  #df <- df %>%filter(!is.na(gps_x) & !is.na(gps_y))
  raster_data <- raster(tif_file_path)
  
  # Création d'un dataframe pour stocker les valeurs extraites
  df_interne <- data.frame(gps_x = df$gps_x, gps_y = df$gps_y)
  proj4Str <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
  # Transformer les coordonnées GPS en système de coordonnées du raster
  gps_coords_sp <- SpatialPoints(df_interne, proj4string = CRS(proj4Str))
  gps_coords_proj <- spTransform(gps_coords_sp, crs(raster_data))
  
  # Extraction des valeurs du raster 
  values <- raster::extract(raster_data, gps_coords_proj)
  
  # Ajout des valeurs extraites comme nouvelles colonnes a df
  #df_save = data.frame()
  #df_save[[nom_col]] <- values / conv
  
  df[[nom_col]] <- values / conv
  
  return(df)
}

# la moyenne des predictores -----------------------------------------------
moyenne_val_extrct <- function(nom_col, vec_col, df=landworm) {
  df[[nom_col]] <- rowMeans(as.matrix(df[, vec_col, drop = FALSE]), na.rm = TRUE)
  df[[nom_col]] = round(df[[nom_col]],1)
  return(as.data.frame(df))
}


# tests de corrélation avec un seuil -----------------------------------------------
cor_function_seuil <- function(data, seuil,affiche=FALSE) {
  # Création d'un vecteur pour stocker les paires de variables corrélées
  variables_corr <- c()
  
  # Boucle pour tester la corrélation entre chaque paire de variables
  for (i in 1:(ncol(data) - 1)) {
    for (j in (i + 1):ncol(data)) {
      # Calcul de la corrélation entre les variables i et j
      cor_value <- stats::cor(data[, i], data[, j], use = "na.or.complete")
      
      # Stockage du résultat dans le vecteur si supérieur au seuil
      if (cor_value >= seuil | cor_value <= -seuil) {
        if(affiche){
        cat(
          "***",
          colnames(data)[i],
          "  __est correlee a__  ",
          colnames(data)[j],
          "avec un R =",
          cor_value,
          "\n \n \n"
        )
      }
        
        variables_corr <-
          c(variables_corr, colnames(data)[i], colnames(data)[j])
      }
    }
  }
  
  return(variables_corr)
}


# tests de valeurs aberant -----------------------------------------------
test_grub <- function(data, variable, direction = "maxi") {
  
  if (direction == "maxi") { 
    repeat {
      #le test de Grubbs
      test_aberrant <- grubbs.test(data[[variable]], opposite = FALSE)
      
      # Obtenir la p-valeur du test
      p.value <- test_aberrant$p.value
      # Si la p-valeur est inférieure au seuil de 0.05, on supprime la valeur aberrante
      if (p.value < 0.05) {
        max_value <- max(data[[variable]],na.rm=TRUE)
        data <- subset(data, data[[variable]] != max_value | is.na(data[[variable]]))
      } else {
        # S'il n'y a plus de valeurs aberrantes, sortir de la boucle
        break
      }
    }
  }
  
  
  if (direction == "mini") { 
    repeat {
      test_aberrant <- grubbs.test(data[[variable]], opposite = TRUE)
      # Obtenir la p-valeur du test
      p.value <- test_aberrant$p.value
      # Si la p-valeur est inférieure au seuil de 0.05, on supprime la valeur aberrante
      if (p.value < 0.05) {
        min_value <- min(data[[variable]],na.rm=TRUE)
        data <- subset(data, data[[variable]] != min_value | is.na(data[[variable]]))
      } else {
        # S'il n'y a plus de valeurs aberrantes, sortir de la boucle
        break
      }
    }
  }
  
  
  return(data)
}




# boxplote -----------------------------------------------
plot_boxplot <-function(donnee,
           x_col,y_col,x_label,y_label,title,legend_title,
           couleurs,
           affiche_point = TRUE,
           ymin = min(donnee[[y_col]]),
           ymax = 1.2 * max(donnee[[y_col]])) {
    
  graphe <-ggplot(donnee,
             aes_string(
               x = x_col,
               y = y_col,
               colour = x_col
             )) +
  geom_boxplot(
        outlier.shape = NA,
        outlier.colour = "black",
        alpha = 0.20,
        size = 1.5 
      ) +
  labs(title = title,x = x_label,y = y_label) +
  scale_color_manual(values = couleurs, name = legend_title) +
  theme_classic(base_size = 12, base_family = "Arial") +
  theme(axis.text = element_text(size = 10),
        axis.title.y = element_text(
          vjust = 5, size = 12, face = "bold"),
        axis.title.x = element_text(face = "bold"),
        axis.ticks.length = unit(0.2, "cm"),
        legend.position = "none",  # Cette ligne supprime la lÃ©gende
        #legend.position = "right",
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12, face = "bold"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title = element_text(size = 14, face = "bold"),
        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm")
      )
    if (affiche_point) {
      graphe <-
        graphe + geom_jitter(position = position_jitter(seed = 0.5), size = 0.8)
    }
    
    if (y_col %in% names(donnee)) {
      graphe <- graphe +
        coord_cartesian(ylim = c(ymin, ymax))
    }
  
    graphe = graphe + stat_summary(
      fun.y = mean,
      geom = "point",
      shape = 15,
      size = 1.5,
      col = "black",
      fill = "black"
    )
    
    return(graphe)
}



#pour le  pairwise.t.test() -----------------------------------------------------
tri.to.squ <- function(x) {
  rn <- row.names(x)
  cn <- colnames(x)
  an <- unique(c(cn, rn))
  myval <- x[!is.na(x)]
  mymat <-
    matrix(
      1,
      nrow = length(an),
      ncol = length(an),
      dimnames = list(an, an)
    )
  for (ext in 1:length(cn))
  {
    for (int in 1:length(rn))
    {
      if (is.na(x[row.names(x) == rn[int], colnames(x) == cn[ext]]))
        next
      mymat[row.names(mymat) == rn[int], colnames(mymat) == cn[ext]] <-
        x[row.names(x) == rn[int], colnames(x) == cn[ext]]
      mymat[row.names(mymat) == cn[ext], colnames(mymat) == rn[int]] <-
        x[row.names(x) == rn[int], colnames(x) == cn[ext]]
    }
  }
  return(mymat)
}



# Selection interaction -------------------------------
select_inter <- function(response_var, df, explanatory_vars) {
  results <- data.frame()
  combinations <- combn(explanatory_vars, 2, simplify = FALSE)

  for(i in seq_along(combinations)) {

    formula <- as.formula(paste(response_var, "~", paste(combinations[[i]], collapse = "*")))
    model <- gam(formula, data = df)
    r_squared <- summary(model)$r.sq
    aic <- AIC(model)
    results <- rbind(results, data.frame("variables" = paste0(combinations[[i]], collapse = ".inter."), 
                                         "r_squared" = r_squared, 
                                 "aic" = aic))
  }
  return(results)
}

# Comparaion betwen predtited and observed -----------------------------------
plot_comp = function (df,ylabel, title_class, legende = TRUE,plotly = FALSE,xlabel = "observations",title=""){ 

  
  p = ggplot(df, aes(x = observation)) + 
  #graph representant observed
  geom_point(aes(y = Observed, color = "Observed values")) +
  geom_line(aes(y = Observed, color = "Observed values")) + 
  
  #graph representant  preticted
  geom_point(aes(y = Predicted, color="Predicted values")) +
  geom_line(aes(y = Predicted, color="Predicted values")) + 
  # ggtitle(title)
  theme(plot.title = element_text(hjust = 0.5)) + 
  labs(title = title,x=xlabel, y=ylabel, color = "Legend :") + 
  ylim(min(c(min(df$Predicted), min(df$Observed))),
            max(c(max(df$Predicted), max(df$Observed)))+1  ) +
    
  scale_color_manual(values = c("Observed values"='red', "Predicted values"='green')) +
  annotate("text", x = 8, y =  max(c(max(df$Predicted), max(df$Observed)))+1, 
           label = title_class, col = "black", size = 3)

  
  if (!legende) {
    p <- p + theme(legend.position = "none")
  }
  
  if(plotly){
    p = ggplotly(p)
  }

return (p)

}


# Calcul R²
calcule_R2 = function(x, y) {cor(x, y)^2}

```

## Plan {.unnumbered}

# Database import

-   Import of database **LandWorm_dataset_site_01_07_2024.xlsx** (february 22, 2024)

```{r import,echo=FALSE}
chemin_fichier_excel = "C:/Users/diall/Downloads/datas/LandWorm_dataset_site_01_07_2024.xlsx"
landworm <- read.xlsx(chemin_fichier_excel, sheet = "Sheet1")
```

-   The database contains **`r nrow(landworm)`** rows and **`r ncol(landworm)`** columns

```{r conversion,echo=FALSE}
col_en_factor = c("Programme","Annee","ID_Site","Code_Parcelle","postal_code","clcm_lvl1", "clcm_lvl2","clcm_lvl3","Modalite","Bloc","Protocole","land_cover_detail","type_tillage","fertilisation","ferti_min_product","ferti_orga_product")
landworm = conv_col(landworm, col_en_factor, "factor")
```

## Protocols (avant séléction)

-   **List of protocols available on the database ( `r length(levels(landworm$Protocole))` levels)**

```{r protocols1,echo=TRUE}
landworm$Protocole = as.factor(landworm$Protocole)
df <- as.data.frame(summary(landworm$Protocole))
colnames(df) <- c("Numbers")
DT::datatable(df, options = list(pageLength = 5))
rm("df")
```

-   **Selection of protocols: 16**

```{r}
df_suivi = landworm
n_line = nrow(df_suivi)

sel_proto = c("AITC_HS","FHS","HS","HS_4","HS_M_16","HSAITC_16","HSAITC_6.25","AITCTM","F_HS","hand sorting","HS_16","HS_F_16","HS_M_25","HSAITC_4",
    "HSAITC_7.95775385","M_HS")

sel_proto = c("AITCTM", "AITC_HS", "HS", "F_HS", "M_HS", "HS_M_16", "HS_M_25" , "HS_F_16", "HS_16" , "HSAITC_7.95775385",  "HSAITC_6.25" , "HS_4" , "HSAITC_4" ,"FHS","HSAITC_16" , "hand sorting")

landworm2 <- landworm
n_line = nrow(landworm2)
landworm2 <- landworm2 %>%
  dplyr::filter(Protocole %in% sel_proto)
landworm2 <- droplevels(landworm2)
df = landworm2 %>%
  pull(Protocole) %>%
  table() %>%
  as.data.frame() %>%
  dplyr::rename(Numbers = 2) 

# kable(df)
df %>% datatable(options = list(pageLength = 5))

landworm = landworm2
rm("landworm2")
```

-   The database therefore changes from **`r n_line`** to **`r nrow(landworm)`** observations.

## Data selection: LandWorm

-   On séléctionne tout sauf *mh* et *NA*

```{r selection dc1,echo=FALSE}
df_suivi = landworm
n_line = nrow(df_suivi)

landworm$owner=as.factor(landworm$owner)
summary_df <- as.data.frame(summary(landworm$owner))
colnames(summary_df) <- c("Numbers")
kable(summary_df)
```

```{r selection dc2,echo=TRUE}
landworm <- subset(landworm, owner %in% c("dc","cp","gp","sg"))
landworm$owner=droplevels(landworm$owner)

```

-   The database therefore changes from **`r n_line`** to **`r nrow(landworm)`** observations.

# Database exploration

-   CR = Completion rate

## Complete columns

```{r Complete columns, echo=TRUE}
df_col=taux_completion(landworm,TRUE,trie=FALSE)
df_col = df_col[df_col$Variables != "Total",]
#print("table")
kable(df_col, caption = "", col.width = c("75%", "25%"))
# cat(                                                    )
# head(landworm[, "ID"])
```

## Non-complete columns

```{r Non-complete columns}
df_col= taux_completion(landworm,FALSE,trie = TRUE)
df_col = df_col[df_col$Variables != "Total",]
# kable(df_col, caption = " ", col.width = c("75%", "25%"))

# df_col %>% datatable(options = list(pageLength = 10), rownames = FALSE)

```

## Focus on GPS coordinates

-   There is **`r sum(is.na(landworm$gps_x))`** NA (CR = `r df_col[df_col$Variable=="gps_x", "CR"]`) in **GPS_X**
-   There is **`r sum(is.na(landworm$gps_y))`** NA (CR = `r df_col[df_col$Variable=="gps_y", "CR"]`) in **GPS_Y**

```{r GPS,echo=TRUE}

df_suivi = landworm
n_line = nrow(df_suivi)

landworm$gps_x <- as.numeric(gsub("[^0-9.-]", "", landworm$gps_x))
landworm$gps_y <- as.numeric(gsub("[^0-9.-]", "", landworm$gps_y))
landworm <- landworm[complete.cases(landworm$gps_x, landworm$gps_y), ]
landworm <- landworm %>%filter(!is.na(gps_x) & !is.na(gps_y))
#sum(is.na(landworm$gps_x))
#sum(is.na(landworm$gps_y))
```

-   We delete the *NA* lines in the GPS coordinates
-   The database therefore changes from **`r n_line`** to **`r nrow(landworm)`** observations.

## Cartography

```{r Cartography,echo=TRUE}
df_suivi = landworm
n_line = nrow(df_suivi)

df_coord <- landworm[, c("gps_x", "gps_y")] %>% mutate(gps_x = as.numeric(gps_x),gps_y = as.numeric(gps_y))

df_coord$num_ligne <- seq(nrow(df_coord))
carte <- leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~gps_x, lat = ~gps_y, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")
carte
```

```{r outside France}
hors_france= read.csv(file = "C:/Users/diall/Downloads/datas/hors_france.csv", header = TRUE)

landworm <- landworm[!(landworm$gps_x %in% hors_france$gps_x & landworm$gps_y %in% hors_france$gps_y), ]
landworm <- droplevels(landworm)
```

-   We delete points outside France (**`r nrow(hors_france)`**)
-   The database therefore changes from **`r n_line`** to **`r nrow(landworm)`** observations.

## Focus on years

-   Cleaning the Annee column <br/>

```{r years1}
df_suivi = landworm
n_line = nrow(df_suivi)

# levels(landworm$Annee) # parfois années et jours et ou mois
landworm$Annee= as.factor(landworm$Annee)
landworm$Annee <- gsub("^(\\d{4}).*$", "\\1", landworm$Annee) # on prend uniquement les 04 premier chiffre
landworm$Annee= as.factor(landworm$Annee)

```

-   CR of Annee = **`r df_col[df_col$Variable=="Annee", "CR"]`** (`r length(levels(landworm$Annee))` levels)

```{r years2, scrollable = TRUE}
landworm$Annee= as.factor(landworm$Annee)
landworm = droplevels(landworm)
summary_df <- as.data.frame(summary(landworm$Annee))
colnames(summary_df) <- c("Numbers")
# kable(summary_df)
```

-   We remove all the years before **1990** and the NA ( *`r sum(is.na(landworm$Annee))`* observations)

```{r years3, echo=TRUE, scrollable = TRUE}
# sum(is.na(landworm$Annee))
landworm <- landworm %>%filter(!is.na(Annee))# on enleve les NA
annes_omit= c("1821", "1960", "1978", "1982", "1983", "1984", "1986", "1988", "1989") # annee sup
landworm <- landworm[!landworm$Annee %in% annes_omit, ]
landworm=droplevels(landworm)
#levels (landworm$Annee)
#summary (landworm$Annee)
summary_df <- as.data.frame(summary(landworm$Annee))
colnames(summary_df) <- c("Numbers")
# kable(summary_df,padding = 5)
summary_df %>% DT::datatable(options = list(pageLength = 5))
```

-   The database therefore changes from **`r n_line`** to **`r nrow(landworm)`** observations.

## Focus on clcm_lvl1

-   CR of clcm_lvl1 = **`r df_col[df_col$Variable=="clcm_lvl1","CR"]`** (`r length(levels(landworm$clcm_lvl1))` levels)

```{r clcm_lvl1, echo=TRUE}
landworm$clcm_lvl1= as.factor(landworm$clcm_lvl1)
summary_df <- as.data.frame(summary(landworm$clcm_lvl1))
colnames(summary_df) <- c("Numbers")
# kable(summary_df,padding = 5)
```

-   Merging levels

```{r merging clcm_lvl1, echo=TRUE}
levels(landworm$clcm_lvl1)[levels(landworm$clcm_lvl1) == "1_Naturel"] <- "Forest and semi natural areas"
levels(landworm$clcm_lvl1)[levels(landworm$clcm_lvl1) == "2_Agricole"] <- "Agricultural areas"

landworm$clcm_lvl1= as.factor(landworm$clcm_lvl1)
summary_df <- as.data.frame(summary(landworm$clcm_lvl1))
colnames(summary_df) <- c("Numbers")
kable(summary_df,padding = 5)
```

-   Update **code_clcm_lvl1**

```{r code_clcm_lvl1, echo=TRUE}
#landworm$code_clcm_lvl1 = as.factor(landworm$code_clcm_lvl1)

landworm$code_clcm_lvl1 <- ifelse(landworm$clcm_lvl1 == "Forest and semi natural areas", 3, landworm$code_clcm_lvl1)

landworm$code_clcm_lvl1 <- ifelse(landworm$clcm_lvl1 == "Agricultural areas", 2, landworm$code_clcm_lvl1)
```

-   For the moment, we will keep the NA of **clcm_lvl1**

## Focus on clcm_lvl2

-   CR of clcm_lvl2 = **`r df_col[df_col$Variable=="clcm_lvl2","CR"]`** (`r length(levels(landworm$clcm_lvl2))` levels)

```{r clcm_lvl2 , echo=TRUE}
landworm$clcm_lvl2= as.factor(landworm$clcm_lvl2)
summary_df <- as.data.frame(summary(landworm$clcm_lvl2))
colnames(summary_df) <- c("Numbers")
# summary_df %>% datatable(options = list(pageLength = 5))
```

-   Merging levels

```{r merging clcm_lvl2, echo=TRUE}
levels(landworm$clcm_lvl2)[levels(landworm$clcm_lvl2) == "21_Agricole ouvert"] <- "Arable land"

landworm$clcm_lvl2= as.factor(landworm$clcm_lvl2)
summary_df <- as.data.frame(summary(landworm$clcm_lvl2))
colnames(summary_df) <- c("Numbers")
# kable(summary_df,padding = 5)
summary_df %>% datatable(options = list(pageLength = 10), rownames = TRUE)
```

-   Update **code_clcm_lvl2**

```{r code_clcm_lvl2, echo=TRUE}

landworm$code_clcm_lvl2 <- ifelse(landworm$clcm_lvl2 == "Arable land", 21, landworm$code_clcm_lvl2)

```

## Focus on clcm_lvl3

-   CR of clcm_lvl3 = **`r df_col[df_col$Variable=="clcm_lvl3","CR"]`** (`r length(levels(landworm$clcm_lvl3))` levels)

```{r clcm_lvl3, echo=TRUE, scrollable = TRUE}
df_suivi = landworm
n_line = nrow(df_suivi)

landworm$clcm_lvl3= as.factor(landworm$clcm_lvl3)
summary_df <- as.data.frame(summary(landworm$clcm_lvl3))
colnames(summary_df) <- c("Numbers")
# kable(summary_df,padding = 5)
summary_df %>% datatable(options = list(pageLength = 10), rownames = TRUE)
```

## Land use selection (clcm_lvl3)

-   **Broad-leaved forest**

-   **Coniferous forest**

-   **Mixed forest**

-   **Pastures, meadows and other permanent grasslands under agricultural use**

-   **Non-irrigated arable land**

-   **Vineyards**

-   **Green urban areas**

-   **Natural grasslands**

```{r select clcm_lvl3, echo=TRUE}
# select_os= c("Broad-leaved forest", "Coniferous forest", "Mixed forest", 
# "Pastures, meadows and other permanent grasslands under agricultural use", "Non-irrigated arable land", "Vineyards","Green urban areas","Natural grasslands")


select_os= c("Broad-leaved forest", "Mixed forest", 
"Pastures, meadows and other permanent grasslands under agricultural use", "Non-irrigated arable land", "Vineyards","Green urban areas","Natural grasslands")


landworm <- landworm[landworm$clcm_lvl3 %in% select_os, ]
landworm=droplevels(landworm)
landworm$clcm_lvl3 = as.factor(landworm$clcm_lvl3)
summary_df <- as.data.frame(summary(landworm$clcm_lvl3))
colnames(summary_df) <- c("Numbers")
summary_df %>% datatable(options = list(pageLength = 5))

```

-   **We merge the two types of forest**

```{r}
landworm$clcm_lvl3= as.factor(landworm$clcm_lvl3)
levels(landworm$clcm_lvl3)[levels(landworm$clcm_lvl3)=="Broad-leaved forest"]="Forest"
# levels(landworm$clcm_lvl3)[levels(landworm$clcm_lvl3) == "Coniferous forest"] <- "Forest"
levels(landworm$clcm_lvl3)[levels(landworm$clcm_lvl3)=="Mixed forest"]="Forest"
landworm$clcm_lvl3= as.factor(landworm$clcm_lvl3)
landworm = droplevels(landworm)

summary_df <- as.data.frame(summary(landworm$clcm_lvl3))
colnames(summary_df) <- c("Numbers")
summary_df %>% datatable(options = list(pageLength = 5))

```

-   The database therefore changes from **`r n_line`** to **`r nrow(landworm)`** observations.

## Focus on protocols (après séléction)

-   List of protocols available on the database ( `r length(levels(landworm$Protocole))` levels)

```{r protocols,echo=TRUE}
landworm$Protocole = as.factor(landworm$Protocole)
summary_df <- as.data.frame(summary(landworm$Protocole))
colnames(summary_df) <- c("Numbers")
summary_df %>% datatable(options = list(pageLength = 5))

```

-   Merging levels :

    -   F_HS $=$ F_HS $+$ FHS
    -   HS $=$ HS $+$ hand sorting

    ```{r merging protocols,echo=TRUE}
    levels(landworm$Protocole)[levels(landworm$Protocole) == "FHS"] <- "F_HS"
    levels(landworm$Protocole)[levels(landworm$Protocole) == "hand sorting"] <- "HS"
    landworm$Protocole = as.factor(landworm$Protocole)
    summary_df <- as.data.frame(summary(landworm$Protocole))
    colnames(summary_df) <- c("Numbers")
       summary_df %>% datatable(options = list(pageLength = 5))
    ```

## Land use & protocol overview

```{r LU & protocol overview, echo=TRUE}
# kable (table(landworm$clcm_lvl1, landworm$Protocole,exclude = NULL), align = "c", format = "pipe", padding = 10)
# kable (table(landworm$clcm_lvl2, landworm$Protocole,exclude = NULL), align = "c", format = "pipe", padding = 10)
df = table(landworm$clcm_lvl3, landworm$Protocole,exclude = NULL)
# df = as.data.frame(df)
kable (df, align = "c", format = "pipe", padding = 10)

# df %>% datatable(options = list(pageLength = 8))
```

# Earthworms data

## Total abundance

```{r fig AB_tot,fig.align='center',fig.height=10}

df_suivi = landworm
n_line = nrow(df_suivi)

AB_tot_aberant = landworm[,c("ID","Programme", "Annee", "ID_Site","clcm_lvl1","clcm_lvl2","clcm_lvl3","Protocole","AB_tot")]
# summary(landworm$AB_tot) 
df_cleaned = landworm

df_cleaned$AB_tot = as.numeric(df_cleaned$AB_tot)
explo_num(nom_col = 'AB_tot', titre = 'AB_tot (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'AB_tot', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'AB_tot', direction = 'mini')
cat("Sppression des valeurs aberrantes")
explo_num(nom_col = 'AB_tot', titre = 'AB_tot (after cleaning)', df = df_cleaned)
# summary(df_cleaned$AB_tot) 
landworm = df_cleaned
```

<!-- **Zoom sur la partie bizard** -->

<!-- ```{r ,fig.align='center',fig.height=10} -->

<!-- # Cleveland plot -->

<!-- df = landworm[1600:3000,] -->

<!-- df = droplevels(df) -->

<!-- dotchart(df$AB_tot, pch = 16, col = 'blue', xlab = "titre") -->

<!-- ``` -->

<!-- **Par Protocole** -->

<!-- ```{r fig,fig.align='center',fig.height=10} -->

<!-- # Plot and color by groups Protocole -->

<!-- grps <- as.factor(df$Protocole) -->

<!-- my_cols <- c("blue", "red", "darkgreen") -->

<!-- dotchart(df$AB_tot, -->

<!--          groups = grps, gcolor = my_cols, -->

<!--          color = my_cols[grps], -->

<!--          cex = 0.9,  pch = 16, xlab = "Abundance") -->

<!-- ``` -->

<!-- ```{r} -->

<!-- landworm$Protocole = as.factor(landworm$Protocole) -->

<!-- summary_df <- as.data.frame(summary(landworm$Protocole)) -->

<!-- colnames(summary_df) <- c("Numbers") -->

<!-- kable(summary_df,padding = 5) -->

<!-- ``` -->

```{r}
# n_line = nrow(landworm)
# #select_protocole =c("F_HS", "FHS", "hand sorting" ,"HS")
# select_protocole =c("M")
# landworm <- landworm[!landworm$Protocole %in% select_protocole, ]
# landworm=droplevels(landworm)
# landworm$Protocole = as.factor(landworm$Protocole)
# summary_df <- as.data.frame(summary(landworm$Protocole))
# colnames(summary_df) <- c("Numbers")
# kable(summary_df,padding = 5)
```

-   The database therefore changes from **`r n_line`** to **`r nrow(landworm)`** observations.

## Graphe valeurs aberant AB_tot

```{r,fig.align='center', echo=TRUE, eval=FALSE}
# summary(AB_tot_aberant)
AB_tot_aberant_2 = AB_tot_aberant[AB_tot_aberant$AB_tot > max(landworm$AB_tot),]
AB_tot_aberant_2$clcm_lvl1 =as.factor(AB_tot_aberant_2$clcm_lvl1)
AB_tot_aberant_2$clcm_lvl2 =as.factor(AB_tot_aberant_2$clcm_lvl2)
AB_tot_aberant_2$clcm_lvl3 =as.factor(AB_tot_aberant_2$clcm_lvl3)
AB_tot_aberant_2 = droplevels(AB_tot_aberant_2)
kable(unique(AB_tot_aberant_2[,c("Programme","Annee","clcm_lvl3")]))

df = AB_tot_aberant_2
df$observation = 1:nrow(df)
df$Richesse_tot_10 = df$Richesse_tot*100
g_AB_tot_aberant = ggplot(df, aes(x = observation)) + 
  geom_point(aes(y = AB_tot, color = "Abundance")) +
  geom_line(aes(y = AB_tot, color = "Abundance")) + 
  geom_point(aes(y = Richesse_tot_10, color="Richness*100")) +
  geom_line(aes(y = Richesse_tot_10, color="Richness*100")) + 
  # ggtitle(title)
  theme(plot.title = element_text(hjust = 0.5)) + 
  labs(title = "  ",x="Observation", y="Values", color = "Legend:") +
  scale_color_manual(values = c("Abundance"='red', "Richness*100"='green'))
# ggsave("g_AB_tot_aberant.png", plot = g_AB_tot_aberant, dpi = 300)
 ggplotly(g_AB_tot_aberant)
 
```

## Total biomass

```{r fig BM_tot,fig.align='center',fig.height=10}

df_suivi = landworm
n_line = nrow(df_suivi)

# summary(landworm$BM_tot) 
df_cleaned = landworm

df_cleaned$BM_tot = as.numeric(df_cleaned$BM_tot)
explo_num(nom_col = 'BM_tot', titre = 'BM_tot (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'BM_tot', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'BM_tot', direction = 'mini')
cat("Sppression des valeurs aberrantes")
explo_num(nom_col = 'BM_tot', titre = 'BM_tot (after cleaning)', df = df_cleaned)
# summary(df_cleaned$BM_tot) 
landworm = df_cleaned
```

-   The database therefore changes from **`r n_line`** to **`r nrow(landworm)`** observations.

## Total taxonomic richness

```{r}
landworm_sp = landworm
```

**Total richness calculation method**

-   

    1.  Removal of columns with only NA and/or only 0

```{r step 1, echo=FALSE}
df_suivi = landworm_sp
n_line = nrow(df_suivi)

# on supprime tout les colonnes ayant que des NA
colonnes_na <- colnames(landworm_sp)[colSums(is.na(landworm_sp)) == nrow(landworm_sp)]
# summary(landworm_sp[, colonnes_na])
landworm_sp <- landworm_sp[, !colnames(landworm_sp) %in% colonnes_na]


# On supprimme toutes les colonnes ayant que des NA et des 0
colonnes_numeriques <- sapply(landworm_sp, is.numeric)
somme_colonnes_numeriques <- colSums(landworm_sp[, colonnes_numeriques],na.rm=TRUE)
colonnes_zeros <- names(somme_colonnes_numeriques[somme_colonnes_numeriques == 0])
#summary(landworm_sp[, colonnes_zeros])
landworm_sp <- landworm_sp[, !colnames(landworm_sp) %in% colonnes_zeros]
```

-   

    2.  Merging sub-species with their species

```{r step 2, echo=FALSE}
chemin_fichier_excel = "C:/Users/diall/Downloads/datas/choix_concaténation espèce_V2024.05.30.xlsx"
df_sp_sous_sp= read.xlsx(chemin_fichier_excel, sheet = "rules_1")

cat("Voici la liste des sp a fusionnée: \n")
df= df_sp_sous_sp []
rownames(df) = NULL
datatable(df, options = list(pageLength = 5))

```

```{r, echo=TRUE}
# function pour fusion les sous especes a leurs especes
sp_identique = function(df, nom_sous_espece, nom_espece ) {
  
  # Si les deux colonnes existent dans df
  if (nom_sous_espece %in% names(df) && nom_espece %in% names(df)) {
    
    # Addition des valeurs des deux colonnes et stockage du résultat dans nom_espece
    # df[[nom_espece]] = df[[nom_sous_espece]] + df[[nom_espece]]
    df[[nom_espece]] = rowSums(df[,c(nom_sous_espece,nom_espece)], na.rm = TRUE)
    

    df[[nom_sous_espece]] = NULL
  
  # Si nom_espece n'existe pas dans df mais nom_sous_espece existe
  } else if (nom_sous_espece %in% names(df) && !(nom_espece %in% names(df))) {
    
    # on renome nom_sous_espece par nom_espece
    names(df)[names(df) == nom_sous_espece] <- nom_espece
    df[[nom_sous_espece]] = NULL
  }
  
  return(df)
}


for (i in 1:nrow(df_sp_sous_sp)){
 
landworm_sp = sp_identique(df = landworm_sp,nom_sous_espece = df_sp_sous_sp[i,"col_sp_origines"],
                  nom_espece = df_sp_sous_sp[i,"col_sp_concatener"]) 
}

```

-   

    3.  Identify columns beginning with **AB\_**

```{r step 3, echo=FALSE}
# On récupère toutes les colonnes qui commencent par **AB_**
colonnes_AB <- grep("^AB_", names(landworm_sp), value = TRUE)
```

-   

    4.  Deletion of **AB\_** columns that are not species

```{r step 4, echo = TRUE}
# On supprimme les colonnes AB_ qui ne sont pas des espèces dans le calcule
ab_supprimee =  c("AB_AD",
                  "AB_JV",
                  "AB_SA",
                  "AB_STAD_X",
                  "AB_indéterminable",
                  "AB_Indéterminable",
                  "AB_indéterminable_endogeic",
                  "AB_tot",
                  "AB_Indéterminable_epigeic",
                  "AB_indéterminable_endogeic",
                  "AB_Ep.X",
                  "AB_vide",
                  "AB_Ep.X1",
                  "AB_Ep.X2",
                  "AB_A.X",
                  "AB_Adult",
                  "AB_cocon",
                  "AB_indéterminé",
                  "AB_Juvenile",
                  "AB_Sub.adult",
                  "AB_Indéterminé")

colonnes_AB <- colonnes_AB[!colonnes_AB %in% ab_supprimee]

cat("A ce stade, la liste des especes est: \n")
df= data.frame(colonnes_AB)
rownames(df) = NULL
DT::datatable(df, options = list(pageLength = 5))
```

-   

    5.  Calculate richness by assigning **1** to each column if the value is different from 0 and NA

<!-- -   Total richness = **1** if the plot has a value in AB and/or BM -->

A ce stade, la richesse varie de:

```{r step 5, echo=TRUE}
# On calcule la richesse en attribiant 1 à chaque colonne si la valeur est différent de 0 et de NA
landworm_sp$Richesse_tot <- 0
landworm_sp$Richesse_tot <- rowSums(!is.na(landworm_sp[colonnes_AB]) & landworm_sp[colonnes_AB] != 0)
#sum (is.na(landworm_sp$Richesse_tot) )
summary(landworm_sp$Richesse_tot)

```

-   

    6.  Décremmentation de la richesse

Voir code:

```{r step 6, echo=TRUE}
# Apres calcule richesse ------------------------------------------------------
sp_prorata <- function(df, sp_x, sp) {
  
  name_col <- names(df)
  
  #  si la colonne sp_x est présente
  if (sp_x %in% name_col) {
    
    # pour chaque ligne 
    for (i in 1:nrow(df)) {
      
      #  si les valeurs de la colonne sp_x ne sont ni 0 ni NA
      if (!is.na(df[i, sp_x]) && df[i, sp_x] != 0) {
        
        # Si la somme des ab des sp est différente de 0
        if (rowSums(df[i, sp], na.rm = TRUE) != 0) {
          # La richesse diminue de 1
          df[i, "Richesse_tot"] <- df[i, "Richesse_tot"] - 1
        }
      }
    }
  }
  
  return(df)
}

# Pour AB_Allolobophora_sp ------------------------------------------
sp_x = "AB_Allolobophora_sp"
sp=c("AB_Allolobophora_burgondiae",	
     "AB_Allolobophora_chlorotica",			
     "AB_Aporrectodea_cupulifera",	
     "AB_Aporrectodea_icterica",	
     "AB_Aporrectodea_limicola",	
     "AB_Aporrectodea_rosea")
# df= landworm_sp[, c(sp_x,sp, "Richesse_tot")]
# df=df[!df$AB_Allolobophora_sp == 0,]
# df=df[! is.na(df$AB_Allolobophora_sp),]
# df$som = rowSums(df[,sp], na.rm=TRUE)
# View(df)
# 
# dff <- sp_prorata(landworm_sp, sp_x, sp)
# dff= dff[, c(sp_x,sp, "Richesse_tot")]
# dff=dff[!dff$AB_Allolobophora_sp == 0,]
# dff=dff[! is.na(dff$AB_Allolobophora_sp),]
# dff$som = rowSums(dff[,sp], na.rm=TRUE)
# View(dff)
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)


# Pour AB_Aporrectodea_indéterminable ------------------------------------------
sp_x = "AB_Aporrectodea_indéterminable"
sp=c("AB_Allolobophora_burgondiae",	
     "AB_Allolobophora_chlorotica",
     "AB_Aporrectodea_cupulifera",
     "AB_Aporrectodea_icterica",
     "AB_Aporrectodea_limicola",
     "AB_Aporrectodea_rosea")
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)


# Pour AB_Aporrectodea_sp ------------------------------------------
sp_x = "AB_Aporrectodea_sp"
sp=c("AB_Aporrectodea_giardi",	
     "AB_Aporrectodea_longa",	
     "AB_Aporrectodea_nocturna",
     "AB_Aporrectodea_ripicola")
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)



# Pour AB_Dendrobaena_sp ------------------------------------------
# Tous les "Dendrobaena" et "Dendrodrilus_rubidus" + Satchellius mammalis
sp_x = "AB_Dendrobaena_sp"
sp=c("AB_Dendrobaena_alpina",     
     "AB_Dendrobaena_attemsi",
     "AB_Dendrobaena_cognettii",
     "AB_Dendrobaena_hortensis",      
     "AB_Dendrobaena_octaedra",
     "AB_Dendrodrilus_rubidus",
     "AB_Satchellius_mammalis")
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)


# Pour AB_Eisenia_sp ------------------------------------------
# Tous les Eisenia possible
sp_x = "AB_Eisenia_sp"
sp=c("AB_Eisenia_andrei",
     "AB_Eisenia_fetida",
     "AB_Eisenia_veneta",             
     "AB_Eiseniella_tetraedra")
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)


# Pour AB_Lumbricus_sp  ------------------------------------------
# Tous les Lumbricus sauf Lumbricus castaneus ?
sp_x = "AB_Lumbricus_sp"
sp=c("AB_Lumbricus_centralis",       
"AB_Lumbricus_festivus",         
"AB_Lumbricus_friendi",          
"AB_Lumbricus_herculeus",        
"AB_Lumbricus_meliboeus",        
"AB_Lumbricus_rubellus" ,        
"AB_Lumbricus_terrestris" )
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)



# Pour AB_Microscolex_sp  ------------------------------------------
# Tous les AB_Microscolex
sp_x = "AB_Microscolex_sp"
sp=c("AB_Microscolex_dubius",         
"AB_Microscolex_phosphoreus")
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)



# Pour AB_Octolasion_sp  ------------------------------------------
# Tous les AB_Octolasion
sp_x = "AB_Octolasion_sp"
sp=c("AB_Octodrilus_complanatus",    
"AB_Octolasion_cyaneum",         
"AB_Octolasion_lacteum")
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)



# Pour AB_Pheretima_indéterminable  ------------------------------------------
# AB_Pheritima_Diffringens
sp_x = "AB_Pheretima_indéterminable"
sp=c("AB_Pheritima_Diffringens", "AB_Pheritima_Diffringens")
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)



# Pour AB_Prosellodrilus_sp  ------------------------------------------
# Tous les Prosellodrilus
sp_x = "AB_Prosellodrilus_sp"
sp=c("AB_Prosellodrilus_amplisetosus",
"AB_Prosellodrilus_fragilis",    
"AB_Prosellodrilus_occidentalis",
"AB_Prosellodrilus_praticola",   
"AB_Prosellodrilus_pyrenaicus")
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)



# Pour AB_Scherotheca_sp  ------------------------------------------
# Tous les AB_Scherotheca_sp
sp_x = "AB_Scherotheca_sp"
sp=c("AB_Satchellius_mammalis",       
"AB_Scherotheca_aquitana",       
"AB_Scherotheca_dinoscolex",     
"AB_Scherotheca_nivicola",       
"AB_Scherotheca_porotheca",      
"AB_Scherotheca_rhodana",       
"AB_Scherotheca_savignyi")
landworm_sp <- sp_prorata(landworm_sp, sp_x, sp)

```

-   

    7.  Rules 3: Si le Owner de la parcelle est DC ou GP alors si Aporrectodea_trapezoides et/ou Aporrectodea_tuberculata sont presentent dans la parcelle alors si Aporrectodea_caliginosa est presente aussi dans la parcelle alors la richesse diminue de 1.

```{r step 7, echo=TRUE}

# dff <- data.frame(
#   owner = c("DC", "GP", "XX", "DC"),
#   AB_Aporrectodea_trapezoides = c(1, NA, 0, 2),
#   AB_Aporrectodea_tuberculata = c(NA, 0, 1, 3),
#   AB_Aporrectodea_caliginosa = c(2, 1, NA, 4),
#   Richesse_tot = c(10, 20, 30, 40)
# )
# df <- dff

df=landworm_sp
for (i in 1:nrow(df)) {
  # Si owner est "DC" ou "GP"
  if (df[i, "owner"] %in% c("DC", "GP")) {
    
    # si AB_Aporrectodea_trapezoides ou AB_Aporrectodea_tuberculata sont présents et non nuls
    if ((!is.na(df[i, "AB_Aporrectodea_trapezoides"]) && 
         df[i, "AB_Aporrectodea_trapezoides"] != 0) 
        || 
        (!is.na(df[i, "AB_Aporrectodea_tuberculata"]) && 
         df[i, "AB_Aporrectodea_tuberculata"] != 0)) {
      
      #  si AB_Aporrectodea_caliginosa est présente et non nulle
      if (!is.na(df[i, "AB_Aporrectodea_caliginosa"]) && 
          df[i, "AB_Aporrectodea_caliginosa"] != 0) {
        
        # La richesse diminue de 1 pour cette ligne
        df[i, "Richesse_tot"] <- df[i, "Richesse_tot"] - 1
      }
    }
  }
}


```

-   

    8.  Verifications

```{r step 8, echo=FALSE}
# Check des lignes ayant des 0 richesse et X AB ou BM : 0 lignes
# vdt_a_checker = landworm_sp[landworm_sp$Richesse_tot == 0 & (landworm_sp$Total_AB !=0 | landworm_sp$BM_to !=0), c("ID_Site","AB_tot","BM_tot","Richesse_tot")]
# vdt_a_checker = subset(vdt_a_checker, Richesse_tot==0)
# View(vdt_a_checker)
# vdt_a_checker$Richesse_tot <- 1
# Mettre à jour les ligne correspondant dans la landworm_sp 
# landworm_sp[rownames(landworm_sp) %in% rownames(vdt_a_checker), "Richesse_tot"] <- 1



# Check si y a des ligne ayant que des NA dans AB, BM et Richesse : nop
# resultat <- subset(landworm_sp, is.na(AB_tot) & is.na(BM_tot) & is.na(Richesse_tot))
# View(resultat[, c("AB_tot","BM_tot", "Richesse_tot")])



# Check si y a des ligne ayant que des zéros ou des NA dans AB, BM et Richesse_tot: 66 ligne
# vdt <- c("AB_tot", "BM_tot", "Richesse_tot")
# lignes_zero <- which(rowSums(landworm_sp[vdt] != 0, na.rm = TRUE) == 0)
# View(landworm_sp[lignes_zero,c("ID_Site","AB_tot", "BM_tot", "Richesse_tot")])



# Check des lignes ayant de BM mais pas de AB
# bm_sans_ab <- subset(landworm_sp, AB_tot == 0 & BM_tot != 0)
# bm_sans_ab[, c("ID","ID_Site", "Programme", "Protocole", "AB_tot", "BM_tot")]

# ab_sans_bm <- subset(landworm_sp, BM_tot == 0 & AB_tot != 0) # 1 parcelles
# ab_sans_bm[, c("ID","ID_Site", "Programme", "Protocole", "AB_tot", "BM_tot")]


# Check des doublons
# 
#duplicated_rows <- subset(landworm_sp, duplicated(landworm_sp[, c("ID", "AB_tot", "BM_tot")]) | #duplicated(landworm_sp[, c("ID", "AB_tot", "BM_tot")], fromLast = TRUE))

```

```{r}
save_landworm = landworm
landworm = landworm_sp
```

```{r fig richness, fig.align='center',fig.height=10}
df_suivi = landworm
n_line = nrow(df_suivi)

df_cleaned = landworm

df_cleaned$Richesse_tot = as.numeric(df_cleaned$Richesse_tot)
explo_num(nom_col = 'Richesse_tot', titre = 'Richesse_tot (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'Richesse_tot', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'Richesse_tot', direction = 'mini')
cat("Sppression des valeurs aberrantes")
explo_num(nom_col = 'Richesse_tot', titre = 'Richesse_tot (after cleaning)', df = df_cleaned)
# summary(df_cleaned$Richesse_tot) 
landworm = df_cleaned
```

-   The database therefore changes from **`r n_line`** to **`r nrow(landworm)`** observations.

```{r}
df= landworm[landworm$Richesse_tot>12,]
```

**Il n y a pas de valeurs aberant. Cependant, il y a `r nrow(df)` parcelles qui ont une richesse superieur a 12, a garder ou a supprimer ?**

**Details des Parcelles a forte richesse:**

```{r}
df= landworm[landworm$Richesse_tot>12,]

# Suppression des observations (lignes) qui ne contiennent que des NA ou des 0
df = df[rowSums(is.na(df) | df == 0) != ncol(df), ]

# Sélection des colonnes qui commencent par "AB_" et qui ont au moins une valeur différente de 0
df = df[, grep("^AB_", colnames(df))]
df = df[, colSums(df != 0, na.rm = TRUE) > 0]

# on elnleve les colonne qui sont dans ab_supprimee
df = df[, !colnames(df) %in% ab_supprimee]
# names(df)

id = landworm[rownames(df), c(1,2,4,13,223)]

dff = cbind(id, df)
# View(dff)
rownames(df) = NULL
DT::datatable(dff, options = list(pageLength = 5))
View(dff)
```

# Climate data extraction

```{r}
Predictors_f = c("CaCO3" ,"gps_x" ,"N" ,"bio3" ,"gps_y" ,"clay" ,
                 "silt" ,"clcm_lvl3" ,"P" ,"bio12" )
```

## The source database ([CHELSA V2](https://chelsa-climate.org/bioclim/){target="_blank"})

```{r Climate df extraction,echo=TRUE}

# Lire le fichier Excel
chemin_fichier_excel <- "C:/Users/diall/Downloads/datas/ODMAP.xlsx"
climat <- read.xlsx(chemin_fichier_excel, sheet = "climat")

# Fusions des cellules des colonnes avec des éléments dupliqués
for (col in names(climat)) {
  climat[[col]] <- ifelse(duplicated(climat[[col]]), "", climat[[col]])
}

# Affichage du tableau avec kableExtra et centrage du contenu des cellules
kableExtra::kable(climat) %>%
  kableExtra::kable_styling() %>%
  kableExtra::column_spec(1:ncol(climat)) 

```

## Extraction method

-   Link recovery ( see file [link .tif](https://1drv.ms/t/s!Avfm81EzNGBHjIZWw8YePljXaGSpCQ?e=qIPeWR){target="_blank"} )

-   Extracting variable names

-   Uses of the **extraction()** function

-   Convert columns to correct format and unit

-   Adding variables to the LANDWORM database

```{r Extraction method,echo=TRUE}
# liens_tif = read.table(file = "C:/Users/diall/Downloads/datas/enviDatas3paths.txt")
# liens_tif$shortname <- str_extract(liens_tif$V1, "(?<=CHELSA_).*?(?=_1981)")
# liens_tif[liens_tif$shortname=="rsds","shortname"]=c("rsds_max","rsds_mean","rsds_min","rsds_range")
# 
# #all(is.na(landworm$gps_x))
# #all(is.na(landworm$gps_y))
# 
# bdd_climat= landworm[, c("ID","gps_x","gps_y")]
# 
# temp_1=Sys.time()
# #for( i in 1:nrow(liens_tif)){
#   #nom=liens_tif[i,c("shortname")]
#   #df_ext <- extraction(nom_col = nom,df = bdd_climat,conv = 1, 
#                   #tif_file_path = liens_tif[i,c("V1")] ) 
#   #bdd_climat[[nom]] <- df_ext [,nom]
#   #rm("df_ext","nom")
#   #cat("Extraction: ",i,"/",nrow(liens_tif), "\n")
# #}
# temp_2=Sys.time()
# duree= difftime(temp_2,temp_1)
# 
# chemin_fichier <- "C:/Users/diall/OneDrive/Bureau/M2_MODE/stage_abdou_m2/datas/bdd_climat.rds"
# # saveRDS(bdd_climat, chemin_fichier)
# #bdd_climat <- readRDS(chemin_fichier)
# 
# # debut cnversion ------------------------------------------------------------
# conv_df_climat= data.frame(shortname =liens_tif$shortname )
# 
# # unit = 1
# conv_df_climat$unit = rep(1)
# # unit = 100
# unit_100=c("bio4")
# conv_df_climat$unit <- ifelse(conv_df_climat$shortname %in% unit_100, 100, 1)
# 
# 
# # scale = 0.1
# conv_df_climat$scale = rep(0.1)
# # scale = 1
# scale_1=c("fcf","fgd","gddlgd0","gddlgd5","gddlgd10","gdgfgd0","gdgfgd5","gdgfgd10","gsl","kg0","kg1" ,"kg2" ,"kg3" ,"kg4" ,"kg5","lgd","ngd0","ngd5","ngd10","scd")
# 
# # scale = 0.01
# scale_01=c("hurs_max","hurs_mean","hurs_min","hurs_range","pet_penman_max",
#        "pet_penman_mean","pet_penman_min","pet_penman_range")
# 
# # scale = 0.001
# scale_001=c("rsds","sfcWind_max","sfcWind_mean","sfcWind_min","sfcWind_range","pet_penman_max","pet_penman_mean","pet_penman_min","pet_penman_range","rsds_max","rsds_mean","rsds_min","rsds_range")
# 
# # Remplacement des valeurs de l'échelle en fonction des conditions
# conv_df_climat$scale <- ifelse(conv_df_climat$shortname %in% scale_1, 1,
#               ifelse(conv_df_climat$shortname %in% scale_01, 0.01,
#                     ifelse(conv_df_climat$shortname %in% scale_001,0.001, 0.1)))
# 
# # offset = 0
# conv_df_climat$offset = rep(0)
# # offset = - 273.15
# offset_273=c("bio1","bio5","bio6","bio8","bio9","bio10","bio11","gdgfgd10","gsl","gst")
# conv_df_climat$offset = ifelse(conv_df_climat$shortname %in% offset_273, -273.15, 0)
# 
# # Pas present dans dans le pdf explicative donc pas de conversion
# pas_pdf=c( "ai","swb", "clt_max","clt_mean","clt_min","clt_range")
# verif=c(unit_100,scale_1,scale_01,scale_001,offset_273)
# pas_pdf_2=setdiff(conv_df_climat$shortname, verif)
# conv_df_climat[conv_df_climat$shortname %in% pas_pdf,"scale"] = 1
# 
# #bdd_climat_ok=bdd_climat[,c("ID","gps_x","gps_y")]
# 
# #for ( i in conv_df_climat$shortname){
#   #if (i %in% names(bdd_climat)){
#   #unitee= conv_df_climat[conv_df_climat$shortname ==i,"unit"]
#   #echelle = conv_df_climat[conv_df_climat$shortname ==i,"scale"]
#   #decalage = conv_df_climat[conv_df_climat$shortname ==i,"offset"]
#   #bdd_climat_ok[[i]] = ((bdd_climat[[i]] / unitee)* echelle) + decalage
#   #}else {
#     #cat("Attention ",i, "n'exite pas dans la bdd_climat","\n")
#   #}
# #}
# 
# 
# # chemin_fichier <- "C:/Users/diall/OneDrive/Bureau/M2_MODE/stage_abdou_m2/datas/bdd_climat_ok.rds"
# # saveRDS(bdd_climat_ok, chemin_fichier)
# # bdd_climat_ok <- readRDS(chemin_fichier)
# # fin conversion
# 
# #df_fusion <- subset(bdd_climat_ok, select = -c(ID,gps_x, gps_y))
# #landworm <- cbind(landworm, df_fusion) # all = TRUE pour garder toutes les lignes
```

-   Merging database and climat database

```{r mergins & climat, echo=TRUE}
# Ajout variables climatiques (voir chunk extraction données climatiques)
chemin_fichier <- "C:/Users/diall/OneDrive/Bureau/M2_MODE/stage_abdou_m2/datas/bdd_climat_ok.rds"
# saveRDS(landworm_climat_ok, chemin_fichier)
landworm_climat_ok <- readRDS(chemin_fichier)
df_fusion <- subset(landworm_climat_ok, select = -c(gps_x, gps_y))

rows_not_in_df_fusion <- anti_join(landworm, df_fusion, by = "ID")

# summary(rows_not_in_df_fusion$owner)

merged_df <- merge(landworm, df_fusion, by = "ID")

ids_not_matching <- anti_join( merged_df,landworm, by = "ID")

landworm = merged_df

#landworm <- cbind(landworm, df_fusion) # all = TRUE pour garder toutes les lignes
```

## List of variables

[Variable description](https://chelsa-climate.org/wp-admin/download-page/CHELSA_tech_specification_V2.pdf){target="_blank"}

```{r}
summary(landworm_climat_ok)
```

<!-- ## temperature -->

<!-- -   Average annual air temperature (°C) = bio1 -->

```{r temperature,fig.align='center',fig.height=8}
# # summary(landworm$bio1)
# # explo_num(nom_col = "bio1", titre = "temp°.")
# 
# 
# df_cleaned = landworm
# 
# df_cleaned$bio1 = as.numeric(df_cleaned$bio1)
# explo_num(nom_col = 'bio1', titre = 'bio1 (before cleaning)', df = df_cleaned)
# df_cleaned <- test_grub(df_cleaned, 'bio1', direction = 'maxi')
# df_cleaned <- test_grub(df_cleaned, 'bio1', direction = 'mini')
# cat("Sppression des valeurs aberrantes")
# explo_num(nom_col = 'bio1', titre = 'bio1 (after cleaning)', df = df_cleaned)
# # summary(df_cleaned$bio1) 
# 
# landworm = df_cleaned
```

<!-- -   Ratio of diurnal variation to annual variation in temperatures (°C) = bio3 -->

```{r Isothermality,fig.align='center',fig.height=8}
# summary(landworm$bio3)
# explo_num(nom_col = "bio3", titre = "temp°.")


df_cleaned = landworm
df_cleaned$bio3 = as.numeric(df_cleaned$bio3)


# explo_num(nom_col = 'bio3', titre = 'bio3 (before cleaning)', df = df_cleaned)
# cat("Sppression des valeurs aberrantes")
df_cleaned = df_cleaned[df_cleaned$bio3 > 0.24, ]
# explo_num(nom_col = 'bio3', titre = 'bio3 (before cleaning)', df = df_cleaned)
# df_cleaned <- test_grub(df_cleaned, 'bio3', direction = 'maxi')
# df_cleaned <- test_grub(df_cleaned, 'bio3', direction = 'mini')
# cat("Sppression des valeurs aberrantes")
# explo_num(nom_col = 'bio3', titre = 'bio3 (after cleaning)', df = df_cleaned)
# summary(df_cleaned$bio3) 

landworm = df_cleaned

```

## Precipitation

-   Annual precipitation (kg/m²) = bio12

```{r Precipitation,fig.align='center',fig.height=8}
# summary(landworm$bio12)
# explo_num(nom_col = "bio12", titre = "temp°.")


df_cleaned = landworm

df_cleaned$bio12 = as.numeric(df_cleaned$bio12)
explo_num(nom_col = 'bio12', titre = 'bio12 (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'bio12', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'bio12', direction = 'mini')
cat("Sppression des valeurs aberrantes")
explo_num(nom_col = 'bio12', titre = 'bio12 (after cleaning)', df = df_cleaned)
# summary(df_cleaned$bio12) 

landworm = df_cleaned
```

# Soil data extraction

```{r Soil data extraction}
# Calcul des distances euclidiennes entre les sites
distances <- dist(cbind(landworm$gps_x, landworm$gps_y))
distance_moyenne <- mean(distances)
# distance_moyenne

df_col= taux_completion(landworm,FALSE,trie = TRUE)
df_col = df_col[df_col$Variables != "Total",]
```

## The source database ([openlandmap](https://openlandmap.org/?center=25,39&zoom=4&opacity=72&base=OpenStreetMap&layer=lc_glc.fcs30d&time=2022){target="_blank"})

```{r soil source database,echo=TRUE}
chemin_fichier_excel <- "C:/Users/diall/Downloads/datas/ODMAP.xlsx"
pedo <- read.xlsx(chemin_fichier_excel, sheet = "pedo")

# Fusion des cellules des colonnes avec des éléments dupliqués
for (col in names(pedo)) {
  pedo[[col]] <- ifelse(duplicated(pedo[[col]]), "", pedo[[col]])
}

#tableau avec kableExtra et centrage du contenu des cellules
kableExtra::kable(pedo) %>%
  kableExtra::kable_styling() %>%
  kableExtra::column_spec(1:ncol(pedo))  # Centrer le contenu de toutes les colonnes
```

\n

-   Average values between surface (0 cm) and 30 cm depth

````{=html}
<!--
## Changing the resolution ![](https://logowik.com/content/uploads/images/python.jpg){width="200"}

-   Long compilation time in R

-   GDAL module with the resampleAlg = bilinear method

-   Resolution = 0.0083 = 30 arc-second \~ 1km

```{r changing resolution}
    test_resolution = landworm
    tif_file_path_origine = "C:/Users/diall/Downloads/datas/raster_origine/sol_ph.h2o_usda.4c1a2a_m_250m_b10..10cm_1950..2017_v0.2.tif"
    raster_ph_origine <- raster(tif_file_path_origine)
    test_resolution <- extraction(nom_col = "ph_10_origine",df = test_resolution,conv = 10, 
                      tif_file_path = tif_file_path_origine)


    tif_file_path_rech = "C:/Users/diall/Downloads/datas/raster_modif/sol_ph.h2o_usda.4c1a2a_m_250m_b10..10cm_1950..2017_v0.2.tif"
    raster_ph_rech <- raster(tif_file_path_rech)
    test_resolution <- extraction(nom_col = "ph_10_rech",df = test_resolution,conv = 10, 
                      tif_file_path = tif_file_path_rech)

    par(mforw=c(1,2))
    image(raster_ph_origine,main="pH at 10cm: original raster (0.002)")
    image(raster_ph_rech, main = "pH at 10cm: raster modify (0.008)")


    bdd_echan = test_resolution
    bdd_echan <- bdd_echan %>%filter(!is.na(ph_10_origine) & !is.na(ph_10_rech))

    # graphique avec ggplot
        # coefficient de corrélation
    correlation <- cor(as.numeric(bdd_echan$ph_10_origine), bdd_echan$ph_10_rech)
    p <- ggplot(bdd_echan, aes(x = ph_10_origine, y = ph_10_rech)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle = paste("r = ", round(correlation, 2)),
           x = "Original pH", y = "Resampled pH") + 
      theme_classic() 

    p

    ```







## Soil organic carbone (g/kg)

```{r extract C,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = "c_orga_0",df = landworm,conv = 5, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_organic.carbon_usda.6a1c_m_250m_b0..0cm_1950..2017_v0.2.tif")
landworm <- extraction(nom_col = "c_orga_10",df = landworm,conv = 5, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_organic.carbon_usda.6a1c_m_250m_b10..10cm_1950..2017_v0.2.tif")
landworm <- extraction(nom_col = "c_orga_30",df = landworm,conv = 5, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_organic.carbon_usda.6a1c_m_250m_b30..30cm_1950..2017_v0.2.tif")
landworm = moyenne_val_extrct(nom_col = "c_orga_0_a_30", vec_col = c("c_orga_0","c_orga_10","c_orga_30"),df=landworm)



df_cleaned = landworm

df_cleaned$c_orga_0_a_30 = as.numeric(df_cleaned$c_orga_0_a_30)
explo_num(nom_col = 'c_orga_0_a_30', titre = 'c_orga_0_a_30 (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'c_orga_0_a_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'c_orga_0_a_30', direction = 'mini')
explo_num(nom_col = 'c_orga_0_a_30', titre = 'c_orga_0_a_30 (after cleaning)', df = df_cleaned)
# summary(df_cleaned$c_orga_0_a_30) 
landworm = df_cleaned


```


## pH

**Extracted values**

```{r extract pH,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = "ph_0",df = landworm,conv = 10, 
                  tif_file_path ="C:/Users/diall/Downloads/datas/raster_modif/sol_ph.h2o_usda.4c1a2a_m_250m_b10..10cm_1950..2017_v0.2.tif")

landworm <- extraction(nom_col = "ph_10" ,df = landworm,conv = 10, 
                  tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_ph.h2o_usda.4c1a2a_m_250m_b10..10cm_1950..2017_v0.2.tif")
landworm <- extraction(nom_col = "ph_30" ,df = landworm,conv = 10, 
                  tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_ph.h2o_usda.4c1a2a_m_250m_b30..30cm_1950..2017_v0.2.tif")
landworm = moyenne_val_extrct(nom_col = "ph_0_a_30", vec_col = c("ph_0","ph_10","ph_30"),df=landworm)
# summary(landworm$ph_0_a_30)

df_cleaned = landworm

df_cleaned$ph_0_a_30 = as.numeric(df_cleaned$ph_0_a_30)
explo_num(nom_col = 'ph_0_a_30', titre = 'ph_0_a_30 (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'ph_0_a_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'ph_0_a_30', direction = 'mini')
explo_num(nom_col = 'ph_0_a_30', titre = 'ph_0_a_30 (after cleaning)', df = df_cleaned)
# summary(df_cleaned$ph_0_a_30) 
landworm = df_cleaned

```

**Measured values & extracted values**

-   Clean pH column

```{r clean pH,echo=TRUE}
# On recupere les deux colonnes du pH
df_comp=landworm[, c("ID", "ID_Site","ph_eau","ph_0_a_30" )]
df_comp =df_comp[complete.cases(df_comp$ph_eau),] 
df_comp =df_comp[complete.cases(df_comp$ph_0_a_30),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$ph_eau), ]
df_comp$ph_eau <- as.numeric(df_comp$ph_eau)
df_comp$ph_0_a_30 <- as.numeric(df_comp$ph_0_a_30)


df_comp = df_comp[!df_comp$ph_eau== 44140.00,]
df_comp = df_comp[!df_comp$ph_eau== "NA",]
df_comp = df_comp[!df_comp$ph_0_a_30== "NA",]
df_comp = droplevels(df_comp)
```

```{r,echo=TRUE}
ID_Site_dupliques <- df_comp$ID_Site[duplicated(df_comp$ID_Site)]
#length(ID_Site_dupliques)

lignes_dupliquees <- subset(df_comp, duplicated(ID_Site) & duplicated(ph_eau))

lignes_unique <- unique(lignes_dupliquees$ID_Site )
#length(lignes_unique)

# nrow(df_comp) - length(ID_Site_dupliques) + length(lignes_unique)


dupliquees <- duplicated(df_comp$ID_Site)
df_comp <- df_comp[!dupliquees, ]
df_comp=droplevels(df_comp)

# correlation <- cor.test(df_comp$ph_eau, df_comp$ph_0_a_30,method = "pearson")
#resultat_test <- t.test(df_comp$ph_eau, df_comp$ph_0_a_30)

df_comp$ph_eau <- as.numeric(df_comp$ph_eau)
df_comp$ph_0_a_30 <- as.numeric(df_comp$ph_0_a_30)

```



::: columns
::: {.column width="60%"}
-   Method ?

-   Depth ?

-   Measured values (CR = `r df_col[df_col$Variable=="ph_eau","CR"]`)

```{r}
  summary(df_comp$ph_eau)
```

-   Extracted values

```{r}
  summary(df_comp$ph_0_a_30)
```
:::

::: {.column width="40%"}
```{r fig cor pH,fig.align='center',fig.height=5,fig.width=4}
    correlation <- cor(as.numeric(df_comp$ph_eau), df_comp$ph_0_a_30)
# graphique avec ggplot
    p <- ggplot(df_comp, aes(x = ph_eau, y = ph_0_a_30)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle =paste("r = ", round(correlation, 2)),x = "pH measured values", y = "pH extracted values") + 
      theme_classic() 
p
# plot(as.numeric(df_comp$ph_eau))
```
:::
:::


## Bulk density (kg / m-cube)

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = "d_ap_0",df = landworm,conv = 10, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_bulkdens.fineearth_usda.4a1h_m_250m_b0..0cm_1950..2017_v0.2.tif")
landworm <- extraction(nom_col = "d_ap_10",df = landworm,conv = 10, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_bulkdens.fineearth_usda.4a1h_m_250m_b10..10cm_1950..2017_v0.2.tif")
landworm <- extraction(nom_col = "d_ap_30",df = landworm,conv = 10, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_bulkdens.fineearth_usda.4a1h_m_250m_b30..30cm_1950..2017_v0.2.tif")
landworm = moyenne_val_extrct(nom_col = "d_ap_0_a_30", vec_col = c("d_ap_0","d_ap_10","d_ap_30"),landworm)
summary(landworm$d_ap_0_a_30)
explo_num(nom_col = "d_ap_0_a_30", titre = "Bulk density (0 - 30 cm)")
```


## Sand content (% kg/kg)

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = "sable_0",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_sand.wfraction_usda.3a1a1a_m_250m_b0..0cm_1950..2017_v0.2.tif")
landworm <- extraction(nom_col = "sable_10",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_sand.wfraction_usda.3a1a1a_m_250m_b10..10cm_1950..2017_v0.2.tif")
landworm <- extraction(nom_col = "sable_30",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sol_sand.wfraction_usda.3a1a1a_m_250m_b30..30cm_1950..2017_v0.2.tif")
landworm = moyenne_val_extrct(nom_col = "sable_0_a_30", vec_col = c("sable_0","sable_10","sable_30"),df=landworm)
summary(landworm$sable_0_a_30)
explo_num(nom_col = "sable_0_a_30", titre = "Sand (0 - 30 cm)")
```





## Sand

**Extracted values (g/kg, 0 - 30 cm)**

```{r extract sand,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = "sable.0_5",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sable.0_5.tif")

landworm <- extraction(nom_col = "sable.5_15",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sable.5_15.tif")

landworm <- extraction(nom_col = "sable.15_30",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/sable.15_30.tif")

landworm = moyenne_val_extrct(nom_col = "sable.0_30", vec_col = c("sable.0_5","sable.5_15","sable.15_30"),df=landworm)

# summary(landworm$sable.0_30)


df_cleaned = landworm

df_cleaned$sable.0_30 = as.numeric(df_cleaned$sable.0_30)
explo_num(nom_col = 'sable.0_30', titre = 'sable.0_30 (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'sable.0_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'sable.0_30', direction = 'mini')
explo_num(nom_col = 'sable.0_30', titre = 'sable.0_30 (after cleaning)', df = df_cleaned)
# summary(df_cleaned$sable.0_30) 
landworm = df_cleaned

```

**Measured values & extracted values**

-   Clean sand column

```{r,echo=TRUE}
# On recupere les deux colonnes du pH
df_comp=landworm[, c("ID", "ID_Site","sand","sable.0_30" )]
df_comp =df_comp[complete.cases(df_comp$sand),] 
df_comp =df_comp[complete.cases(df_comp$sable.0_30),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$sand), ]
df_comp$sand <- as.numeric(df_comp$sand)
df_comp$sable.0_30 <- as.numeric(df_comp$sable.0_30)
# colSums(is.na(df_comp))

df_comp = df_comp[!df_comp$sand== "NA",]
df_comp = df_comp[!df_comp$sable.0_30== "NaN",]
df_comp = droplevels(df_comp)
```

```{r,echo=TRUE}
# -   Deleting duplicate measured values

ID_Site_dupliques <- df_comp$ID_Site[duplicated(df_comp$ID_Site)]
#length(ID_Site_dupliques)

lignes_dupliquees <- subset(df_comp, duplicated(ID_Site) & duplicated(sand))

lignes_unique <- unique(lignes_dupliquees$ID_Site )
#length(lignes_unique)
# nrow(df_comp) - length(ID_Site_dupliques) + length(lignes_unique)

dupliquees <- duplicated(df_comp$ID_Site)
df_comp <- df_comp[!dupliquees, ]
df_comp=droplevels(df_comp)
df_comp$sand <- as.numeric(df_comp$sand)
df_comp$sable.0_30 <- as.numeric(df_comp$sable.0_30)

# summary(df_comp$sand)
# explo_num(nom_col = "sand", titre = "Sand extracted values",df = df_comp)
id_ligne <- df_comp[which(df_comp$sand >=83), "ID"] 
df_comp <- df_comp[!df_comp$ID %in% id_ligne, ]
df_comp=droplevels(df_comp)


# 
# summary(df_comp$sable.0_30)
# explo_num(nom_col = "sable.0_30", titre = "Sand extracted values",df = df_comp)
id_ligne <- df_comp[which(df_comp$sable.0_30 >=60), "ID"] 
df_comp <- df_comp[!df_comp$ID %in% id_ligne, ]
df_comp=droplevels(df_comp)

```

::: columns
::: {.column width="60%"}
-   Method ?

-   Depth ?

-   Measured values (CR = `r df_col[df_col$Variable=="sand","CR"]`)

```{r}
  summary(df_comp$sand)
```

-   Extracted values

```{r}
  summary(df_comp$sable.0_30)
```
:::

::: {.column width="40%"}
\n\n\n

```{r,fig.align='center',fig.height=5,fig.width=4}
# graphique avec ggplot
correlation <- cor(as.numeric(df_comp$sand), df_comp$sable.0_30)
    p <- ggplot(df_comp, aes(x = sand, y = sable.0_30)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle =paste("r = ", round(correlation, 2)) ,x = "Sand measured values", y = "Sand extracted values") + 
      theme_classic() 
p
# plot(as.numeric(df_comp$sand))
# plot(df_comp$sable.0_30)
```

:::
:::

-->
````

## Silt

**Extracted values (g/kg, 0 - 30 cm)**

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = "limon.0_5",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.0_5.tif")

landworm <- extraction(nom_col = "limon.5_15",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.5_15.tif")

landworm <- extraction(nom_col = "limon.15_30",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.15_30.tif")

landworm = moyenne_val_extrct(nom_col = "limon.0_30", vec_col = c("limon.0_5","limon.5_15","limon.15_30"),df=landworm)

df_cleaned = landworm

df_cleaned$limon.0_30 = as.numeric(df_cleaned$limon.0_30)
explo_num(nom_col = 'limon.0_30', titre = 'limon.0_30 (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'limon.0_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'limon.0_30', direction = 'mini')
cat("Sppression des valeurs aberrantes")
explo_num(nom_col = 'limon.0_30', titre = 'limon.0_30 (after cleaning)', df = df_cleaned)
# summary(df_cleaned$limon.0_30) 
landworm = df_cleaned

```

**Measured values & extracted values**

-   Clean silt column

```{r,echo=TRUE}
# On recupere les deux colonnes du pH
df_comp=landworm[, c("ID", "ID_Site","silt","limon.0_30" )]
df_comp =df_comp[complete.cases(df_comp$silt),] 
df_comp =df_comp[complete.cases(df_comp$limon.0_30),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$silt), ]
df_comp$silt <- as.numeric(df_comp$silt)
df_comp$limon.0_30 <- as.numeric(df_comp$limon.0_30)
# colSums(is.na(df_comp))


df_comp = df_comp[!df_comp$silt== "NA",]
df_comp = df_comp[!df_comp$limon.0_30== "NaN",]
df_comp = droplevels(df_comp)
```

```{r,echo=TRUE}
# -   Deleting duplicate measured values

ID_Site_dupliques <- df_comp$ID_Site[duplicated(df_comp$ID_Site)]
#length(ID_Site_dupliques)

lignes_dupliquees <- subset(df_comp, duplicated(ID_Site) & duplicated(silt))

lignes_unique <- unique(lignes_dupliquees$ID_Site )
#length(lignes_unique)
# nrow(df_comp) - length(ID_Site_dupliques) + length(lignes_unique)


dupliquees <- duplicated(df_comp$ID_Site)
df_comp <- df_comp[!dupliquees, ]
df_comp=droplevels(df_comp)
df_comp$silt <- as.numeric(df_comp$silt)
df_comp$limon.0_30 <- as.numeric(df_comp$limon.0_30)




# summary(df_comp$silt)
# explo_num(nom_col = "silt", titre = "Silt",df = df_comp)
id_ligne <- df_comp[which(df_comp$silt <=7.3), "ID"] 
df_comp <- df_comp[!df_comp$ID %in% id_ligne, ]
df_comp=droplevels(df_comp)



# summary(df_comp$limon.0_30)
# explo_num(nom_col = "limon.0_30", titre = "limon.0_30",df = df_comp)
id_ligne <- df_comp[which(df_comp$limon.0_30 >=80), "ID"] 
df_comp <- df_comp[!df_comp$ID %in% id_ligne, ]
df_comp=droplevels(df_comp)


```

::: columns
::: {.column width="60%"}
-   Method ?

-   Depth ?

-   Measured values (CR = `r df_col[df_col$Variable=="silt","CR"]`)

```{r}
  summary(df_comp$silt)
```

-   Extracted values

```{r}
  summary(df_comp$limon.0_30)
```
:::

::: {.column width="40%"}
\n\n\n

```{r,fig.align='center',fig.height=5,fig.width=4}
# graphique avec ggplot
correlation <- cor(as.numeric(df_comp$silt), df_comp$limon.0_30)
    p <- ggplot(df_comp, aes(x = silt, y = limon.0_30)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle =paste("r = ", round(correlation, 2)) ,x = "Silt measured values", y = "Silt extracted values") + 
      theme_classic() 
p

# plot(as.numeric(df_comp$limon.0_30))
```
:::
:::

## Clay

**Extracted values (g/kg, 0 - 30 cm)**

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = "argile.0_5",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/argile.0_5.tif")

landworm <- extraction(nom_col = "argile.5_15",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/argile.5_15.tif")

landworm <- extraction(nom_col = "argile.15_30",df = landworm,conv = 1, 
      tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/argile.15_30.tif")

landworm = moyenne_val_extrct(nom_col = "argile.0_30", vec_col = c("argile.0_5","argile.5_15","argile.15_30"),df=landworm)


df_cleaned = landworm

df_cleaned$argile.0_30 = as.numeric(df_cleaned$argile.0_30)
explo_num(nom_col = 'argile.0_30', titre = 'argile.0_30 (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'argile.0_30', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'argile.0_30', direction = 'mini')
cat("Sppression des valeurs aberrantes")
explo_num(nom_col = 'argile.0_30', titre = 'argile.0_30 (after cleaning)', df = df_cleaned)
# summary(df_cleaned$argile.0_30) 
landworm = df_cleaned

```

**Measured values & extracted values** - Clean clay column

```{r,echo=TRUE}
# On recupere les deux colonnes du pH
df_comp=landworm[, c("ID", "ID_Site","clay","argile.0_30" )]
df_comp =df_comp[complete.cases(df_comp$clay),] 
df_comp =df_comp[complete.cases(df_comp$argile.0_30),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$clay), ]
df_comp$clay <- as.numeric(df_comp$clay)
df_comp$argile.0_30 <- as.numeric(df_comp$argile.0_30)
# colSums(is.na(df_comp))

df_comp = df_comp[!df_comp$clay== "NA",]
df_comp = df_comp[!df_comp$argile.0_30== "NaN",]
df_comp = droplevels(df_comp)
```

```{r,echo=TRUE}
# -   Deleting duplicate measured values

ID_Site_dupliques <- df_comp$ID_Site[duplicated(df_comp$ID_Site)]
#length(ID_Site_dupliques)

lignes_dupliquees <- subset(df_comp, duplicated(ID_Site) & duplicated(clay))

lignes_unique <- unique(lignes_dupliquees$ID_Site )
#length(lignes_unique)
# nrow(df_comp) - length(ID_Site_dupliques) + length(lignes_unique)

dupliquees <- duplicated(df_comp$ID_Site)
df_comp <- df_comp[!dupliquees, ]
df_comp=droplevels(df_comp)
df_comp$clay <- as.numeric(df_comp$clay)
df_comp$argile.0_30 <- as.numeric(df_comp$argile.0_30)


df_comp$clay = as.numeric(df_comp$clay)/10 # pour conv en %

```

::: columns
::: {.column width="60%"}
-   Method ?

-   Depth ?

-   Measured values (CR = `r df_col[df_col$Variable=="clay","CR"]`)

```{r}
  summary(df_comp$clay)
```

-   Extracted values

```{r}
  summary(df_comp$argile.0_30)
```
:::

::: {.column width="40%"}
\n\n\n

```{r,fig.align='center',fig.height=5,fig.width=4}
# graphique avec ggplot
correlation <- cor(as.numeric(df_comp$clay), df_comp$argile.0_30)
    p <- ggplot(df_comp, aes(x = clay, y = argile.0_30)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = FALSE, color = "red") + 
      labs(subtitle =paste("r = ", round(correlation, 2)) ,x = "Clay measured values", y = "Clay extracted values") + 
      theme_classic() 
p
```
:::
:::

````{=html}
<!--
## Elevation

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = "elevation",df = landworm,conv = 1, 
                  tif_file_path ="C:/Users/diall/Downloads/datas/raster_modif/GMTED2010_Spatial.tif")


df_cleaned = landworm

df_cleaned$elevation = as.numeric(df_cleaned$elevation)
explo_num(nom_col = 'elevation', titre = 'elevation (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'elevation', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'elevation', direction = 'mini')
explo_num(nom_col = 'elevation', titre = 'elevation (after cleaning)', df = df_cleaned)
# summary(df_cleaned$elevation) 
landworm = df_cleaned

```



## pH_H2O_CaCl 

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = 'jrc_pH_H2O_CaCl', df = landworm, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/pH_H2O_CaCl.tif')

summary(landworm$jrc_pH_H2O_CaCl)

explo_num(nom_col = 'jrc_pH_H2O_CaCl', titre = 'jrc_pH_H2O_CaCl')
```

## pH_H2O 

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = 'jrc_pH_H2O', df = landworm, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/pH_H2O.tif')

summary(landworm$jrc_pH_H2O)

explo_num(nom_col = 'jrc_pH_H2O', titre = 'jrc_pH_H2O')

df_comp=landworm[, c("ID", "ID_Site","ph_eau","jrc_pH_H2O" )]
df_comp =df_comp[complete.cases(df_comp$ph_eau),] 
df_comp =df_comp[complete.cases(df_comp$jrc_pH_H2O),] 
df_comp <- df_comp[!grepl("[^0-9.]", df_comp$ph_eau), ]
df_comp$ph_eau <- as.numeric(df_comp$ph_eau)
df_comp$jrc_pH_H2O <- as.numeric(df_comp$jrc_pH_H2O)


df_comp = df_comp[!df_comp$ph_eau== 44140.00,]
df_comp = df_comp[!df_comp$ph_eau== "NA",]
df_comp = df_comp[!df_comp$jrc_pH_H2O== "NA",]
df_comp = droplevels(df_comp)

correlation <- cor(as.numeric(df_comp$ph_eau), df_comp$jrc_pH_H2O)
```

## pH_CaCl 

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = 'jrc_pH_CaCl', df = landworm, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/pH_CaCl.tif')

summary(landworm$jrc_pH_CaCl)

explo_num(nom_col = 'jrc_pH_CaCl', titre = 'jrc_pH_CaCl')
```

-->
````

## Phosphore (P, mg/kg)

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = 'P', df = landworm, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/P.tif')

df_cleaned = landworm

df_cleaned$P = as.numeric(df_cleaned$P)
explo_num(nom_col = 'P', titre = 'P (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'P', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'P', direction = 'mini')
cat("Sppression des valeurs aberrantes")
explo_num(nom_col = 'P', titre = 'P (after cleaning)', df = df_cleaned)
# summary(df_cleaned$P) 
landworm = df_cleaned
```

## Azote (N, g/kg) {#azote-n-gkg}

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = 'N', df = landworm, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/N.tif')


df_cleaned = landworm

df_cleaned$N = as.numeric(df_cleaned$N)
explo_num(nom_col = 'N', titre = 'N (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'N', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'N', direction = 'mini')
cat("Sppression des valeurs aberrantes")
explo_num(nom_col = 'N', titre = 'N (after cleaning)', df = df_cleaned)
# summary(df_cleaned$N) 
landworm = df_cleaned
```

back to [Plan]

````{=html}
<!-- 
## Potassium (K, mg/kg)

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = 'K', df = landworm, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/K.tif')


df_cleaned = landworm

df_cleaned$K = as.numeric(df_cleaned$K)
explo_num(nom_col = 'K', titre = 'K (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'K', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'K', direction = 'mini')
explo_num(nom_col = 'K', titre = 'K (after cleaning)', df = df_cleaned)
# summary(df_cleaned$N) 
landworm = df_cleaned
```

## C/N

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = 'CN', df = landworm, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/CN.tif')


df_cleaned = landworm

df_cleaned$CN = as.numeric(df_cleaned$CN)
explo_num(nom_col = 'CN', titre = 'CN (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'CN', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'CN', direction = 'mini')
explo_num(nom_col = 'CN', titre = 'CN (after cleaning)', df = df_cleaned)
# summary(df_cleaned$N) 
landworm = df_cleaned
```

## Capacité d'échange de cations (CEC, cmol/kg)

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = 'CEC', df = landworm, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/CEC.tif')

df_cleaned = landworm

df_cleaned$CEC = as.numeric(df_cleaned$CEC)
explo_num(nom_col = 'CEC', titre = 'CEC (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'CEC', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'CEC', direction = 'mini')
explo_num(nom_col = 'CEC', titre = 'CEC (after cleaning)', df = df_cleaned)
# summary(df_cleaned$N) 
landworm = df_cleaned
```

-->
````

## Carbonates de calcium (CaCO3, g/kg)

```{r,fig.align='center',fig.height=8}
landworm <- extraction(nom_col = 'CaCO3', df = landworm, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/CaCO3.tif')


df_cleaned = landworm

df_cleaned$CaCO3 = as.numeric(df_cleaned$CaCO3)
explo_num(nom_col = 'CaCO3', titre = 'CaCO3 (before cleaning)', df = df_cleaned)
df_cleaned <- test_grub(df_cleaned, 'CaCO3', direction = 'maxi')
df_cleaned <- test_grub(df_cleaned, 'CaCO3', direction = 'mini')
cat("Sppression des valeurs aberrantes")
explo_num(nom_col = 'CaCO3', titre = 'CaCO3 (after cleaning)', df = df_cleaned)
# summary(df_cleaned$N) 
landworm = df_cleaned
```

# Exploratory analysis

**Data set reduction**

```{r ana explo,echo=TRUE,fig.height=8,fig.show='animate',fig.align='center'}
id_col=c("ID","Programme","Annee","ID_Site","Protocole")

vdt_col=c("AB_tot", "BM_tot", "Richesse_tot")

Predictors_f = c("CaCO3" ,"gps_x" ,"N" ,"bio3" ,"gps_y" ,"argile.0_30" ,
                 "limon.0_30" ,"clcm_lvl3" ,"P" ,"bio12" )


landworm_explo = landworm[,c(id_col,vdt_col,Predictors_f)]

landworm_explo <- landworm_explo %>%
  dplyr::rename(
    silt = limon.0_30,
    clay = argile.0_30,
  )

Predictors_f = c("CaCO3" ,"gps_x" ,"N" ,"bio3" ,"gps_y" ,"clay" ,
                 "silt" ,"clcm_lvl3" ,"P" ,"bio12" )

cl_original <- levels(landworm_explo$clcm_lvl3)
new_cl <- c("f","gua", "ng", "nial", "p", "v")
landworm_explo$clcm_lvl3 <- factor(landworm_explo$clcm_lvl3, levels = cl_original, labels = new_cl)

```

```{r}
write.csv(x =landworm,file = "datas/landworm_richness.csv", row.names = FALSE)

write.xlsx(x =landworm,file = "datas/landworm_richness.xlsx")
```

## Total abundance distributions

```{r abundance dist,fig.align='center',fig.height=4,fig.width=4}
df <- data.frame(y =landworm_explo$AB_tot)
# Test de Shapiro-Wilk
AB_tot_test_nor = shapiro.test(df$y)
AB_tot_p.value =round(AB_tot_test_nor$p.value,3)
 if(AB_tot_p.value ==0){
   AB_tot_p.value = "; p.value > 0.001"
 } else {
   AB_tot_p.value = paste0("; p.value = ",AB_tot_p.value)   
 }
AB_tot_sub = paste0("Shapiro-Wilk; W = ",round(AB_tot_test_nor$statistic,2),AB_tot_p.value)

```

::: columns
::: {.column width="50%"}
<p><img src="lamda_boxcox.png"/></p>

<br/>

```{r}
# Histogramme
ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Abundance", subtitle =AB_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
```

-   Transformation sqrt

```{r ,fig.dpi=300,fig.align='center',fig.height=4,fig.width=4}
df_2 <- data.frame(y =sqrt(landworm_explo$AB_tot))
# Test de Shapiro-Wilk
AB_tot_test_nor = shapiro.test(df_2$y)
AB_tot_p.value =round(AB_tot_test_nor$p.value,3)
 if(AB_tot_p.value ==0){
   AB_tot_p.value = "; p.value > 0.001"
 } else {
   AB_tot_p.value = paste0("; p.value = ",AB_tot_p.value)   
 }
AB_tot_sub = paste0("Shapiro-Wilk; W = ",round(AB_tot_test_nor$statistic,2),AB_tot_p.value)

```

```{r}
# Histogramme
ggplot(df_2, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Abundance", subtitle =AB_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))

```
:::

::: {.column width="50%"}
```{r}
# https://r-coder.com/box-cox-transformation-r/?utm_content=cmp-true
# landworm_explo$AB_tot[landworm_explo$AB_tot < 0]
x = as.numeric ( landworm_explo$AB_tot )+1


b <- MASS::boxcox(lm(x ~ 1),plotit = FALSE) # ou bestNormalize

# Exact lambda
lambda1 <- b$x[which.max(b$y)]

MASS::boxcox(lm(x ~ 1),plotit = TRUE)


```

```         
lamda = `r lambda1`
```

<br/>

```{r}
# QQ-plot
qqnorm(df$y)
qqline(df$y)
```

<br/> <br/>

```{r}

# QQ-plot
qqnorm(df_2$y)
qqline(df_2$y)
```
:::
:::

## Total biomass distributions

```{r biomass dist,fig.align='center',fig.height=4,fig.width=4}
df <- data.frame(y =landworm_explo$BM_tot)
# Test de Shapiro-Wilk
BM_tot_test_nor = shapiro.test(df$y)
BM_tot_p.value =round(BM_tot_test_nor$p.value,3)
 if(BM_tot_p.value ==0){
   BM_tot_p.value = "; p.value > 0.001"
 } else {
   BM_tot_p.value = paste0("; p.value = ",BM_tot_p.value)   
 }
BM_tot_sub = paste0("Shapiro-Wilk; W = ",round(BM_tot_test_nor$statistic,2),BM_tot_p.value)

```

::: columns
::: {.column width="50%"}
<p><img src="lamda_boxcox.png"/></p>

<br/>

```{r}
# Histogramme
ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="biomass", subtitle =BM_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
```

-   Transformation sqrt

```{r ,fig.dpi=300,fig.align='center',fig.height=4,fig.width=4}
df_2 <- data.frame(y =sqrt(landworm_explo$BM_tot))
# Test de Shapiro-Wilk
BM_tot_test_nor = shapiro.test(df_2$y)
BM_tot_p.value =round(BM_tot_test_nor$p.value,3)
 if(BM_tot_p.value ==0){
   BM_tot_p.value = "; p.value > 0.001"
 } else {
   BM_tot_p.value = paste0("; p.value = ",BM_tot_p.value)   
 }
BM_tot_sub = paste0("Shapiro-Wilk; W = ",round(BM_tot_test_nor$statistic,2),BM_tot_p.value)

```

```{r}
# Histogramme
ggplot(df_2, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="biomass", subtitle =BM_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))

```
:::

::: {.column width="50%"}
```{r}
# https://r-coder.com/box-cox-transformation-r/?utm_content=cmp-true
# landworm_explo$BM_tot[landworm_explo$BM_tot < 0]
x = as.numeric ( landworm_explo$BM_tot )+1


b <- MASS::boxcox(lm(x ~ 1),plotit = FALSE)

# Exact lambda
lambda <- b$x[which.max(b$y)]

lambda = round(lambda,3)
MASS::boxcox(lm(x ~ 1),plotit = TRUE)


```

```         
lamda = `r lambda`
```

<br/>

```{r}
# QQ-plot
qqnorm(df$y)
qqline(df$y)
```

<br/> <br/>

```{r}

# QQ-plot
qqnorm(df_2$y)
qqline(df_2$y)
```
:::
:::

## Total taxonomic richness distributions

```{r richness dist,fig.align='center',fig.height=4,fig.width=4}
df <- data.frame(y =landworm_explo$Richesse_tot)
# Test de Shapiro-Wilk
Richesse_tot_test_nor = shapiro.test(df$y)
Richesse_tot_p.value =round(Richesse_tot_test_nor$p.value,3)
 if(Richesse_tot_p.value ==0){
   Richesse_tot_p.value = "; p.value > 0.001"
 } else {
   Richesse_tot_p.value = paste0("; p.value = ",Richesse_tot_p.value)   
 }
Richesse_tot_sub = paste0("Shapiro-Wilk; W = ",round(Richesse_tot_test_nor$statistic,2),Richesse_tot_p.value)

```

::: columns
::: {.column width="50%"}
<p><img src="lamda_boxcox.png"/></p>

<br/>

```{r}
# Histogramme
ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="richness", subtitle =Richesse_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
```

-   Transformation sqrt

```{r ,fig.dpi=300,fig.align='center',fig.height=4,fig.width=4}
df_2 <- data.frame(y =sqrt(landworm_explo$Richesse_tot))
# Test de Shapiro-Wilk
Richesse_tot_test_nor = shapiro.test(df_2$y)
Richesse_tot_p.value =round(Richesse_tot_test_nor$p.value,3)
 if(Richesse_tot_p.value ==0){
   Richesse_tot_p.value = "; p.value > 0.001"
 } else {
   Richesse_tot_p.value = paste0("; p.value = ",Richesse_tot_p.value)   
 }
Richesse_tot_sub = paste0("Shapiro-Wilk; W = ",round(Richesse_tot_test_nor$statistic,2),Richesse_tot_p.value)

```

```{r}
# Histogramme
ggplot(df_2, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="richness", subtitle =Richesse_tot_sub, x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))

```
:::

::: {.column width="50%"}
```{r}
# https://r-coder.com/box-cox-transformation-r/?utm_content=cmp-true
# landworm_explo$Richesse_tot[landworm_explo$Richesse_tot < 0]
x = as.numeric ( landworm_explo$Richesse_tot )+1


b <- MASS::boxcox(lm(x ~ 1),plotit = FALSE)

# Exact lambda
lambda1 <- b$x[which.max(b$y)]

MASS::boxcox(lm(x ~ 1),plotit = TRUE)


```

```         
lamda = `r lambda1`
```

<br/>

```{r}
# QQ-plot
qqnorm(df$y)
qqline(df$y)
```

<br/> <br/>

```{r}

# QQ-plot
qqnorm(df_2$y)
qqline(df_2$y)
```
:::
:::

## Standarization

-   Transformation sqrt de l'abondance et de la biomasse

-   Transformation centrée reduite des prédicteurs

```{r}
landworm_explo_non_t = landworm_explo
landworm_explo$AB_tot = sqrt(landworm_explo$AB_tot)
landworm_explo$BM_tot = sqrt(landworm_explo$BM_tot)
# landworm_explo$Richesse_tot = sqrt(landworm_explo$Richesse_tot)

landworm_explo[,Predictors_f[-8]] = scale(landworm_explo[,Predictors_f[-8]])



data_lm = landworm_explo # données pour les models GLM, GAM et polY
data_deep = landworm_explo # données pour les models RF, GBM et ANN

```

# Spatial Thinning

## Spatial Thinning

```{r thin , eval =FALSE}
# write.csv2(x =landworm_explo_non_t,file = "datas/landW/landworm_explo_non_t.csv", row.names = FALSE)

landw_thining = landworm_explo_non_t

df_coord <- landworm_explo_non_t[, c("gps_x", "gps_y")] 
leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~gps_x, lat = ~gps_y, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")


```

## Bretagne

```{r, eval =FALSE}
bzh = read.csv2("datas/landW/bzh.csv",sep = ",")
bzh = bzh %>% mutate(gps_x = as.numeric(gps_x),gps_y = as.numeric(gps_y))
cat("nrow BZH befor thinning: ",nrow(bzh))
landw_thining = landw_thining[!landw_thining$ID %in% bzh$ID,]


df = bzh
df$AB_tot = rep("AB_tot")

set.seed(455)
thinned_dataset_full <-
  spThin::thin( loc.data = df, 
        lat.col = "gps_y", long.col = "gps_x", 
        spec.col = "AB_tot", 
        thin.par = 10, reps = 5, 
        locs.thinned.list.return = TRUE, 
        write.files = FALSE, 
        write.log.file = FALSE)

# plotThin( thinned_dataset_full )
df_bzh_thine= thinned_dataset_full[[1]]


df_coord <- bzh[, c("gps_x", "gps_y")] 
leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~gps_x, lat = ~gps_y, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")


df_coord <- df_bzh_thine[, c("Longitude", "Latitude")] 
leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~Longitude, lat = ~Latitude, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")


bzh_thining = bzh[rownames(bzh) %in% rownames(df_bzh_thine),]
landw_thining = rbind(landw_thining,bzh_thining)

cat("nrow BZH befor thinning: ",nrow(bzh_thining))

```

## Dijon

```{r , eval =FALSE}
dijon = read.csv2("datas/landW/dijon.csv",sep = ",")
dijon = dijon %>% mutate(gps_x = as.numeric(gps_x),gps_y = as.numeric(gps_y))

cat("nrow dijon befor thinning: ",nrow(dijon))

landw_thining = landw_thining[!landw_thining$ID %in% dijon$ID,]

df_coord <- dijon[, c("gps_x", "gps_y")] 
leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~gps_x, lat = ~gps_y, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")



df = dijon
df$AB_tot = rep("AB_tot")

set.seed(455)
thinned_dataset_full <-
  spThin::thin( loc.data = df, 
        lat.col = "gps_y", long.col = "gps_x", 
        spec.col = "AB_tot", 
        thin.par = 10, reps = 5, 
        locs.thinned.list.return = TRUE, 
        write.files = FALSE, 
        write.log.file = FALSE)

# plotThin( thinned_dataset_full )
df_dijon_thine= thinned_dataset_full[[1]]

df_coord <- df_dijon_thine[, c("Longitude", "Latitude")] 
leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~Longitude, lat = ~Latitude, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")


dijon_thining = dijon[rownames(dijon) %in% rownames(df_dijon_thine),]
landw_thining = rbind(landw_thining,dijon_thining)

cat("nrow dijon after thinning: ",nrow(dijon_thining))
```

## IDF

```{r , eval =FALSE}
idf = read.csv2("datas/landW/idf.csv",sep = ",")
idf = idf %>% mutate(gps_x = as.numeric(gps_x),gps_y = as.numeric(gps_y))

cat("nrow idf befor thinning: ",nrow(idf))


landw_thining = landw_thining[!landw_thining$ID %in% idf$ID,]

df_coord <- idf[, c("gps_x", "gps_y")] 
leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~gps_x, lat = ~gps_y, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")



df = idf
df$AB_tot = rep("AB_tot")

set.seed(455)
thinned_dataset_full <-
  spThin::thin( loc.data = df, 
        lat.col = "gps_y", long.col = "gps_x", 
        spec.col = "AB_tot", 
        thin.par = 10, reps = 5, 
        locs.thinned.list.return = TRUE, 
        write.files = FALSE, 
        write.log.file = FALSE)

# plotThin( thinned_dataset_full )
df_idf_thine= thinned_dataset_full[[1]]

df_coord <- df_idf_thine[, c("Longitude", "Latitude")] 
leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~Longitude, lat = ~Latitude, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")


idf_thining = idf[rownames(idf) %in% rownames(df_idf_thine),]
landw_thining = rbind(landw_thining,idf_thining)

cat("nrow idf after thinning: ",nrow(idf_thining))

```

## All

```{r , eval =FALSE}
df_coord <- landw_thining[, c("gps_x", "gps_y")]
leaflet(df_coord) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~gps_x, lat = ~gps_y, radius = 0.8, fillOpacity = 0.8, fillColor = "blue")


df_thin_s = landw_thining
set.seed(455)
thinned_dataset_full <-
  spThin::thin( loc.data = df_thin_s, 
        lat.col = "gps_y", long.col = "gps_x", 
        spec.col = "AB_tot", 
        thin.par = 10, reps = 5, 
        locs.thinned.list.return = TRUE, 
        write.files = FALSE, 
        write.log.file = FALSE)

# plotThin( thinned_dataset_full )
df_thin_s= thinned_dataset_full[[1]]


# sv_landw_thining = landw_thining
# 
# 
# sv_landw_thining_non_t = sv_landw_thining
# sv_landw_thining$AB_tot = as.numeric(sv_landw_thining$AB_tot)
# sv_landw_thining$AB_tot = sqrt(sv_landw_thining$AB_tot)
# sv_landw_thining$BM_tot = sqrt(sv_landw_thining$BM_tot)
# # sv_landw_thining$Richesse_tot = sqrt(sv_landw_thining$Richesse_tot)
# 
# sv_landw_thining = sv_landw_thining %>% mutate(bio3 = as.numeric(bio3),bio12 = as.numeric(bio12))
# sv_landw_thining[,Predictors_f[-8]] = scale(sv_landw_thining[,Predictors_f[-8]])
# 
# 
# 
# data_lm = sv_landw_thining # données pour les models GLM, GAM et polY
# data_deep = sv_landw_thining # données pour les models RF, GBM et ANN

```

## Test de corrélation

```{r, fig.align='center',fig.dpi=300}
correlation_matrix <- cor(data_deep[,Predictors_f[-8]],use = "na.or.complete")
corrplot::corrplot(correlation_matrix, method = "color", type = "lower", order = "hclust", addCoef.col = "black",diag = FALSE,cl.cex = 1,number.cex = 1)

```

## VIF

```{r, fig.align='center',fig.dpi=300}
# usdm::vif(data_deep[,Predictors_f[-8]])
# usdm::vifcor(data_deep[,Predictors_f[-8]], th = 0.7, keep = NULL, method = 'pearson')
usdm::vifstep(data_deep[,Predictors_f[-8]], th = 10, keep = NULL, method = 'pearson')
```

# Relationship between variables

<!-- [Explanatory power of variables] -->

## Abundance

```{r re AB_tot,fig.align='center',fig.show='animate'}
df_re_AB_tot= data_deep[,c("AB_tot",Predictors_f)]
for (i in names(df_re_AB_tot[,-1])){
  plot(df_re_AB_tot[,i],df_re_AB_tot[,1], main = paste("AB_tot &",i), xlab = i,ylab="Abundance" )
   # col_posi <- which(names(df_re_AB_tot) == i)
   # g =ggpairs(df_re_AB_tot[,c(1,col_posi)])
   # print(g)
}
```

-   Plots

```{r re AB_tot2,fig.align='center'}
df_re_AB_tot= data_deep[,c("AB_tot",Predictors_f)]
for (i in names(df_re_AB_tot[,-1])){
  # plot(df_re_AB_tot[,i],df_re_AB_tot[,1], main = paste("AB_tot &",i), xlab = i,ylab="Abundance" )
  cat(paste("- Abundance &",i,"\n"))
   col_posi <- which(names(df_re_AB_tot) == i)
   g =ggpairs(df_re_AB_tot[,c(1,col_posi)])
   print(g)
}

```

## Biomass

```{r re BM_tot,fig.align='center',fig.show='animate'}
df_re_BM_tot= data_deep[,c("BM_tot",Predictors_f)]
for (i in names(df_re_BM_tot[,-1])){
  plot(df_re_BM_tot[,i],df_re_BM_tot[,1], main = paste("BM_tot &",i), xlab = i,ylab="Biomass" )
   # col_posi <- which(names(df_re_BM_tot) == i)
   # g =ggpairs(df_re_BM_tot[,c(1,col_posi)])
   # print(g)
}
```

-   Plots

```{r re BM_tot2,fig.align='center'}
df_re_BM_tot= data_deep[,c("BM_tot",Predictors_f)]
for (i in names(df_re_BM_tot[,-1])){
  # plot(df_re_BM_tot[,i],df_re_BM_tot[,1], main = paste("BM_tot &",i), xlab = i,ylab="Biomass" )
  cat(paste("- Biomass &",i,"\n"))
   col_posi <- which(names(df_re_BM_tot) == i)
   g =ggpairs(df_re_BM_tot[,c(1,col_posi)])
   print(g)
}

```

## Richness

```{r re Richesse_tot,fig.align='center',fig.show='animate'}
df_re_Richesse_tot= data_deep[,c("Richesse_tot",Predictors_f)]
for (i in names(df_re_Richesse_tot[,-1])){
  plot(df_re_Richesse_tot[,i],df_re_Richesse_tot[,1], main = paste("Richesse_tot &",i), xlab = i,ylab="Richness" )
   # col_posi <- which(names(df_re_Richesse_tot) == i)
   # g =ggpairs(df_re_Richesse_tot[,c(1,col_posi)])
   # print(g)
}
```

-   Plots

```{r re Richesse_tot2,fig.align='center'}
df_re_Richesse_tot= data_deep[,c("Richesse_tot",Predictors_f)]
for (i in names(df_re_Richesse_tot[,-1])){
  # plot(df_re_Richesse_tot[,i],df_re_Richesse_tot[,1], main = paste("Richesse_tot &",i), xlab = i,ylab="Richness" )
  cat(paste("- Richness &",i,"\n"))
   col_posi <- which(names(df_re_Richesse_tot) == i)
   g =ggpairs(df_re_Richesse_tot[,c(1,col_posi)])
   print(g)
}

```

# Modeling

## Data preparation

```{r modeling AB_tot, echo=TRUE}
# AB_tot --------------------------------------------------------------------------
df_mod_AB_tot = data_deep[,c("AB_tot",Predictors_f)]
# # # colnames(df_mod_AB_tot)[colnames(df_mod_AB_tot) == "clcm_lvl3"] <- "clc3"
dummy_vars <- model.matrix(~ clcm_lvl3 - 1, data = df_mod_AB_tot)
df_mod_AB_tot <- cbind(df_mod_AB_tot, dummy_vars)
df_mod_AB_tot <- df_mod_AB_tot[, -which(names(df_mod_AB_tot) == "clcm_lvl3")]

df_mod_AB_tot = drop_na(df_mod_AB_tot)
df_mod_AB_tot = droplevels(df_mod_AB_tot)


# Partition
set.seed(123)
ind <- sample(2, nrow(df_mod_AB_tot), replace = T, prob = c(.8, .2))
AB_tot_train <- df_mod_AB_tot[ind==1,]
AB_tot_test <- df_mod_AB_tot[ind==2,]

# write.csv2(x =AB_tot_train,file = "datas/landW/AB_tot_train.csv", row.names = FALSE)
# write.csv2(x =AB_tot_test,file = "datas/landW/AB_tot_test.csv", row.names = FALSE)
# 
# AB_tot_train = read.csv2("datas/landW/AB_tot_train.csv")
# AB_tot_test = read.csv2("datas/landW/AB_tot_test.csv")
# df_mod_AB_tot = rbind(AB_tot_train,AB_tot_test)

AB_tot_train = as.data.frame(AB_tot_train)
AB_tot_test = as.data.frame(AB_tot_test)

df <- data.frame(y =AB_tot_train[,"AB_tot"])
abundance_dist_train = ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Abundance: Train", x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
# ggsave("Results/landW/abundance_dist_train.png", plot = abundance_dist_train, dpi = 300,width = 3,height = 2)

df <- data.frame(y =AB_tot_test[,"AB_tot"])
abundance_dist_test = ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Abundance: Test", x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
# ggsave("Results/landW/abundance_dist_test.png", plot = abundance_dist_test, dpi = 300,width = 3,height = 2)

# Distrvitbution de var rep dans train et de test: est ce homogene ?
abundance_dist_train_and_test = ggarrange(abundance_dist_train, abundance_dist_test,
                          labels = c('(a)', '(b)'),
                          common.legend = TRUE,
                          legend = 'right'
)


ggsave("Results/landW/abundance_dist_train_and_test.png", plot = abundance_dist_train_and_test, dpi = 300,height = 2,width = 4)

```

```{r modeling BM_tot}
# BM_tot --------------------------------------------------------------------------
df_mod_BM_tot = data_deep[,c("BM_tot",Predictors_f)]
# # # colnames(df_mod_BM_tot)[colnames(df_mod_BM_tot) == "clcm_lvl3"] <- "clc3"
dummy_vars <- model.matrix(~ clcm_lvl3 - 1, data = df_mod_BM_tot)
df_mod_BM_tot <- cbind(df_mod_BM_tot, dummy_vars)
df_mod_BM_tot <- df_mod_BM_tot[, -which(names(df_mod_BM_tot) == "clcm_lvl3")]

df_mod_BM_tot = drop_na(df_mod_BM_tot)
df_mod_BM_tot = droplevels(df_mod_BM_tot)

# Partition
set.seed(1862)
ind <- sample(2, nrow(df_mod_BM_tot), replace = T, prob = c(.8, .2))
BM_tot_train <- df_mod_BM_tot[ind==1,]
BM_tot_test <- df_mod_BM_tot[ind==2,]


# write.csv2(x =BM_tot_train,file = "datas/landW/BM_tot_train.csv", row.names = FALSE)
# write.csv2(x =BM_tot_test,file = "datas/landW/BM_tot_test.csv", row.names = FALSE)
# 
# 
# BM_tot_train = read.csv2("datas/landW/BM_tot_train.csv")
# BM_tot_test = read.csv2("datas/landW/BM_tot_test.csv")
# df_mod_BM_tot = rbind(BM_tot_train,BM_tot_test)


BM_tot_train = as.data.frame(BM_tot_train)
BM_tot_test = as.data.frame(BM_tot_test)



# # Distribution de var rep
df <- data.frame(y =BM_tot_train[,"BM_tot"])
biomass_dist_train = ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Biomass: Train", x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
# ggsave("Results/landW/biomass_dist_train.png", plot = biomass_dist_train, dpi = 300,width = 3,height = 2)

df <- data.frame(y =BM_tot_test[,"BM_tot"])
biomass_dist_test = ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Biomass: Test", x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
# ggsave("Results/landW/biomass_dist_test.png", plot = biomass_dist_test, dpi = 300,width = 3,height = 2)


# Distrvitbution de var rep dans train et de test: est ce homogene ?
biomass_dist_train_and_test = ggarrange(biomass_dist_train, biomass_dist_test,
                                          labels = c('(a)', '(b)'),
                                          common.legend = TRUE,
                                          legend = 'right')

ggsave("Results/landW/biomass_dist_train_and_test.png", plot = biomass_dist_train_and_test, dpi = 300 ,height = 2,width = 4)
```

```{r modeling Richesse_tot}
# Richesse_tot --------------------------------------------------------------------------
df_mod_Richesse_tot = data_deep[,c("Richesse_tot",Predictors_f)]
# # # colnames(df_mod_Richesse_tot)[colnames(df_mod_Richesse_tot) == "clcm_lvl3"] <- "clc3"
dummy_vars <- model.matrix(~ clcm_lvl3 - 1, data = df_mod_Richesse_tot)
df_mod_Richesse_tot <- cbind(df_mod_Richesse_tot, dummy_vars)
df_mod_Richesse_tot <- df_mod_Richesse_tot[, -which(names(df_mod_Richesse_tot) == "clcm_lvl3")]

df_mod_Richesse_tot = drop_na(df_mod_Richesse_tot)
df_mod_Richesse_tot = droplevels(df_mod_Richesse_tot)


# Partition
set.seed(123)
ind <- sample(2, nrow(df_mod_Richesse_tot), replace = T, prob = c(.8, .2))
Richesse_tot_train <- df_mod_Richesse_tot[ind==1,]
Richesse_tot_test <- df_mod_Richesse_tot[ind==2,]

# write.csv2(x =Richesse_tot_train,file = "datas/landW/Richesse_tot_train.csv", row.names = FALSE)
# write.csv2(x =Richesse_tot_test,file = "datas/landW/Richesse_tot_test.csv", row.names = FALSE)
# 
# Richesse_tot_train = read.csv2("datas/landW/Richesse_tot_train.csv")
# Richesse_tot_test = read.csv2("datas/landW/Richesse_tot_test.csv")
# df_mod_Richesse_tot = rbind(Richesse_tot_train,Richesse_tot_test)


Richesse_tot_train = as.data.frame(Richesse_tot_train)
Richesse_tot_test = as.data.frame(Richesse_tot_test)



# Distribution de var rep
df <- data.frame(y =Richesse_tot_train[,"Richesse_tot"])
richness_dist_train = ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Richness: Train", x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
# ggsave("Results/landW/richness_dist_train.png", plot = richness_dist_train, dpi = 300 ,width = 3,height = 2)

df <- data.frame(y =Richesse_tot_test[,"Richesse_tot"])
richness_dist_test = ggplot(df, aes(x=y)) +
  geom_histogram(aes(y=..density..), fill="#69b3a2", color="#e9ecef", bins=30, alpha=2) +
  geom_density(fill="black", alpha=0.2) +
  theme_gray() +
  labs(title="Richness: Test", x="Value", y="Density") +
  theme(plot.title = element_text(hjust = 0.5))
# ggsave("Results/landW/richness_dist_test.png", plot = richness_dist_test, dpi = 300 ,width = 3,height = 2)

# Distrvitbution de var rep dans train et de test: est ce homogene ?
richness_dist_train_and_test = ggarrange(richness_dist_train, richness_dist_test,
                                          labels = c('(a)', '(b)'),
                                          common.legend = TRUE,
                                          legend = 'right')

ggsave("Results/landW/richness_dist_train_and_test.png", plot = richness_dist_train_and_test, dpi = 300 ,height = 2,width = 4)

```

::: columns
::: {.column width="50%"}
**Abundance**

```{r, eval = FALSE}

dffff = data_deep[,c("AB_tot",Predictors_f)]
# # # colnames(dffff)[colnames(dffff) == "clcm_lvl3"] <- "clc3"
dummy_vars <- model.matrix(~ clcm_lvl3 - 1, data = dffff)
dffff <- cbind(dffff, dummy_vars)
dffff <- dffff[, -which(names(dffff) == "clcm_lvl3")]

dffff = drop_na(dffff)
dffff = droplevels(dffff)
cat("dim Abondance", nrow(dffff),"\n")
cat("dim Abondance", dim(dffff),"\n")
cat("dim Abondance", nrow(dffff),"\n")
```

-   Data partition (`r dim(df_mod_AB_tot)`):

    -   train data (80 %) = `r dim(AB_tot_train)`

    -   test data (20 %) = `r dim(AB_tot_test)`

**Biomasse**

-   Data partition (`r dim(df_mod_BM_tot)`):

    -   train data (80 %) = `r dim(BM_tot_train)`

    -   test data (20 %) = `r dim(BM_tot_test)`

**Richness**

-   Data partition (`r dim(df_mod_Richesse_tot)`):

    -   train data (80 %) = `r dim(Richesse_tot_train)`

    -   test data (20 %) = `r dim(Richesse_tot_test)`
:::

::: {.column width="50%"}
<p><img src="Results/landW/abundance_dist_train_and_test.png"/></p>

<p><img src="Results/landW/biomass_dist_train_and_test.png"/></p>

<p><img src="Results/landW/richness_dist_train_and_test.png"/></p>
:::
:::

## GLM

```{r function GLM, echo=TRUE}
GLM <- function(var_rep, df_app, df_valid,family = 'gaussian'){
  
  
  var_predicteurs = names(df_app[,-1])
 
  df_app = df_app[,c(var_rep,var_predicteurs)]
  df_valid = df_valid[,c(var_rep,var_predicteurs)]
  
  formula <- substitute(var_rep ~ ., list(var_rep = as.name(var_rep)))
  
  
  # entrainement du modele sur le jeu d'entrainement
  modelglm<-glm(formula,family = family ,data = df_app)
  
  # Prediction sur le jeu de validation
  pred.GLM<-predict(modelglm,newdata=as.data.frame(df_valid[,var_predicteurs]))
  
  # Calcul du RMSE pour évaluer la qualite du modele
  rmse <- round (sqrt(mean((df_valid[,var_rep] - pred.GLM)^2,na.rm=TRUE)),2)
  
  
 # Calcul du R² ajusté pour train
  R_adj_train <- calcule_R2(df_app[,var_rep],  predict(modelglm, newdata=df_app))
  n_train <- nrow(df_app)
  p_train <- ncol(df_app) - 1
  r_adj_train <- 1 - ((1 - R_adj_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² 
  # R_adj_test <-calcule_R2(df_valid[,var_rep],pred.GLM)
  # n_test <- nrow(df_valid)
  # p_test <- ncol(df_valid) - 1
  # r_adj_test <- 1 - ((1 - R_adj_test) * (n_test - 1) / (n_test - p_test - 1))
  
  res <- rms::lrm(df_valid[,var_rep]  ~ pred.GLM, x= TRUE, y = TRUE)
  res = res$stats
  r_adj_test = round (res[["R2"]],2)
  
  MAE <- mean(abs(pred.GLM - df_valid[,var_rep]),na.rm=TRUE)
  
  # Round results
  rmse <- round(rmse, 2)
  r_adj_train <- round(r_adj_train, 2)
  r_adj_test <- round(r_adj_test, 2)
  MAE <- round(MAE, 2)
  
  # output
  results_df <- data.frame(Algorithms = "GLM",
                         Response_variables = var_rep,
                         R2_adjusted_train = r_adj_train,
                         R2_adjusted_test = r_adj_test,
                         RMSE = rmse,
                         MAE = MAE)
    
  
  results <- list(RMSE = rmse, R_adj_train = r_adj_train, R_adj_test = r_adj_test, MAE = MAE, model = modelglm,predit = pred.GLM, df = results_df)
  return(results)
}

```

-   Gaussian distribution

## GAM

```{r function GAM, echo=TRUE}
GAM <- function(var_rep, df_app, df_valid, family = 'gaussian',method = "REML", interaction = FALSE){
  
  var_predicteurs = names(df_app[,-1])
  
  
  if (var_rep == "AB_tot"){ 

  modelgam<-gam(AB_tot ~ s(CaCO3) + s(gps_x) + s(N) + s(bio3) + s(gps_y) + s(clay) + s(silt) + s(P) + s(bio12) + clcm_lvl3f + clcm_lvl3gua + clcm_lvl3ng + clcm_lvl3nial + clcm_lvl3p + clcm_lvl3v,
        family=family,method = method,data = df_app)
  
  }
  
  
  
  
  if (var_rep == "BM_tot"){ 

  modelgam<-gam(BM_tot ~ s(CaCO3) + s(gps_x) + s(N) + s(bio3) + s(gps_y) + s(clay) + s(silt) + s(P) + s(bio12) + clcm_lvl3f + clcm_lvl3gua + clcm_lvl3ng + clcm_lvl3nial + clcm_lvl3p + clcm_lvl3v,
        family=family,method = method,data = df_app)
  
    
  }
  
  
  
  if(var_rep == "Richesse_tot"){ 
    
  modelgam<-gam(Richesse_tot ~ s(CaCO3) + s(gps_x) + s(N) + s(bio3) + s(gps_y) + s(clay) + s(silt) + s(P) + s(bio12) + clcm_lvl3f + clcm_lvl3gua + clcm_lvl3ng + clcm_lvl3nial + clcm_lvl3p + clcm_lvl3v ,
        family=family,method = method,data = df_app)
   
  }
  
  
  # Prediction sur le jeu de validation
  pred.GAM <- predict(modelgam,newdata=as.data.frame(df_valid[,var_predicteurs]))
  
  # Calcul du RMSE pour évaluer la qualite du modele
  rmse <- sqrt(mean((df_valid[,var_rep] - pred.GAM)^2,na.rm=TRUE))

  
# Calcul du R² ajusté pour train
  R_adj_train <- calcule_R2(df_app[,var_rep],  predict(modelgam, newdata=df_app))
  n_train <- nrow(df_app)
  p_train <- ncol(df_app) - 1
  r_adj_train <- 1 - ((1 - R_adj_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  # R_adj_test <-calcule_R2(df_valid[,var_rep],pred.GAM)
  # n_test <- nrow(df_valid)
  # p_test <- ncol(df_valid) - 1
  # r_adj_test <- 1 - ((1 - R_adj_test) * (n_test - 1) / (n_test - p_test - 1))
    res <- rms::lrm(df_valid[,var_rep]  ~ pred.GAM, x= TRUE, y = TRUE)
  res = res$stats
  r_adj_test = round (res[["R2"]],2)
  

  # Calcule le MAE
  MAE <- mean(abs(pred.GAM - df_valid[,var_rep]))
  
  # Round results
  rmse <- round(rmse, 2)
  r_adj_train <- round(r_adj_train, 2)
  r_adj_test <- round(r_adj_test, 2)
  MAE <- round(MAE, 2)
  
  
  # output
  results_df <- data.frame(Algorithms = "GAM",
                         Response_variables = var_rep,
                         R2_adjusted_train = r_adj_train,
                         R2_adjusted_test = r_adj_test,
                         RMSE = rmse,
                         MAE = MAE)
  
  
  results <- list(RMSE = rmse, R_adj_train = r_adj_train, R_adj_test = r_adj_test, MAE = MAE, model = modelgam, predit = pred.GAM, df = results_df)
  
  return(results)
}

```

-   Family = gaussian

-   Link function = identity

-   Method = REML

-   Tuning

## RF

-   Default model

```{r}
# Grille de hyperparametisation
RF_df_grid <- expand.grid(ntree = c(100,300,500,700,900,1000,1300,1500,1700,2000),
                       mtry = c(2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24),
                       nodesize = c(10 , 20,  30,  40,  50,  60,  70,  80))
```

-   RF model tuning by grid

-   ntree = $100,300,500,700,900,1000,1300,1500,1700,2000$

-   mtry = $2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24$

-   maxnodes = $10 , 20, 30, 40, 50, 60, 70, 80, 90, 100$

**Total number of models =** $ntree * mtry * maxnode = `r nrow(RF_df_grid)`$

-   Validation of models on test data

```{r function RF, echo=TRUE,fig.align='center'}
ForetAlea <- function(var_rep, df_app, df_valid, mtry, ntree, maxnodes) {
  
  set.seed(1863)
  col_posi <- which(names(df_app) == var_rep)
  ForeVDT <- randomForest::randomForest(df_app[-col_posi], df_app[[col_posi]], mtry = mtry, ntree = ntree, maxnodes = maxnodes)
  
  # Prediction on the validation dataset
  col_posi <- which(names(df_valid) == var_rep)
  pred.RF <- predict(ForeVDT, newdata = df_valid[, -col_posi])
  
  # Calculate RMSE to evaluate model quality
  rmse <- sqrt(mean((df_valid[, col_posi] - pred.RF)^2))
  
  
  # Calcul du R² ajusté pour train
  R_adj_train <- calcule_R2(df_app[,var_rep],  predict(ForeVDT, newdata=df_app))
  n_train <- nrow(df_app)
  p_train <- ncol(df_app) - 1
  r_adj_train <- 1 - ((1 - R_adj_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  # R_adj_test <-calcule_R2(df_valid[,col_posi],pred.RF)
  # n_test <- nrow(df_valid)
  # p_test <- ncol(df_valid) - 1
  # r_adj_test <- 1 - ((1 - R_adj_test) * (n_test - 1) / (n_test - p_test - 1))
  res <- rms::lrm(df_valid[,var_rep]  ~ pred.RF, x= TRUE, y = TRUE)
  res = res$stats
  r_adj_test = round (res[["R2"]],2)
  
  # Calculate MAE
  MAE <- mean(abs(pred.RF - df_valid[, col_posi]))
  
  # Round results
  rmse <- round(rmse, 2)
  r_adj_train <- round(r_adj_train, 2)
  r_adj_test <- round(r_adj_test, 2)
  MAE <- round(MAE, 2)
  
    # output
  results_df <- data.frame(Algorithms = "RF",
                         Response_variables = var_rep,
                         R2_adjusted_train = r_adj_train,
                         R2_adjusted_test = r_adj_test,
                         RMSE = rmse,
                         MAE = MAE)
  
  
  results <- list(RMSE = rmse, R_adj_train = r_adj_train, R_adj_test = r_adj_test, MAE = MAE, model = ForeVDT, predit = pred.RF, df = results_df)
  
  return(results)
}
```

```{r,fig.align='center'}
# # # Pour AB_tot  -----------------------------------------------------------------
# 
# AB_tot_RF_tuning = read.csv2("results_tuning/AB_tot_RF_tuning.csv")
# 
# 
# AB_tot_RF_tuning = as.data.frame(AB_tot_RF_tuning)
# AB_tot_RF_tuning = AB_tot_RF_tuning %>% arrange(mae)
# # head(AB_tot_RF_tuning)
# 
# AB_tot_best_param = AB_tot_RF_tuning[1,]
# 
# # plot(seq(1:nrow(AB_tot_RF_tuning)), AB_tot_RF_tuning$r_squared)
# 
# 
# 
# df <- data.frame(x = seq(1:nrow(AB_tot_RF_tuning)), y = AB_tot_RF_tuning$r_squared)
# RF_tuning = ggplot(df, aes(x = x, y = y)) +
#   geom_point() +
#   labs(x = "Index", y = "R Squared", title = "Abundance: R Squared over Index") +
#   theme_minimal()
# 
# 
# # ggsave("results_tuning/RF_tuning.png", plot = RF_tuning, dpi = 300)

```

<!-- <p> -->

<!--   <img src="results_tuning/RF_tuning.png"> -->

<!-- </p> -->

## GBM

```{r}
# Grille de hyperparametisation
GBM_df_grid <- expand.grid(n.trees = c(1000,1500,1700,2000,3000),
                       interaction.depth = c(3,  5,  6,  8, 10),
                       shrinkage = c(0.01, 0.02, 0.05, 0.001, 0.002, 0.005),
                       n.minobsinnode = c(2 , 5,  10,  30,  50,  70))
```

-   Default model

-   GBM model tuning by grid

-   n.trees = $1000, 1500, 1700, 2000, 3000$

-   shrinkage = $0.01, 0.02, 0.05, 0.001, 0.002, 0.005$

-   interaction.depth = $3, 5, 6, 8, 10$

-   n.minobsinnode = $2, 5, 10, 30, 50, 70$

**Total number of models =** $n.trees * shrinkage * interaction.depth * n.minobsinnode = `r nrow(GBM_df_grid)`$

-   Validation of models on test data

```{r function GBM, echo=TRUE}
GBM <- function(var_rep, df_app, df_valid,distribution = 'gaussian',n.trees ,shrinkage,interaction.depth,n.minobsinnode){

  formula <- substitute(var_rep ~ ., list(var_rep = as.name(var_rep)))

  Gradboost<-gbm(formula, data = df_app,
    distribution = distribution, 
    n.trees = n.trees,
    shrinkage = shrinkage,
    interaction.depth = interaction.depth,
    n.minobsinnode = n.minobsinnode) 
  
  # Prediction sur le jeu de validation :
   col_posi <- which(names(df_valid) == var_rep)
  prev.GBM<-predict(Gradboost,newdata=as.data.frame(df_valid[,-col_posi]))
 
  # Calcul du RMSE pour évaluer la qualité du modele
  rmse <- sqrt(mean((df_valid[,var_rep] - prev.GBM)^2))


# Calcul du R² ajusté pour train
  R_adj_train <- calcule_R2(df_app[,var_rep],  predict(Gradboost, newdata=df_app))
  n_train <- nrow(df_app)
  p_train <- ncol(df_app) - 1
  r_adj_train <- 1 - ((1 - R_adj_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  # R_adj_test <-calcule_R2(df_valid[,col_posi],prev.GBM)
  # n_test <- nrow(df_valid)
  # p_test <- ncol(df_valid) - 1
  # r_adj_test <- 1 - ((1 - R_adj_test) * (n_test - 1) / (n_test - p_test - 1))
    res <- rms::lrm(df_valid[,var_rep]  ~ prev.GBM, x= TRUE, y = TRUE)
  res = res$stats
  r_adj_test = round (res[["R2"]],2)
  

  # calcule MAE
  MAE <- mean(abs(prev.GBM - df_valid[,col_posi])) 
  
    
    # Round results
  rmse <- round(rmse, 2)
  r_adj_train <- round(r_adj_train, 2)
  r_adj_test <- round(r_adj_test, 2)
  MAE <- round(MAE, 2)
  
  
      # output
  results_df <- data.frame(Algorithms = "GBM",
                         Response_variables = var_rep,
                         R2_adjusted_train = r_adj_train,
                         R2_adjusted_test = r_adj_test,
                         RMSE = rmse,
                         MAE = MAE)
  
  
  results <- list(RMSE = rmse, R_adj_train = r_adj_train, R_adj_test = r_adj_test, MAE = MAE, model = Gradboost, predit = prev.GBM, df = results_df)
  
  
  return(results)
}
```

```{r}
# # Pour AB_tot  ------------------------------------------------------------------
# AB_tot_GBM_tuning = read.csv2("results_tuning/AB_tot_GBM_tuning.csv")
# 
# 
# AB_tot_GBM_tuning = as.data.frame(AB_tot_GBM_tuning)
# AB_tot_GBM_tuning = AB_tot_GBM_tuning %>% arrange(mae)
# # head(AB_tot_GBM_tuning)
# AB_tot_best_param = AB_tot_GBM_tuning[1,]
# 
# 
# df <- data.frame(x = seq(1:nrow(AB_tot_GBM_tuning)), y = AB_tot_GBM_tuning$r_squared)
# GBM_tuning = ggplot(df, aes(x = x, y = y)) +
#   geom_point() +
#   labs(x = "Index", y = "R Squared", title = "Abundance: R Squared over Index") +
#   theme_minimal()
# 
# 
# # ggsave("results_tuning/GBM_tuning.png", plot = GBM_tuning, dpi = 300)

```

<!-- <p> -->

<!--   <img src="results_tuning/GBM_tuning.png"> -->

<!-- </p> -->

## ANN

-   Default model

```{r,include=TRUE}
# # for(i in names(df_mod_AB_tot)){ cat(i,"+")}
# 
# n <- neuralnet(AB_tot~ clcm_lvl3f +clcm_lvl3gua +clcm_lvl3ng +clcm_lvl3nial +clcm_lvl3p +clcm_lvl3v + CaCO3 +gps_x + N+ bio3+ gps_y+clay+
#                  +silt+P+bio12,
#                data = AB_tot_train,
#                # hidden = c(1),
#                linear.output = F,
#                lifesign = 'full',
#                rep=1)
# 
# plot(n,
#      col.hidden = 'black',
#      col.hidden.synapse = 'black',
#      show.weights = F,
#      information = F,
#      fill = 'lightblue')
# 
# 
# 
# 
# ANN_1 <- keras_model_sequential()
# ANN_1 %>% 
#   layer_dense(units = 1, activation = 'relu', input_shape = c(15)) %>%
#   layer_dense(units = 1)
# 
# # Compile
# ANN_1 %>% keras::compile(loss = 'mse',
#                   optimizer = 'rmsprop',
#                   metrics = 'mae')
# summary(ANN_1)
# 
# Fit ANN_1
# myANN_1 <- ANN_1 %>%
#   fit(training,
#       trainingtarget,
#       epochs = 100,
#       #batch_size = 1,
#       validation_split = 0.2)
# plot_ANN1 = plot(myANN_1)

# ggsave("models/plot_ANN_default_model.png", plot = plot_ANN1, dpi = 300)

```

<!-- <p> -->

<!--   <img src="models/ANN_default_model.png"> -->

<!-- </p> -->

<!-- <p> -->

<!--   <img src="models/plot_ANN_default_model.png"> -->

<!-- </p> -->

-   Tunning

runs \<- tuning_run("Experiment.R", flags = list(dense_units1 = c(32, 64), dense_units2 = c(16, 32), dense_units3 = c(8, 16), dense_units4 = c(4, 8), dropout1 = c(0.4, 0.5), dropout2 = c(0.3, 0.4), dropout3 = c(0.2, 0.3), dropout4 = c(0.1, 0.2), batch_size = c(32, 64)))

-   hidden = c(32,32,16,8)

```{r}
# n <- neuralnet(AB_tot~ clcm_lvl3f +clcm_lvl3gua +clcm_lvl3ng +clcm_lvl3nial +clcm_lvl3p +clcm_lvl3v + CaCO3 +gps_x + N+ bio3+ gps_y+clay+
#                  +silt+P+bio12,
#                data = AB_tot_train,
#                hidden = c(32,32,16,8),
#                linear.output = F,
#                lifesign = 'full',
#                rep=1)
# 
# plot(n,
#      col.hidden = 'black',
#      col.hidden.synapse = 'black',
#      show.weights = F,
#      information = F,
#      fill = 'lightblue')
# 
# # Pour AB_tot  ------------------------------------------------------------------
# var_rep="AB_tot"
# AB_tot_ANN_tuning = read.csv2("results_tuning/AB_tot_ANN_tuning.csv")
# 
# # Best hyperparameter values
# AB_tot_ANN_tuning = as.data.frame(AB_tot_ANN_tuning)
# AB_tot_ANN_tuning = AB_tot_ANN_tuning %>% arrange(metric_val_mae)
# # head(AB_tot_ANN_tuning[,2:16])
# 
# best_param = AB_tot_ANN_tuning[1,]
# 
# 
# dense_units1 = as.numeric(best_param$flag_dense_units1)
# dense_units2 = as.numeric(best_param$flag_dense_units2)
# dense_units3 = as.numeric(best_param$flag_dense_units3)
# dense_units4 = as.numeric(best_param$flag_dense_units4)
# 
# dropout1 =as.numeric(best_param$flag_dropout1)
# dropout2 =as.numeric(best_param$flag_dropout2)
# dropout3 =as.numeric(best_param$flag_dropout3)
# dropout4 =as.numeric(best_param$flag_dropout4)
# 
# batch_size =as.numeric(best_param$flag_batch_size)
# 
# 
# # AB_tot TUNE MODEL
# ANN_tune_AB_tot <- keras_model_sequential()
# ANN_tune_AB_tot %>% 
#   layer_dense(units = dense_units1, activation = 'relu', input_shape = c(15)) %>%
#   layer_dropout(rate = dropout1)  %>%
#   layer_dense(units = dense_units2, activation = 'relu') %>%
#   layer_dropout(rate = dropout2)  %>%
#   layer_dense(units = dense_units3, activation = 'relu') %>%
#   layer_dropout(rate = dropout3)  %>%
#   layer_dense(units = dense_units4, activation = 'relu') %>%
#   layer_dropout(rate = dropout4)  %>%
#   layer_dense(units = 1)
# 
# 
# # Compile
# ANN_tune_AB_tot %>% keras::compile(loss = 'mse',
#                   optimizer = 'rmsprop',
#                   metrics = 'mae')
# 
# summary(ANN_tune_AB_tot)
# #  callback EarlyStopping
# mon_callback <- callback_early_stopping(
#   monitor = "val_mae",  # Surveille la perte sur l'ensemble de validation
#   patience = 10,         # Nombre d'époques sans amélioration avant l'arrêt
#   restore_best_weights = TRUE  # Restaure les poids du meilleur modèle
# )
# 
# 
# # Fit ANN_tune_AB_tot
# myANN_tune_AB_tot <- ANN_tune_AB_tot %>%
#   fit(training,
#       trainingtarget,
#       epochs = 100,
#       batch_size = batch_size,
#       validation_split = 0.2,
#       #callbacks = list(mon_callback)
#       )


```

<!-- <p> -->

<!--   <img src="models/ANN_tuning_model.png"> -->

<!-- </p> -->

<!-- <p> -->

<!--   <img src="Results/fig_ANN_tune_BM_tot.png"> -->

<!-- </p> -->

## Compilation

-   ANN AB_tot

```{r ANN AB_tot}
# Pour AB_tot  ------------------------------------------------------------------
var_rep="AB_tot"
AB_tot_ANN_tuning = read.csv2("results_tuning/AB_tot_ANN_tuning.csv")

# Best hyperparameter values
AB_tot_ANN_tuning = as.data.frame(AB_tot_ANN_tuning)
AB_tot_ANN_tuning = AB_tot_ANN_tuning %>% arrange(metric_val_mae)
# head(AB_tot_ANN_tuning[,2:16])

best_param = AB_tot_ANN_tuning[1,]


dense_units1 = as.numeric(best_param$flag_dense_units1)
dense_units2 = as.numeric(best_param$flag_dense_units2)
dense_units3 = as.numeric(best_param$flag_dense_units3)
dense_units4 = as.numeric(best_param$flag_dense_units4)

dropout1 =as.numeric(best_param$flag_dropout1)
dropout2 =as.numeric(best_param$flag_dropout2)
dropout3 =as.numeric(best_param$flag_dropout3)
dropout4 =as.numeric(best_param$flag_dropout4)

batch_size =as.numeric(best_param$flag_batch_size)


# data
training = AB_tot_train
test = AB_tot_test

training %<>% mutate_if(is.factor, as.numeric)
ind_var_rep <- which(names(training) == var_rep)
trainingtarget <- training[, ind_var_rep]
training <- training[, -ind_var_rep]
training <- as.matrix(training)
dimnames(training) <- NULL

ind_var_rep <- which(names(test) == var_rep)
testtarget <- test[, ind_var_rep]
test <- test[, -ind_var_rep]
test %<>% mutate_if(is.factor, as.numeric)
test <- as.matrix(test)
dimnames(test) <- NULL


# AB_tot TUNE MODEL
ANN_tune_AB_tot <- keras_model_sequential()
ANN_tune_AB_tot %>% 
  layer_dense(units = dense_units1, activation = 'relu', input_shape = c(15)) %>%
  layer_dropout(rate = dropout1)  %>%
  layer_dense(units = dense_units2, activation = 'relu') %>%
  layer_dropout(rate = dropout2)  %>%
  layer_dense(units = dense_units3, activation = 'relu') %>%
  layer_dropout(rate = dropout3)  %>%
  layer_dense(units = dense_units4, activation = 'relu') %>%
  layer_dropout(rate = dropout4)  %>%
  layer_dense(units = 1)


# Compile
ANN_tune_AB_tot %>% keras::compile(loss = 'mse',
                  optimizer = 'rmsprop',
                  metrics = 'mae')

#  callback EarlyStopping
mon_callback <- callback_early_stopping(
  monitor = "val_mae",  # Surveille la perte sur l'ensemble de validation
  patience = 10,         # Nombre d'époques sans amélioration avant l'arrêt
  restore_best_weights = TRUE  # Restaure les poids du meilleur modèle
)


# Fit ANN_tune_AB_tot
myANN_tune_AB_tot <- ANN_tune_AB_tot %>%
  fit(training,
      trainingtarget,
      epochs = 100,
      batch_size = batch_size,
      validation_split = 0.2,
      #callbacks = list(mon_callback)
      )


# fig_ANN_tune_AB_tot = plot(myANN_tune_AB_tot)
# ggsave("Results/landW/fig_ANN_tune_AB_tot.png", plot = fig_ANN_tune_AB_tot, dpi = 300)

# Evaluate
# ANN_tune_AB_tot %>% evaluate(test, testtarget)
ANN_tune_AB_tot_pred = ANN_tune_AB_tot %>% predict(test)
ANN_tune_AB_tot_mse = mean((testtarget-ANN_tune_AB_tot_pred)^2) # loss -> mse
ANN_tune_AB_tot_mae = mean(abs(ANN_tune_AB_tot_pred - testtarget),na.rm=TRUE) # MAE 
ANN_tune_AB_tot_rmse = sqrt(mean((testtarget - ANN_tune_AB_tot_pred)^2,na.rm=TRUE)) # rmse
ANN_tune_AB_tot_cor = cor(testtarget,ANN_tune_AB_tot_pred)^2 # R²



# Calcul du R² ajusté pour train
  R_adj_train <- calcule_R2(trainingtarget,  ANN_tune_AB_tot %>% predict(training))
  n_train <- nrow(training)
  p_train <- ncol(training)
  r_adj_train <- 1 - ((1 - R_adj_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  # R_adj_test <-calcule_R2(testtarget,ANN_tune_AB_tot_pred)
  # n_test <- nrow(test)
  # p_test <- ncol(test)
  # r_adj_test <- 1 - ((1 - R_adj_test) * (n_test - 1) / (n_test - p_test - 1))
  
  res <- rms::lrm(testtarget  ~ ANN_tune_AB_tot_pred, x= TRUE, y = TRUE)
  res = res$stats
  r_adj_test = round (res[["R2"]],2)
  
  

ANN_tune_AB_tot_results = data.frame(model = "ANN_tune_AB_tot",
                                     mse = round(ANN_tune_AB_tot_mse,2),                                                        mae = round(ANN_tune_AB_tot_mae,2),
                                     rmse = round(ANN_tune_AB_tot_rmse,2), 
                                     R_adj_train= round(r_adj_train,2),
                                     R_adj_test= round(r_adj_test,2))

      # output
ANN_tune_AB_tot_results_df <- data.frame(Algorithms = "ANN",
                         Response_variables = "AB_tot",
                         R2_adjusted_train = r_adj_train,
                         R2_adjusted_test = r_adj_test,
                         RMSE = ANN_tune_AB_tot_rmse,
                         MAE = ANN_tune_AB_tot_mae)
  
# ANN_tune_AB_tot_results

```

-   ANN BM_tot

```{r ANN BM_tot}
# Pour BM_tot  ------------------------------------------------------------------
var_rep="BM_tot"
BM_tot_ANN_tuning = read.csv2("results_tuning/BM_tot_ANN_tuning.csv")

# Best hyperparameter values
BM_tot_ANN_tuning = as.data.frame(BM_tot_ANN_tuning)
BM_tot_ANN_tuning = BM_tot_ANN_tuning %>% arrange(metric_val_mae)
# head(BM_tot_ANN_tuning[,2:16])

best_param = BM_tot_ANN_tuning[1,]

dense_units1 = as.numeric(best_param$flag_dense_units1)
dense_units2 = as.numeric(best_param$flag_dense_units2)
dense_units3 = as.numeric(best_param$flag_dense_units3)
dense_units4 = as.numeric(best_param$flag_dense_units4)

dropout1 =as.numeric(best_param$flag_dropout1)
dropout2 =as.numeric(best_param$flag_dropout2)
dropout3 =as.numeric(best_param$flag_dropout3)
dropout4 =as.numeric(best_param$flag_dropout4)

batch_size =as.numeric(best_param$flag_batch_size)


# data
training = BM_tot_train
test = BM_tot_test

training %<>% mutate_if(is.factor, as.numeric)
ind_var_rep <- which(names(training) == var_rep)
trainingtarget <- training[, ind_var_rep]
training <- training[, -ind_var_rep]
training <- as.matrix(training)
dimnames(training) <- NULL

ind_var_rep <- which(names(test) == var_rep)
testtarget <- test[, ind_var_rep]
test <- test[, -ind_var_rep]
test %<>% mutate_if(is.factor, as.numeric)
test <- as.matrix(test)
dimnames(test) <- NULL


# BM_tot TUNE MODEL
ANN_tune_BM_tot <- keras_model_sequential()
ANN_tune_BM_tot %>% 
  layer_dense(units = dense_units1, activation = 'relu', input_shape = c(15)) %>%
  layer_dropout(rate = dropout1)  %>%
  layer_dense(units = dense_units2, activation = 'relu') %>%
  layer_dropout(rate = dropout2)  %>%
  layer_dense(units = dense_units3, activation = 'relu') %>%
  layer_dropout(rate = dropout3)  %>%
  layer_dense(units = dense_units4, activation = 'relu') %>%
  layer_dropout(rate = dropout4)  %>%
  layer_dense(units = 1)


# Compile
ANN_tune_BM_tot %>% keras::compile(loss = 'mse',
                  optimizer = 'rmsprop',
                  metrics = 'mae')

#  callback EarlyStopping
mon_callback <- callback_early_stopping(
  monitor = "val_mae",  # Surveille la perte sur l'ensemble de validation
  patience = 10,         # Nombre d'époques sans amélioration avant l'arrêt
  restore_best_weights = TRUE  # Restaure les poids du meilleur modèle
)


# Fit ANN_tune_BM_tot
myANN_tune_BM_tot <- ANN_tune_BM_tot %>%
  fit(training,
      trainingtarget,
      epochs = 100,
      batch_size = batch_size,
      validation_split = 0.2,
      #callbacks = list(mon_callback)
      )

# fig_ANN_tune_BM_tot = plot(myANN_tune_BM_tot)
# ggsave("Results/landW/fig_ANN_tune_BM_tot.png", plot = fig_ANN_tune_BM_tot, dpi = 300)


# Evaluate
# ANN_tune_BM_tot %>% evaluate(test, testtarget)
ANN_tune_BM_tot_pred = ANN_tune_BM_tot %>% predict(test)
ANN_tune_BM_tot_mse = mean((testtarget-ANN_tune_BM_tot_pred)^2) # loss -> mse
ANN_tune_BM_tot_mae = mean(abs(ANN_tune_BM_tot_pred - testtarget),na.rm=TRUE) # MAE 
ANN_tune_BM_tot_rmse = sqrt(mean((testtarget - ANN_tune_BM_tot_pred)^2,na.rm=TRUE)) # rmse
ANN_tune_BM_tot_cor = cor(testtarget,ANN_tune_BM_tot_pred)^2 # R²



# Calcul du R² ajusté pour train
  R_adj_train <- calcule_R2(trainingtarget,  ANN_tune_BM_tot %>% predict(training))
  n_train <- nrow(training)
  p_train <- ncol(training)
  r_adj_train <- 1 - ((1 - R_adj_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  # R_adj_test <-calcule_R2(testtarget,ANN_tune_BM_tot_pred)
  # n_test <- nrow(test)
  # p_test <- ncol(test)
  # r_adj_test <- 1 - ((1 - R_adj_test) * (n_test - 1) / (n_test - p_test - 1))
    res <- rms::lrm(testtarget  ~ ANN_tune_BM_tot_pred, x= TRUE, y = TRUE)
  res = res$stats
  r_adj_test = round (res[["R2"]],2)
  
  
  

ANN_tune_BM_tot_results = data.frame(model = "ANN_tune_BM_tot",
                                     mse = round(ANN_tune_BM_tot_mse,2),                                                        mae = round(ANN_tune_BM_tot_mae,2),
                                     rmse = round(ANN_tune_BM_tot_rmse,2), 
                                     R_adj_train= round(r_adj_train,2),
                                     R_adj_test= round(r_adj_test,2))
# ANN_tune_BM_tot_results


      # output
ANN_tune_BM_tot_results_df <- data.frame(Algorithms = "ANN",
                         Response_variables = "BM_tot",
                         R2_adjusted_train = r_adj_train,
                         R2_adjusted_test = r_adj_test,
                         RMSE = ANN_tune_BM_tot_rmse,
                         MAE = ANN_tune_BM_tot_mae)


```

-   ANN Richesse_tot

```{r ANN Richesse_tot}
# Pour Richesse_tot  ------------------------------------------------------------------
var_rep="Richesse_tot"
Richesse_tot_ANN_tuning = read.csv2("results_tuning/Richesse_tot_ANN_tuning.csv")

# Best hyperparameter values
Richesse_tot_ANN_tuning = as.data.frame(Richesse_tot_ANN_tuning)
Richesse_tot_ANN_tuning = Richesse_tot_ANN_tuning %>% arrange(metric_val_mae)
# head(Richesse_tot_ANN_tuning[,2:16])

best_param = Richesse_tot_ANN_tuning[1,]

dense_units1 = as.numeric(best_param$flag_dense_units1)
dense_units2 = as.numeric(best_param$flag_dense_units2)
dense_units3 = as.numeric(best_param$flag_dense_units3)
dense_units4 = as.numeric(best_param$flag_dense_units4)

dropout1 =as.numeric(best_param$flag_dropout1)
dropout2 =as.numeric(best_param$flag_dropout2)
dropout3 =as.numeric(best_param$flag_dropout3)
dropout4 =as.numeric(best_param$flag_dropout4)

batch_size =as.numeric(best_param$flag_batch_size)


# data
training = Richesse_tot_train
test = Richesse_tot_test

training %<>% mutate_if(is.factor, as.numeric)
ind_var_rep <- which(names(training) == var_rep)
trainingtarget <- training[, ind_var_rep]
training <- training[, -ind_var_rep]
training <- as.matrix(training)
dimnames(training) <- NULL

ind_var_rep <- which(names(test) == var_rep)
testtarget <- test[, ind_var_rep]
test <- test[, -ind_var_rep]
test %<>% mutate_if(is.factor, as.numeric)
test <- as.matrix(test)
dimnames(test) <- NULL


# Richesse_tot TUNE MODEL
ANN_tune_Richesse_tot <- keras_model_sequential()
ANN_tune_Richesse_tot %>% 
  layer_dense(units = dense_units1, activation = 'relu', input_shape = c(15)) %>%
  layer_dropout(rate = dropout1+0.2)  %>%
  layer_dense(units = dense_units2, activation = 'relu') %>%
  layer_dropout(rate = dropout2+0.2)  %>%
  layer_dense(units = dense_units3, activation = 'relu') %>%
  layer_dropout(rate = dropout3+0.2)  %>%
  layer_dense(units = dense_units4, activation = 'relu') %>%
  layer_dropout(rate = dropout4+0.2)  %>%
  layer_dense(units = 1)


# Compile
ANN_tune_Richesse_tot %>% keras::compile(loss = 'mse',
                  optimizer = 'rmsprop',
                  metrics = 'mae')

#  callback EarlyStopping
mon_callback <- callback_early_stopping(
  monitor = "val_mae",  # Surveille la perte sur l'ensemble de validation
  patience = 10,         # Nombre d'époques sans amélioration avant l'arrêt
  restore_best_weights = TRUE  # Restaure les poids du meilleur modèle
)


# Fit ANN_tune_Richesse_tot
myANN_tune_Richesse_tot <- ANN_tune_Richesse_tot %>%
  fit(training,
      trainingtarget,
      epochs = 100,
      batch_size = batch_size,
      validation_split = 0.2,
      #callbacks = list(mon_callback)
      )


# fig_ANN_tune_Richesse_tot = plot(myANN_tune_Richesse_tot)
# ggsave("Results/landW/fig_ANN_tune_Richesse_tot.png", plot = fig_ANN_tune_Richesse_tot, dpi = 300)

# Evaluate
# ANN_tune_Richesse_tot %>% evaluate(test, testtarget)
ANN_tune_Richesse_tot_pred = ANN_tune_Richesse_tot %>% predict(test)
ANN_tune_Richesse_tot_mse = mean((testtarget-ANN_tune_Richesse_tot_pred)^2) # loss -> mse
ANN_tune_Richesse_tot_mae = mean(abs(ANN_tune_Richesse_tot_pred - testtarget),na.rm=TRUE) # MAE 
ANN_tune_Richesse_tot_rmse = sqrt(mean((testtarget - ANN_tune_Richesse_tot_pred)^2,na.rm=TRUE)) # rmse
ANN_tune_Richesse_tot_cor = cor(testtarget,ANN_tune_Richesse_tot_pred)^2 # R²



# Calcul du R² ajusté pour train
  R_adj_train <- calcule_R2(trainingtarget,  ANN_tune_Richesse_tot %>% predict(training))
  n_train <- nrow(training)
  p_train <- ncol(training)
  r_adj_train <- 1 - ((1 - R_adj_train) * (n_train - 1) / (n_train - p_train - 1))
  
  # Calcul du R² ajusté pour test
  # R_adj_test <-calcule_R2(testtarget,ANN_tune_Richesse_tot_pred)
  # n_test <- nrow(test)
  # p_test <- ncol(test)
  # r_adj_test <- 1 - ((1 - R_adj_test) * (n_test - 1) / (n_test - p_test - 1))
  res <- rms::lrm(testtarget  ~ ANN_tune_Richesse_tot_pred, x= TRUE, y = TRUE)
  res = res$stats
  r_adj_test = round (res[["R2"]],2)
  
  
  

ANN_tune_Richesse_tot_results = data.frame(model = "ANN_tune_Richesse_tot",
                                     mse = round(ANN_tune_Richesse_tot_mse,2),                                            mae = round(ANN_tune_Richesse_tot_mae,2),
                                     rmse = round(ANN_tune_Richesse_tot_rmse,2), 
                                     R_adj_train= round(r_adj_train,2),
                                     R_adj_test= round(r_adj_test,2))
# ANN_tune_Richesse_tot_results


# output
ANN_tune_Richesse_tot_results_df <- data.frame(Algorithms = "ANN",
                         Response_variables = "Richesse_tot",
                         R2_adjusted_train = r_adj_train,
                         R2_adjusted_test = r_adj_test,
                         RMSE = ANN_tune_Richesse_tot_rmse,
                         MAE = ANN_tune_Richesse_tot_mae)

```

# LandWorm results

<!-- : Case 1 -> repeated data -->

```{r}
# coul = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2")
# coul2 = c("#E69F00", "#1F77B4", "#009E73", "#F0E442", "#9467BD")
# coul3=c("#1F77B4", "#7F7F7F", "#2CA02C", "#D62728", "#9467BD")
couleurs = c("#2CA02C","#E69F00", "#1F77B4","#7F7F7F", "#D62728","#9467BD")
```

## Prediction of total abundance

```{r}
subtitle <- sprintf("Abundance : %.2f ± %.2f ind/m²", mean(data_deep$AB_tot, na.rm = TRUE), sd(data_deep$AB_tot, na.rm = TRUE))
```

```{r predit AB_tot, fig.align='center',}
# Prediction avec GLM -----------------------------------------
GLM_result_AB_tot = GLM(var_rep ="AB_tot", 
                             df_app=AB_tot_train, 
                             df_valid = AB_tot_test,
                             family = 'gaussian')
# GLM_result_AB_tot$RMSE
# GLM_result_AB_tot$MAE
# GLM_result_AB_tot$R_adj_train
# GLM_result_AB_tot$R_adj_test
# GLM_result_AB_tot$predit
# GLM_result_AB_tot$model
# GLM_result_AB_tot$df


GLM_AB_tot_pred <- GLM_result_AB_tot$predit^2

GLM_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = GLM_AB_tot_pred)

cor_GLM_AB_tot <- cor(GLM_df_AB_tot$Observed, GLM_df_AB_tot$Predicted)

  # graphique avec ggplot
GLM_AB_tot <- ggplot(GLM_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" GLM: R² adj (train) = ", round(GLM_result_AB_tot$R_adj_train,2),
                           "; \n R² = ", round(GLM_result_AB_tot$R_adj_test,2),
                           "; RMSE = ",  round(GLM_result_AB_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic() 

# Prediction avec GAM -----------------------------------------
GAM_result_AB_tot = GAM(var_rep ="AB_tot", 
                             df_app=AB_tot_train, 
                             df_valid = AB_tot_test,
                             family = 'gaussian',
                             method = "REML")
# GAM_result_AB_tot$RMSE
# GAM_result_AB_tot$MAE
# GAM_result_AB_tot$R_adj_train
# GAM_result_AB_tot$R_adj_test
# GAM_result_AB_tot$predit
# GAM_result_AB_tot$model

# mod_gam1_ab = GAM_result_AB_tot$model
# cv <- gam.check(GAM_result_AB_tot$model)
# print(cv)
# plot(mod_gam1_ab, pages = 1, seWithMean = TRUE)
# plot(mod_gam1_ab, residuals = TRUE, pch = 1)
# plot(ggeffects::ggpredict(mod_gam1_ab), facets = TRUE)
# gratia::draw(mod_gam1_ab, residuals = TRUE)
# # Verification
# par(mfrow = c(2, 2))
# gam.check(mod_gam1_ab)
# shapiro.test(mod_gam1_ab$res)
# concurvity(mod_gam1_ab,full = TRUE)
# concurvity(mod_gam1_ab,full = FALSE)





GAM_AB_tot_pred <- GAM_result_AB_tot$predit^2

GAM_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = GAM_AB_tot_pred)

cor_GAM_AB_tot <- cor(GAM_df_AB_tot$Observed, GAM_df_AB_tot$Predicted)

  # graphique avec ggplot
GAM_AB_tot <- ggplot(GAM_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" GAM: R² adj (train) = ", round(GAM_result_AB_tot$R_adj_train,2),
                           "; \n R² = ", round(GAM_result_AB_tot$R_adj_test,2),
                           "; RMSE = ",  round(GAM_result_AB_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic() 

# Prediction avec RF -----------------------------------------
AB_tot_RF_tuning = read.csv2("results_tuning/AB_tot_RF_tuning.csv")


AB_tot_RF_tuning = as.data.frame(AB_tot_RF_tuning)
AB_tot_RF_tuning = AB_tot_RF_tuning %>% arrange(mae)
# head(AB_tot_RF_tuning)

AB_tot_best_param = AB_tot_RF_tuning[1,]

# plot(seq(1:nrow(AB_tot_RF_tuning)), AB_tot_RF_tuning$r_squared)
# Best hyperparameter values
AB_tot_best_mtry = AB_tot_best_param$mtry
AB_tot_best_ntree = AB_tot_best_param$ntree
AB_tot_best_maxnodes = AB_tot_best_param$maxnode


RF_result_AB_tot = ForetAlea(var_rep ="AB_tot", 
                            df_app=AB_tot_train, 
                            df_valid = AB_tot_test,
                             mtry = 3,
                             ntree= AB_tot_best_ntree,
                             maxnodes = NULL)


# RF_result_AB_tot$RMSE
# RF_result_AB_tot$MAE
# RF_result_AB_tot$R_adj_train
# RF_result_AB_tot$R_adj_test
# RF_result_AB_tot$predit
# RF_result_AB_tot$model
# RF_result_AB_tot$df

# varImpPlot(RF_result_AB_tot$model)

RF_AB_tot_pred <- RF_result_AB_tot$predit^2

RF_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = RF_AB_tot_pred)

# cor_RF_AB_tot <- cor(RF_df_AB_tot$Observed, RF_df_AB_tot$Predicted)
# cor_RF_AB_tot^2
# res <- rms::lrm(RF_df_AB_tot$Observed  ~ RF_df_AB_tot$Predicted, x= TRUE, y = TRUE)
# res = res$stats
# round (res[["R2"]],2)


  # graphique avec ggplot
RF_AB_tot <- ggplot(RF_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(
        " RF: R² adj (train) = ", round(RF_result_AB_tot$R_adj_train,2),
        # "Abundance (ind./m²)",
                           "; \n R² = ", round(RF_result_AB_tot$R_adj_test,2),
                           "; RMSE = ",  round(RF_result_AB_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") + 
      theme_classic() 
best_algo_AB_tot = RF_AB_tot
saveRDS(RF_result_AB_tot$model, "cartographie/best_mod/RF_mod_AB_tot.RDS")

# Prediction avec GBM -----------------------------------------
AB_tot_GBM_tuning = read.csv2("results_tuning/AB_tot_GBM_tuning.csv")


AB_tot_GBM_tuning = as.data.frame(AB_tot_GBM_tuning)
AB_tot_GBM_tuning = AB_tot_GBM_tuning %>% arrange(mae)
# head(AB_tot_GBM_tuning)
AB_tot_best_param = AB_tot_GBM_tuning[1,]


# Best hyperparameter values
AB_tot_best_n.trees = AB_tot_best_param$n.trees
AB_tot_best_shrinkage = AB_tot_best_param$shrinkage
AB_tot_best_interaction.depth = AB_tot_best_param$interaction.depth
AB_tot_best_n.minobsinnode = AB_tot_best_param$n.minobsinnode


GBM_result_AB_tot =  GBM(var_rep ="AB_tot", 
                         df_app=AB_tot_train, 
                         df_valid = AB_tot_test,
                         distribution = 'gaussian',
                         n.trees = AB_tot_best_n.trees,
                         shrinkage = AB_tot_best_shrinkage,
                         interaction.depth = AB_tot_best_interaction.depth,
                         n.minobsinnode = AB_tot_best_n.minobsinnode)

# GBM_result_AB_tot$RMSE
# GBM_result_AB_tot$MAE
# GBM_result_AB_tot$R_adj_train
# GBM_result_AB_tot$R_adj_test
# GBM_result_AB_tot$predit
# GBM_result_AB_tot$model


# summary(GBM_result_AB_tot$model)
# best.iter <- gbm.perf(GBM_result_AB_tot$model, method = "cv")
# summary(GBM_result_AB_tot$model, n.trees = best.iter)




GBM_AB_tot_pred = GBM_result_AB_tot$predit^2

GBM_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = GBM_AB_tot_pred)

cor_GBM_AB_tot<- cor(GBM_df_AB_tot$Observed, GBM_df_AB_tot$Predicted)

# graphique avec ggplot
GBM_AB_tot <- ggplot(GBM_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" GBM: R² adj (train) = ", round(GBM_result_AB_tot$R_adj_train,2),
                           "; \n R² = ", round(GBM_result_AB_tot$R_adj_test,2),
                           "; RMSE = ",  round(GBM_result_AB_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic() 





# Prediction avec ANN -----------------------------------------
# ANN_tune_AB_tot_results$mse
# ANN_tune_AB_tot_results$mae
# ANN_tune_AB_tot_results$rmse
# ANN_tune_AB_tot_results$r_adj_train
# ANN_tune_AB_tot_results$r_adj_test


ANN_AB_tot_pred = ANN_tune_AB_tot_pred^2

ANN_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = ANN_AB_tot_pred)

cor_ANN_AB_tot <- cor(ANN_df_AB_tot$Observed, ANN_df_AB_tot$Predicted)

  # graphique avec ggplot
ANN_AB_tot <- ggplot(ANN_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") +
labs(subtitle =paste0(" ANN: R² adj (train) = ", round(ANN_tune_AB_tot_results$R_adj_train,2),
                           "; \n R² = ", round(ANN_tune_AB_tot_results$R_adj_test,2),
                           "; RMSE = ",  round(ANN_tune_AB_tot_results$rmse^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic()

# best algo --------------------------------------
graphe_AB_tot = ggarrange(GLM_AB_tot, GAM_AB_tot, RF_AB_tot, GBM_AB_tot, ANN_AB_tot,
  labels = c('(a)', '(b)','(c)', '(d)','(e)'),widths = 10,
  common.legend = TRUE,
  legend = 'right'
)
# ggsave("Results/landW/graphe_AB_tot.png", plot = graphe_AB_tot, dpi = 300,height = 6,width = 7)

# graphe_AB_tot


# df_tot = RF_df_AB_tot
# df_tot$observation = seq(1,nrow(df_tot))
# 
# 
# 
# # Calcul des quartiles
# q1 <- quantile(df_tot$Observed, 0.25)
# median <- quantile(df_tot$Observed, 0.50)
# q3 <- quantile(df_tot$Observed, 0.75)
# max_value <- max(df_tot$Observed)
# 
# # Création des DataFrames en fonction des quartiles
# df1 <- df_tot[df_tot$Observed <= q1,]
# df2 <- df_tot[df_tot$Observed > q1 & df_tot$Observed <= median,]
# df3 <- df_tot[df_tot$Observed > median & df_tot$Observed <= q3,]
# df4 <- df_tot[df_tot$Observed > q3,]
# 
# 
# 
# 
# AB_tot_p1 = plot_comp(df = df1,ylabel = "",title_class = "  min to Q1",legende = TRUE,xlabel = "",title = "RF: Abundance predicted and Observed valuess \n for different quartiles")
# 
# AB_tot_p2 = plot_comp(df = df2,ylabel = "" ,title_class = "Q1 to median",legende = FALSE,xlabel = "")
# AB_tot_p3 = plot_comp(df = df3,ylabel = "" ,title_class = "median to Q3" ,legende = FALSE,xlabel = "")
# AB_tot_p4 = plot_comp(df = df4,ylabel = "" ,title_class = " Q3 to max" ,legende = FALSE)
# 
# 
# RF_AB_tot_fig = ggarrange(AB_tot_p1, AB_tot_p2, AB_tot_p3, AB_tot_p4,
#   # labels = c('(a)', '(b)','(c)', '(d)'),
#   ncol = 1,vjust = 0.5,
#   common.legend = TRUE,
#   legend = 'right'
# )
# 
# ggsave("Results/landW/RF_AB_tot_fig.png", plot = RF_AB_tot_fig, dpi = 300,height = 8)
# 
# 
# df_tot$diff = abs(df_tot$Observed - df_tot$Predicted)
# df_best = df_tot[df_tot$diff<=15,]
# 
# plot_comp(df = df_best,ylabel = "Abundance" ,title_class = "     Best prediction",legende = TRUE,plotly = TRUE)



```

<p align="center">

<img src="Results/landW/graphe_AB_tot.png"/>

</p>

**The best algorithm for total abundance is: RF**

<!-- <p align="center"> -->

<!--   <img src="Results/landW/RF_AB_tot_fig.png"> -->

<!-- </p> -->

## Prediction of total biomass

```{r}
subtitle <- sprintf("Biomass : %.2f ± %.2f g/m²", mean(data_deep$BM_tot, na.rm = TRUE), sd(data_deep$BM_tot, na.rm = TRUE))
```

```{r predit BM_tot , fig.align='center' ,}
# Prediction avec GLM -----------------------------------------
GLM_result_BM_tot = GLM(var_rep ="BM_tot", 
                             df_app=BM_tot_train, 
                             df_valid = BM_tot_test,
                             family = 'gaussian')
# GLM_result_BM_tot$RMSE
# GLM_result_BM_tot$MAE
# GLM_result_BM_tot$R_adj_train
# GLM_result_BM_tot$R_adj_test
# GLM_result_BM_tot$predit
# GLM_result_BM_tot$model



GLM_BM_tot_pred <- GLM_result_BM_tot$predit^2

GLM_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = GLM_BM_tot_pred)

cor_GLM_BM_tot <- cor(GLM_df_BM_tot$Observed, GLM_df_BM_tot$Predicted)

  # graphique avec ggplot
GLM_BM_tot <- ggplot(GLM_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" GLM: R² adj (train) = ", round(GLM_result_BM_tot$R_adj_train,2),
                           "; \n R² = ", round(GLM_result_BM_tot$R_adj_test,2),
                           "; RMSE = ",  round(GLM_result_BM_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic() 

# Prediction avec GAM -----------------------------------------
GAM_result_BM_tot = GAM(var_rep ="BM_tot", 
                             df_app=BM_tot_train, 
                             df_valid = BM_tot_test,
                             family = 'gaussian',
                             method = "REML")
# GAM_result_BM_tot$RMSE
# GAM_result_BM_tot$MAE
# GAM_result_BM_tot$R_adj_train
# GAM_result_BM_tot$R_adj_test
# GAM_result_BM_tot$predit
# GAM_result_BM_tot$model

# mod_gam1_ab = GAM_result_BM_tot$model
# cv <- gam.check(GAM_result_BM_tot$model)
# print(cv)
# plot(mod_gam1_ab, pages = 1, seWithMean = TRUE)
# plot(mod_gam1_ab, residuals = TRUE, pch = 1)
# plot(ggeffects::ggpredict(mod_gam1_ab), facets = TRUE)
# gratia::draw(mod_gam1_ab, residuals = TRUE)
# # Verification
# par(mfrow = c(2, 2))
# gam.check(mod_gam1_ab)
# shapiro.test(mod_gam1_ab$res)
# concurvity(mod_gam1_ab,full = TRUE)
# concurvity(mod_gam1_ab,full = FALSE)





GAM_BM_tot_pred <- GAM_result_BM_tot$predit^2

GAM_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = GAM_BM_tot_pred)

cor_GAM_BM_tot <- cor(GAM_df_BM_tot$Observed, GAM_df_BM_tot$Predicted)

  # graphique avec ggplot
GAM_BM_tot <- ggplot(GAM_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" GAM: R² adj (train) = ", round(GAM_result_BM_tot$R_adj_train,2),
                           "; \n R² = ", round(GAM_result_BM_tot$R_adj_test,2),
                           "; RMSE = ",  round(GAM_result_BM_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic() 

# Prediction avec RF -----------------------------------------
BM_tot_RF_tuning = read.csv2("results_tuning/BM_tot_RF_tuning.csv")


BM_tot_RF_tuning = as.data.frame(BM_tot_RF_tuning)
BM_tot_RF_tuning = BM_tot_RF_tuning %>% arrange(mae)
# head(BM_tot_RF_tuning)

BM_tot_best_param = BM_tot_RF_tuning[1,]

# plot(seq(1:nrow(BM_tot_RF_tuning)), BM_tot_RF_tuning$r_squared)
# Best hyperparameter values
BM_tot_best_mtry = BM_tot_best_param$mtry
BM_tot_best_ntree = BM_tot_best_param$ntree
BM_tot_best_maxnodes = BM_tot_best_param$maxnode


RF_result_BM_tot = ForetAlea(var_rep ="BM_tot", 
                             df_app=BM_tot_train, 
                             df_valid = BM_tot_test,
                             mtry = 3,
                             ntree= BM_tot_best_ntree,
                             maxnodes = NULL)

# RF_result_BM_tot$RMSE
# RF_result_BM_tot$MAE
# RF_result_BM_tot$R_adj_train
# RF_result_BM_tot$R_adj_test
# RF_result_BM_tot$predit
# RF_result_BM_tot$model


RF_BM_tot_pred <- RF_result_BM_tot$predit^2

RF_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = RF_BM_tot_pred)

cor_RF_BM_tot <- cor(RF_df_BM_tot$Observed, RF_df_BM_tot$Predicted)

  # graphique avec ggplot
RF_BM_tot <- ggplot(RF_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(
        " RF: R² adj (train) = ", round(RF_result_BM_tot$R_adj_train,2),
         # "Biomass (g/m²)",
                           "; \n R² = ", round(RF_result_BM_tot$R_adj_test,2),
                           "; RMSE = ",  round(RF_result_BM_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") + 
      theme_classic() 
best_algo_BM_tot = RF_BM_tot
saveRDS(RF_result_BM_tot$model, "cartographie/best_mod/RF_mod_BM_tot.RDS")


# Prediction avec GBM -----------------------------------------
BM_tot_GBM_tuning = read.csv2("results_tuning/BM_tot_GBM_tuning.csv")


BM_tot_GBM_tuning = as.data.frame(BM_tot_GBM_tuning)
BM_tot_GBM_tuning = BM_tot_GBM_tuning %>% arrange(mae)
# head(BM_tot_GBM_tuning)
BM_tot_best_param = BM_tot_GBM_tuning[1,]


# Best hyperparameter values
BM_tot_best_n.trees = BM_tot_best_param$n.trees
BM_tot_best_shrinkage = BM_tot_best_param$shrinkage
BM_tot_best_interaction.depth = BM_tot_best_param$interaction.depth
BM_tot_best_n.minobsinnode = BM_tot_best_param$n.minobsinnode


GBM_result_BM_tot =  GBM(var_rep ="BM_tot", 
                         df_app=BM_tot_train, 
                         df_valid = BM_tot_test,
                         distribution = 'gaussian',
                         n.trees = BM_tot_best_n.trees,
                         shrinkage = BM_tot_best_shrinkage,
                         interaction.depth = BM_tot_best_interaction.depth,
                         n.minobsinnode = BM_tot_best_n.minobsinnode)

# GBM_result_BM_tot$RMSE
# GBM_result_BM_tot$MAE
# GBM_result_BM_tot$R_adj_train
# GBM_result_BM_tot$R_adj_test
# GBM_result_BM_tot$predit
# GBM_result_BM_tot$model


# summary(GBM_result_BM_tot$model)
# best.iter <- gbm.perf(GBM_result_BM_tot$model, method = "cv")
# summary(GBM_result_BM_tot$model, n.trees = best.iter)




GBM_BM_tot_pred = GBM_result_BM_tot$predit^2

GBM_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = GBM_BM_tot_pred)

cor_GBM_BM_tot<- cor(GBM_df_BM_tot$Observed, GBM_df_BM_tot$Predicted)

# graphique avec ggplot
GBM_BM_tot <- ggplot(GBM_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" GBM: R² adj (train) = ", round(GBM_result_BM_tot$R_adj_train,2),
                           "; \n R² = ", round(GBM_result_BM_tot$R_adj_test,2),
                           "; RMSE = ",  round(GBM_result_BM_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic() 





# Prediction avec ANN -----------------------------------------
# ANN_tune_BM_tot_results$mse
# ANN_tune_BM_tot_results$mae
# ANN_tune_BM_tot_results$rmse
# ANN_tune_BM_tot_results$r_adj_train
# ANN_tune_BM_tot_results$r_adj_test


ANN_BM_tot_pred = ANN_tune_BM_tot_pred^2

ANN_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = ANN_BM_tot_pred)

cor_ANN_BM_tot <- cor(ANN_df_BM_tot$Observed, ANN_df_BM_tot$Predicted)

  # graphique avec ggplot
ANN_BM_tot <- ggplot(ANN_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") +
labs(subtitle =paste0(" ANN: R² adj (train) = ", round(ANN_tune_BM_tot_results$R_adj_train,2),
                           "; \n R² = ", round(ANN_tune_BM_tot_results$R_adj_test,2),
                           "; RMSE = ",  round(ANN_tune_BM_tot_results$rmse^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic()

# best algo --------------------------------------
graphe_BM_tot = ggarrange(GLM_BM_tot, GAM_BM_tot, RF_BM_tot, GBM_BM_tot, ANN_BM_tot,
  labels = c('(a)', '(b)','(c)', '(d)','(e)'),widths = 10,
  common.legend = TRUE,
  legend = 'right'
)
# ggsave("Results/landW/graphe_BM_tot.png", plot = graphe_BM_tot, dpi = 300, height = 6,width = 7)




# df_tot = RF_df_BM_tot
# df_tot$observation = seq(1,nrow(df_tot))
# 
# # Calcul des quartiles
# q1 <- quantile(df_tot$Observed, 0.25)
# median <- quantile(df_tot$Observed, 0.50)
# q3 <- quantile(df_tot$Observed, 0.75)
# max_value <- max(df_tot$Observed)
# 
# # Création des DataFrames en fonction des quartiles
# df1 <- df_tot[df_tot$Observed <= q1,]
# df2 <- df_tot[df_tot$Observed > q1 & df_tot$Observed <= median,]
# df3 <- df_tot[df_tot$Observed > median & df_tot$Observed <= q3,]
# df4 <- df_tot[df_tot$Observed > q3,]
# 
# 
# 
# 
# BM_tot_p1 = plot_comp(df = df1,ylabel = "",title_class = "  min to Q1",legende = TRUE,xlabel = "",title = "RF: Biomass predicted and Observed valuess \n for different quartiles")
# 
# BM_tot_p2 = plot_comp(df = df2,ylabel = "" ,title_class = "Q1 to median",legende = FALSE,xlabel = "")
# BM_tot_p3 = plot_comp(df = df3,ylabel = "" ,title_class = "median to Q3" ,legende = FALSE,xlabel = "")
# BM_tot_p4 = plot_comp(df = df4,ylabel = "" ,title_class = " Q3 to max" ,legende = FALSE)
# 
# 
# RF_BM_tot_fig = ggarrange(BM_tot_p1, BM_tot_p2, BM_tot_p3, BM_tot_p4,
#   # labels = c('(a)', '(b)','(c)', '(d)'),
#   ncol = 1,vjust = 0.5,
#   common.legend = TRUE,
#   legend = 'right'
# )
# 
# 
# ggsave("Results/landW/RF_BM_tot_fig.png", plot = RF_BM_tot_fig, dpi = 300,height = 8)



# df_tot$diff = abs(df_tot$Observed - df_tot$Predicted)
# df_best = df_tot[df_tot$diff<=15,]
# 
# plot_comp(df = df_best,ylabel = "Biomass" ,title_class = "     Best prediction",legende = TRUE,plotly = TRUE)
```

<p align="center">

<img src="Results/landW/graphe_BM_tot.png"/>

</p>

**The best algorithm for total Biomass is: RF**

<!-- <p align="center"> -->

<!--   <img src="Results/landW/RF_BM_tot_fig.png"> -->

<!-- </p> -->

## Prediction of total taxonomic richness

```{r}
subtitle <- sprintf("Richness : %.2f ± %.2f", round(mean(data_deep$Richesse_tot, na.rm = TRUE)), round(sd(data_deep$Richesse_tot, na.rm = TRUE)))
```

```{r predit Richesse_tot , fig.align='center', }
# Prediction avec GLM -----------------------------------------
GLM_result_Richesse_tot = GLM(var_rep ="Richesse_tot", 
                             df_app=Richesse_tot_train, 
                             df_valid = Richesse_tot_test,
                             family = 'gaussian')
# GLM_result_Richesse_tot$RMSE
# GLM_result_Richesse_tot$MAE
# GLM_result_Richesse_tot$R_adj_train
# GLM_result_Richesse_tot$R_adj_test
# GLM_result_Richesse_tot$predit
# GLM_result_Richesse_tot$model



GLM_Richesse_tot_pred <- GLM_result_Richesse_tot$predit

GLM_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = GLM_Richesse_tot_pred)

cor_GLM_Richesse_tot <- cor(GLM_df_Richesse_tot$Observed, GLM_df_Richesse_tot$Predicted)

  # graphique avec ggplot
GLM_Richesse_tot <- ggplot(GLM_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" GLM: R² adj (train) = ", round(GLM_result_Richesse_tot$R_adj_train,2),
                           "; \n R² = ", round(GLM_result_Richesse_tot$R_adj_test,2),
                           "; RMSE = ",  round(GLM_result_Richesse_tot$RMSE,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic() 

# Prediction avec GAM -----------------------------------------
GAM_result_Richesse_tot = GAM(var_rep ="Richesse_tot", 
                             df_app=Richesse_tot_train, 
                             df_valid = Richesse_tot_test,
                             family = 'gaussian',
                             method = "REML")
# GAM_result_Richesse_tot$RMSE
# GAM_result_Richesse_tot$MAE
# GAM_result_Richesse_tot$R_adj_train
# GAM_result_Richesse_tot$R_adj_test
# GAM_result_Richesse_tot$predit
# GAM_result_Richesse_tot$model

# mod_gam1_ab = GAM_result_Richesse_tot$model
# cv <- gam.check(GAM_result_Richesse_tot$model)
# print(cv)
# plot(mod_gam1_ab, pages = 1, seWithMean = TRUE)
# plot(mod_gam1_ab, residuals = TRUE, pch = 1)
# plot(ggeffects::ggpredict(mod_gam1_ab), facets = TRUE)
# gratia::draw(mod_gam1_ab, residuals = TRUE)
# # Verification
# par(mfrow = c(2, 2))
# gam.check(mod_gam1_ab)
# shapiro.test(mod_gam1_ab$res)
# concurvity(mod_gam1_ab,full = TRUE)
# concurvity(mod_gam1_ab,full = FALSE)





GAM_Richesse_tot_pred <- GAM_result_Richesse_tot$predit

GAM_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = GAM_Richesse_tot_pred)

cor_GAM_Richesse_tot <- cor(GAM_df_Richesse_tot$Observed, GAM_df_Richesse_tot$Predicted)

  # graphique avec ggplot
GAM_Richesse_tot <- ggplot(GAM_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" GAM: R² adj (train) = ", round(GAM_result_Richesse_tot$R_adj_train,2),
                           "; \n R² = ", round(GAM_result_Richesse_tot$R_adj_test,2),
                           "; RMSE = ",  round(GAM_result_Richesse_tot$RMSE,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic() 

# Prediction avec RF -----------------------------------------
Richesse_tot_RF_tuning = read.csv2("results_tuning/Richesse_tot_RF_tuning.csv")


Richesse_tot_RF_tuning = as.data.frame(Richesse_tot_RF_tuning)
Richesse_tot_RF_tuning = Richesse_tot_RF_tuning %>% arrange(mae)
# head(Richesse_tot_RF_tuning)

Richesse_tot_best_param = Richesse_tot_RF_tuning[1,]

# plot(seq(1:nrow(Richesse_tot_RF_tuning)), Richesse_tot_RF_tuning$r_squared)
# Best hyperparameter values
Richesse_tot_best_mtry = Richesse_tot_best_param$mtry
Richesse_tot_best_ntree = Richesse_tot_best_param$ntree
Richesse_tot_best_maxnodes = Richesse_tot_best_param$maxnode


RF_result_Richesse_tot = ForetAlea(var_rep ="Richesse_tot", 
                             df_app=Richesse_tot_train, 
                             df_valid = Richesse_tot_test,
                             mtry = 3,
                             ntree= Richesse_tot_best_ntree,
                             maxnodes = NULL)

# RF_result_Richesse_tot$RMSE
# RF_result_Richesse_tot$MAE
# RF_result_Richesse_tot$R_adj_train
# RF_result_Richesse_tot$R_adj_test
# RF_result_Richesse_tot$predit
# RF_result_Richesse_tot$model
# RF_result_Richesse_tot$df


RF_Richesse_tot_pred <- RF_result_Richesse_tot$predit

RF_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = RF_Richesse_tot_pred)

cor_RF_Richesse_tot <- cor(RF_df_Richesse_tot$Observed, RF_df_Richesse_tot$Predicted)

  # graphique avec ggplot
RF_Richesse_tot <- ggplot(RF_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(
        " RF: R² adj (train) = ", round(RF_result_Richesse_tot$R_adj_train,2),
        # "Richness (nr. of spp.)",
                           " \n R² = ", round(RF_result_Richesse_tot$R_adj_test,2),
                           "; RMSE = ",  round(RF_result_Richesse_tot$RMSE,2)),
                            x = "Observed values", 
                            y = "Predicted values") + 
      theme_classic() 
best_algo_Richesse_tot = RF_Richesse_tot
saveRDS(RF_result_Richesse_tot$model, "cartographie/best_mod/RF_mod_Richesse_tot.RDS")


# Prediction avec GBM -----------------------------------------
Richesse_tot_GBM_tuning = read.csv2("results_tuning/Richesse_tot_GBM_tuning.csv")


Richesse_tot_GBM_tuning = as.data.frame(Richesse_tot_GBM_tuning)
Richesse_tot_GBM_tuning = Richesse_tot_GBM_tuning %>% arrange(mae)
# head(Richesse_tot_GBM_tuning)
Richesse_tot_best_param = Richesse_tot_GBM_tuning[1,]


# Best hyperparameter values
Richesse_tot_best_n.trees = Richesse_tot_best_param$n.trees
Richesse_tot_best_shrinkage = Richesse_tot_best_param$shrinkage
Richesse_tot_best_interaction.depth = Richesse_tot_best_param$interaction.depth
Richesse_tot_best_n.minobsinnode = Richesse_tot_best_param$n.minobsinnode


GBM_result_Richesse_tot =  GBM(var_rep ="Richesse_tot", 
                         df_app=Richesse_tot_train, 
                         df_valid = Richesse_tot_test,
                         distribution = 'gaussian',
                         n.trees = Richesse_tot_best_n.trees,
                         shrinkage = Richesse_tot_best_shrinkage,
                         interaction.depth = Richesse_tot_best_interaction.depth,
                         n.minobsinnode = Richesse_tot_best_n.minobsinnode)

# GBM_result_Richesse_tot$RMSE
# GBM_result_Richesse_tot$MAE
# GBM_result_Richesse_tot$R_adj_train
# GBM_result_Richesse_tot$R_adj_test
# GBM_result_Richesse_tot$predit
# GBM_result_Richesse_tot$model
# GBM_result_Richesse_tot$df

# summary(GBM_result_Richesse_tot$model)
# best.iter <- gbm.perf(GBM_result_Richesse_tot$model, method = "cv")
# summary(GBM_result_Richesse_tot$model, n.trees = best.iter)




GBM_Richesse_tot_pred = GBM_result_Richesse_tot$predit

GBM_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = GBM_Richesse_tot_pred)

cor_GBM_Richesse_tot<- cor(GBM_df_Richesse_tot$Observed, GBM_df_Richesse_tot$Predicted)

# graphique avec ggplot
GBM_Richesse_tot <- ggplot(GBM_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" GBM: R² adj (train) = ", round(GBM_result_Richesse_tot$R_adj_train,2),
                           "; \n R² = ", round(GBM_result_Richesse_tot$R_adj_test,2),
                           "; RMSE = ",  round(GBM_result_Richesse_tot$RMSE,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic() 





# Prediction avec ANN -----------------------------------------
# ANN_tune_Richesse_tot_results$mse
# ANN_tune_Richesse_tot_results$mae
# ANN_tune_Richesse_tot_results$rmse
# ANN_tune_Richesse_tot_results$r_adj_train
# ANN_tune_Richesse_tot_results$r_adj_test


ANN_Richesse_tot_pred = ANN_tune_Richesse_tot_pred

ANN_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = ANN_Richesse_tot_pred)

cor_ANN_Richesse_tot <- cor(ANN_df_Richesse_tot$Observed, ANN_df_Richesse_tot$Predicted)

  # graphique avec ggplot
ANN_Richesse_tot <- ggplot(ANN_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") +
labs(subtitle =paste0(" ANN: R² adj (train) = ", round(ANN_tune_Richesse_tot_results$R_adj_train,2),
                           "; \n R² = ", round(ANN_tune_Richesse_tot_results$R_adj_test,2),
                           "; RMSE = ",  round(ANN_tune_Richesse_tot_results$rmse,2)),
                            x = "Observed values", 
                            y = "Predicted values") +
      theme_classic()

# best algo --------------------------------------
graphe_Richesse_tot = ggarrange(GLM_Richesse_tot, GAM_Richesse_tot, RF_Richesse_tot, GBM_Richesse_tot, ANN_Richesse_tot,
  labels = c('(a)', '(b)','(c)', '(d)','(e)'),widths = 10,
  common.legend = TRUE,
  legend = 'right'
)
# ggsave("Results/landW/graphe_Richesse_tot.png", plot = graphe_Richesse_tot, dpi = 300, height = 6,width = 7)



# 
# df_tot = RF_df_Richesse_tot
# df_tot$observation = seq(1,nrow(df_tot))
# 
# df_tot$Predicted = round(df_tot$Predicted)
# # Calcul des quartiles
# q1 <- quantile(df_tot$Observed, 0.25)
# median <- quantile(df_tot$Observed, 0.50)
# q3 <- quantile(df_tot$Observed, 0.75)
# max_value <- max(df_tot$Observed)
# 
# # Création des DataFrames en fonction des quartiles
# df1 <- df_tot[df_tot$Observed <= q1,]
# df2 <- df_tot[df_tot$Observed > q1 & df_tot$Observed <= median,]
# df3 <- df_tot[df_tot$Observed > median & df_tot$Observed <= q3,]
# df4 <- df_tot[df_tot$Observed > q3,]
# 
# 
# 
# 
# Richesse_tot_p1 = plot_comp(df = df1,ylabel = "",title_class = "  min to Q1",legende = TRUE,xlabel = "",title = "RF: Richness predicted and Observed valuess \n for different quartiles")
# 
# Richesse_tot_p2 = plot_comp(df = df2,ylabel = "" ,title_class = "Q1 to median",legende = FALSE,xlabel = "")
# Richesse_tot_p3 = plot_comp(df = df3,ylabel = "" ,title_class = "median to Q3" ,legende = FALSE,xlabel = "")
# Richesse_tot_p4 = plot_comp(df = df4,ylabel = "" ,title_class = " Q3 to max" ,legende = FALSE)
# 
# 
# GBM_Richesse_tot_fig = ggarrange(Richesse_tot_p1, Richesse_tot_p2, Richesse_tot_p3, Richesse_tot_p4,
#   # labels = c('(a)', '(b)','(c)', '(d)'),
#   ncol = 1,vjust = 0.5,
#   common.legend = TRUE,
#   legend = 'right'
# )
# 
# ggsave("Results/landW/RF_Richesse_tot_fig.png", plot = GBM_Richesse_tot_fig, dpi = 300,height = 8)


# df_tot$diff = abs(df_tot$Observed - df_tot$Predicted)
# df_best = df_tot[df_tot$diff<=0.5,]
# 
# 
# plot_comp(df = df_best,ylabel = "Richness" ,title_class = "     Best prediction",legende = TRUE,plotly = FALSE)
```

<p align="center">

<img src="Results/landW/graphe_Richesse_tot.png"/>

</p>

**The best algorithm for total Richness is: RF**

<!-- <p align="center"> -->

<!--   <img src="Results/landW/RF_Richesse_tot_fig.png"> -->

<!-- </p> -->

## Best algorithm (RF)

<!-- **-   Summary: ** *Results Case 1 -> repeated data* -->

<br/>

```{r saving best algo1,fig.align='center'}
best_algo_RF_1 = ggpubr::ggarrange(best_algo_AB_tot, best_algo_BM_tot, best_algo_Richesse_tot,
                          labels = c('(a)', '(b)','(c)'),ncol = 3,
                          common.legend = TRUE,
                          legend = 'right'
)
# ggsave("Results/landW/best_algo_RF_1.png", plot = best_algo_RF_1, dpi = 300,height = 3,width = 7)



g1 <- ggplot(RF_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(
        "Abundance (ind./m²)",
                           "\nR² = ", round(RF_result_AB_tot$R_adj_test,2),
                           "; RMSE = ",  round(RF_result_AB_tot$RMSE^2,2)),
                            x = " ",
                            y = " "
        ) + 
      theme_classic() 

g2 <- ggplot(RF_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(
         "Biomass (g/m²)",
                           "\nR² = ", round(RF_result_BM_tot$R_adj_test,2),
                           "; RMSE = ",  round(RF_result_BM_tot$RMSE^2,2)),
                            x = " ",
                            y = " "
         ) + 
      theme_classic() 

g3 <- ggplot(RF_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(
        "Richness (nr. of spp.)",
                           "\nR² = ", round(RF_result_Richesse_tot$R_adj_test,2),
                           "; RMSE = ",  round(RF_result_Richesse_tot$RMSE,2)),
                            x = " ",
                            y = " "
        ) + 
      theme_classic() 

figure <- ggpubr::ggarrange(g1, g2, g3,
                                    labels = c('(a)', '(b)', '(c)'), ncol = 3,
                                    common.legend = TRUE, legend = 'right')


figure = annotate_figure(figure,

                bottom = text_grob("Observed values", color = "black",
                                   vjust = 0, face = "bold", size = 10),
                left = text_grob("Predicted values", color = "black", rot = 90),)

# figure
# ggsave("Results/landW/best_algo_RF_rapport.png", plot = figure, dpi = 300,height = 3,width = 7)


```

<p align="center">

<img src="Results/landW/best_algo_RF_1.png"/>

</p>

````{=html}
<!-- 

## Improved prediction of extreme values 

```{r increase prediction}
### model AB_tot
# AB_tot_train = read.csv2("datas/landW/AB_tot_train.csv")
# AB_tot_test = read.csv2("datas/landW/AB_tot_test.csv")
RF_result_AB_tot = ForetAlea(var_rep ="AB_tot", 
                              df_app=AB_tot_train, 
                              df_valid = AB_tot_test,
                             mtry = 3,
                             ntree= AB_tot_best_ntree,
                             maxnodes = NULL)
# RF_result_AB_tot$RMSE
# RF_result_AB_tot$MAE
# RF_result_AB_tot$R_adj_train
# RF_result_AB_tot$R_adj_test
# RF_result_AB_tot$predit
# RF_result_AB_tot$model

RF_AB_tot_pred <- RF_result_AB_tot$predit^2
RF_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = RF_AB_tot_pred)
cor_RF_AB_tot <- cor(RF_df_AB_tot$Observed, RF_df_AB_tot$Predicted)

# summary(RF_df_AB_tot)
  # graphique avec ggplot
RF_AB_tot <- ggplot(RF_df_AB_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" RF: R² adj (train) = ", round(RF_result_AB_tot$R_adj_train,2), 
                           "; \n R² = ", round(RF_result_AB_tot$R_adj_test,2),
                           "; RMSE = ",  round(RF_result_AB_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") + 
      theme_classic()+ 
    scale_x_continuous(limits = c(0,1000),breaks = seq(0, 800, by = 200)) +
  scale_y_continuous(limits = c(0,800),breaks = seq(0, 800, by = 200)) 

RF_AB_tot_best2 = RF_AB_tot


### model BM_tot
# BM_tot_train = read.csv2("datas/landW/BM_tot_train.csv")
# BM_tot_test = read.csv2("datas/landW/BM_tot_test.csv")
RF_result_BM_tot = ForetAlea(var_rep ="BM_tot", 
                             df_app=BM_tot_train,
                             df_valid = BM_tot_test,
                             mtry = 3,
                             ntree= BM_tot_best_ntree,
                             maxnodes = NULL)
# RF_result_BM_tot$RMSE
# RF_result_BM_tot$MAE
# RF_result_BM_tot$R_adj_train
# RF_result_BM_tot$R_adj_test
# # RF_result_BM_tot$predit
# RF_result_BM_tot$model

RF_BM_tot_pred <- RF_result_BM_tot$predit^2
RF_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = RF_BM_tot_pred)
cor_RF_BM_tot <- cor(RF_df_BM_tot$Observed, RF_df_BM_tot$Predicted)

# summary(RF_df_BM_tot)
  # graphique avec ggplot
RF_BM_tot <- ggplot(RF_df_BM_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" RF: R² adj (train) = ", round(RF_result_BM_tot$R_adj_train,2), 
                           "; \n R² = ", round(RF_result_BM_tot$R_adj_test,2),
                           "; RMSE = ",  round(RF_result_BM_tot$RMSE^2,2)),
                            x = "Observed values", 
                            y = "Predicted values") + 
      theme_classic()+ 
    scale_x_continuous(limits = c(0,300),breaks = seq(0, 300, by = 50)) +
  scale_y_continuous(limits = c(0,300),breaks = seq(0, 300, by = 50))

RF_BM_tot_best2 =RF_BM_tot

### model Richesse_tot
# Richesse_tot_train = read.csv2("datas/landW/Richesse_tot_train.csv")
# Richesse_tot_test = read.csv2("datas/landW/Richesse_tot_test.csv")
RF_result_Richesse_tot = ForetAlea(var_rep ="Richesse_tot", 
                             df_app=Richesse_tot_train, 
                             df_valid = Richesse_tot_test,
                             mtry = 3,
                             ntree= Richesse_tot_best_ntree,
                             maxnodes = NULL)
# RF_result_Richesse_tot$RMSE
# RF_result_Richesse_tot$MAE
# RF_result_Richesse_tot$R_adj_train
# RF_result_Richesse_tot$R_adj_test
# # RF_result_Richesse_tot$predit
# RF_result_Richesse_tot$model

RF_Richesse_tot_pred <- RF_result_Richesse_tot$predit
RF_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = RF_Richesse_tot_pred)
cor_RF_Richesse_tot <- cor(RF_df_Richesse_tot$Observed, RF_df_Richesse_tot$Predicted)

# summary(RF_df_Richesse_tot)
  # graphique avec ggplot
RF_Richesse_tot <- ggplot(RF_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
      geom_point() + # Ajout des points
      geom_smooth(method = "lm", se = TRUE, color = "red") + 
      labs(subtitle =paste0(" RF: R² adj (train) = ", round(RF_result_Richesse_tot$R_adj_train,2), 
                           "; \n R² = ", round(RF_result_Richesse_tot$R_adj_test,2),
                           "; RMSE = ",  round(RF_result_Richesse_tot$RMSE,2)),
                            x = "Observed values", 
                            y = "Predicted values") + 
      theme_classic() + 
  scale_x_continuous(breaks = seq(0, 12, by = 3)) +
  scale_y_continuous(breaks = seq(0, 12, by = 3))

RF_Richesse_tot_best2 = RF_Richesse_tot

best_algo_RF_2 = ggarrange(RF_AB_tot, RF_BM_tot, RF_Richesse_tot,
                          labels = c('(a)', '(b)','(c)'),ncol = 3,
                          common.legend = TRUE,
                          legend = 'right'
)
# ggsave("Results/landW/best_algo_RF_2.png", plot = best_algo_RF_2, dpi = #300,height = 3,width = 7)

```

- best 1

<p align="center">
  <img src="Results/landW/best_algo_RF_1.png">
</p>


- best 2

<p align="center">
  <img src="Results/landW/best_algo_RF_2.png">
</p>


-->
````

## Table LandWorm results

```{r LandWorm output}
# AB_tot_results = rbind(GLM_result_AB_tot$df,
#                         GAM_result_AB_tot$df,
#                         RF_result_AB_tot$df,
#                         GBM_result_AB_tot$df,
#                         ANN_tune_AB_tot_results_df
#                          )
# AB_tot_results$RMSE = round(AB_tot_results$RMSE^2,2)
# 
# BM_tot_results = rbind(GLM_result_BM_tot$df,
#                         GAM_result_BM_tot$df,
#                         RF_result_BM_tot$df,
#                         GBM_result_BM_tot$df,
#                         ANN_tune_BM_tot_results_df
#                          )
# BM_tot_results$RMSE = round(BM_tot_results$RMSE^2,2)
# 
# Richesse_tot_results = rbind(GLM_result_Richesse_tot$df,
#                         GAM_result_Richesse_tot$df,
#                         RF_result_Richesse_tot$df,
#                         GBM_result_Richesse_tot$df,
#                         ANN_tune_Richesse_tot_results_df
#                          )
# 
# all_result = rbind(AB_tot_results,BM_tot_results,Richesse_tot_results)
# landworm_results = data.frame(Datas = rep("LandWorm", 15))
# landworm_results = cbind(landworm_results, all_result)
# landworm_results <- landworm_results %>%
#   dplyr::mutate_if(is.numeric, ~ round(., 2))
# 
# 
# write.csv(x =landworm_results,file = "Results/landW/landworm_results.csv", row.names = FALSE)

df = read.csv("Results/landW/landworm_results.csv")
df$R2_adjusted_train = NULL
df$MAE=NULL
# df$RMSE = round(df$RMSE^2,2)
colnames(df) = c("Datas","Algorithms","Response_variables",
                               "R²","RMSE")
df %>% datatable(options = list(pageLength = 5))
```

back to [Plan]

````{=html}
<!-- 
## Comparaison entre EcoBiosoil et LandWorm

```{r comp LandW and Eco, eval=FALSE}
library(tidyverse)
library(DT)
# landworm_results

ecobiosoil_results = read.csv("Results/ecobiosoil_results.csv")

colnames(ecobiosoil_results) = c("Datas","Algorithms","Response \n variables",
                               "R2_adj \ntrain","R2_ad \ntest","RMSE","MAE")

landworm_ecobisoil = rbind(landworm_results,ecobiosoil_results)


colnames(landworm_ecobisoil) = c("Datas","Algorithms","Response \n variables",
                               "R2_adj \ntrain","R2_ad \ntest","RMSE","MAE")

write.csv(x =landworm_ecobisoil,file = "Results/landW/landworm_ecobisoil.csv", row.names = FALSE)

# datatable(landworm_ecobisoil, options = list(pageLength = 5))
kable(landworm_ecobisoil)


```


## Fig comp

- LandWorm

<p align="center">
  <img src="Results/landW/best_algo_RF_1.png">
</p>


- EcoBioSoil

<p align="center">
  <img src="Results/best_algo_RF_1.png">
</p>

-->
````

# Importance and effects of variables

```{r}
Predictors_f = c("CaCO3" ,"gps_x" ,"N" ,"bio3" ,"gps_y" ,"clay" ,
                 "silt" ,"clcm_lvl3" ,"P" ,"bio12" )
```

## Abundance

[Plan]

```{r}
# AB_tot_train = read.csv2("datas/landW/AB_tot_train.csv")
# AB_tot_test = read.csv2("datas/landW/AB_tot_test.csv")

# RF_result_AB_tot = ForetAlea(var_rep ="AB_tot", 
#                               df_app=AB_tot_train, 
#                               df_valid = AB_tot_test,
#                              mtry = 3,
#                              ntree= AB_tot_best_ntree,
#                              maxnodes = NULL)
# RF_result_AB_tot$RMSE^2
# RF_result_AB_tot$R_adj_train
# RF_result_AB_tot$R_adj_test
# RF_result_AB_tot$model

var_importance <- data.frame(RF_result_AB_tot$model$importance)
var_importance$nom=rownames(var_importance)
row.names(var_importance)=NULL
var_importance$percent <- var_importance$IncNodePurity / sum(var_importance$IncNodePurity)*100
nom_os = c("clcm_lvl3f","clcm_lvl3gua","clcm_lvl3ng","clcm_lvl3nial","clcm_lvl3p","clcm_lvl3v")
df_impor_AB_tot = var_importance[!var_importance$nom %in% nom_os,]
df_AB_tot_os = var_importance[var_importance$nom %in% nom_os,]
df_AB_tot_os= data.frame(IncNodePurity = sum(df_AB_tot_os$IncNodePurity), nom="clcm_lvl3",
                         percent = sum(df_AB_tot_os$percent))
df_impor_AB_tot = rbind(df_impor_AB_tot,df_AB_tot_os)

df_impor_AB_tot <- df_impor_AB_tot[order(df_impor_AB_tot$nom,decreasing = FALSE), ]
df_impor_AB_tot$percent = round(df_impor_AB_tot$percent)
abr_var = c("bio12","bio3","CaCO3","clay","clcm_lvl3","gps_x","gps_y","N","P","silt")
abr_var = c("Prec","Isot","CaCO3","Clay","CLC","Long","Lat","N","P","Silt")
df_impor_AB_tot$nom = abr_var

# ggplot(df_impor_AB_tot, aes(x = nom, y = percent)) +
#   geom_bar(stat = "identity", fill = "steelblue") +
#   labs(title = "",
#        x = "Variables",
#        y = "Importance (%)") +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))


# RF_AB_tot_pred <- RF_result_AB_tot$predit^2
# RF_df_AB_tot = data.frame(Observed=AB_tot_test[,1]^2,Predicted = RF_AB_tot_pred)
# cor_RF_AB_tot <- cor(RF_df_AB_tot$Observed, RF_df_AB_tot$Predicted)

# summary(RF_df_AB_tot)
  # graphique avec ggplot
# RF_AB_tot <- ggplot(RF_df_AB_tot, aes(x = Observed, y = Predicted)) +
#       geom_point() + # Ajout des points
#       geom_smooth(method = "lm", se = TRUE, color = "red") + 
#       labs(title = "After",subtitle =paste0(" RF: R² adj (train) = ", round(RF_result_AB_tot$R_adj_train,2), 
#                            "; \n R² = ", round(RF_result_AB_tot$R_adj_test,2),
#                            "; RMSE = ",  round(RF_result_AB_tot$RMSE^2,2)),
#                             x = "Observed values", 
#                             y = "Predicted values") + 
#       theme_classic()+ 
#     scale_x_continuous(limits = c(0,1000),breaks = seq(0, 800, by = 200)) +
#   scale_y_continuous(limits = c(0,800),breaks = seq(0, 800, by = 200)) 
# 
# # RF_AB_tot_best2
# # RF_AB_tot
# graphe = ggarrange(RF_AB_tot_best2, RF_AB_tot,
#                           labels = c('(a)', '(b)'),ncol = 2,widths = 4.666667, heights = 3,common.legend = TRUE,legend = 'right')
# graphe


# mod_AB_tot = RF_result_AB_tot$model
# varImpPlot(mod_AB_tot, main = "Abundance") #produce variable importance plot
# importance_rf <- as.data.frame(importance(mod_AB_tot))
# importance_rf$nom=rownames(importance_rf)
# importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
# row.names(importance_rf)=NULL
# importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
# os = c("clcm_lvl3v","clcm_lvl3nial","clcm_lvl3p","clcm_lvl3gua","clcm_lvl3f","clcm_lvl3ng")
# 
# barplot(importance_rf$percent, main = "Importance of variables for total abundance", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)
```

```{r abundance response, fig.align='center', eval = FALSE}
#_______________

AB_tot_df = landworm_explo_non_t[,c("AB_tot",Predictors_f)]

AB_tot_df = drop_na(AB_tot_df)
abr_var = c("bio12","bio3","CaCO3","clay","clcm_lvl3","gps_x","gps_y","N","P","silt")
abr_var = c("Prec","Isot","CaCO3","Clay","CLC","Long","Lat","N","P","Silt")

colnames(AB_tot_df) = c("AB_tot","CaCO3","Long","N","Isot","Lat"   ,"Clay","Silt","CLC","P","Prec")
rf <- randomForest(AB_tot ~ ., data = AB_tot_df, ntree = 500)
# rf <- glm(AB_tot ~ ., data = AB_tot_df, family = 'gaussian')

# Utilisation du conteneur iml Predictor()
X <- AB_tot_df[which(names(AB_tot_df) != "AB_tot")]
predictor <- Predictor$new(rf, data = X, y = AB_tot_df$AB_tot)




cat("Importance of predictors")
# Importance des fonctionnalités
# On calcule l'importance de chaque caractéristique pour les prédictions avec FeatureImp. La mesure de l'importance des fonctionnalités fonctionne en mélangeant chaque fonctionnalité et en mesurant l'ampleur de la baisse des performances. Pour cette tâche de régression, nous choisissons de mesurer la perte de performance avec l'erreur absolue moyenne (« mae »), un autre choix serait l'erreur quadratique moyenne (« mse »).

# https://christophm.github.io/interpretable-ml-book/feature-importance.html

imp_AB_tot <- FeatureImp$new(predictor, loss = "rmse") # mean absolute error
# imp_AB_tot <- FeatureImp$new(predictor, loss = "mse") # mean squared error  
imp_AB_tot_plot = plot(imp_AB_tot)
plot(imp_AB_tot)

# imp_AB_tot.dat <- imp_AB_tot$results
# head(imp_AB_tot.dat)
# ggplot(imp_AB_tot$results, aes(x=importance, y=reorder(feature, importance))) +
#   geom_point() +
#   geom_errorbar(aes(xmin=importance.05, xmax=importance.95), width=0.1) + 
#   labs(x = "Features importance (loss : rmse)", y = "") +
#   theme()


importance_rf <- as.data.frame(importance(rf))
importance_rf$nom=rownames(importance_rf)
importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
row.names(importance_rf)=NULL
importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
# barplot(importance_rf$percent, main = "Importance of variables for total abundance", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)




df_imp = imp_AB_tot$results
df_impor_AB_tot <- as.data.frame(df_imp)
for (i in names(df_impor_AB_tot)[-1]){
df_impor_AB_tot[[i]] <- df_impor_AB_tot[[i]] / sum(df_impor_AB_tot[[i]])*100 
}
df_impor_AB_tot <- df_impor_AB_tot[order(df_impor_AB_tot$feature,decreasing = FALSE), ]
abr_var = c("bio12","bio3","CaCO3","clay","clcm_lvl3","gps_x","gps_y","N","P","silt")
abr_var = c("Prec","Isot","CaCO3","Clay","CLC","Long","Lat","N","P","Silt")

df_impor_AB_tot$abr_var = abr_var
df_impor_AB_tot$Resp_variable = rep("Abundance")
# barplot(df_impor_AB_tot$importance, names.arg = df_impor_AB_tot$abr_var, 
#         ylab = "Importance (%)", las = 2)





cat("Predictor effects")
# Effets de fonctionnalités
# Les effets locaux accumulés décrivent comment les predicteurs influencent en moyenne la prédiction d'un modèle d'apprentissage automatique: ALE montre comment la prédiction change localement, lorsque les predicteurs varie. Les marques sur l'axe des x indiquent la distribution des predicteurs, montrant la pertinence d'une région pour l'interprétation (peu ou pas de points signifie que nous ne devons pas surinterpréter cette région).

# ale <- FeatureEffect$new(predictor, feature = "gps_x") # uniquement lstat
# ale$plot()
# ale$set.feature("rm")
# ale$plot()
effs <- FeatureEffects$new(predictor) # toutes les variables
plot(effs)






cat("Predictor interactions")
# Mesurer les interactions
# Nous pouvons également mesurer la force avec laquelle les fonctionnalités interagissent les unes avec les autres. La mesure d'interaction concerne la part de la variance de F(X) s’explique par l’interaction. La mesure est comprise entre 0 (pas d'interaction) et 1 (= 100 % de variance deF(X) en raison des interactions). Pour chaque fonctionnalité, nous mesurons dans quelle mesure elles interagissent avec toute autre fonctionnalité.


interact <- Interaction$new(predictor)
plot(interact)
cat("Predictor interactions: Land use")
interact <- Interaction$new(predictor, feature = "CLC")
plot(interact)

```

[Plan]

## Biomass

[Plan]

```{r}
# BM_tot_train = read.csv2("datas/landW/BM_tot_train.csv")
# BM_tot_test = read.csv2("datas/landW/BM_tot_test.csv")
# 
# 
# RF_result_BM_tot = ForetAlea(var_rep ="BM_tot", 
#                              df_app=BM_tot_train,
#                              df_valid = BM_tot_test,
#                              mtry = 3,
#                              ntree= BM_tot_best_ntree,
#                              maxnodes = NULL)
# RF_result_BM_tot$RMSE^2
# RF_result_BM_tot$R_adj_train
# RF_result_BM_tot$R_adj_test
# RF_result_BM_tot$model



# RF_BM_tot_pred <- RF_result_BM_tot$predit^2
# RF_df_BM_tot = data.frame(Observed=BM_tot_test[,1]^2,Predicted = RF_BM_tot_pred)
# cor_RF_BM_tot <- cor(RF_df_BM_tot$Observed, RF_df_BM_tot$Predicted)
# 
# # summary(RF_df_BM_tot)
#   # graphique avec ggplot
# RF_BM_tot <- ggplot(RF_df_BM_tot, aes(x = Observed, y = Predicted)) +
#   geom_point() + # Ajout des points
#   geom_smooth(method = "lm", se = TRUE, color = "red") +
#   labs(title = "After",subtitle =paste0(" RF: R² adj (train) = ", round(RF_result_BM_tot$R_adj_train,2), 
#                            "; \n R² = ", round(RF_result_BM_tot$R_adj_test,2),
#                            "; RMSE = ",  round(RF_result_BM_tot$RMSE^2,2)),
#                             x = "Observed values", 
#                             y = "Predicted values") + 
#       theme_classic()  
  # scale_x_continuous(breaks = seq(0, 800, by = 200)) +
  # scale_y_continuous(breaks = seq(0, 750, by = 100)) 

# RF_BM_tot_best2
# RF_BM_tot
# graphe = ggarrange(RF_BM_tot_best2, RF_BM_tot,
#                           labels = c('(a)', '(b)'),ncol = 2,widths = 4.666667, heights = 3,common.legend = TRUE,legend = 'right')
# graphe


var_importance <- data.frame(RF_result_BM_tot$model$importance)
var_importance$nom=rownames(var_importance)
row.names(var_importance)=NULL
var_importance$percent <- var_importance$IncNodePurity / sum(var_importance$IncNodePurity)*100
nom_os = c("clcm_lvl3f","clcm_lvl3gua","clcm_lvl3ng","clcm_lvl3nial","clcm_lvl3p","clcm_lvl3v")
df_impor_BM_tot = var_importance[!var_importance$nom %in% nom_os,]
df_BM_tot_os = var_importance[var_importance$nom %in% nom_os,]
df_BM_tot_os= data.frame(IncNodePurity = sum(df_BM_tot_os$IncNodePurity), nom="clcm_lvl3",
                         percent = sum(df_BM_tot_os$percent))
df_impor_BM_tot = rbind(df_impor_BM_tot,df_BM_tot_os)

df_impor_BM_tot <- df_impor_BM_tot[order(df_impor_BM_tot$nom,decreasing = FALSE), ]
df_impor_BM_tot$percent = round(df_impor_BM_tot$percent)
abr_var = c("bio12","bio3","CaCO3","clay","clcm_lvl3","gps_x","gps_y","N","P","silt")
abr_var = c("Prec","Isot","CaCO3","Clay","CLC","Long","Lat","N","P","Silt")
df_impor_BM_tot$nom = abr_var

# ggplot(df_impor_BM_tot, aes(x = nom, y = percent)) +
#   geom_bar(stat = "identity", fill = "steelblue") +
#   labs(title = "",
#        x = "Variables",
#        y = "Importance (%)") +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r Biomass response, fig.align='center'}
#_______________
BM_tot_df = landworm_explo_non_t[,c("BM_tot",Predictors_f)]

BM_tot_df = drop_na(BM_tot_df)
colnames(BM_tot_df) = c("BM_tot","CaCO3","Long","N","Isot","Lat"   ,"Clay","Silt","CLC","P","Prec")
rf <- randomForest(BM_tot ~ ., data = BM_tot_df, ntree = 500)

# Utilisation du conteneur iml Predictor()
X <- BM_tot_df[which(names(BM_tot_df) != "BM_tot")]
predictor <- Predictor$new(rf, data = X, y = BM_tot_df$BM_tot)


cat("Importance of predictors")
# Importance des fonctionnalités
# On calcule l'importance de chaque caractéristique pour les prédictions avec FeatureImp. La mesure de l'importance des fonctionnalités fonctionne en mélangeant chaque fonctionnalité et en mesurant l'ampleur de la baisse des performances. Pour cette tâche de régression, nous choisissons de mesurer la perte de performance avec l'erreur absolue moyenne (« mae »), un autre choix serait l'erreur quadratique moyenne (« mse »).


imp_BM_tot <- FeatureImp$new(predictor, loss = "rmse") # mean absolute error
# imp_BM_tot <- FeatureImp$new(predictor, loss = "mse") # mean squared error  
imp_BM_tot_plot = plot(imp_BM_tot)
plot(imp_BM_tot)

# imp_BM_tot$results
# importance_rf <- as.data.frame(importance(rf))
# importance_rf$nom=rownames(importance_rf)
# importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
# row.names(importance_rf)=NULL
# importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
# barplot(importance_rf$percent, main = "Importance of variables for total Biomass", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)
df_imp = imp_BM_tot$results
df_impor_BM_tot <- as.data.frame(df_imp)
for (i in names(df_impor_BM_tot)[-1]){
df_impor_BM_tot[[i]] <- df_impor_BM_tot[[i]] / sum(df_impor_BM_tot[[i]])*100 
}
df_impor_BM_tot <- df_impor_BM_tot[order(df_impor_BM_tot$feature,decreasing = FALSE), ]
abr_var = c("bio12","bio3","CaCO3","clay","clcm_lvl3","gps_x","gps_y","N","P","silt")
abr_var = c("Prec","Isot","CaCO3","Clay","CLC","Long","Lat","N","P","Silt")

df_impor_BM_tot$abr_var = abr_var
df_impor_BM_tot$Resp_variable = rep("Biomass")
# barplot(df_impor_BM_tot$importance, names.arg = df_impor_BM_tot$abr_var, 
#         ylab = "Importance (%)", las = 2)




cat("Predictor effects")
# Effets de fonctionnalités
# Les effets locaux accumulés décrivent comment les predicteurs influencent en moyenne la prédiction d'un modèle d'apprentissage automatique: ALE montre comment la prédiction change localement, lorsque les predicteurs varie. Les marques sur l'axe des x indiquent la distribution des predicteurs, montrant la pertinence d'une région pour l'interprétation (peu ou pas de points signifie que nous ne devons pas surinterpréter cette région).

# ale <- FeatureEffect$new(predictor, feature = "gps_x") # uniquement lstat
# ale$plot()
# ale$set.feature("rm")
# ale$plot()
effs <- FeatureEffects$new(predictor) # toutes les variables
plot(effs)






cat("Predictor interactions")
# Mesurer les interactions
# Nous pouvons également mesurer la force avec laquelle les fonctionnalités interagissent les unes avec les autres. La mesure d'interaction concerne la part de la variance de F(X) s’explique par l’interaction. La mesure est comprise entre 0 (pas d'interaction) et 1 (= 100 % de variance deF(X) en raison des interactions). Pour chaque fonctionnalité, nous mesurons dans quelle mesure elles interagissent avec toute autre fonctionnalité.


interact <- Interaction$new(predictor)
plot(interact)
cat("Predictor interactions: Land use")
interact <- Interaction$new(predictor, feature = "CLC")
plot(interact)

```

[Plan]

## Richness

[Plan]

```{r}
# Richesse_tot_train = read.csv2("datas/landW/Richesse_tot_train.csv")
# Richesse_tot_test = read.csv2("datas/landW/Richesse_tot_test.csv")
# 
# 
# RF_result_Richesse_tot = ForetAlea(var_rep ="Richesse_tot", 
#                              df_app=Richesse_tot_train, 
#                              df_valid = Richesse_tot_test,
#                              mtry = 3,
#                              ntree= Richesse_tot_best_ntree,
#                              maxnodes = NULL)
# RF_result_Richesse_tot$RMSE 
# RF_result_Richesse_tot$R_adj_train 
# RF_result_Richesse_tot$R_adj_test 
# RF_result_Richesse_tot$model
# 
# 
# 
# RF_Richesse_tot_pred <- RF_result_Richesse_tot$predit
# RF_df_Richesse_tot = data.frame(Observed=Richesse_tot_test[,1],Predicted = RF_Richesse_tot_pred)
# cor_RF_Richesse_tot <- cor(RF_df_Richesse_tot$Observed, RF_df_Richesse_tot$Predicted)
# 
# # summary(RF_df_Richesse_tot)
#   # graphique avec ggplot
# RF_Richesse_tot <- ggplot(RF_df_Richesse_tot, aes(x = Observed, y = Predicted)) +
#   geom_point() + # Ajout des points
#   geom_smooth(method = "lm", se = TRUE, color = "red") +
#   labs(title = "After",subtitle =paste0(" RF: R² adj (train) = ", round(RF_result_Richesse_tot$R_adj_train,2), 
#                            "; \n R² = ", round(RF_result_Richesse_tot$R_adj_test,2),
#                            "; RMSE = ",  round(RF_result_Richesse_tot$RMSE,2)),
#                             x = "Observed values", 
#                             y = "Predicted values") + 
#       theme_classic() + 
#   scale_x_continuous(breaks = seq(0, 12, by = 3)) +
#   scale_y_continuous(breaks = seq(0, 12, by = 3))

# RF_Richesse_tot_best2
# RF_Richesse_tot
# graphe = ggarrange(RF_Richesse_tot_best2, RF_Richesse_tot,
#                           labels = c('(a)', '(b)'),ncol = 2,widths = 4.666667, heights = 3,common.legend = TRUE,legend = 'right')
# graphe
# 

var_importance <- data.frame(RF_result_Richesse_tot$model$importance)
var_importance$nom=rownames(var_importance)
row.names(var_importance)=NULL
var_importance$percent <- var_importance$IncNodePurity / sum(var_importance$IncNodePurity)*100
nom_os = c("clcm_lvl3f","clcm_lvl3gua","clcm_lvl3ng","clcm_lvl3nial","clcm_lvl3p","clcm_lvl3v")
df_impor_Richesse_tot = var_importance[!var_importance$nom %in% nom_os,]
df_Richesse_tot_os = var_importance[var_importance$nom %in% nom_os,]
df_Richesse_tot_os= data.frame(IncNodePurity = sum(df_Richesse_tot_os$IncNodePurity), nom="clcm_lvl3",
                         percent = sum(df_Richesse_tot_os$percent))
df_impor_Richesse_tot = rbind(df_impor_Richesse_tot,df_Richesse_tot_os)

df_impor_Richesse_tot <- df_impor_Richesse_tot[order(df_impor_Richesse_tot$nom,decreasing = FALSE), ]
df_impor_Richesse_tot$percent = round(df_impor_Richesse_tot$percent)
abr_var = c("bio12","bio3","CaCO3","clay","clcm_lvl3","gps_x","gps_y","N","P","silt")
abr_var = c("Prec","Isot","CaCO3","Clay","CLC","Long","Lat","N","P","Silt")
df_impor_Richesse_tot$nom = abr_var

# ggplot(df_impor_Richesse_tot, aes(x = nom, y = percent)) +
#   geom_bar(stat = "identity", fill = "steelblue") +
#   labs(title = "",
#        x = "Variables",
#        y = "Importance (%)") +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r Richness response, fig.align='center'}
#_______________
Richesse_tot_df = landworm_explo_non_t[,c("Richesse_tot",Predictors_f)]
Richesse_tot_df = drop_na(Richesse_tot_df)
colnames(Richesse_tot_df) = c("Richesse_tot","CaCO3","Long","N","Isot","Lat"   ,"Clay","Silt","CLC","P","Prec")

rf <- randomForest(Richesse_tot ~ ., data = Richesse_tot_df, ntree = 500)

# Utilisation du conteneur iml Predictor()
X <- Richesse_tot_df[which(names(Richesse_tot_df) != "Richesse_tot")]
predictor <- Predictor$new(rf, data = X, y = Richesse_tot_df$Richesse_tot)


cat("Importance of predictors")
# Importance des fonctionnalités
# On calcule l'importance de chaque caractéristique pour les prédictions avec FeatureImp. La mesure de l'importance des fonctionnalités fonctionne en mélangeant chaque fonctionnalité et en mesurant l'ampleur de la baisse des performances. Pour cette tâche de régression, nous choisissons de mesurer la perte de performance avec l'erreur absolue moyenne (« mae »), un autre choix serait l'erreur quadratique moyenne (« mse »).

imp_Richesse_tot <- FeatureImp$new(predictor, loss = "rmse") # mean absolute error
# imp_Richesse_tot <- FeatureImp$new(predictor, loss = "mse") # mean squared error  
imp_Richesse_tot_plot = plot(imp_Richesse_tot)
plot(imp_Richesse_tot) 


# imp_Richesse_tot$results
# importance_rf <- as.data.frame(importance(rf))
# importance_rf$nom=rownames(importance_rf)
# importance_rf <- importance_rf[order(importance_rf$IncNodePurity,decreasing = TRUE), ]
# row.names(importance_rf)=NULL
# importance_rf$percent <- importance_rf$IncNodePurity / sum(importance_rf$IncNodePurity)*100
# barplot(importance_rf$percent, main = "Importance of variables for total Richness", names.arg = importance_rf$nom, ylab = "Importance (%)", las = 2)
df_imp = imp_Richesse_tot$results
df_impor_Richesse_tot <- as.data.frame(df_imp)
for (i in names(df_impor_Richesse_tot)[-1]){
df_impor_Richesse_tot[[i]] <- df_impor_Richesse_tot[[i]] / sum(df_impor_Richesse_tot[[i]])*100 
}
df_impor_Richesse_tot <- df_impor_Richesse_tot[order(df_impor_Richesse_tot$feature,decreasing = FALSE), ]
abr_var = c("bio12","bio3","CaCO3","clay","clcm_lvl3","gps_x","gps_y","N","P","silt")
abr_var = c("Prec","Isot","CaCO3","Clay","CLC","Long","Lat","N","P","Silt")

df_impor_Richesse_tot$abr_var = abr_var
df_impor_Richesse_tot$Resp_variable = rep("Richness")
# barplot(df_impor_Richesse_tot$importance, names.arg = df_impor_Richesse_tot$abr_var, 
#         ylab = "Importance (%)", las = 2)




cat("Predictor effects")
# Effets de fonctionnalités
# Les effets locaux accumulés décrivent comment les predicteurs influencent en moyenne la prédiction d'un modèle d'apprentissage automatique: ALE montre comment la prédiction change localement, lorsque les predicteurs varie. Les marques sur l'axe des x indiquent la distribution des predicteurs, montrant la pertinence d'une région pour l'interprétation (peu ou pas de points signifie que nous ne devons pas surinterpréter cette région).

# ale <- FeatureEffect$new(predictor, feature = "gps_x") # uniquement lstat
# ale$plot()
# ale$set.feature("rm")
# ale$plot()
effs <- FeatureEffects$new(predictor) # toutes les variables
plot(effs)






cat("Predictor interactions")
# Mesurer les interactions
# Nous pouvons également mesurer la force avec laquelle les fonctionnalités interagissent les unes avec les autres. La mesure d'interaction concerne la part de la variance de F(X) s’explique par l’interaction. La mesure est comprise entre 0 (pas d'interaction) et 1 (= 100 % de variance deF(X) en raison des interactions). Pour chaque fonctionnalité, nous mesurons dans quelle mesure elles interagissent avec toute autre fonctionnalité.


interact <- Interaction$new(predictor)
plot(interact)
cat("Predictor interactions: Land use")
interact <- Interaction$new(predictor, feature = "CLC")
plot(interact)

```

[Plan]

## Importance of variables

```{r, eval=FALSE}
df_combined <- bind_rows(
  df_impor_AB_tot %>% mutate(resp_variable = "Abondance"),
  df_impor_BM_tot %>% mutate(resp_variable = "Biomasse"),
  df_impor_Richesse_tot %>% mutate(resp_variable = "Richesse")
)
nom_ordonne = c("Prec","Isot","CLC","CaCO3","Clay","N","P","Silt","Long","Lat")
df_combined$nom <- factor(df_combined$nom, levels = nom_ordonne)
df_combined <- df_combined[order(df_combined$nom), ]



g_impo = ggplot(df_combined, aes(x = nom, y = percent, fill = resp_variable)) +
  geom_bar(stat = "identity", color = "black", width = 0.7) +
  # scale_fill_viridis(discrete = TRUE) +
  scale_fill_manual(values = c("Abondance" = "black",
                               "Biomasse" = "gray",
                               "Richesse" = "brown")) +
  labs(title = "",
       x = "Predictor Variables",
       y = "Importance (%)") +
  theme_classic(base_size = 12) +
  theme(axis.text = element_text(size = 10),
        axis.title.y = element_text(
          vjust = 5, size = 12, face = "bold"),
        axis.title.x = element_text(vjust = -1, size = 12, face = "bold"),
        axis.ticks.length = unit(0.2, "cm"),
        legend.text = element_text(size = 10),
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title = element_text(size = 14, face = "bold"),
        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm"),
        legend.position = "top"
      ) +
    coord_flip()
g_impo
# 
# ggsave("Results/landW/importance_var.png", plot = g_impo, dpi = 300,height = 4,width = 6)
# 
# df_combined %>%
#   group_by(nom) %>%
#   summarise(percent = sum(percent))


# imp_AB_tot_plot
# imp_BM_tot_plot
# imp_Richesse_tot_plot

combined_df <- rbind(imp_AB_tot$results, imp_BM_tot$results, imp_Richesse_tot$results)
combined_df$variable <- rep(c("Abundance", "Biomass", "Richness"), each = nrow(imp_AB_tot$results))

# g_impo = ggplot(combined_df, aes(x = importance, y = reorder(feature, importance), color = variable)) +
#   geom_point(size =2) +
#   geom_errorbar(aes(xmin = importance.05, xmax = importance.95), width = 0.1, size=0.8) +
#   labs(x = "Features importance (loss : rmse)", y = "") +
#   # theme() +
#   scale_color_manual(values = c("steelblue", "coral2", "black")) +
#   # theme_classic(base_size = 12) +
#   theme(axis.text = element_text(size = 10),
#         axis.title.y = element_text(
#           vjust = 5, size = 12, face = "bold"),
#         axis.title.x = element_text(vjust = -1, size = 12, face = "bold"),
#         axis.ticks.length = unit(0.2, "cm"),
#         legend.text = element_text(size = 10),
#         legend.title = element_blank(),
#         # panel.grid.major = element_blank(),
#         # panel.grid.minor = element_blank(),
#         plot.title = element_text(size = 14, face = "bold"),
#         plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm"),
#         legend.position = "top"
#       )
# 
# g_impo
# 
# ggsave("Results/landW/importance_var.png", plot = g_impo, dpi = 300
#        ,height = 4,width = 6.5
#        )

```

<p align="center">

<img src="Results/landW/importance_var.png"/>

</p>

# Prediction and mapping

```{r}
Predictors_f = c("CaCO3" ,"gps_x" ,"N" ,"bio3" ,"gps_y" ,"clay" ,
                 "silt" ,"clcm_lvl3" ,"P" ,"bio12" )
```

## Sampling

-   800 m regular grid

-   Stores gps coordinates

```{r Cartographie}
#grille régulière couvrant la zone géographique d'intérêt
res <- 0.008333333  # Résolution de la grille en degrés
grid <- expand.grid(x = seq(from = -5.141277, to = 8.232497, by = res),
                    y = seq(from = 42.33292, to = 51.08899, by = res))
coordinates(grid) <- ~x + y
gridded(grid) <- TRUE

library(magick)
im = image_read("C:/Users/diall/Downloads/datas/fr_1km.png")
plot(im)
```

## Extraction

-   **CLC**

```{r,fig.align='center',fig.height=8 , eval=FALSE}
# N = raster('C:/Users/diall/Downloads/datas/raster_modif/N.tif')
# tif_file_path_origine ="C:/Users/diall/Downloads/72294/Results/U2018_CLC2018_V2020_20u1/U2018_CLC2018_V2020_20u1/U2018_CLC2018_V2020_20u1.tif"
# tif_file_path_origine="C:/Users/diall/Downloads/datas/clc_2018_select_reproj.tif"
# 
# raster_clc <- raster(tif_file_path_origine)
# res(raster_clc)
# crs(raster_clc)
# plot(raster_clc, color = values)
# 
# # raster_clc_trans <- projectRaster(raster_clc, crs = crs(N))
# df_raster_clc <- as.data.frame(raster_clc,xy=TRUE)
# # summary(df_raster_clc)
# df_raster_clc_select = df_raster_clc
# df_raster_clc_select = drop_na(df_raster_clc_select)
# colnames(df_raster_clc_select) = c("gps_x","gps_y", "values_clc")
# str(df_raster_clc_select)
# code_os = c(23,24,25,18,12,15,10,26)
# 
# df = df_raster_clc_select[df_raster_clc_select$values_clc %in% code_os, ]
# df$values_clc = as.factor(df$values_clc)
# str(df)
# summary(df)
# df=droplevels(df)
# df_clc_2018 =df
# # summary(df_clc_2018)
# 
# write.csv(x =df_clc_2018,
#            file = paste0("cartographie/df_clc_2018.csv"),
#            row.names = FALSE)
# 
# df_clc_2018 = read.csv("cartographie/df_clc_2018.csv")
# ggplot(df_clc_2018, aes(x = gps_x, y = gps_y, fill = values_clc)) +
#   geom_point()+
#   scale_fill_manual()
# 
# 
# n_vars = "clc"
# temps1 = Sys.time()
# 
# var_predictors <- extraction(nom_col = 'clc', df = var_predictors, conv = 1, tif_file_path = "C:/Users/diall/Downloads/datas/CL_2018_Fr_res008.tif")
# 
# write.xlsx(x =var_predictors,
#            file = paste0("cartographie/var_predictors_",n_vars,"excel.xlsx"),
#            row.names = FALSE)
# 
# 
# saveRDS(var_predictors, paste0("cartographie/var_predictors_",n_vars,".rds"))
# var_predictors <- readRDS(paste0("cartographie/var_predictors_",n_vars,".rds"))
# 
# 
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree

```

```{=html}
<!--
-   **Broad-leaved forest** 23, 311
-   **Coniferous forest** 24,  312
-   **Mixed forest**  25,      313

-   **Pastures, meadows and other permanent grasslands under agricultural use** 18, 231 

-   **Non-irrigated arable land** 12,  211

-   **Vineyards** 15, 221

-   **Green urban areas** 10,  141

-   **Natural grasslands** 26,  321
-->
```
-   **Limon (g/kg, 0 - 30 cm)**

```{r, eval=FALSE}
# gps_points = as.data.frame(grid)
# 
# summary(gps_points)
# 
# var_predictors = gps_points
# var_predictors =df_clc_2018
# colnames(var_predictors) = c("gps_x","gps_y")
# 
# n_vars = "limon.0_30"
# 
# temps1 = Sys.time()
# var_predictors <- extraction(nom_col = "limon.0_5",df = var_predictors,conv = 1,
#       tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.0_5.tif")
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree
# 
# var_predictors = drop_na(var_predictors)
# 
# temps1 = Sys.time()
# var_predictors <- extraction(nom_col = "limon.5_15",df = var_predictors,conv = 1,
#       tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.5_15.tif")
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree
# # 
# var_predictors = drop_na(var_predictors)
# # 
# temps1 = Sys.time()
# var_predictors <- extraction(nom_col = "limon.15_30",df = var_predictors,conv = 1,
#       tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.15_30.tif")
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree
# var_predictors = drop_na(var_predictors)
# 
# temps1 = Sys.time()
# var_predictors = moyenne_val_extrct(nom_col = "limon.0_30", vec_col = c("limon.0_5","limon.5_15","limon.15_30"),df=var_predictors)
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree
# 
# var_predictors = drop_na(var_predictors)
# 
# write.csv2(x =var_predictors,
#            file = paste0("cartographie/var_predictors_",n_vars,".csv"),
#            row.names = FALSE)
# 

```

-   **Argile (g/kg, 0 - 30 cm)**

```{r,fig.align='center',fig.height=8 , eval=FALSE}
# 
# n_vars = "argile.0_30"
# temps1 = Sys.time()
# 
# 
# var_predictors <- extraction(nom_col = "argile.0_5",df = var_predictors,conv = 1,
#       tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/argile.0_5.tif")
# var_predictors = drop_na(var_predictors)
# 
# var_predictors <- extraction(nom_col = "argile.5_15",df = var_predictors,conv = 1,
#       tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/argile.5_15.tif")
# var_predictors = drop_na(var_predictors)
# 
# var_predictors <- extraction(nom_col = "argile.15_30",df = var_predictors,conv = 1,
#       tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/argile.15_30.tif")
# var_predictors = drop_na(var_predictors)
# 
# var_predictors = moyenne_val_extrct(nom_col = "argile.0_30", vec_col = c("argile.0_5","argile.5_15","argile.15_30"),df=var_predictors)
# 
# write.csv2(x =var_predictors,
#            file = paste0("cartographie/var_predictors_",n_vars,".csv"),
#            row.names = FALSE)
# 
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree

```

-   **Phosphore (P, mg/kg)**

```{r,fig.align='center',fig.height=8 , eval=FALSE}
# 
# n_vars = "P"
# temps1 = Sys.time()
# 
# var_predictors <- extraction(nom_col = 'P', df = var_predictors, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/P.tif')
# var_predictors = drop_na(var_predictors)
# 
# write.csv2(x =var_predictors,
#            file = paste0("cartographie/var_predictors_",n_vars,".csv"),
#            row.names = FALSE)
# 
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree

```

-   **Azote (N, g/kg)**

```{r,fig.align='center',fig.height=8 , eval=FALSE}
# n_vars = "N"
# temps1 = Sys.time()
# 
# var_predictors <- extraction(nom_col = 'N', df = var_predictors, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/N.tif')
# var_predictors = drop_na(var_predictors)
# 
# write.csv2(x =var_predictors,
#            file = paste0("cartographie/var_predictors_",n_vars,".csv"),
#            row.names = FALSE)
# 
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree

```

-   **Carbonates de calcium (CaCO3, g/kg)**

```{r,fig.align='center',fig.height=8 , eval=FALSE}
# n_vars = "CaCO3"
# temps1 = Sys.time()
# 
# var_predictors <- extraction(nom_col = 'CaCO3', df = var_predictors, conv = 1, tif_file_path = 'C:/Users/diall/Downloads/datas/raster_modif/CaCO3.tif')
# 
# var_predictors = drop_na(var_predictors)
# 
# write.csv2(x =var_predictors,
#            file = paste0("cartographie/var_predictors_",n_vars,".csv"),
#            row.names = FALSE)
# 
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree

```

-   **Climat**

```{r, eval=FALSE}
# liens_tif = read.table(file = "C:/Users/diall/Downloads/datas/envidatS3paths.txt")
# liens_tif$shortname <- str_extract(liens_tif$V1, "(?<=CHELSA_).*?(?=_1981)")
# liens_tif[liens_tif$shortname=="rsds","shortname"]=c("rsds_max","rsds_mean","rsds_min","rsds_range")
# 
# ch_bio12 = liens_tif[liens_tif$shortname %in% c("bio3", "bio12"),"V1"][1]
# ch_bio3 = liens_tif[liens_tif$shortname %in% c("bio3", "bio12"),"V1"][2]
# 
# 
# n_vars = "climat"
# temps1 = Sys.time()
# 
# var_predictors <- extraction(nom_col = 'bio3', df = var_predictors, conv = 1, tif_file_path = ch_bio3)
# var_predictors = drop_na(var_predictors)
# 
# var_predictors <- extraction(nom_col = 'bio12', df = var_predictors, conv = 1, tif_file_path = ch_bio12)
# var_predictors = drop_na(var_predictors)
# 
# write.csv(x =var_predictors,
#            file = paste0("cartographie/var_predictors_",n_vars,".csv"),
#            row.names = FALSE)
# 
# 
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree


```

```{r}
# saveRDS(var_predictors, "cartographie/var_predictors.rds")
```

```{r, eval=FALSE}
# Predictors_f = c("CaCO3" ,"gps_x" ,"N" ,"bio3" ,"gps_y" ,"clay" ,
#                  "silt" ,"clcm_lvl3" ,"P" ,"bio12" )
# 
# new_cl <- c("f", "ng",  "p","nial", "v" , "gua")
# code_os = c(23,24,25,18,12,15,10,26)
# df = var_predictors
# df$clcm_lvl3 = rep("NA")
# df$clcm_lvl3 <- ifelse(var_predictors$clc %in% c(23,24,25), "f",
#     ifelse(df$clc == 18, "p",
#        ifelse(df$clc == 12, "nial", 
#            ifelse(df$clc == 15, "v",
#               ifelse(df$clc == 10, "gua",
#                  ifelse(df$clc == 26, "ng", "NA"))))))
# 
# df = drop_na(df)
# df$silt = df$limon.0_30
# df$clay = df$argile.0_30
# 
# df_2 = df[,Predictors_f]
# 
# predictors = df_2
# predictors$bio3 = predictors$bio3 *0.1
# predictors$bio12 = predictors$bio12 *0.1
# 
# 
# predictors$clcm_lvl3 = as.factor(predictors$clcm_lvl3)
# predictors = predictors[!predictors$clcm_lvl3 =="NA",]
# predictors = drop_na(predictors)
# predictors = droplevels(predictors)
# predictors = predictors[!predictors$N>5,]
# predictors = predictors[!predictors$bio12>2000,]
# saveRDS(predictors, "cartographie/predictors.rds")
# predictors <- readRDS("cartographie/predictors.rds")
# 

# write.csv(x =predictors,
#            file = paste0("cartographie/predictor.csv"),
#            row.names = FALSE)


```

```{r, eval=FALSE}
# predictors <- readRDS("cartographie/predictors.rds")
# # summary(predictors)
# # str(predictors)
# 
# predictors_trans = predictors
# Predictors_f = c("CaCO3" ,"gps_x" ,"N" ,"bio3" ,"gps_y" ,"clay" ,
#                  "silt" ,"clcm_lvl3" ,"P" ,"bio12" )
# predictors_trans[,Predictors_f[-8]] = scale(predictors_trans[,Predictors_f[-8]])
# 
# 
# dummy_vars <- model.matrix(~ clcm_lvl3 - 1, data = predictors_trans)
# predictors_trans <- cbind(predictors_trans, dummy_vars)
# predictors_trans$clcm_lvl3 = NULL
# 
# 
# saveRDS(predictors_trans, "cartographie/predictors_trans.rds")
# predictors_trans <- readRDS("cartographie/predictors_trans.rds")

```

```{r, message=FALSE, warning=FALSE, results='hide'}
predictors <- readRDS("cartographie/predictors.rds")
predictors_trans <- readRDS("cartographie/predictors_trans.rds")

france_shapefile <- st_read("cartographie/france_shapefile_sans_corse.shp")
```

## Import best models

-   Cleaning

-   Predictions

## Interpolation

```         
                               +-----------------+-------------+
                               |        Donnée d'entrée:       |
                               |        données prédite        |
                               +----------------+--------------+
                                                 |
                                                 |
                                                 v
                               +-----------------+-------------+
                               |    Modèle d'interpolation     |
                               |        idw (nmax = 10)        |
                               +----------------+--------------+
                                                 |
                                                 |
                                                 v
                               +-----------------+-------------+
                               |                               |
                               |        Nouvelles données      |
                               |        à prédire              |
                               |        ()                     |
                               |                               |
                               +----------------+--------------+
                                                 |
                                                 |
                                                 v
                               +-----------------+-------------+
                               |                               |
                               |      Prédictions de l'IDW     |
                               |                               |
                               +-------------------------------+
```

```{r, fig.align='center'}
im = magick::image_read("https://rafatieppo.github.io/post/pics/2018_07_27_pointsa.png")
print(im)
```

```{r}
france_shapefile <- st_read("cartographie/france_shapefile_sans_corse.shp")

couleur <- colorRampPalette(c("red", "darkorange", "orange", "goldenrod1", "yellow", "yellow", "yellow","greenyellow", "greenyellow", "greenyellow", "greenyellow", "greenyellow", "greenyellow", "green", "green", "green2", "green2", "green2", "green2", "green2", "green2", "green3", "green4", "green4"))(255)

```

## Abundance

```{r Abundance prediction}
# mod_AB_tot = readRDS("cartographie/best_mod/RF_mod_AB_tot.RDS")
# 
# AB_tot_pred<- predict(mod_AB_tot, newdata = predictors_trans)
# AB_tot_pred = round(as.numeric(AB_tot_pred))
# # summary(AB_tot_pred)
# AB_tot_pred = data.frame(Abundance = AB_tot_pred, Longitude = predictors$gps_x, Latitude = predictors$gps_y)
# 
# write.csv(x =AB_tot_pred,file = "cartographie/AB_tot_pred.csv",row.names = FALSE)
# 
# saveRDS(AB_tot_pred, "cartographie/AB_tot_pred.rds")
# 
# AB_tot_pred = readRDS("cartographie/AB_tot_pred.rds")


```

```{r Abundance map}
# AB_tot_pred = readRDS("cartographie/AB_tot_pred.rds")
# df <- AB_tot_pred
# df$Abundance = df$Abundance^2

# #1
# AB_tot_mesuree = landworm_explo_non_t[, c("AB_tot","gps_x", "gps_y")]
# colnames(AB_tot_mesuree) = c("Abundance","Longitude","Latitude")
# AB_tot_mesuree$Abundance = round(AB_tot_mesuree$Abundance)
# AB_tot_mesuree = AB_tot_mesuree[!AB_tot_mesuree$Abundance>800,]
# # AB_tot_mesuree$Longitude = round(AB_tot_mesuree$Longitude, 6)
# # AB_tot_mesuree$Latitude = round(AB_tot_mesuree$Latitude, 5)
# 
# 
# df = rbind(df,AB_tot_mesuree)
###
# temps1 = Sys.time()
# # Convertir le dataframe en SpatialPointsDataFrame
# coordinates(df) <- c("Longitude", "Latitude")
# 
# pts_a_idw_gps = pts_a_idw[,c("Longitude", "Latitude")]
# colnames(pts_a_idw_gps) <- c("x", "y")
# coordinates(pts_a_idw_gps) <- ~x + y
# gridded(pts_a_idw_gps) <- TRUE

#grille régulière couvrant la zone géographique d'intérêt
# res <- 0.008333333  # Résolution de la grille en degrés
# grid <- expand.grid(x = seq(from = -5.141277, to = 8.232497, by = res),
#                     y = seq(from = 42.33292, to = 51.08899, by = res))
# coordinates(grid) <- ~x + y
# gridded(grid) <- TRUE
# 

# Interpolation des valeurs de AB_tot des vers de terre sur la grille
# idw_AB_tot <- gstat::idw(Abundance ~ 1, df, newdata = pts_a_idw_gps,nmax=10, idp =10)
# saveRDS(idw_AB_tot, "cartographie/idw_AB_tot.rds")
# idw_AB_tot = readRDS("cartographie/idw_AB_tot.rds")
# Abundance_raster <- raster(idw_AB_tot)
# 
# # crs(Abundance_raster) = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
# crs(Abundance_raster) = crs(france_shapefile)
# res(Abundance_raster) = 0.008333333
# extent(Abundance_raster) = extent(france_shapefile)
# Abundance_raster = raster::mask(Abundance_raster,france_shapefile)
# 
# raster::writeRaster(x = Abundance_raster,filename = "cartographie/raster_AB_tot.tif", overwrite=TRUE)
# 
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree

###


# Abundance_raster <- raster("cartographie/raster_AB_tot.tif")

# plot(Abundance_raster, main = "Abundance ")
# mapview::mapview(Abundance_raster, main = "Abundance", maxpixels  = 2001670)



# # Manipulating data
# 
# 
# #1
# AB_tot_mesuree = landworm_explo_non_t[, c("gps_x", "gps_y", "AB_tot")]
# colnames(AB_tot_mesuree) = c("Longitude","Latitude","Abundance")
# AB_tot_mesuree$Abundance = round(AB_tot_mesuree$Abundance)
# AB_tot_mesuree$Longitude = round(AB_tot_mesuree$Longitude, 6)
# AB_tot_mesuree$Latitude = round(AB_tot_mesuree$Latitude, 5)
# 
# 
# #2
# df <- AB_tot_pred
# df$Abundance = df$Abundance^2
# 
# 
# df_AB_tot_all = rbind(AB_tot_mesuree,df)
# write.csv(x =df_AB_tot_all,file = "cartographie/df_AB_tot_all.csv",row.names = FALSE)
#
```

```{r Abundance map2, fig.dpi=300}
# df <- AB_tot_pred
# df$Abundance = df$Abundance^2
# 
# Abundance_raster <- raster("cartographie/raster_AB_tot.tif")
# x <- rasterize(df[, 2:3], Abundance_raster, df[,1], fun=mean)
# raster::writeRaster(x = x,filename = "cartographie/x.tif", overwrite=TRUE)
# # plot(x)
# rasdf_x <- as.data.frame(x,xy=TRUE) #%>%drop_na()
# colnames(rasdf_x) = c("Longitude", "Latitude","Abundance")
# pts_a_idw = rasdf_x[is.na(rasdf_x$Abundance), ]
# # rasdf_x$ID = paste0(rasdf_x$Longitude,"_",rasdf_x$Latitude)
# clean_rasdf_x = drop_na(rasdf_x)
# 
# df <- AB_tot_pred
# df$Abundance = df$Abundance^2
# coordinates(df) <- c("Longitude", "Latitude")
# pts_a_idw_gps = pts_a_idw[,c("Longitude", "Latitude")]
# colnames(pts_a_idw_gps) <- c("x", "y")
# coordinates(pts_a_idw_gps) <- ~x + y
# idw_AB_tot <- gstat::idw(Abundance ~ 1, df, newdata = pts_a_idw_gps,nmax=10, idp =10)
# saveRDS(idw_AB_tot, "cartographie/idw_AB_tot.rds")
# 
# idw_rasdf_x = data.frame(Longitude = pts_a_idw$Longitude,
#                           Latitude = pts_a_idw$Latitude ,
#                           Abundance = idw_AB_tot$var1.pred)
# all_pts_AB_tot = rbind(clean_rasdf_x, idw_rasdf_x)
# saveRDS(all_pts_AB_tot, "cartographie/all_pts_AB_tot.rds")
# 
# all_pts_AB_tot = readRDS("cartographie/all_pts_AB_tot.rds")
# 
# r_all_pts_AB_tot = raster::rasterize(all_pts_AB_tot[, 1:2], Abundance_raster, all_pts_AB_tot[,3], fun=mean)
# r_all_pts_AB_tot = raster::mask(r_all_pts_AB_tot,france_shapefile)
# raster::writeRaster(x = r_all_pts_AB_tot,filename = "cartographie/r_all_pts_AB_tot.tif", overwrite=TRUE)
# r_all_pts_AB_tot = raster("cartographie/r_all_pts_AB_tot.tif")


# raster::plot(r_all_pts_AB_tot, main = "Predicted total \nabundance (ind./m²)",
#      col=couleur ,add=FALSE, axes = FALSE, box=FALSE)
# plot(france_shapefile,add=TRUE, color="gray", alpha=0.001, axes = FALSE)

# Abundance = r_all_pts_AB_tot
# mapview::mapview(Abundance, col.regions = couleur, legend = TRUE, main = "Abundance", maxpixels =  '1686855', legend.name = "Predicted total \nabundance (ind./m²)")

# 
# df_AB_tot_carte = rasdf
# df_AB_tot_carte[df_AB_tot_carte$Abundance>700, "Abundance"]=700
# Plotting

# df_AB_tot_pred = as.data.frame(r_all_pts_AB_tot,xy=TRUE)
# colnames(df_AB_tot_pred) <- c("x", "y","Abundance")
# carte_AB_tot =  ggplot() +
#   geom_raster(aes(x = x, y = y, fill = Abundance), data = df_AB_tot_pred) +
#   geom_sf(fill = 'transparent', data = france_shapefile) +
#   scale_fill_gradientn(
#     colors = couleur,
#     name = 'Predicted total \nabundance (ind./m²)\n',
#     breaks = c(100, 200, 300, 400, 500),
#     labels = c('100', '200', '300', '400', '500'),
#     na.value = "white"
#   )+
#   labs(x='Longitude',y='Latitude',
#        # title="Total Abundance map",
#        # subtitle='',
#        # caption='Source: LandWorm, 2024'
#        )+
#   theme(panel.grid.major = element_line(color = gray(.5),
#                                         linetype = 'dashed',
#                                         size = 0.1),
#         panel.grid.minor = element_blank(),
#         panel.background = element_rect(fill=NA,color = 'black'),
#         panel.ontop = TRUE,
#         axis.text = element_text(size = 8),
#         axis.title.y = element_text(vjust = 5, size = 10, face = "bold"),
#         axis.title.x = element_text(size = 10, face = "bold",vjust = -1),
#         axis.ticks.length = unit(0.2, "cm"),
#         plot.caption = element_text(vjust = -1.5),
#         plot.margin = unit(c(0.2, 0.2, 0.2, 0.2), "cm")) #gauche,droite,haut,bas
# 
# carte_AB_tot
# ggsave("cartographie/carte_AB_tot.png", plot = carte_AB_tot, dpi = 300
#        ,height = 2.8,width = 5
#        )


```

<p align="center">

<img src="cartographie/carte_AB_tot.png"/>

</p>

## Biomass

```{r Biomass prediction}
# mod_BM_tot = readRDS("cartographie/best_mod/RF_mod_BM_tot.RDS")
# 
# BM_tot_pred<- predict(mod_BM_tot, newdata = predictors_trans)
# BM_tot_pred = round(as.numeric(BM_tot_pred))
# # summary(BM_tot_pred)
# BM_tot_pred = data.frame(Biomass = BM_tot_pred, Longitude = predictors$gps_x, Latitude = predictors$gps_y)
# 
# write.csv(x =BM_tot_pred,file = "cartographie/BM_tot_pred.csv",row.names = FALSE)
# 
# saveRDS(BM_tot_pred, "cartographie/BM_tot_pred.rds")

# BM_tot_pred = readRDS("cartographie/BM_tot_pred.rds")
```

```{r Biomass map}
# BM_tot_pred = readRDS("cartographie/BM_tot_pred.rds")
# df <- BM_tot_pred
# df$Biomass = df$Biomass^2

# #1
# BM_tot_mesuree = landworm_explo_non_t[, c("BM_tot","gps_x", "gps_y")]
# colnames(BM_tot_mesuree) = c("Biomass","Longitude","Latitude")
# # BM_tot_mesuree$Biomass = round(BM_tot_mesuree$Biomass)
# # BM_tot_mesuree$Longitude = round(BM_tot_mesuree$Longitude, 6)
# # BM_tot_mesuree$Latitude = round(BM_tot_mesuree$Latitude, 5)
# 
# 
# df = rbind(df,BM_tot_mesuree)
# df = drop_na(df)
###
# temps1 = Sys.time()
# # Convertir le dataframe en SpatialPointsDataFrame
# coordinates(df) <- c("Longitude", "Latitude")
# 
# #grille régulière couvrant la zone géographique d'intérêt
# res <- 0.008333333  # Résolution de la grille en degrés
# grid <- expand.grid(x = seq(from = -5.141277, to = 8.232497, by = res),
#                     y = seq(from = 42.33292, to = 51.08899, by = res))
# coordinates(grid) <- ~x + y
# gridded(grid) <- TRUE
# 
# 
# # Interpolation des valeurs de BM_tot des vers de terre sur la grille
# idw_BM_tot <- gstat::idw(Biomass ~ 1, df, newdata = grid,nmax=5, idp =10)
# saveRDS(idw_BM_tot, "cartographie/idw_BM_tot.rds")
# # idw_BM_tot = readRDS("cartographie/idw_BM_tot.rds")
# Biomass_raster <- raster(idw_BM_tot)
# 
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree
# 
# 
# 
# # crs(Biomass_raster) = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
# crs(Biomass_raster) = crs(france_shapefile)
# res(Biomass_raster) = 0.008333333
# extent(Biomass_raster) = extent(france_shapefile)
# Biomass_raster = raster::mask(Biomass_raster,france_shapefile)
# 
# raster::writeRaster(x = Biomass_raster,filename = "cartographie/raster_BM_tot.tif", overwrite=TRUE)

###


# Biomass_raster <- raster("cartographie/raster_BM_tot.tif")

# plot(Biomass_raster, main = "Biomass ")
# mapview::mapview(Biomass_raster, main = "Biomass", maxpixels  = 2001670)



# # Manipulating data
# rasdf <- as.data.frame(Biomass_raster,xy=TRUE)%>%drop_na()
# # head(rasdf)
# colnames(rasdf) = c("x","y","Biomass")
# df_BM_tot_carte = rasdf
# df_BM_tot_carte[df_BM_tot_carte$Abundance>300, "Biomass"]=300


# df <- BM_tot_pred
# df$Biomass = df$Biomass^2
# 
# Biomass_raster <- raster("cartographie/raster_BM_tot.tif")
# x <- rasterize(df[, 2:3], Biomass_raster, df[,1], fun=mean)
# raster::writeRaster(x = x,filename = "cartographie/x_BM_tot.tif", overwrite=TRUE)
# # plot(x)
# rasdf_x <- as.data.frame(x,xy=TRUE) #%>%drop_na()
# colnames(rasdf_x) = c("Longitude", "Latitude","Biomass")
# pts_a_idw = rasdf_x[is.na(rasdf_x$Biomass), ]
# # rasdf_x$ID = paste0(rasdf_x$Longitude,"_",rasdf_x$Latitude)
# clean_rasdf_x = drop_na(rasdf_x)
# 
# df <- BM_tot_pred
# df$Biomass = df$Biomass^2
# coordinates(df) <- c("Longitude", "Latitude")
# pts_a_idw_gps = pts_a_idw[,c("Longitude", "Latitude")]
# colnames(pts_a_idw_gps) <- c("x", "y")
# coordinates(pts_a_idw_gps) <- ~x + y
# idw_BM_tot <- gstat::idw(Biomass ~ 1, df, newdata = pts_a_idw_gps,nmax=5, idp =10)
# saveRDS(idw_BM_tot, "cartographie/idw_BM_tot.rds")
# 
# idw_rasdf_x = data.frame(Longitude = pts_a_idw$Longitude,
#                           Latitude = pts_a_idw$Latitude ,
#                           Biomass = idw_BM_tot$var1.pred)
# all_pts_BM_tot = rbind(clean_rasdf_x, idw_rasdf_x)
# saveRDS(all_pts_BM_tot, "cartographie/all_pts_BM_tot.rds")
# 
# all_pts_BM_tot = readRDS("cartographie/all_pts_BM_tot.rds")
# 
# r_all_pts_BM_tot = rasterize(all_pts_BM_tot[, 1:2], x, all_pts_BM_tot[,3], fun=mean)
# r_all_pts_BM_tot = raster::mask(r_all_pts_BM_tot,france_shapefile)
# raster::writeRaster(x = r_all_pts_BM_tot,filename = "cartographie/r_all_pts_BM_tot.tif", overwrite=TRUE)
# r_all_pts_BM_tot = raster("cartographie/r_all_pts_BM_tot.tif")
# xlim <- c(-5.141277, 8.232497)
# ylim <- c(42.33292, 51.08899)
# plot(r_all_pts_BM_tot, main = "Predicted total \nbiomass (ind./g)",
#           col=colorRampPalette(c("red", "darkorange", "orange", "goldenrod1", "yellow", "yellow", "yellow","greenyellow", "greenyellow", "greenyellow", "greenyellow", "greenyellow", "greenyellow", "green", "green", "green2", "green2", "green2", "green2", "green2", "green2", "green3", "green4", "green4"))(255) , xlim = xlim, ylim = ylim)
# plot(france_shapefile,add=TRUE, color="gray", alpha=0.001)


# df_BM_tot_pred = as.data.frame(r_all_pts_BM_tot,xy=TRUE)
# colnames(df_BM_tot_pred) <- c("x", "y","Biomass")
# carte_BM_tot =  ggplot() +
#   geom_raster(aes(x = x, y = y, fill = Biomass), data = df_BM_tot_pred) +
#   geom_sf(fill = 'transparent', data = france_shapefile) +
#   scale_fill_gradientn(
#     colors = couleur,
#     name = 'Predicted total \nbiomass (g/m²)\n',
#     breaks = c(50, 100, 150, 200),
#     labels = c('50', '100', '150', '200'),
#     na.value = "white"
#   )+
#   labs(x='Longitude',y='Latitude',
#        # title="Total Biomass map",
#        # subtitle='',
#        # caption='Source: LandWorm, 2024'
#        )+
#   theme(panel.grid.major = element_line(color = gray(.5),
#                                         linetype = 'dashed',
#                                         size = 0.1),
#         panel.grid.minor = element_blank(),
#         panel.background = element_rect(fill=NA,color = 'black'),
#         panel.ontop = TRUE,
#         axis.text = element_text(size = 8),
#         axis.title.y = element_text(vjust = 5, size = 10, face = "bold"),
#         axis.title.x = element_text(size = 10, face = "bold",vjust = -1),
#         axis.ticks.length = unit(0.2, "cm"),
#         plot.caption = element_text(vjust = -1.5),
#         plot.margin = unit(c(0.2, 0.2, 0.2, 0.2), "cm")) #gauche,droite,haut,bas
# 
# carte_BM_tot
# ggsave("cartographie/carte_BM_tot.png", plot = carte_BM_tot, dpi = 300
#        ,height = 2.8,width = 5
#        )
```

<p align="center">

<img src="cartographie/carte_BM_tot.png"/>

</p>

## Richness

```{r Richness prediction}
# mod_Richesse_tot = readRDS("cartographie/best_mod/RF_mod_Richesse_tot.RDS")
# 
# Richesse_tot_pred<- predict(mod_Richesse_tot, newdata = predictors_trans)
# Richesse_tot_pred = round(as.numeric(Richesse_tot_pred))
# # summary(Richesse_tot_pred)
# Richesse_tot_pred = data.frame(Richness = Richesse_tot_pred, Longitude = predictors$gps_x, Latitude = predictors$gps_y)
# 
# write.csv(x =Richesse_tot_pred,file = "cartographie/Richesse_tot_pred.csv",row.names = FALSE)
# 
# saveRDS(Richesse_tot_pred, "cartographie/Richesse_tot_pred.rds")
# 
# Richesse_tot_pred = readRDS("cartographie/Richesse_tot_pred.rds")

```

```{r Richness map}
# Richesse_tot_pred = readRDS("cartographie/Richesse_tot_pred.rds")
# df <- Richesse_tot_pred
# 

# #1
# Richesse_tot_mesuree = landworm_explo_non_t[, c("Richesse_tot","gps_x", "gps_y")]
# colnames(Richesse_tot_mesuree) = c("Richness","Longitude","Latitude")
# Richesse_tot_mesuree$Richness = round(Richesse_tot_mesuree$Richness)
# # Richesse_tot_mesuree$Longitude = round(Richesse_tot_mesuree$Longitude, 6)
# # Richesse_tot_mesuree$Latitude = round(Richesse_tot_mesuree$Latitude, 5)
# 
# 
# df = rbind(df,Richesse_tot_mesuree)
# ###
# temps1 = Sys.time()
# # Convertir le dataframe en SpatialPointsDataFrame
# coordinates(df) <- c("Longitude", "Latitude")
# 
# #grille régulière couvrant la zone géographique d'intérêt
# res <- 0.008333333  # Résolution de la grille en degrés
# grid <- expand.grid(x = seq(from = -5.141277, to = 8.232497, by = res),
#                     y = seq(from = 42.33292, to = 51.08899, by = res))
# coordinates(grid) <- ~x + y
# gridded(grid) <- TRUE
# 
# 
# # Interpolation des valeurs de Richesse_tot des vers de terre sur la grille
# idw_Richesse_tot <- gstat::idw(Richness ~ 1, df, newdata = grid,nmax=10, idp =10)
# saveRDS(idw_Richesse_tot, "cartographie/idw_Richesse_tot.rds")
# # idw_Richesse_tot = readRDS("cartographie/idw_Richesse_tot.rds")
# Richness_raster <- raster(idw_Richesse_tot)
# 
# temps2 = Sys.time()
# duree = difftime(temps2,temps1)
# duree
# 
# 
# 
# # crs(Richness_raster) = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
# crs(Richness_raster) = crs(france_shapefile)
# res(Richness_raster) = 0.008333333
# extent(Richness_raster) = extent(france_shapefile)
# Richness_raster = raster::mask(Richness_raster,france_shapefile)
# 
# raster::writeRaster(x = Richness_raster,filename = "cartographie/raster_Richesse_tot.tif", overwrite=TRUE)

###


# Richness_raster <- raster("cartographie/raster_Richesse_tot.tif")

# plot(Richness_raster, main = "Richness ")
# mapview::mapview(Richness_raster, main = "Richness", maxpixels  = 2001670)
# 
# 
# 
# # Manipulating data
# rasdf <- as.data.frame(Richness_raster,xy=TRUE)%>%drop_na()
# # head(rasdf)
# colnames(rasdf) = c("x","y","Richness")
# 
# df_Richesse_tot_carte = rasdf

# df <- Richesse_tot_pred
# Richness_raster <- raster("cartographie/raster_Richesse_tot.tif")
# x <- rasterize(df[, 2:3], Richness_raster, df[,1], fun=mean)
# raster::writeRaster(x = x,filename = "cartographie/x.tif", overwrite=TRUE)
# # plot(x)
# rasdf_x <- as.data.frame(x,xy=TRUE) #%>%drop_na()
# colnames(rasdf_x) = c("Longitude", "Latitude","Richness")
# pts_a_idw = rasdf_x[is.na(rasdf_x$Richness), ]
# # rasdf_x$ID = paste0(rasdf_x$Longitude,"_",rasdf_x$Latitude)
# clean_rasdf_x = drop_na(rasdf_x)
# 
# df <- Richesse_tot_pred
# coordinates(df) <- c("Longitude", "Latitude")
# pts_a_idw_gps = pts_a_idw[,c("Longitude", "Latitude")]
# colnames(pts_a_idw_gps) <- c("x", "y")
# coordinates(pts_a_idw_gps) <- ~x + y
# idw_Richesse_tot <- gstat::idw(Richness ~ 1, df, newdata = pts_a_idw_gps,nmax=5, idp =10)
# saveRDS(idw_Richesse_tot, "cartographie/idw_Richesse_tot.rds")
# 
# idw_rasdf_x = data.frame(Longitude = pts_a_idw$Longitude,
#                           Latitude = pts_a_idw$Latitude ,
#                           Richness = round(idw_Richesse_tot$var1.pred))
# all_pts_Richesse_tot = rbind(clean_rasdf_x, idw_rasdf_x)
# saveRDS(all_pts_Richesse_tot, "cartographie/all_pts_Richesse_tot.rds")
# 
# all_pts_Richesse_tot = readRDS("cartographie/all_pts_Richesse_tot.rds")
# 
# r_all_pts_Richesse_tot = rasterize(all_pts_Richesse_tot[, 1:2], x, all_pts_Richesse_tot[,3], fun=mean)
# r_all_pts_Richesse_tot = raster::mask(r_all_pts_Richesse_tot,france_shapefile)
# raster::writeRaster(x = r_all_pts_Richesse_tot,filename = "cartographie/r_all_pts_Richesse_tot.tif", overwrite=TRUE)
# r_all_pts_Richesse_tot = raster("cartographie/r_all_pts_Richesse_tot.tif")
# xlim <- c(-5.141277, 8.232497)
# ylim <- c(42.33292, 51.08899)
# plot(r_all_pts_Richesse_tot, main = "Predicted total \nrichness (nr. of spp.)",
#                col=colorRampPalette(c("red", "darkorange", "orange", "goldenrod1", "yellow", "yellow", "yellow","greenyellow", "greenyellow", "greenyellow", "greenyellow", "greenyellow", "greenyellow", "green", "green", "green2", "green2", "green2", "green2", "green2", "green2", "green3", "green4", "green4"))(255) , xlim = xlim, ylim = ylim)
# plot(france_shapefile,add=TRUE, color="gray", alpha=0.001)
# 



# df_Richesse_tot_pred = as.data.frame(r_all_pts_Richesse_tot,xy=TRUE)
# colnames(df_Richesse_tot_pred) <- c("x", "y","Richness")
# carte_Richesse_tot =  ggplot() +
#   geom_raster(aes(x = x, y = y, fill = Richness), data = df_Richesse_tot_pred) +
#   geom_sf(fill = 'transparent', data = france_shapefile) +
#   scale_fill_gradientn(
#     colors = couleur,
#     name = 'Predicted total \nrichness (nr. of spp.)\n',
#     breaks = c(2, 4, 6, 8, 10),
#     labels = c('2', '4', '6', '8', '10'),
#     na.value = "white"
#   )+
#   labs(x='Longitude',y='Latitude',
#        )+
#   theme(panel.grid.major = element_line(color = gray(.5),
#                                         linetype = 'dashed',
#                                         size = 0.1),
#         panel.grid.minor = element_blank(),
#         panel.background = element_rect(fill=NA,color = 'black'),
#         panel.ontop = TRUE,
#         axis.text = element_text(size = 8),
#         axis.title.y = element_text(vjust = 5, size = 10, face = "bold"),
#         axis.title.x = element_text(size = 10, face = "bold",vjust = -1),
#         axis.ticks.length = unit(0.2, "cm"),
#         plot.caption = element_text(vjust = -1.5),
#         plot.margin = unit(c(0.2, 0.2, 0.2, 0.2), "cm")) #gauche,droite,haut,bas
# 
# carte_Richesse_tot
# ggsave("cartographie/carte_Richesse_tot.png", plot = carte_Richesse_tot, dpi = 300
#        ,height = 2.8,width = 5
#        )

```

<p align="center">

<img src="cartographie/carte_Richesse_tot.png"/>

</p>

## Approximate earthworm diversity

```{r}
# df1=df_AB_tot_pred # Abundance
# df2=df_Richesse_tot_pred # Richesse
# colnames(df1) = colnames(df2)=c("x","y","values")
# 
# # Fonction de normalisation min-max
# normalize <- function(x) {
#   return((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))
# }
# 
# 
# df1_normalized <- df1 %>%
#   mutate(values_normalized = normalize(values))
# 
# df2_normalized <- df2 %>%
#   mutate(values_normalized = normalize(values))
# 
# 
# df_merged <- full_join(df1_normalized, df2_normalized, by = c("x", "y"))
# df_merged$biodiversity = df_merged$values_normalized.x + df_merged$values_normalized.y
# 
# biodiversity =  ggplot() +
#   geom_raster(aes(x = x, y = y, fill = biodiversity), data = df_merged) +
#   # geom_raster(aes(x = x, y = y, fill = values), data = df2) +
#   geom_sf(fill = 'transparent', data = france_shapefile) +
#   scale_fill_gradientn(
#     colors = couleur,
#     name = 'Predicted approximate \nearthworm diversity\n',
#     breaks = c(0.2, 0.6, 1, 1.4, 1.8),
#     labels = c("Very low","Low","Medium","High","Very high"),
#     na.value = "white"
#   )+
#   labs(x='Longitude',y='Latitude',
#        # title="Total Abundance map",
#        # subtitle='',
#        # caption='Source: LandWorm, 2024'
#        )+
#   theme(panel.grid.major = element_line(color = gray(.5),
#                                         linetype = 'dashed',
#                                         size = 0.1),
#         panel.grid.minor = element_blank(),
#         panel.background = element_rect(fill=NA,color = 'black'),
#         panel.ontop = TRUE,
#         axis.text = element_text(size = 8),
#         axis.title.y = element_text(vjust = 5, size = 10, face = "bold"),
#         axis.title.x = element_text(size = 10, face = "bold",vjust = -1),
#         axis.ticks.length = unit(0.2, "cm"),
#         plot.caption = element_text(vjust = -1.5),
#         plot.margin = unit(c(0.2, 0.2, 0.2, 0.2), "cm")) #gauche,droite,haut,bas
# 
# biodiversity
# 
# ggsave("cartographie/biodiversity.png", plot = biodiversity, dpi = 300
#        ,height = 2.8,width = 5
#        )

```

<p align="center">

<img src="cartographie/biodiversity.png"/>

</p>

## Mapview

```{r}
# # Abundance
# Abundance = r_all_pts_AB_tot
# val_ab = values(Abundance)
# val_ab <- ifelse(!is.na(val_ab), round(val_ab), NA)
# values(Abundance) = val_ab
# 
# # Biomass
# Biomass = round(r_all_pts_BM_tot)
# 
# # Richness
# Richness = round(r_all_pts_Richesse_tot)
# 
# map = mapview::mapview(Abundance, col.regions = couleur, legend = TRUE, layer.name = "Abundance (ind.m-²)", main = "Abundance", maxpixels = '1686855', trim=FALSE) +
# 
#  mapview::mapview(Biomass, col.regions = couleur, legend = TRUE, layer.name = "Biomass (ind.g)")+
# 
# mapview::mapview(Richness, col.regions = couleur, legend = TRUE, layer.name = "Richness (nr. of spp.)", trim=FALSE, maxpixels =  "2001670")
# 
# map

# carte_AB_tot
# carte_BM_tot
# carte_Richesse_tot
# biodiversity

form <- function(g) {
  gg <- g +
    labs(x = '', y = '') +
    theme(
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.background = element_blank(),
      panel.ontop = TRUE,
      axis.text = element_blank(),
      axis.title.y = element_blank(),
      axis.title.x = element_blank(),
      axis.ticks.length = unit(0, "cm"),
    legend.key.size = unit(1, 'cm'), #change legend key size
    legend.key.height = unit(0.4, 'cm'), #change legend key height
    legend.key.width = unit(0.4, 'cm'), #change legend key width
    legend.title = element_text(size=7), #change legend title font size
    legend.text = element_text(size=6) #change legend text font size
    )
  return(gg)
}
# 
# 
# g_carte_AB_tot = form(carte_AB_tot)
# g_carte_BM_tot = form(carte_BM_tot)
# g_carte_Richesse_tot = form(carte_Richesse_tot)
# g_biodiversity = form(biodiversity)
# 
# carte_vdt = ggarrange(g_carte_AB_tot, g_carte_BM_tot, g_carte_Richesse_tot, g_biodiversity,
#   labels = c('(a)', '(b)','(c)', '(d)'),align = "hv" , ncol = 2, nrow=2
#   # ,widths = 10,
#   # common.legend = TRUE,
#   # legend = 'right'
# )
# carte_vdt
# ggsave("cartographie/carte_vdt.png", plot = carte_vdt, dpi = 300
#        ,height = 4.5,width = 6.5
#        )


# ggsave("cartographie/g_carte_AB_tot.png", plot = g_carte_AB_tot, dpi = 300
#        ,height = 3.5,width = 5.5
#        )
# 
# ggsave("cartographie/g_carte_BM_tot.png", plot = g_carte_BM_tot, dpi = 300
#        ,height = 3.5,width = 5.5
#        )
# 
# ggsave("cartographie/g_carte_Richesse_tot.png", plot = g_carte_Richesse_tot, dpi = 300
#        ,height = 3.5,width = 5.5
#        )
# 
# ggsave("cartographie/g_biodiversity.png", plot = g_biodiversity, dpi = 300
#        ,height = 3.5,width = 5.5
#        )


```

<p align="center">

<img src="cartographie/carte_vdt.png"/>

</p>

See [Mapping earthworm prediction inFrance](https://rpubs.com/Abdou_diallo/1184840){target="_blank"}

back to [Plan]

## Co-kriging

```{r, eval= FALSE}
# Installer et charger les packages
install.packages("gstat")
install.packages("sp")
library(gstat)
library(sp)

# Exemple de données
set.seed(123)
df <- data.frame(
  x = runif(20, 0, 10),
  y = runif(20, 0, 10),
  abundance = rnorm(20, 5, 2),
  land_use = factor(sample(1:6, 20, replace = TRUE))
)
coordinates(df) <- ~x + y

# Création de variables indicatrices pour l'occupation du sol
df_ind <- model.matrix(~ land_use - 1, data = df)
df_ind <- as.data.frame(df_ind)
df <- cbind(df, df_ind)

# Grille pour l'interpolation
grd <- expand.grid(x = seq(0, 10, by = 0.5), y = seq(0, 10, by = 0.5))
coordinates(grd) <- ~x + y

# Définition des modèles gstat pour co-kriging
g <- gstat(NULL, id = "abundance", form = abundance ~ 1, data = df)
for(i in colnames(df_ind)) {
  g <- gstat(g, id = i, form = as.formula(paste(i, "~ 1")), data = df)
  g <- gstat(g, id = "abundance", form = as.formula(paste("abundance ~", i)), data = df)
}

# Calcul des variogrammes expérimentaux
v <- variogram(g)

# Ajustement des modèles de variogramme théorique
vgm <- fit.lmc(v, g, model = vgm(1, "Sph", 1, 1))

# Prédire les valeurs
ck_result <- predict(vgm, grd)

# Visualiser les résultats
spplot(ck_result["var1.pred"], main = "Predicted Abundance")

```

# Internship report

-   Introduction (80 %)

-   M & M (85 %)

-   Résultats (30 %)

-   Discussion (10 %)

-   Conclusion (0 %)

-   Autres (0 %)

( [Stage_abdou.docx](C:/Users/diall/OneDrive/Bureau/M2_MODE/stage_abdou_m2/Redaction/Stage_abdou.docx){target="_blank"} )

back to [Plan]

## Cate M&M

```{r, eval=FALSE}
# 
# fr_region = "C:/Users/diall/Downloads/ADMIN-EXPRESS_3-2__SHP_LAMB93_FXX_2024-04-23/ADMIN-EXPRESS_3-2__SHP_LAMB93_FXX_2024-04-23/ADMIN-EXPRESS/1_DONNEES_LIVRAISON_2024-04-00116/ADE_3-2_SHP_LAMB93_FXX-ED2024-04-23/REGION.shp"
# france_shapefile <- st_read(fr_region)
# 
# st_crs(france_shapefile)
# france_shapefile <- st_transform(france_shapefile, crs = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
# st_crs(france_shapefile)
# 
# g = ggplot(france_shapefile) +
#   geom_sf()
# g
# 
# # Excluez la région Corse
# france_shapefile <- france_shapefile[france_shapefile$NOM_M != "CORSE", ]
# st_write(france_shapefile, "cartographie/france_shapefile_sans_corse.shp")

france_shapefile <- st_read("cartographie/france_shapefile_sans_corse.shp")

g = ggplot(france_shapefile) +
  geom_sf(color ="")
g
gg = form(g)

# Carte
landworm_sf = landworm[,c("gps_x", "gps_y")]
landworm_sf <- st_as_sf(landworm_sf, coords = c("gps_x", "gps_y"))
st_crs(landworm_sf) =  "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"



carte_obs <- ggplot() +
  geom_sf(data = france_shapefile) +  
  geom_sf(data = landworm_sf, color = "red", size = 0.01) +
  labs(x = 'Longitude', y = 'Latitude',
       # title = "Map of France",
       # subtitle = '',
       caption = 'Source: LandWorm, 2024')+
  # ggsn::scalebar(location = "bottomleft", dist = 100, dist_unit = "km") +
  # cowplot::theme_cowplot()+
  theme(panel.grid.major = element_line(color = gray(.5),
                                        linetype = 'dashed',
                                        size = 0.1),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill=NA,color = 'black'),
        panel.ontop = TRUE,
        axis.text = element_text(size = 8),
        axis.title.y = element_text(vjust = 5, size = 10, face = "bold"),
        axis.title.x = element_text(size = 10, face = "bold",vjust = -1),
        axis.ticks.length = unit(0.2, "cm"),
        plot.caption = element_text(vjust = -1.5),
        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm"))

carte_obs = carte_obs +
  # blank() +
  ggsn::north(landworm_sf) +
  ggsn::scalebar(landworm_sf, dist = 50, dist_unit = "km",
           transform = TRUE, model = "WGS84",location = "bottomleft", st.size = 1)

ggsave("cartographie/carte_obs.png", plot = carte_obs, dpi = 300
       ,height = 3,width = 3
       )



# Carte spatial thining BZH, Dijon et IDF ------------------------
landworm_sf = landw_thining_non_t[,c("gps_x", "gps_y")]
set.seed(123)
ind <- sample(2, nrow(landworm_sf), replace = T, prob = c(.8, .2))
train <- landworm_sf[ind==1,]
test <- landworm_sf[ind==2,]
landworm_sf = test
landworm_sf <- st_as_sf(landworm_sf, coords = c("gps_x", "gps_y"))
st_crs(landworm_sf) =  "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"

carte_obs <- ggplot() +
  geom_sf(data = france_shapefile) +  
  geom_sf(data = landworm_sf, color = "blue", size = 0.01) +
  labs(x = 'Longitude', y = 'Latitude',
       # title = "Map of France",
       # subtitle = '',
       # caption = 'Source: LandWorm, 2024'
       )+
  # ggsn::scalebar(location = "bottomleft", dist = 100, dist_unit = "km") +
  # cowplot::theme_cowplot()+
  theme(panel.grid.major = element_line(color = gray(.5),
                                        linetype = 'dashed',
                                        size = 0.1),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill=NA,color = 'black'),
        panel.ontop = TRUE,
        axis.text = element_text(size = 8),
        axis.title.y = element_text(vjust = 5, size = 10, face = "bold"),
        axis.title.x = element_text(size = 10, face = "bold",vjust = -1),
        axis.ticks.length = unit(0.2, "cm"),
        plot.caption = element_text(vjust = -1.5),
        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm"))

carte_obs = carte_obs +
  # blank() +
  ggsn::north(landworm_sf) +
  ggsn::scalebar(landworm_sf, dist = 75, dist_unit = "km",
           transform = TRUE, model = "WGS84",location = "bottomleft", st.size = 1)

ggsave("cartographie/carte_obs-thinning.png", plot = carte_obs, dpi = 300
       ,height = 2.8,width = 3
       )

gg = form(carte_obs)


# Carte spatial thining all  ------------------------
df = landworm[,c("gps_x", "gps_y", "AB_tot")]
df$AB_tot = rep("AB_tot")
thinned_dataset_full <-
  thin( loc.data = df, 
        lat.col = "gps_y", long.col = "gps_x", 
        spec.col = "AB_tot", 
        thin.par = 1, reps = 10, 
        locs.thinned.list.return = TRUE, 
        write.files = FALSE, 
        write.log.file = FALSE)

df_thine= thinned_dataset_full[[2]]
plotThin( thinned_dataset_full )

data( Heteromys_anomalus_South_America )
summary ( Heteromys_anomalus_South_America )

# Carte
landworm_sf = df_thine
# landworm_sf = df_mod_AB_tot[,c("gps_x", "gps_y", "AB_tot")]
landworm_sf <- st_as_sf(landworm_sf, coords = c("Longitude", "Latitude"))
landworm_sf <- st_as_sf(landworm_sf, coords = c("gps_x", "gps_y"))
st_crs(landworm_sf) =  "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"

carte_obs <- ggplot() +
  geom_sf(data = france_shapefile) +  
  geom_sf(data = landworm_sf, color = "red", size = 0.01) +
  labs(x = 'Longitude', y = 'Latitude',
       # title = "Map of France",
       # subtitle = '',
       caption = 'Source: LandWorm, 2024')+
  # ggsn::scalebar(location = "bottomleft", dist = 100, dist_unit = "km") +
  # cowplot::theme_cowplot()+
  theme(panel.grid.major = element_line(color = gray(.5),
                                        linetype = 'dashed',
                                        size = 0.1),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill=NA,color = 'black'),
        panel.ontop = TRUE,
        axis.text = element_text(size = 8),
        axis.title.y = element_text(vjust = 5, size = 10, face = "bold"),
        axis.title.x = element_text(size = 10, face = "bold",vjust = -1),
        axis.ticks.length = unit(0.2, "cm"),
        plot.caption = element_text(vjust = -1.5),
        plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm"))

carte_obs = carte_obs +
  # blank() +
  ggsn::north(landworm_sf) +
  ggsn::scalebar(landworm_sf, dist = 50, dist_unit = "km",
           transform = TRUE, model = "WGS84",location = "bottomleft", st.size = 1)


```

```{r, eval=FALSE}
tif_file_path = "C:/Users/diall/Downloads/datas/raster_modif/limon.0_5.tif"
rass = raster(tif_file_path)
 plot(rass,axe =FALSE, box =FALSE,legend=FALSE)
# image(rass)
```

<!-- <p align="center"> -->

<!--   <img src="cartographie/carte_obs.png"> -->

<!-- </p> -->

<!-- **Après thinning** -->

<p align="center">

<img src="cartographie/carte_obs-thinning.png"/>

</p>

## Carte CLC

```{r, eval=FALSE}
# predictors <- readRDS("cartographie/predictors.rds")
# os_predictors = predictors[, c("gps_x", "gps_y", "clcm_lvl3")]
# 
# 
# custom_colors <- c("f" = "green", "gua" = "blue", "ng" = "orange", 
#                    "nial" = "purple", "p" = "cyan", "v" = "grey")
# 
# carte_os <- ggplot(os_predictors, aes(x = gps_x, y = gps_y, color = clcm_lvl3)) +
#   geom_point() +
#   scale_color_manual(values = custom_colors)
# carte_os
# ggsave("Results/carte_os.png", plot = carte_os, dpi = 300,height = 4,width = 6)
```

<p align="center">

<img src="Results/carte_os.png"/>

</p>

## Redaction results

```{r , eval=FALSE}
# Abundance
# Calcul du test de Friedman pour comparer les prediction
df_friedman = data.frame(Abundance = AB_tot_test$AB_tot)
df_friedman$types = rep("observed")
df_friedman = rbind(df_friedman,
                    data.frame(Abundance =GLM_result_AB_tot$predit,types=rep("GLM")),
                    data.frame(Abundance =GAM_result_AB_tot$predit,types=rep("GAM")),
                    data.frame(Abundance =RF_result_AB_tot$predit,types=rep("RF")),
                    data.frame(Abundance =GBM_result_AB_tot$predit,types=rep("GBM")),
                    data.frame(Abundance =ANN_tune_AB_tot_pred,types=rep("ANN"))
                    )
df_friedman$types = as.factor(df_friedman$types)
df_friedman %>%
  group_by(types) %>%
  get_summary_stats(Abundance, type = "common")
ggboxplot(df_friedman, x = "types", y = "Abundance", add = "jitter")
# friedman_result <- friedman.test(Abundance ~ types, data = df_friedman)
# Test de somme des rangs de Wilcoxon par paires avec correction de Bonferroni
# pairwise.wilcox.test(selfesteem$score, selfesteem$time, p.adj = "bonf")

ab = c(0.22,0.26,0.43,0.43,0.35); round(sd(ab),2)
rmse_ab = c(34.57,33.06,25.20,25.30,28.94); round(sd(rmse_ab),2)

bm = c(0.23,0.24,0.35,0.32,0.27); round(sd(bm),2)
rmse_bm = c(1.69,10.50,8.76,9.30,10.50); round(sd(rmse_bm),2)

rch = c(0.36,0.44,0.59,0.59,0.40); round(sd(rch),2)
rmse_rch = c(2.18,2.04,1.75,1.75,2.16); round(sd(rmse_rch),2)



```

```{r , eval=FALSE}
df_os_pred_AB_tot = AB_tot_pred
df_os_pred_AB_tot$Abundance = df_os_pred_AB_tot$Abundance^2
df_os_pred_AB_tot = cbind(df_os_pred_AB_tot,predictors)

clc_AB_tot_pred = df_os_pred_AB_tot %>%
  group_by(clcm_lvl3) %>%
  summarise(mean_ab = round(mean(Abundance)),
            sd_ab = round(sd(Abundance))) %>% 
  as.data.frame()
clc_AB_tot_pred$type = rep("Predected")
colnames(clc_AB_tot_pred) <- c("CLC", "Mean_ab", "SD_ab", "type")

clc_AB_tot_obs = landworm_explo_non_t  %>%
  group_by(clcm_lvl3) %>%
  summarise(mean_ab = round(mean(AB_tot)),
            sd_ab = round(sd(AB_tot))) %>% 
  as.data.frame()
clc_AB_tot_obs$type = rep("Observed")
colnames(clc_AB_tot_obs) <- c("CLC", "Mean_ab", "SD_ab", "type")



comp_AB_tot = rbind(clc_AB_tot_pred,clc_AB_tot_obs)
comp_plot_AB_tot <- ggplot(comp_AB_tot, aes(x = CLC, y = Mean_ab, color = type)) +
  geom_point(position = position_dodge(width = 0.9), size = 3, alpha = 0.7) +
  geom_errorbar(aes(ymin = Mean_ab - SD_ab, ymax = Mean_ab + SD_ab), position = position_dodge(width = 0.9), width = 0.3) +
  labs(x = "CLC", y = "Abundance", title = "Comparison of observed and predicted abundance by CLC") +
  scale_color_manual(values = c("blue", "red"), name = "", labels = c("Observed", "Predicted")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip()

comp_plot_AB_tot

```

```{r , eval=FALSE}
df_os_pred_BM_tot = BM_tot_pred
df_os_pred_BM_tot$Biomass = df_os_pred_BM_tot$Biomass^2
df_os_pred_BM_tot = cbind(df_os_pred_BM_tot,predictors)

clc_BM_tot_pred = df_os_pred_BM_tot %>%
  group_by(clcm_lvl3) %>%
  summarise(mean_ab = round(mean(Biomass)),
            sd_ab = round(sd(Biomass))) %>% 
  as.data.frame()
clc_BM_tot_pred$type = rep("Predected")
colnames(clc_BM_tot_pred) <- c("CLC", "Mean_ab", "SD_ab", "type")

clc_BM_tot_obs = landworm_explo_non_t  %>%
  group_by(clcm_lvl3) %>%
  summarise(mean_ab = round(mean(BM_tot, na.rm=TRUE)),
            sd_ab = round(sd(BM_tot, na.rm=TRUE))) %>% 
  as.data.frame()
clc_BM_tot_obs$type = rep("Observed")
colnames(clc_BM_tot_obs) <- c("CLC", "Mean_ab", "SD_ab", "type")



comp_BM_tot = rbind(clc_BM_tot_pred,clc_BM_tot_obs)
comp_plot_BM_tot <- ggplot(comp_BM_tot, aes(x = CLC, y = Mean_ab, color = type)) +
  geom_point(position = position_dodge(width = 0.9), size = 3, alpha = 0.7) +
  geom_errorbar(aes(ymin = Mean_ab - SD_ab, ymax = Mean_ab + SD_ab), position = position_dodge(width = 0.9), width = 0.3) +
  labs(x = "CLC", y = "Biomass", title = "Comparison of observed and predicted Biomass by CLC") +
  scale_color_manual(values = c("blue", "red"), name = "", labels = c("Observed", "Predicted")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip()

comp_plot_BM_tot

```

```{r , eval=FALSE}
df_os_pred_Richesse_tot = Richesse_tot_pred
# df_os_pred_Richesse_tot$Richness = df_os_pred_Richesse_tot$Richness^2
df_os_pred_Richesse_tot = cbind(df_os_pred_Richesse_tot,predictors)

clc_Richesse_tot_pred = df_os_pred_Richesse_tot %>%
  group_by(clcm_lvl3) %>%
  summarise(mean_ab = round(mean(Richness)),
            sd_ab = round(sd(Richness))) %>% 
  as.data.frame()
clc_Richesse_tot_pred$type = rep("Predected")
colnames(clc_Richesse_tot_pred) <- c("CLC", "Mean_ab", "SD_ab", "type")

clc_Richesse_tot_obs = landworm_explo_non_t  %>%
  group_by(clcm_lvl3) %>%
  summarise(mean_ab = round(mean(Richesse_tot)),
            sd_ab = round(sd(Richesse_tot))) %>% 
  as.data.frame()
clc_Richesse_tot_obs$type = rep("Observed")
colnames(clc_Richesse_tot_obs) <- c("CLC", "Mean_ab", "SD_ab", "type")



comp_Richesse_tot = rbind(clc_Richesse_tot_pred,clc_Richesse_tot_obs)
comp_plot_Richesse_tot <- ggplot(comp_Richesse_tot, aes(x = CLC, y = Mean_ab, color = type)) +
  geom_point(position = position_dodge(width = 0.9), size = 3, alpha = 0.7) +
  geom_errorbar(aes(ymin = Mean_ab - SD_ab, ymax = Mean_ab + SD_ab), position = position_dodge(width = 0.9), width = 0.3) +
  labs(x = "CLC", y = "Richness", title = "Comparison of observed and predicted Richness by CLC") +
  scale_color_manual(values = c("blue", "red"), name = "", labels = c("Observed", "Predicted")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  coord_flip()

comp_plot_Richesse_tot

```

```{r, eval=FALSE}
data_min_mean_max = landworm_explo_non_t [, c(9:15, 17:18)]

df = data.frame(var = character(),min=numeric(), mean = numeric(), max = numeric())

for (i in names(data_min_mean_max)){
  
 df_2 = data.frame(var = i,
                  min=min(data_min_mean_max[,i], na.rm=TRUE), 
                  mean = mean(data_min_mean_max[,i], na.rm=TRUE), 
                  max = max(data_min_mean_max[,i], na.rm=TRUE)
                            )
 df= rbind (df, df_2)
}
df

```

## Test outliers

-   Aberrant values (example de [Azote (N, g/kg)](#azote-n-gkg) )

    ```         
                                   +-------------------------------+
                                   |                               |
                                   |        Données d'entrée       |
                                   |          (data)               |
                                   |                               |
                                   +------------+------------------+
                                                |
                                                |
                                                v
                                   +-------------------------------+
                                   |                               |
                                   |        Test de Grub           |
                                   |          (data)               |
                                   |                               |
                                   +------------+------------------+
                                                |
                                                |
                         +----------------------|---------------------+
                         |                      |                     |
                         |                      |                     |
                         |                      |                     |
                         |     +----------------|-------------+       |
                         |     |                |             |       |
                         |     |                |             |       |
                         |     v                v             v       |
                         |                                            |
                         |    (opposite = FALSE) (opposite = TRUE)    |
                         |                      |                     |
                         |                      |                     |
                         |     +----------------|-------------+       |
                         |     |                |             |       |
                         |     |                |             |       |
                         |     v                v             v       |
                         |    Obtenir p-valeur  Obtenir p-valeur      |
                         |                      |                     |
                         |                      |                     |
                         |     +----------------|-------------+       |
                         |     |                |             |       |
                         |     |                |             |       |
                         |     v                v             v       |
                         |   Si p-value < 0.05  Si p-value < 0.05     |
                         |     Supprimer valeur  Supprimer valeur     |
                         |     aberrante         aberrante            |
                         |                      |                     |
                         |                      |                     |
                         |     +----------------|-------------+       |
                         |     |                |             |       |
                         |     |                |             |       |
                         |     v                v             v       |
                         |    Répéter            Répéter              |
                         |                      |                     |
                         |                      |                     |
                         +----------------------|---------------------+
                                                |
                                                |
                                                v
                                    +-----------+--------------+
                                    |                          |
                                    |        Données           |
                                    |       traitées           |
                                    |                          |
                                    +--------------------------+
    ```

    back to [Plan]

<!-- ## To do next -->

<!-- - Worskshop prediction in Montpellier (du 27 au 31 mai) -->

<!-- - Rédaction (jusqu'au 05 juin) -->

<!-- - Préparation soutenance  (du 05 au 19 juin) -->

<!-- - Rédaction/Publication (du 21 juin jusqu'au 31 juillet) -->

<!-- info: ICSZ Afrique du Sud (du 26 au 30 Août) -->

<!-- back to [Plan] -->

## Additional information

<br/> <br/> <!-- <br/> --> <!-- See [species explorations](https://posit.cloud/content/7997063){target="_blank"} --> <br/> <br/> All the material from my internship, including scripts and datasets, is available on my [GitHub](https://github.com/diallo-abdou/stage_abdou_m2){target="_blank"} and my [Rpubs.](https://rpubs.com/Abdou_diallo){target="_blank"}

#  {.unnumbered}

::: {style="text-align: center; font-size: larger"}
<strong>Thank you for your attention</strong>
:::
